{
  "last_updated": "2025-07-29T01:04:42.167118",
  "papers": [
    {
      "title": "Riesz representers for the rest of us",
      "authors": [
        "Nicholas T. Williams",
        "Oliver J. Hines",
        "Kara E. Rudolph"
      ],
      "abstract": "The application of semiparametric efficient estimators, particularly those\nthat leverage machine learning, is rapidly expanding within epidemiology and\ncausal inference. Much of the recent methodological literature on these\nestimators relies heavily on the Riesz representation theorem and Riesz\nregression. This paper aims to introduce the Riesz representation theorem to an\napplied audience, explaining why and how Riesz regression is becoming widely\nused in the semiparametric estimator statistical literature.",
      "pdf_url": "http://arxiv.org/pdf/2507.19413v1",
      "arxiv_url": "http://arxiv.org/abs/2507.19413v1",
      "published": "2025-07-25",
      "categories": [
        "math.ST",
        "stat.TH"
      ]
    },
    {
      "title": "Probably Approximately Correct Causal Discovery",
      "authors": [
        "Mian Wei",
        "Somesh Jha",
        "David Page"
      ],
      "abstract": "The discovery of causal relationships is a foundational problem in artificial\nintelligence, statistics, epidemiology, economics, and beyond. While elegant\ntheories exist for accurate causal discovery given infinite data, real-world\napplications are inherently resource-constrained. Effective methods for\ninferring causal relationships from observational data must perform well under\nfinite data and time constraints, where \"performing well\" implies achieving\nhigh, though not perfect accuracy. In his seminal paper A Theory of the\nLearnable, Valiant highlighted the importance of resource constraints in\nsupervised machine learning, introducing the concept of Probably Approximately\nCorrect (PAC) learning as an alternative to exact learning. Inspired by\nValiant's work, we propose the Probably Approximately Correct Causal (PACC)\nDiscovery framework, which extends PAC learning principles to the causal field.\nThis framework emphasizes both computational and sample efficiency for\nestablished causal methods such as propensity score techniques and instrumental\nvariable approaches. Furthermore, we show that it can also provide theoretical\nguarantees for other widely used methods, such as the Self-Controlled Case\nSeries (SCCS) method, which had previously lacked such guarantees.",
      "pdf_url": "http://arxiv.org/pdf/2507.18903v1",
      "arxiv_url": "http://arxiv.org/abs/2507.18903v1",
      "published": "2025-07-25",
      "categories": [
        "stat.ML",
        "cs.LG"
      ]
    },
    {
      "title": "Deep Learning for Blood-Brain Barrier Permeability Prediction",
      "authors": [
        "Zihan Yang",
        "Haipeng Gong"
      ],
      "abstract": "Predicting whether a molecule can cross the blood-brain barrier (BBB) is a\nkey step in early-stage neuropharmaceutical development, directly influencing\nboth research efficiency and success rates in drug discovery. Traditional\nempirical methods based on physicochemical properties are prone to systematic\nmisjudgements due to their reliance on static rules. Early machine learning\nmodels, although data-driven, often suffer from limited capacity, poor\ngeneralization, and insufficient interpretability. In recent years, artificial\nintelligence (AI) methods have become essential tools for predicting BBB\npermeability and guiding related drug design, owing to their ability to model\nmolecular structures and capture complex biological mechanisms. This article\nsystematically reviews the evolution of this field-from deep neural networks to\ngraph-based structural modeling-highlighting the advantages of multi-task and\nmultimodal learning strategies in identifying mechanism-relevant variables. We\nfurther explore the emerging potential of generative models and causal\ninference methods for integrating permeability prediction with mechanism-aware\ndrug design. BBB modeling is in the transition from static classification\ntoward mechanistic perception and structure-function modeling. This paradigm\nshift provides a methodological foundation and future roadmap for the\nintegration of AI into neuropharmacological development.",
      "pdf_url": "http://arxiv.org/pdf/2507.18557v1",
      "arxiv_url": "http://arxiv.org/abs/2507.18557v1",
      "published": "2025-07-24",
      "categories": [
        "q-bio.QM"
      ]
    },
    {
      "title": "A Two-armed Bandit Framework for A/B Testing",
      "authors": [
        "Jinjuan Wang",
        "Qianglin Wen",
        "Yu Zhang",
        "Xiaodong Yan",
        "Chengchun Shi"
      ],
      "abstract": "A/B testing is widely used in modern technology companies for policy\nevaluation and product deployment, with the goal of comparing the outcomes\nunder a newly-developed policy against a standard control. Various causal\ninference and reinforcement learning methods developed in the literature are\napplicable to A/B testing. This paper introduces a two-armed bandit framework\ndesigned to improve the power of existing approaches. The proposed procedure\nconsists of three main steps: (i) employing doubly robust estimation to\ngenerate pseudo-outcomes, (ii) utilizing a two-armed bandit framework to\nconstruct the test statistic, and (iii) applying a permutation-based method to\ncompute the $p$-value. We demonstrate the efficacy of the proposed method\nthrough asymptotic theories, numerical experiments and real-world data from a\nridesharing company, showing its superior performance in comparison to existing\nmethods.",
      "pdf_url": "http://arxiv.org/pdf/2507.18118v1",
      "arxiv_url": "http://arxiv.org/abs/2507.18118v1",
      "published": "2025-07-24",
      "categories": [
        "stat.ML",
        "cs.LG",
        "stat.AP"
      ]
    },
    {
      "title": "GrAInS: Gradient-based Attribution for Inference-Time Steering of LLMs and VLMs",
      "authors": [
        "Duy Nguyen",
        "Archiki Prasad",
        "Elias Stengel-Eskin",
        "Mohit Bansal"
      ],
      "abstract": "Inference-time steering methods offer a lightweight alternative to\nfine-tuning large language models (LLMs) and vision-language models (VLMs) by\nmodifying internal activations at test time without updating model weights.\nHowever, most existing approaches rely on fixed, global intervention vectors,\noverlook the causal influence of individual input tokens, and fail to leverage\ninformative gradients from the model's logits, particularly in multimodal\nsettings where visual and textual inputs contribute unevenly. To address these\nlimitations, we introduce GrAInS, an inference-time steering approach that\noperates across both language-only and vision-language models and tasks. GrAInS\nuses contrastive, gradient-based attribution via Integrated Gradients to\nidentify the top-k most influential tokens, both positively and negatively\nattributed based on their contribution to preferred versus dispreferred\noutputs. These tokens are then used to construct directional steering vectors\nthat capture semantic shifts from undesirable to desirable behavior. During\ninference, GrAInS adjusts hidden activations at transformer layers guided by\ntoken-level attribution signals, and normalizes activations to preserve\nrepresentational scale. This enables fine-grained, interpretable, and modular\ncontrol over model behavior, without retraining or auxiliary supervision.\nEmpirically, GrAInS consistently outperforms both fine-tuning and existing\nsteering baselines: it achieves a 13.22% accuracy gain on TruthfulQA using\nLlama-3.1-8B, reduces hallucination rates on MMHal-Bench from 0.624 to 0.514\nwith LLaVA-1.6-7B, and improves alignment win rates on SPA-VL by 8.11%, all\nwhile preserving the model's fluency and general capabilities.",
      "pdf_url": "http://arxiv.org/pdf/2507.18043v1",
      "arxiv_url": "http://arxiv.org/abs/2507.18043v1",
      "published": "2025-07-24",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "title": "Debiased maximum-likelihood estimators for hazard ratios under machine-learning adjustment",
      "authors": [
        "Takashi Hayakawa",
        "Satoshi Asai"
      ],
      "abstract": "Previous studies have shown that hazard ratios between treatment groups\nestimated with the Cox model are uninterpretable because the indefinite\nbaseline hazard of the model fails to identify temporal change in the risk set\ncomposition due to treatment assignment and unobserved factors among multiple,\ncontradictory scenarios. To alleviate this problem, especially in studies based\non observational data with uncontrolled dynamic treatment and real-time\nmeasurement of many covariates, we propose abandoning the baseline hazard and\nusing machine learning to explicitly model the change in the risk set with or\nwithout latent variables. For this framework, we clarify the context in which\nhazard ratios can be causally interpreted, and then develop a method based on\nNeyman orthogonality to compute debiased maximum-likelihood estimators of\nhazard ratios. Computing the constructed estimators is more efficient than\ncomputing those based on weighted regression with marginal structural Cox\nmodels. Numerical simulations confirm that the proposed method identifies the\nground truth with minimal bias. These results lay the foundation for developing\na useful, alternative method for causal inference with uncontrolled,\nobservational data in modern epidemiology.",
      "pdf_url": "http://arxiv.org/pdf/2507.17686v1",
      "arxiv_url": "http://arxiv.org/abs/2507.17686v1",
      "published": "2025-07-23",
      "categories": [
        "stat.ML",
        "cs.LG"
      ]
    },
    {
      "title": "See the Forest and the Trees: A Synergistic Reasoning Framework for Knowledge-Based Visual Question Answering",
      "authors": [
        "Junjie Wang",
        "Yunhan Tang",
        "Yijie Wang",
        "Zhihao Yuan",
        "Huan Wang",
        "Yangfan He",
        "Bin Li"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) have pushed the frontiers of\nKnowledge-Based Visual Question Answering (KBVQA), yet their reasoning is\nfundamentally bottlenecked by a reliance on uni-dimensional evidence. This\n\"seeing only the trees, but not the forest\" approach prevents robust,\nmulti-faceted understanding. Inspired by the principle of seeing both the\nforest and trees, we propose Synergos-VQA, a novel synergistic reasoning\nframework. At its core, Synergos-VQA concurrently generates and fuses three\ncomplementary evidence streams at inference time: (1) Holistic Evidence to\nperceive the entire scene (the \"forest\"), (2) Structural Evidence from a\nprototype-driven module to identify key objects (the \"trees\"), and (3) Causal\nEvidence from a counterfactual probe to ensure the reasoning is robustly\ngrounded. By synergistically fusing this multi-faceted evidence, our framework\nachieves a more comprehensive and reliable reasoning process. Extensive\nexperiments show that Synergos-VQA decisively establishes a new\nstate-of-the-art on three challenging benchmarks, including OK-VQA and A-OKVQA.\nFurthermore, our approach demonstrates strong plug-and-play capabilities,\nsignificantly boosting various open-source MLLMs and proving that superior\nmethodological design can outperform sheer model scale.",
      "pdf_url": "http://arxiv.org/pdf/2507.17659v1",
      "arxiv_url": "http://arxiv.org/abs/2507.17659v1",
      "published": "2025-07-23",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "Doubly robust outlier resistant inference on causal treatment effect",
      "authors": [
        "Joonsung Kang"
      ],
      "abstract": "Outliers can severely distort causal effect estimation in observational\nstudies, yet this issue has received limited attention in the literature. Their\ninfluence is especially pronounced in small sample sizes, where detecting and\nremoving outliers becomes increasingly difficult. Therefore, it is essential to\nestimate treatment effects robustly without excluding these influential data\npoints. To address this, we propose a doubly robust point estimator for the\naverage treatment effect under a contaminated model that includes outliers.\nRobustness in outcome regression is achieved through a robust estimating\nequation, while covariate balancing propensity scores (CBPS) ensure resilience\nin propensity score modeling.\n  To prevent model overfitting due to the inclusion of numerous parameters, we\nincorporate variable selection. All these components are unified under a\npenalized empirical likelihood framework. For confidence interval estimation,\nmost existing approaches rely on asymptotic properties, which may be unreliable\nin finite samples. We derive an optimal finite-sample confidence interval for\nthe average treatment effect using our proposed estimating equation, ensuring\nthat the interval bounds remain unaffected by outliers. Through simulations and\na real-world application involving hypertension data with outliers, we\ndemonstrate that our method consistently outperforms existing approaches in\nboth accuracy and robustness.",
      "pdf_url": "http://arxiv.org/pdf/2507.17439v1",
      "arxiv_url": "http://arxiv.org/abs/2507.17439v1",
      "published": "2025-07-23",
      "categories": [
        "stat.ME",
        "cs.LG"
      ]
    },
    {
      "title": "CAPRI-CT: Causal Analysis and Predictive Reasoning for Image Quality Optimization in Computed Tomography",
      "authors": [
        "Sneha George Gnanakalavathy",
        "Hairil Abdul Razak",
        "Robert Meertens",
        "Jonathan E. Fieldsend",
        "Xujiong Ye",
        "Mohammed M. Abdelsamea"
      ],
      "abstract": "In computed tomography (CT), achieving high image quality while minimizing\nradiation exposure remains a key clinical challenge. This paper presents\nCAPRI-CT, a novel causal-aware deep learning framework for Causal Analysis and\nPredictive Reasoning for Image Quality Optimization in CT imaging. CAPRI-CT\nintegrates image data with acquisition metadata (such as tube voltage, tube\ncurrent, and contrast agent types) to model the underlying causal relationships\nthat influence image quality. An ensemble of Variational Autoencoders (VAEs) is\nemployed to extract meaningful features and generate causal representations\nfrom observational data, including CT images and associated imaging parameters.\nThese input features are fused to predict the Signal-to-Noise Ratio (SNR) and\nsupport counterfactual inference, enabling what-if simulations, such as changes\nin contrast agents (types and concentrations) or scan parameters. CAPRI-CT is\ntrained and validated using an ensemble learning approach, achieving strong\npredictive performance. By facilitating both prediction and interpretability,\nCAPRI-CT provides actionable insights that could help radiologists and\ntechnicians design more efficient CT protocols without repeated physical scans.\nThe source code and dataset are publicly available at\nhttps://github.com/SnehaGeorge22/capri-ct.",
      "pdf_url": "http://arxiv.org/pdf/2507.17420v1",
      "arxiv_url": "http://arxiv.org/abs/2507.17420v1",
      "published": "2025-07-23",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "Causal Mechanism Estimation in Multi-Sensor Systems Across Multiple Domains",
      "authors": [
        "Jingyi Yu",
        "Tim Pychynski",
        "Marco F. Huber"
      ],
      "abstract": "To gain deeper insights into a complex sensor system through the lens of\ncausality, we present common and individual causal mechanism estimation\n(CICME), a novel three-step approach to inferring causal mechanisms from\nheterogeneous data collected across multiple domains. By leveraging the\nprinciple of Causal Transfer Learning (CTL), CICME is able to reliably detect\ndomain-invariant causal mechanisms when provided with sufficient samples. The\nidentified common causal mechanisms are further used to guide the estimation of\nthe remaining causal mechanisms in each domain individually. The performance of\nCICME is evaluated on linear Gaussian models under scenarios inspired from a\nmanufacturing process. Building upon existing continuous optimization-based\ncausal discovery methods, we show that CICME leverages the benefits of applying\ncausal discovery on the pooled data and repeatedly on data from individual\ndomains, and it even outperforms both baseline methods under certain scenarios.",
      "pdf_url": "http://arxiv.org/pdf/2507.17792v2",
      "arxiv_url": "http://arxiv.org/abs/2507.17792v2",
      "published": "2025-07-23",
      "categories": [
        "cs.LG",
        "stat.ML"
      ]
    }
  ]
}