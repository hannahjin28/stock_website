{
  "last_updated": "2025-07-09T00:56:50.372574",
  "papers": [
    {
      "title": "Identification of Causal Effects with a Bunching Design",
      "authors": [
        "Carolina Caetano",
        "Gregorio Caetano",
        "Leonard Goff",
        "Eric Nielsen"
      ],
      "abstract": "We show that causal effects can be identified when there is bunching in the\ndistribution of a continuous treatment variable, without imposing any\nparametric assumptions. This yields a new nonparametric method for overcoming\nselection bias in the absence of instrumental variables, panel data, or other\npopular research designs for causal inference. The method leverages the change\nof variables theorem from integration theory, relating the selection bias to\nthe ratio of the density of the treatment and the density of the part of the\noutcome that varies with confounders. At the bunching point, the treatment\nlevel is constant, so the variation in the outcomes is due entirely to\nunobservables, allowing us to identify the denominator. Our main result\nidentifies the average causal response to the treatment among individuals who\nmarginally select into the bunching point. We further show that under\nadditional smoothness assumptions on the selection bias, treatment effects away\nfrom the bunching point may also be identified. We propose estimators based on\nstandard software packages and apply the method to estimate the effect of\nmaternal smoking during pregnancy on birth weight.",
      "pdf_url": "http://arxiv.org/pdf/2507.05210v1",
      "arxiv_url": "http://arxiv.org/abs/2507.05210v1",
      "published": "2025-07-07",
      "categories": [
        "econ.EM"
      ]
    },
    {
      "title": "Practical considerations for Gaussian Process modeling for causal inference quasi-experimental studies with panel data",
      "authors": [
        "Sofia L. Vega",
        "Rachel C. Nethery"
      ],
      "abstract": "Estimating causal effects in quasi-experiments with spatio-temporal panel\ndata often requires adjusting for unmeasured confounding that varies across\nspace and time. Gaussian Processes (GPs) offer a flexible, nonparametric\nmodeling approach that can account for such complex dependencies through\ncarefully chosen covariance kernels. In this paper, we provide a practical and\ninterpretable framework for applying GPs to causal inference in panel data\nsettings. We demonstrate how GPs generalize popular methods such as synthetic\ncontrol and vertical regression, and we show that the GP posterior mean can be\nrepresented as a weighted average of observed outcomes, where the weights\nreflect spatial and temporal similarity. To support applied use, we explore how\ndifferent kernel choices impact both estimation performance and\ninterpretability, offering guidance for selecting between separable and\nnonseparable kernels. Through simulations and application to Hurricane Katrina\nmortality data, we illustrate how GP models can be used to estimate\ncounterfactual outcomes and quantify treatment effects. All code and materials\nare made publicly available to support reproducibility and encourage adoption.\nOur results suggest that GPs are a promising and interpretable tool for\naddressing unmeasured spatio-temporal confounding in quasi-experimental\nstudies.",
      "pdf_url": "http://arxiv.org/pdf/2507.05128v1",
      "arxiv_url": "http://arxiv.org/abs/2507.05128v1",
      "published": "2025-07-07",
      "categories": [
        "stat.ME",
        "stat.AP"
      ]
    },
    {
      "title": "Boosting Temporal Sentence Grounding via Causal Inference",
      "authors": [
        "Kefan Tang",
        "Lihuo He",
        "Jisheng Dang",
        "Xinbo Gao"
      ],
      "abstract": "Temporal Sentence Grounding (TSG) aims to identify relevant moments in an\nuntrimmed video that semantically correspond to a given textual query. Despite\nexisting studies having made substantial progress, they often overlook the\nissue of spurious correlations between video and textual queries. These\nspurious correlations arise from two primary factors: (1) inherent biases in\nthe textual data, such as frequent co-occurrences of specific verbs or phrases,\nand (2) the model's tendency to overfit to salient or repetitive patterns in\nvideo content. Such biases mislead the model into associating textual cues with\nincorrect visual moments, resulting in unreliable predictions and poor\ngeneralization to out-of-distribution examples. To overcome these limitations,\nwe propose a novel TSG framework, causal intervention and counterfactual\nreasoning that utilizes causal inference to eliminate spurious correlations and\nenhance the model's robustness. Specifically, we first formulate the TSG task\nfrom a causal perspective with a structural causal model. Then, to address\nunobserved confounders reflecting textual biases toward specific verbs or\nphrases, a textual causal intervention is proposed, utilizing do-calculus to\nestimate the causal effects. Furthermore, visual counterfactual reasoning is\nperformed by constructing a counterfactual scenario that focuses solely on\nvideo features, excluding the query and fused multi-modal features. This allows\nus to debias the model by isolating and removing the influence of the video\nfrom the overall effect. Experiments on public datasets demonstrate the\nsuperiority of the proposed method. The code is available at\nhttps://github.com/Tangkfan/CICR.",
      "pdf_url": "http://arxiv.org/pdf/2507.04958v1",
      "arxiv_url": "http://arxiv.org/abs/2507.04958v1",
      "published": "2025-07-07",
      "categories": [
        "cs.CV",
        "cs.MM"
      ]
    },
    {
      "title": "A validity-guided workflow for robust large language model research in psychology",
      "authors": [
        "Zhicheng Lin"
      ],
      "abstract": "Large language models (LLMs) are rapidly being integrated into psychological\nresearch as research tools, evaluation targets, human simulators, and cognitive\nmodels. However, recent evidence reveals severe measurement unreliability:\nPersonality assessments collapse under factor analysis, moral preferences\nreverse with punctuation changes, and theory-of-mind accuracy varies widely\nwith trivial rephrasing. These \"measurement phantoms\"--statistical artifacts\nmasquerading as psychological phenomena--threaten the validity of a growing\nbody of research. Guided by the dual-validity framework that integrates\npsychometrics with causal inference, we present a six-stage workflow that\nscales validity requirements to research ambition--using LLMs to code text\nrequires basic reliability and accuracy, while claims about psychological\nproperties demand comprehensive construct validation. Researchers must (1)\nexplicitly define their research goal and corresponding validity requirements,\n(2) develop and validate computational instruments through psychometric\ntesting, (3) design experiments that control for computational confounds, (4)\nexecute protocols with transparency, (5) analyze data using methods appropriate\nfor non-independent observations, and (6) report findings within demonstrated\nboundaries and use results to refine theory. We illustrate the workflow through\nan example of model evaluation--\"LLM selfhood\"--showing how systematic\nvalidation can distinguish genuine computational phenomena from measurement\nartifacts. By establishing validated computational instruments and transparent\npractices, this workflow provides a path toward building a robust empirical\nfoundation for AI psychology research.",
      "pdf_url": "http://arxiv.org/pdf/2507.04491v1",
      "arxiv_url": "http://arxiv.org/abs/2507.04491v1",
      "published": "2025-07-06",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ]
    },
    {
      "title": "Long-Context Modeling Networks for Monaural Speech Enhancement: A Comparative Study",
      "authors": [
        "Qiquan Zhang",
        "Moran Chen",
        "Zeyang Song",
        "Hexin Liu",
        "Xiangyu Zhang",
        "Haizhou Li"
      ],
      "abstract": "Advanced long-context modeling backbone networks, such as Transformer,\nConformer, and Mamba, have demonstrated state-of-the-art performance in speech\nenhancement. However, a systematic and comprehensive comparative study of these\nbackbones within a unified speech enhancement framework remains lacking. In\naddition, xLSTM, a more recent and efficient variant of LSTM, has shown\npromising results in language modeling and as a general-purpose vision\nbackbone. In this paper, we investigate the capability of xLSTM in speech\nenhancement, and conduct a comprehensive comparison and analysis of the\nTransformer, Conformer, Mamba, and xLSTM backbones within a unified framework,\nconsidering both causal and noncausal configurations. Overall, xLSTM and Mamba\nachieve better performance than Transformer and Conformer. Mamba demonstrates\nsignificantly superior training and inference efficiency, particularly for long\nspeech inputs, whereas xLSTM suffers from the slowest processing speed.",
      "pdf_url": "http://arxiv.org/pdf/2507.04368v1",
      "arxiv_url": "http://arxiv.org/abs/2507.04368v1",
      "published": "2025-07-06",
      "categories": [
        "eess.AS"
      ]
    },
    {
      "title": "Deconfounding Causal Inference through Two-Branch Framework with Early-Forking for Sensor-Based Cross-Domain Activity Recognition",
      "authors": [
        "Di Xiong",
        "Lei Zhang",
        "Shuoyuan Wang",
        "Dongzhou Cheng",
        "Wenbo Huang"
      ],
      "abstract": "Recently, domain generalization (DG) has emerged as a promising solution to\nmitigate distribution-shift issue in sensor-based human activity recognition\n(HAR) scenario. However, most existing DG-based works have merely focused on\nmodeling statistical dependence between sensor data and activity labels,\nneglecting the importance of intrinsic casual mechanism. Intuitively, every\nsensor input can be viewed as a mixture of causal (category-aware) and\nnon-causal factors (domain-specific), where only the former affects activity\nclassification judgment. In this paper, by casting such DG-based HAR as a\ncasual inference problem, we propose a causality-inspired representation\nlearning algorithm for cross-domain activity recognition. To this end, an\nearly-forking two-branch framework is designed, where two separate branches are\nrespectively responsible for learning casual and non-causal features, while an\nindependence-based Hilbert-Schmidt Information Criterion is employed to\nimplicitly disentangling them. Additionally, an inhomogeneous domain sampling\nstrategy is designed to enhance disentanglement, while a category-aware domain\nperturbation layer is performed to prevent representation collapse. Extensive\nexperiments on several public HAR benchmarks demonstrate that our\ncausality-inspired approach significantly outperforms eleven related\nstate-of-the-art baselines under cross-person, cross-dataset, and\ncross-position settings. Detailed ablation and visualizations analyses reveal\nunderlying casual mechanism, indicating its effectiveness, efficiency, and\nuniversality in cross-domain activity recognition scenario.",
      "pdf_url": "http://arxiv.org/pdf/2507.03898v1",
      "arxiv_url": "http://arxiv.org/abs/2507.03898v1",
      "published": "2025-07-05",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "GenAI-Powered Inference",
      "authors": [
        "Kosuke Imai",
        "Kentaro Nakamura"
      ],
      "abstract": "We introduce GenAI-Powered Inference (GPI), a statistical framework for both\ncausal and predictive inference using unstructured data, including text and\nimages. GPI leverages open-source Generative Artificial Intelligence (GenAI)\nmodels - such as large language models and diffusion models - not only to\ngenerate unstructured data at scale but also to extract low-dimensional\nrepresentations that capture their underlying structure. Applying machine\nlearning to these representations, GPI enables estimation of causal and\npredictive effects while quantifying associated estimation uncertainty. Unlike\nexisting approaches to representation learning, GPI does not require\nfine-tuning of generative models, making it computationally efficient and\nbroadly accessible. We illustrate the versatility of the GPI framework through\nthree applications: (1) analyzing Chinese social media censorship, (2)\nestimating predictive effects of candidates' facial appearance on electoral\noutcomes, and (3) assessing the persuasiveness of political rhetoric. An\nopen-source software package is available for implementing GPI.",
      "pdf_url": "http://arxiv.org/pdf/2507.03897v1",
      "arxiv_url": "http://arxiv.org/abs/2507.03897v1",
      "published": "2025-07-05",
      "categories": [
        "cs.LG",
        "stat.ME",
        "stat.ML"
      ]
    },
    {
      "title": "Enhancing Uncertainty Quantification for Runtime Safety Assurance Using Causal Risk Analysis and Operational Design Domain",
      "authors": [
        "Radouane Bouchekir",
        "Michell Guzman Cancimance"
      ],
      "abstract": "Ensuring the runtime safety of autonomous systems remains challenging due to\ndeep learning components' inherent uncertainty and their sensitivity to\nenvironmental changes. In this paper, we propose an enhancement of traditional\nuncertainty quantification by explicitly incorporating environmental conditions\nusing risk-based causal analysis. We leverage Hazard Analysis and Risk\nAssessment (HARA) and fault tree modeling to identify critical operational\nconditions affecting system functionality. These conditions, together with\nuncertainties from the data and model, are integrated into a unified Bayesian\nNetwork (BN). At runtime, this BN is instantiated using real-time environmental\nobservations to infer a probabilistic distribution over the safety estimation.\nThis distribution enables the computation of both expected performance and its\nassociated variance, providing a dynamic and context-aware measure of\nuncertainty. We demonstrate our approach through a case study of the Object\nDetection (OD) component in an Automated Valet Parking (AVP).",
      "pdf_url": "http://arxiv.org/pdf/2507.03515v1",
      "arxiv_url": "http://arxiv.org/abs/2507.03515v1",
      "published": "2025-07-04",
      "categories": [
        "cs.SE"
      ]
    },
    {
      "title": "Nonparametric regression for cost-effectiveness analyses with observational data -- a tutorial",
      "authors": [
        "Jonas Esser",
        "Mateus Maia",
        "Judith Bosmans",
        "Johanna van Dongen"
      ],
      "abstract": "Healthcare decision-making often requires selecting among treatment options\nunder budget constraints, particularly when one option is more effective but\nalso more costly. Cost-effectiveness analysis (CEA) provides a framework for\nevaluating whether the health benefits of a treatment justify its additional\ncosts. A key component of CEA is the estimation of treatment effects on both\nhealth outcomes and costs, which becomes challenging when using observational\ndata, due to potential confounding. While advanced causal inference methods\nexist for use in such circumstances, their adoption in CEAs remains limited,\nwith many studies relying on overly simplistic methods such as linear\nregression or propensity score matching. We believe that this is mainly due to\nhealth economists being generally unfamiliar with superior methodology. In this\npaper, we address this gap by introducing cost-effectiveness researchers to\nmodern nonparametric regression models, with a particular focus on Bayesian\nAdditive Regression Trees (BART). We provide practical guidance on how to\nimplement BART in CEAs, including code examples, and discuss its advantages in\nproducing more robust and credible estimates from observational data.",
      "pdf_url": "http://arxiv.org/pdf/2507.03511v1",
      "arxiv_url": "http://arxiv.org/abs/2507.03511v1",
      "published": "2025-07-04",
      "categories": [
        "econ.EM",
        "stat.AP"
      ]
    },
    {
      "title": "ReTimeCausal: EM-Augmented Additive Noise Models for Interpretable Causal Discovery in Irregular Time Series",
      "authors": [
        "Weihong Li",
        "Anpeng Wu",
        "Kun Kuang",
        "Keting Yin"
      ],
      "abstract": "This paper studies causal discovery in irregularly sampled time series-a\npivotal challenge in high-stakes domains like finance, healthcare, and climate\nscience, where missing data and inconsistent sampling frequencies distort\ncausal mechanisms. Traditional methods (e.g., Granger causality, PCMCI) fail to\nreconcile multi-scale interactions (e.g., hourly storms vs. decadal climate\nshifts), while neural approaches (e.g., CUTS+) lack interpretability, stemming\nfrom a critical gap: existing frameworks either rigidly assume temporal\nregularity or aggregate dynamics into opaque representations, neglecting\nreal-world granularity and auditable logic. To bridge this gap, we propose\nReTimeCausal, a novel integration of Additive Noise Models (ANM) and\nExpectation-Maximization (EM) that unifies physics-guided data imputation with\nsparse causal inference. Through kernelized sparse regression and structural\nconstraints, ReTimeCausal iteratively refines missing values (E-step) and\ncausal graphs (M-step), resolving cross-frequency dependencies and missing data\nissues. Extensive experiments on synthetic and real-world datasets demonstrate\nthat ReTimeCausal outperforms existing state-of-the-art methods under\nchallenging irregular sampling and missing data conditions.",
      "pdf_url": "http://arxiv.org/pdf/2507.03310v1",
      "arxiv_url": "http://arxiv.org/abs/2507.03310v1",
      "published": "2025-07-04",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    }
  ]
}