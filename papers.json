{
  "last_updated": "2025-12-09T00:55:40.156430",
  "papers": [
    {
      "title": "Standard and stressed value at risk forecasting using dynamic Bayesian networks",
      "authors": [
        "Eden Gross",
        "Ryan Kruger",
        "Francois Toerien"
      ],
      "abstract": "This study introduces a dynamic Bayesian network (DBN) framework for forecasting value at risk (VaR) and stressed VaR (SVaR) and compares its performance to several commonly applied models. Using daily S&P 500 index returns from 1991 to 2020, we produce 10-day 99% VaR and SVaR forecasts using a rolling period and historical returns for the traditional models, while three DBNs use both historical and forecasted returns. We evaluate the models' forecasting accuracy using standard backtests and forecasting error measures. Results show that autoregressive models deliver the most accurate VaR forecasts, while the DBNs achieve comparable performance to the historical simulation model, despite incorporating forward-looking return forecasts. For SVaR, all models produce highly conservative forecasts, with minimal breaches and limited differentiation in accuracy. While DBNs do not outperform traditional models, they demonstrate feasibility as a forward-looking approach to provide a foundation for future research on integrating causal inference into financial risk forecasting.",
      "pdf_url": "https://arxiv.org/pdf/2512.05661v1",
      "arxiv_url": "http://arxiv.org/abs/2512.05661v1",
      "published": "2025-12-05",
      "categories": [
        "q-fin.RM"
      ]
    },
    {
      "title": "ShaRP: SHAllow-LayeR Pruning for Video Large Language Models Acceleration",
      "authors": [
        "Yingjie Xia",
        "Tao Liu",
        "Jinglei Shi",
        "Qingsong Xie",
        "Heng Guo",
        "Jian Yang",
        "Xi Wang"
      ],
      "abstract": "Video Large Language Models (VLLMs) face the challenge of high computational load during the pre-filling stage due to the processing of an enormous number of visual tokens. Although attention-based pruning methods are widely used to accelerate inference, trials at early decoder layers often result in significant performance degradation, especially under high compression rates. We argue that while attention-based pruning inherently holds the potential to identify the most relevant visual tokens, its effectiveness in shallow decoder layers is limited by factors such as positional encoding bias and insufficient information interaction. In this paper, we propose an improved attention-based pruning framework, termed ShaRP, that integrates segment-aware causal masking, positional debiasing, and token deduplication for enhanced token selection. It enables effective pruning at shallow layers while maintaining stable performance under high compression rates without retraining. Extensive experiments demonstrate that ShaRP achieves competitive performance across multiple video understanding benchmarks, establishing a new paradigm for accelerating VLLM inference.",
      "pdf_url": "https://arxiv.org/pdf/2512.05385v1",
      "arxiv_url": "http://arxiv.org/abs/2512.05385v1",
      "published": "2025-12-05",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "Text Rationalization for Robust Causal Effect Estimation",
      "authors": [
        "Lijinghua Zhang",
        "Hengrui Cai"
      ],
      "abstract": "Recent advances in natural language processing have enabled the increasing use of text data in causal inference, particularly for adjusting confounding factors in treatment effect estimation. Although high-dimensional text can encode rich contextual information, it also poses unique challenges for causal identification and estimation. In particular, the positivity assumption, which requires sufficient treatment overlap across confounder values, is often violated at the observational level, when massive text is represented in feature spaces. Redundant or spurious textual features inflate dimensionality, producing extreme propensity scores, unstable weights, and inflated variance in effect estimates. We address these challenges with Confounding-Aware Token Rationalization (CATR), a framework that selects a sparse necessary subset of tokens using a residual-independence diagnostic designed to preserve confounding information sufficient for unconfoundedness. By discarding irrelevant texts while retaining key signals, CATR mitigates observational-level positivity violations and stabilizes downstream causal effect estimators. Experiments on synthetic data and a real-world study using the MIMIC-III database demonstrate that CATR yields more accurate, stable, and interpretable causal effect estimates than existing baselines.",
      "pdf_url": "https://arxiv.org/pdf/2512.05373v1",
      "arxiv_url": "http://arxiv.org/abs/2512.05373v1",
      "published": "2025-12-05",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ME",
        "stat.ML"
      ]
    },
    {
      "title": "Learning Causality for Longitudinal Data",
      "authors": [
        "Mouad EL Bouchattaoui"
      ],
      "abstract": "This thesis develops methods for causal inference and causal representation learning (CRL) in high-dimensional, time-varying data.\n  The first contribution introduces the Causal Dynamic Variational Autoencoder (CDVAE), a model for estimating Individual Treatment Effects (ITEs) by capturing unobserved heterogeneity in treatment response driven by latent risk factors that affect only outcomes. CDVAE comes with theoretical guarantees on valid latent adjustment and generalization bounds for ITE error. Experiments on synthetic and real datasets show that CDVAE outperforms baselines, and that state-of-the-art models greatly improve when augmented with its latent substitutes, approaching oracle performance without access to true adjustment variables.\n  The second contribution proposes an efficient framework for long-term counterfactual regression based on RNNs enhanced with Contrastive Predictive Coding (CPC) and InfoMax. It captures long-range dependencies under time-varying confounding while avoiding the computational cost of transformers, achieving state-of-the-art results and introducing CPC into causal inference.\n  The third contribution advances CRL by addressing how latent causes manifest in observed variables. We introduce a model-agnostic interpretability layer based on the geometry of the decoder Jacobian. A sparse self-expression prior induces modular, possibly overlapping groups of observed features aligned with shared latent influences. We provide recovery guarantees in both disjoint and overlapping settings and show that meaningful latent-to-observed structure can be recovered without anchor features or single-parent assumptions. Scalable Jacobian-based regularization techniques are also developed.",
      "pdf_url": "https://arxiv.org/pdf/2512.04980v1",
      "arxiv_url": "http://arxiv.org/abs/2512.04980v1",
      "published": "2025-12-04",
      "categories": [
        "stat.ML",
        "cs.IT",
        "cs.LG"
      ]
    },
    {
      "title": "Live Avatar: Streaming Real-time Audio-Driven Avatar Generation with Infinite Length",
      "authors": [
        "Yubo Huang",
        "Hailong Guo",
        "Fangtai Wu",
        "Shifeng Zhang",
        "Shijie Huang",
        "Qijun Gan",
        "Lin Liu",
        "Sirui Zhao",
        "Enhong Chen",
        "Jiaming Liu",
        "Steven Hoi"
      ],
      "abstract": "Existing diffusion-based video generation methods are fundamentally constrained by sequential computation and long-horizon inconsistency, limiting their practical adoption in real-time, streaming audio-driven avatar synthesis. We present Live Avatar, an algorithm-system co-designed framework that enables efficient, high-fidelity, and infinite-length avatar generation using a 14-billion-parameter diffusion model. Our approach introduces Timestep-forcing Pipeline Parallelism (TPP), a distributed inference paradigm that pipelines denoising steps across multiple GPUs, effectively breaking the autoregressive bottleneck and ensuring stable, low-latency real-time streaming. To further enhance temporal consistency and mitigate identity drift and color artifacts, we propose the Rolling Sink Frame Mechanism (RSFM), which maintains sequence fidelity by dynamically recalibrating appearance using a cached reference image. Additionally, we leverage Self-Forcing Distribution Matching Distillation to facilitate causal, streamable adaptation of large-scale models without sacrificing visual quality. Live Avatar demonstrates state-of-the-art performance, reaching 20 FPS end-to-end generation on 5 H800 GPUs, and, to the best of our knowledge, is the first to achieve practical, real-time, high-fidelity avatar generation at this scale. Our work establishes a new paradigm for deploying advanced diffusion models in industrial long-form video synthesis applications.",
      "pdf_url": "https://arxiv.org/pdf/2512.04677v2",
      "arxiv_url": "http://arxiv.org/abs/2512.04677v2",
      "published": "2025-12-04",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "Addressing Logical Fallacies In Scientific Reasoning From Large Language Models: Towards a Dual-Inference Training Framework",
      "authors": [
        "Peter B. Walker",
        "Hannah Davidson",
        "Aiden Foster",
        "Matthew Lienert",
        "Thomas Pardue",
        "Dale Russell"
      ],
      "abstract": "Large Language Models (LLMs) have transformed natural language processing and hold growing promise for advancing science, healthcare, and decision-making. Yet their training paradigms remain dominated by affirmation-based inference, akin to \\textit{modus ponens}, where accepted premises yield predicted consequents. While effective for generative fluency, this one-directional approach leaves models vulnerable to logical fallacies, adversarial manipulation, and failures in causal reasoning. This paper makes two contributions. First, it demonstrates how existing LLMs from major platforms exhibit systematic weaknesses when reasoning in scientific domains with negation, counterexamples, or faulty premises \\footnote{Code to recreate these experiments are at https://github.com/hannahdavidsoncollege-maker/ScientificReasoningForEnvironment-MedicineWithLLMs. Second, it introduces a dual-reasoning training framework that integrates affirmative generation with structured counterfactual denial. Grounded in formal logic, cognitive science, and adversarial training, this training paradigm formalizes a computational analogue of ``denying the antecedent'' as a mechanism for disconfirmation and robustness. By coupling generative synthesis with explicit negation-aware objectives, the framework enables models that not only affirm valid inferences but also reject invalid ones, yielding systems that are more resilient, interpretable, and aligned with human reasoning.",
      "pdf_url": "https://arxiv.org/pdf/2512.04228v1",
      "arxiv_url": "http://arxiv.org/abs/2512.04228v1",
      "published": "2025-12-03",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "GaussDetect-LiNGAM:Causal Direction Identification without Gaussianity test",
      "authors": [
        "Ziyi Ding",
        "Xiao-Ping Zhang"
      ],
      "abstract": "We propose GaussDetect-LiNGAM, a novel approach for bivariate causal discovery that eliminates the need for explicit Gaussianity tests by leveraging a fundamental equivalence between noise Gaussianity and residual independence in the reverse regression. Under the standard LiNGAM assumptions of linearity, acyclicity, and exogeneity, we prove that the Gaussianity of the forward-model noise is equivalent to the independence between the regressor and residual in the reverse model. This theoretical insight allows us to replace fragile and sample-sensitive Gaussianity tests with robust kernel-based independence tests. Experimental results validate the equivalence and demonstrate that GaussDetect-LiNGAM maintains high consistency across diverse noise types and sample sizes, while reducing the number of tests per decision (TPD). Our method enhances both the efficiency and practical applicability of causal inference, making LiNGAM more accessible and reliable in real-world scenarios.",
      "pdf_url": "https://arxiv.org/pdf/2512.03428v1",
      "arxiv_url": "http://arxiv.org/abs/2512.03428v1",
      "published": "2025-12-03",
      "categories": [
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "title": "Assumption-Lean Differential Variance Inference for Heterogeneous Treatment Effect Detection",
      "authors": [
        "Philippe A. Boileau",
        "Hani Zaki",
        "Gabriele Lileikyte",
        "Niklas Nielsen",
        "Patrick R. Lawler",
        "Mireille E. Schnitzer"
      ],
      "abstract": "The conditional average treatment effect (CATE) is frequently estimated to refute the homogeneous treatment effect assumption. Under this assumption, all units making up the population under study experience identical benefit from a given treatment. Uncovering heterogeneous treatment effects through inference about the CATE, however, requires that covariates truly modifying the treatment effect be reliably collected at baseline. CATE-based techniques will necessarily fail to detect violations when effect modifiers are omitted from the data due to, for example, resource constraints. Severe measurement error has a similar impact. To address these limitations, we prove that the homogeneous treatment effect assumption can be gauged through inference about contrasts of the potential outcomes' variances. We derive causal machine learning estimators of these contrasts and study their asymptotic properties. We establish that these estimators are doubly robust and asymptotically linear under mild conditions, permitting formal hypothesis testing about the homogeneous treatment effect assumption even when effect modifiers are missing or mismeasured. Numerical experiments demonstrate that these estimators' asymptotic guarantees are approximately achieved in experimental and observational data alike. These inference procedures are then used to detect heterogeneous treatment effects in the re-analysis of randomized controlled trials investigating targeted temperature management in cardiac arrest patients.",
      "pdf_url": "https://arxiv.org/pdf/2512.03254v1",
      "arxiv_url": "http://arxiv.org/abs/2512.03254v1",
      "published": "2025-12-02",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "The BEAT-CF Causal Model: A model for guiding the design of trials and observational analyses of cystic fibrosis exacerbations",
      "authors": [
        "Steven Mascaro",
        "Owen Woodberry",
        "Charlie McLeod",
        "Mitch Messer",
        "Hiran Selvadurai",
        "Yue Wu",
        "Andre Schultz",
        "Thomas L Snelling"
      ],
      "abstract": "Loss of lung function in cystic fibrosis (CF) occurs progressively, punctuated by acute pulmonary exacerbations (PEx) in which abrupt declines in lung function are not fully recovered. A key component of CF management over the past half century has been the treatment of PEx to slow lung function decline. This has been credited with improvements in survival for people with CF (PwCF), but there is no consensus on the optimal approach to PEx management. BEAT-CF (Bayesian evidence-adaptive treatment of CF) was established to build an evidence-informed knowledge base for CF management. The BEAT-CF causal model is a directed acyclic graph (DAG) and Bayesian network (BN) for PEx that aims to inform the design and analysis of clinical trials comparing the effectiveness of alternative approaches to PEx management. The causal model describes relationships between background risk factors, treatments, and pathogen colonisation of the airways that affect the outcome of an individual PEx episode. The key factors, outcomes, and causal relationships were elicited from CF clinical experts and together represent current expert understanding of the pathophysiology of a PEx episode, guiding the design of data collection and studies and enabling causal inference. Here, we present the DAG that documents this understanding, along with the processes used in its development, providing transparency around our trial design and study processes, as well as a reusable framework for others.",
      "pdf_url": "https://arxiv.org/pdf/2512.03110v1",
      "arxiv_url": "http://arxiv.org/abs/2512.03110v1",
      "published": "2025-12-02",
      "categories": [
        "q-bio.QM",
        "cs.AI"
      ]
    },
    {
      "title": "SpriteHand: Real-Time Versatile Hand-Object Interaction with Autoregressive Video Generation",
      "authors": [
        "Zisu Li",
        "Hengye Lyu",
        "Jiaxin Shi",
        "Yufeng Zeng",
        "Mingming Fan",
        "Hanwang Zhang",
        "Chen Liang"
      ],
      "abstract": "Modeling and synthesizing complex hand-object interactions remains a significant challenge, even for state-of-the-art physics engines. Conventional simulation-based approaches rely on explicitly defined rigid object models and pre-scripted hand gestures, making them inadequate for capturing dynamic interactions with non-rigid or articulated entities such as deformable fabrics, elastic materials, hinge-based structures, furry surfaces, or even living creatures. In this paper, we present SpriteHand, an autoregressive video generation framework for real-time synthesis of versatile hand-object interaction videos across a wide range of object types and motion patterns. SpriteHand takes as input a static object image and a video stream in which the hands are imagined to interact with the virtual object embedded in a real-world scene, and generates corresponding hand-object interaction effects in real time. Our model employs a causal inference architecture for autoregressive generation and leverages a hybrid post-training approach to enhance visual realism and temporal coherence. Our 1.3B model supports real-time streaming generation at around 18 FPS and 640x368 resolution, with an approximate 150 ms latency on a single NVIDIA RTX 5090 GPU, and more than a minute of continuous output. Experiments demonstrate superior visual quality, physical plausibility, and interaction fidelity compared to both generative and engine-based baselines.",
      "pdf_url": "https://arxiv.org/pdf/2512.01960v1",
      "arxiv_url": "http://arxiv.org/abs/2512.01960v1",
      "published": "2025-12-01",
      "categories": [
        "cs.CV",
        "cs.HC"
      ]
    }
  ]
}