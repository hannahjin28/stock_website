{
  "last_updated": "2025-06-17T00:55:00.463237",
  "papers": [
    {
      "title": "Identification and Inference of Partial Effects in Sharp Regression Kink Designs",
      "authors": [
        "Zhixin Wang",
        "Zhengyu Zhang"
      ],
      "abstract": "The partial effect refers to the impact of a change in a target variable D on\nthe distribution of an outcome variable Y . This study examines the\nidentification and inference of a wide range of partial effects at the\nthreshold in the sharp regression kink (RK) design under general policy\ninterventions. We establish a unifying framework for conducting inference on\nthe effect of an infinitesimal change in D on smooth functionals of the\ndistribution of Y, particularly when D is endogenous and instrumental variables\nare unavailable. This framework yields a general formula that clarifies the\ncausal interpretation of numerous existing sharp RK estimands in the\nliterature.\n  We develop the relevant asymptotic theory, introduce a multiplier bootstrap\nprocedure for inference, and provide practical implementation guidelines.\nApplying our method to the effect of unemployment insurance (UI) benefits on\nunemployment duration, we find that while higher benefits lead to longer\ndurations, they also tend to reduce their dispersion. Furthermore, our results\nshow that the magnitude of the partial effect can change substantially\ndepending on the specific form of the policy intervention.",
      "pdf_url": "http://arxiv.org/pdf/2506.11663v1",
      "arxiv_url": "http://arxiv.org/abs/2506.11663v1",
      "published": "2025-06-13",
      "categories": [
        "econ.EM"
      ]
    },
    {
      "title": "GraphRAG-Causal: A novel graph-augmented framework for causal reasoning and annotation in news",
      "authors": [
        "Abdul Haque",
        "Umm e Hani",
        "Ahmad Din",
        "Muhammad Babar",
        "Ali Abbas",
        "Insaf Ullah"
      ],
      "abstract": "GraphRAG-Causal introduces an innovative framework that combines graph-based\nretrieval with large language models to enhance causal reasoning in news\nanalysis. Traditional NLP approaches often struggle with identifying complex,\nimplicit causal links, especially in low-data scenarios. Our approach addresses\nthese challenges by transforming annotated news headlines into structured\ncausal knowledge graphs. It then employs a hybrid retrieval system that merges\nsemantic embeddings with graph-based structural cues leveraging Neo4j to\naccurately match and retrieve relevant events. The framework is built on a\nthree-stage pipeline: First, during Data Preparation, news sentences are\nmeticulously annotated and converted into causal graphs capturing cause,\neffect, and trigger relationships. Next, the Graph Retrieval stage stores these\ngraphs along with their embeddings in a Neo4j database and utilizes hybrid\nCypher queries to efficiently identify events that share both semantic and\nstructural similarities with a given query. Finally, the LLM Inference stage\nutilizes these retrieved causal graphs in a few-shot learning setup with\nXML-based prompting, enabling robust classification and tagging of causal\nrelationships. Experimental evaluations demonstrate that GraphRAG-Causal\nachieves an impressive F1-score of 82.1% on causal classification using just 20\nfew-shot examples. This approach significantly boosts accuracy and consistency,\nmaking it highly suitable for real-time applications in news reliability\nassessment, misinformation detection, and policy analysis.",
      "pdf_url": "http://arxiv.org/pdf/2506.11600v1",
      "arxiv_url": "http://arxiv.org/abs/2506.11600v1",
      "published": "2025-06-13",
      "categories": [
        "cs.IR",
        "cs.AI"
      ]
    },
    {
      "title": "Bayesian Sensitivity Analysis for Causal Estimation with Time-varying Unmeasured Confounding",
      "authors": [
        "Yushu Zou",
        "Liangyuan Hu",
        "Amanda Ricciuto",
        "Mark Deneau",
        "Kuan Liu"
      ],
      "abstract": "Causal inference relies on the untestable assumption of no unmeasured\nconfounding. Sensitivity analysis can be used to quantify the impact of\nunmeasured confounding on causal estimates. Among sensitivity analysis methods\nproposed in the literature for unmeasured confounding, the latent confounder\napproach is favoured for its intuitive interpretation via the use of bias\nparameters to specify the relationship between the observed and unobserved\nvariables and the sensitivity function approach directly characterizes the net\ncausal effect of the unmeasured confounding without explicitly introducing\nlatent variables to the causal models. In this paper, we developed and extended\ntwo sensitivity analysis approaches, namely the Bayesian sensitivity analysis\nwith latent confounding variables and the Bayesian sensitivity function\napproach for the estimation of time-varying treatment effects with longitudinal\nobservational data subjected to time-varying unmeasured confounding. We\ninvestigated the performance of these methods in a series of simulation studies\nand applied them to a multi-center pediatric disease registry data to provide\npractical guidance on their implementation.",
      "pdf_url": "http://arxiv.org/pdf/2506.11322v1",
      "arxiv_url": "http://arxiv.org/abs/2506.11322v1",
      "published": "2025-06-12",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Variance estimation after matching or re-weighting",
      "authors": [
        "Xiang Meng",
        "Aaron Smith",
        "Luke Miratrix"
      ],
      "abstract": "This paper develops a variance estimation framework for matching estimators\nthat enables valid population inference for treatment effects. We provide\ntheoretical analysis of a variance estimator that addresses key limitations in\nthe existing literature. While Abadie and Imbens (2006) proposed a foundational\nvariance estimator requiring matching for both treatment and control groups,\nthis approach is computationally prohibitive and rarely used in practice. Our\nmethod provides a computationally feasible alternative that only requires\nmatching treated units to controls while maintaining theoretical validity for\npopulation inference.\n  We make three main contributions. First, we establish consistency and\nasymptotic normality for our variance estimator, proving its validity for\naverage treatment effect on the treated (ATT) estimation in settings with small\ntreated samples. Second, we develop a generalized theoretical framework with\nnovel regularity conditions that significantly expand the class of matching\nprocedures for which valid inference is available, including radius matching,\nM-nearest neighbor matching, and propensity score matching. Third, we\ndemonstrate that our approach extends naturally to other causal inference\nestimators such as stable balancing weighting methods.\n  Through simulation studies across different data generating processes, we\nshow that our estimator maintains proper coverage rates while the\nstate-of-the-art bootstrap method can exhibit substantial undercoverage\n(dropping from 95% to as low as 61%), particularly in settings with extensive\ncontrol unit reuse. Our framework provides researchers with both theoretical\nguarantees and practical tools for conducting valid population inference across\na wide range of causal inference applications. An R package implementing our\nmethod is available at https://github.com/jche/scmatch2.",
      "pdf_url": "http://arxiv.org/pdf/2506.11317v1",
      "arxiv_url": "http://arxiv.org/abs/2506.11317v1",
      "published": "2025-06-12",
      "categories": [
        "stat.ME",
        "math.ST",
        "stat.TH"
      ]
    },
    {
      "title": "Foundation Models for Causal Inference via Prior-Data Fitted Networks",
      "authors": [
        "Yuchen Ma",
        "Dennis Frauen",
        "Emil Javurek",
        "Stefan Feuerriegel"
      ],
      "abstract": "Prior-data fitted networks (PFNs) have recently been proposed as a promising\nway to train tabular foundation models. PFNs are transformers that are\npre-trained on synthetic data generated from a prespecified prior distribution\nand that enable Bayesian inference through in-context learning. In this paper,\nwe introduce CausalFM, a comprehensive framework for training PFN-based\nfoundation models in various causal inference settings. First, we formalize the\nconstruction of Bayesian priors for causal inference based on structural causal\nmodels (SCMs) in a principled way and derive necessary criteria for the\nvalidity of such priors. Building on this, we propose a novel family of prior\ndistributions using causality-inspired Bayesian neural networks that enable\nCausalFM to perform Bayesian causal inference in various settings, including\nback-door, front-door, and instrumental variable adjustment. Finally, we\ninstantiate CausalFM and explicitly train a foundation model for estimating\nconditional average treatment effects (CATEs) using back-door adjustment. We\nshow that CausalFM performs competitively for CATE estimation using various\nsynthetic and semi-synthetic benchmarks. In sum, our framework can be used as a\ngeneral recipe to train foundation models for various causal inference\nsettings. In contrast to the current state-of-the-art in causal inference,\nCausalFM offers a novel paradigm with the potential to fundamentally change how\npractitioners perform causal inference in medicine, economics, and other\ndisciplines.",
      "pdf_url": "http://arxiv.org/pdf/2506.10914v1",
      "arxiv_url": "http://arxiv.org/abs/2506.10914v1",
      "published": "2025-06-12",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "From Images to Insights: Explainable Biodiversity Monitoring with Plain Language Habitat Explanations",
      "authors": [
        "Yutong Zhou",
        "Masahiro Ryo"
      ],
      "abstract": "Explaining why the species lives at a particular location is important for\nunderstanding ecological systems and conserving biodiversity. However, existing\necological workflows are fragmented and often inaccessible to non-specialists.\nWe propose an end-to-end visual-to-causal framework that transforms a species\nimage into interpretable causal insights about its habitat preference. The\nsystem integrates species recognition, global occurrence retrieval,\npseudo-absence sampling, and climate data extraction. We then discover causal\nstructures among environmental features and estimate their influence on species\noccurrence using modern causal inference methods. Finally, we generate\nstatistically grounded, human-readable causal explanations from structured\ntemplates and large language models. We demonstrate the framework on a bee and\na flower species and report early results as part of an ongoing project,\nshowing the potential of the multimodal AI assistant backed up by a recommended\necological modeling practice for describing species habitat in\nhuman-understandable language.",
      "pdf_url": "http://arxiv.org/pdf/2506.10559v1",
      "arxiv_url": "http://arxiv.org/abs/2506.10559v1",
      "published": "2025-06-12",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.ET"
      ]
    },
    {
      "title": "Towards Robust Multimodal Emotion Recognition under Missing Modalities and Distribution Shifts",
      "authors": [
        "Guowei Zhong",
        "Ruohong Huan",
        "Mingzhen Wu",
        "Ronghua Liang",
        "Peng Chen"
      ],
      "abstract": "Recent advancements in Multimodal Emotion Recognition (MER) face challenges\nin addressing both modality missing and Out-Of-Distribution (OOD) data\nsimultaneously. Existing methods often rely on specific models or introduce\nexcessive parameters, which limits their practicality. To address these issues,\nwe propose a novel robust MER framework, Causal Inference Distiller (CIDer),\nand introduce a new task, Random Modality Feature Missing (RMFM), to generalize\nthe definition of modality missing. CIDer integrates two key components: a\nModel-Specific Self-Distillation (MSSD) module and a Model-Agnostic Causal\nInference (MACI) module. MSSD enhances robustness under the RMFM task through a\nweight-sharing self-distillation approach applied across low-level features,\nattention maps, and high-level representations. Additionally, a Word-level\nSelf-aligned Attention Module (WSAM) reduces computational complexity, while a\nMultimodal Composite Transformer (MCT) facilitates efficient multimodal fusion.\nTo tackle OOD challenges, MACI employs a tailored causal graph to mitigate\nlabel and language biases using a Multimodal Causal Module (MCM) and\nfine-grained counterfactual texts. Notably, MACI can independently enhance OOD\ngeneralization with minimal additional parameters. Furthermore, we also\nintroduce the new repartitioned MER OOD datasets. Experimental results\ndemonstrate that CIDer achieves robust performance in both RMFM and OOD\nscenarios, with fewer parameters and faster training compared to\nstate-of-the-art methods. The implementation of this work is publicly\naccessible at https://github.com/gw-zhong/CIDer.",
      "pdf_url": "http://arxiv.org/pdf/2506.10452v1",
      "arxiv_url": "http://arxiv.org/abs/2506.10452v1",
      "published": "2025-06-12",
      "categories": [
        "cs.CV",
        "cs.CL",
        "cs.LG",
        "cs.MM"
      ]
    },
    {
      "title": "Correlation vs causation in Alzheimer's disease: an interpretability-driven study",
      "authors": [
        "Hamzah Dabool",
        "Raghad Mustafa"
      ],
      "abstract": "Understanding the distinction between causation and correlation is critical\nin Alzheimer's disease (AD) research, as it impacts diagnosis, treatment, and\nthe identification of true disease drivers. This experiment investigates the\nrelationships among clinical, cognitive, genetic, and biomarker features using\na combination of correlation analysis, machine learning classification, and\nmodel interpretability techniques. Employing the XGBoost algorithm, we\nidentified key features influencing AD classification, including cognitive\nscores and genetic risk factors. Correlation matrices revealed clusters of\ninterrelated variables, while SHAP (SHapley Additive exPlanations) values\nprovided detailed insights into feature contributions across disease stages.\nOur results highlight that strong correlations do not necessarily imply\ncausation, emphasizing the need for careful interpretation of associative data.\nBy integrating feature importance and interpretability with classical\nstatistical analysis, this work lays groundwork for future causal inference\nstudies aimed at uncovering true pathological mechanisms. Ultimately,\ndistinguishing causal factors from correlated markers can lead to improved\nearly diagnosis and targeted interventions for Alzheimer's disease.",
      "pdf_url": "http://arxiv.org/pdf/2506.10179v1",
      "arxiv_url": "http://arxiv.org/abs/2506.10179v1",
      "published": "2025-06-11",
      "categories": [
        "cs.AI",
        "q-bio.QM",
        "stat.AP"
      ]
    },
    {
      "title": "Multiverse: Your Language Models Secretly Decide How to Parallelize and Merge Generation",
      "authors": [
        "Xinyu Yang",
        "Yuwei An",
        "Hongyi Liu",
        "Tianqi Chen",
        "Beidi Chen"
      ],
      "abstract": "Autoregressive Large Language Models (AR-LLMs) frequently exhibit implicit\nparallelism in sequential generation. Inspired by this, we introduce\nMultiverse, a new generative model that enables natively parallel generation.\nMultiverse internalizes a MapReduce paradigm, generating automatically through\nthree stages: (i) a Map stage for adaptive task decomposition, (ii) a Process\nstage for parallel subtask execution, and (iii) a Reduce stage for lossless\nresult synthesis. Next, we build a real-world Multiverse reasoning model with\nco-design of data, algorithm, and system, enabling rapid and seamless transfer\nfrom frontier AR-LLMs. For data creation, we develop Multiverse Curator, an\nautomated LLM-assisted pipeline that transforms sequential reasoning chains\ninto structured training data, avoiding costly human annotations.\nAlgorithmically, we design Multiverse Attention to separate parallel reasoning\nsteps while keeping compatibility with causal attention for efficient training.\nSystematically, we implement Multiverse Engine to support parallel inference.\nIt features a dedicated interpreter that dynamically switches between\nsequential and parallel generation, triggered directly by the model. After a\n3-hour fine-tuning with 1K examples, our Multiverse-32B stands as the only\nopen-sourced non-AR model achieving performance on par with leading AR-LLMs of\nthe same scale, evidenced by AIME24 & 25 scores of 54% and 46%, respectively.\nMoreover, our budget control experiments show that Multiverse-32B exhibits\nsuperior scaling, outperforming AR-LLMs by 1.87% on average using the same\ncontext length. Such scaling further leads to practical efficiency gains,\nachieving up to 2x speedup across varying batch sizes. We have open-sourced the\nentire Multiverse ecosystem, including data, model weights, engine, as well as\ncomplete data curation prompts and detailed training and evaluation recipes.",
      "pdf_url": "http://arxiv.org/pdf/2506.09991v2",
      "arxiv_url": "http://arxiv.org/abs/2506.09991v2",
      "published": "2025-06-11",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "Causal Sufficiency and Necessity Improves Chain-of-Thought Reasoning",
      "authors": [
        "Xiangning Yu",
        "Zhuohan Wang",
        "Linyi Yang",
        "Haoxuan Li",
        "Anjie Liu",
        "Xiao Xue",
        "Jun Wang",
        "Mengyue Yang"
      ],
      "abstract": "Chain-of-Thought (CoT) prompting plays an indispensable role in endowing\nlarge language models (LLMs) with complex reasoning capabilities. However, CoT\ncurrently faces two fundamental challenges: (1) Sufficiency, which ensures that\nthe generated intermediate inference steps comprehensively cover and\nsubstantiate the final conclusion; and (2) Necessity, which identifies the\ninference steps that are truly indispensable for the soundness of the resulting\nanswer. We propose a causal framework that characterizes CoT reasoning through\nthe dual lenses of sufficiency and necessity. Incorporating causal Probability\nof Sufficiency and Necessity allows us not only to determine which steps are\nlogically sufficient or necessary to the prediction outcome, but also to\nquantify their actual influence on the final reasoning outcome under different\nintervention scenarios, thereby enabling the automated addition of missing\nsteps and the pruning of redundant ones. Extensive experimental results on\nvarious mathematical and commonsense reasoning benchmarks confirm substantial\nimprovements in reasoning efficiency and reduced token usage without\nsacrificing accuracy. Our work provides a promising direction for improving LLM\nreasoning performance and cost-effectiveness.",
      "pdf_url": "http://arxiv.org/pdf/2506.09853v1",
      "arxiv_url": "http://arxiv.org/abs/2506.09853v1",
      "published": "2025-06-11",
      "categories": [
        "cs.CL",
        "cs.AI",
        "math.ST",
        "stat.ME",
        "stat.TH"
      ]
    }
  ]
}