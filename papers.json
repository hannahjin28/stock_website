{
  "last_updated": "2025-10-09T00:50:23.800080",
  "papers": [
    {
      "title": "Can language models boost the power of randomized experiments without statistical bias?",
      "authors": [
        "Xinrui Ruan",
        "Xinwei Ma",
        "Yingfei Wang",
        "Waverly Wei",
        "Jingshen Wang"
      ],
      "abstract": "Randomized experiments or randomized controlled trials (RCTs) are gold\nstandards for causal inference, yet cost and sample-size constraints limit\npower. Meanwhile, modern RCTs routinely collect rich, unstructured data that\nare highly prognostic of outcomes but rarely used in causal analyses. We\nintroduce CALM (Causal Analysis leveraging Language Models), a statistical\nframework that integrates large language models (LLMs) predictions with\nestablished causal estimators to increase precision while preserving\nstatistical validity. CALM treats LLM outputs as auxiliary prognostic\ninformation and corrects their potential bias via a heterogeneous calibration\nstep that residualizes and optimally reweights predictions. We prove that CALM\nremains consistent even when LLM predictions are biased and achieves efficiency\ngains over augmented inverse probability weighting estimators for various\ncausal effects. In particular, CALM develops a few-shot variant that aggregates\npredictions across randomly sampled demonstration sets. The resulting\nU-statistic-like predictor restores i.i.d. structure and also mitigates\nprompt-selection variability. Empirically, in simulations calibrated to a\nmobile-app depression RCT, CALM delivers lower variance relative to other\nbenchmarking methods, is effective in zero- and few-shot settings, and remains\nstable across prompt designs. By principled use of LLMs to harness unstructured\ndata and external knowledge learned during pretraining, CALM provides a\npractical path to more precise causal analyses in RCTs.",
      "pdf_url": "http://arxiv.org/pdf/2510.05545v1",
      "arxiv_url": "http://arxiv.org/abs/2510.05545v1",
      "published": "2025-10-07",
      "categories": [
        "stat.ME",
        "econ.EM"
      ]
    },
    {
      "title": "Rivaling Transformers: Multi-Scale Structured State-Space Mixtures for Agentic 6G O-RAN",
      "authors": [
        "Farhad Rezazadeh",
        "Hatim Chergui",
        "Merouane Debbah",
        "Houbing Song",
        "Dusit Niyato",
        "Lingjia Liu"
      ],
      "abstract": "In sixth-generation (6G) Open Radio Access Networks (O-RAN), proactive\ncontrol is preferable. A key open challenge is delivering control-grade\npredictions within Near-Real-Time (Near-RT) latency and computational\nconstraints under multi-timescale dynamics. We therefore cast RAN Intelligent\nController (RIC) analytics as an agentic perceive-predict xApp that turns\nnoisy, multivariate RAN telemetry into short-horizon per-User Equipment (UE)\nkey performance indicator (KPI) forecasts to drive anticipatory control. In\nthis regard, Transformers are powerful for sequence learning and time-series\nforecasting, but they are memory-intensive, which limits Near-RT RIC use.\nTherefore, we need models that maintain accuracy while reducing latency and\ndata movement. To this end, we propose a lightweight Multi-Scale Structured\nState-Space Mixtures (MS3M) forecaster that mixes HiPPO-LegS kernels to capture\nmulti-timescale radio dynamics. We develop stable discrete state-space models\n(SSMs) via bilinear (Tustin) discretization and apply their causal impulse\nresponses as per-feature depthwise convolutions. Squeeze-and-Excitation gating\ndynamically reweights KPI channels as conditions change, and a compact gated\nchannel-mixing layer models cross-feature nonlinearities without\nTransformer-level cost. The model is KPI-agnostic -- Reference Signal Received\nPower (RSRP) serves as a canonical use case -- and is trained on sliding\nwindows to predict the immediate next step. Empirical evaluations conducted\nusing our bespoke O-RAN testbed KPI time-series dataset (59,441 windows across\n13 KPIs). Crucially for O-RAN constraints, MS3M achieves a 0.057 s\nper-inference latency with 0.70M parameters, yielding 3-10x lower latency than\nthe Transformer baselines evaluated on the same hardware, while maintaining\ncompetitive accuracy.",
      "pdf_url": "http://arxiv.org/pdf/2510.05255v1",
      "arxiv_url": "http://arxiv.org/abs/2510.05255v1",
      "published": "2025-10-06",
      "categories": [
        "cs.NI"
      ]
    },
    {
      "title": "Structural Identifiability of Graphical Continuous Lyapunov Models",
      "authors": [
        "Carlos Am√©ndola",
        "Tobias Boege",
        "Benjamin Hollering",
        "Pratik Misra"
      ],
      "abstract": "We prove two characterizations of model equivalence of acyclic graphical\ncontinuous Lyapunov models (GCLMs) with uncorrelated noise. The first result\nshows that two graphs are model equivalent if and only if they have the same\nskeleton and equivalent induced 4-node subgraphs. We also give a\ntransformational characterization via structured edge reversals. The two\ntheorems are Lyapunov analogues of celebrated results for Bayesian networks by\nVerma and Pearl, and Chickering, respectively. Our results have broad\nconsequences for the theory of causal inference of GCLMs. First, we find that\nmodel equivalence classes of acyclic GCLMs refine the corresponding classes of\nBayesian networks. Furthermore, we obtain polynomial-time algorithms to test\nmodel equivalence and structural identifiability of given directed acyclic\ngraphs.",
      "pdf_url": "http://arxiv.org/pdf/2510.04985v1",
      "arxiv_url": "http://arxiv.org/abs/2510.04985v1",
      "published": "2025-10-06",
      "categories": [
        "math.ST",
        "stat.TH",
        "62H22, 60J60 (Primary) 15A24, 62R01, 60J70 (Secondary)"
      ]
    },
    {
      "title": "On Predicting Post-Click Conversion Rate via Counterfactual Inference",
      "authors": [
        "Junhyung Ahn",
        "Sanghack Lee"
      ],
      "abstract": "Accurately predicting conversion rate (CVR) is essential in various\nrecommendation domains such as online advertising systems and e-commerce. These\nsystems utilize user interaction logs, which consist of exposures, clicks, and\nconversions. CVR prediction models are typically trained solely based on\nclicked samples, as conversions can only be determined following clicks.\nHowever, the sparsity of clicked instances necessitates the collection of a\nsubstantial amount of logs for effective model training. Recent works address\nthis issue by devising frameworks that leverage non-clicked samples. While\nthese frameworks aim to reduce biases caused by the discrepancy between clicked\nand non-clicked samples, they often rely on heuristics. Against this\nbackground, we propose a method to counterfactually generate conversion labels\nfor non-clicked samples by using causality as a guiding principle, attempting\nto answer the question, \"Would the user have converted if he or she had clicked\nthe recommended item?\" Our approach is named the Entire Space Counterfactual\nInference Multi-task Model (ESCIM). We initially train a structural causal\nmodel (SCM) of user sequential behaviors and conduct a hypothetical\nintervention (i.e., click) on non-clicked items to infer counterfactual CVRs.\nWe then introduce several approaches to transform predicted counterfactual CVRs\ninto binary counterfactual conversion labels for the non-clicked samples.\nFinally, the generated samples are incorporated into the training process.\nExtensive experiments on public datasets illustrate the superiority of the\nproposed algorithm. Online A/B testing further empirically validates the\neffectiveness of our proposed algorithm in real-world scenarios. In addition,\nwe demonstrate the improved performance of the proposed method on latent\nconversion data, showcasing its robustness and superior generalization\ncapabilities.",
      "pdf_url": "http://arxiv.org/pdf/2510.04816v1",
      "arxiv_url": "http://arxiv.org/abs/2510.04816v1",
      "published": "2025-10-06",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Causality-aware Graph Aggregation Weight Estimator for Popularity Debiasing in Top-K Recommendation",
      "authors": [
        "Yue Que",
        "Yingyi Zhang",
        "Xiangyu Zhao",
        "Chen Ma"
      ],
      "abstract": "Graph-based recommender systems leverage neighborhood aggregation to generate\nnode representations, which is highly sensitive to popularity bias, resulting\nin an echo effect during information propagation. Existing graph-based\ndebiasing solutions refine the aggregation process with attempts such as edge\nreconstruction or weight adjustment. However, these methods remain inadequate\nin fully alleviating popularity bias. Specifically, this is because 1) they\nprovide no insights into graph aggregation rationality, thus lacking an\noptimality guarantee; 2) they fail to well balance the training and debiasing\nprocess, which undermines the effectiveness. In this paper, we propose a novel\napproach to mitigate popularity bias through rational modeling of the graph\naggregation process. We reveal that graph aggregation is a special form of\nbackdoor adjustment in causal inference, where the aggregation weight\ncorresponds to the historical interaction likelihood distribution. Based on\nthis insight, we devise an encoder-decoder architecture, namely Causality-aware\nGraph Aggregation Weight Estimator for Debiasing (CAGED), to approximate the\nunbiased aggregation weight by optimizing the evidence lower bound of the\ninteraction likelihood. In order to enhance the debiasing effectiveness during\nearly training stages, we further design a momentum update strategy that\nincrementally refines the aggregation weight matrix. Extensive experiments on\nthree datasets demonstrate that CAGED outperforms existing graph-based\ndebiasing methods. Our implementation is available at\nhttps://github.com/QueYork/CAGED.",
      "pdf_url": "http://arxiv.org/pdf/2510.04502v1",
      "arxiv_url": "http://arxiv.org/abs/2510.04502v1",
      "published": "2025-10-06",
      "categories": [
        "cs.IR",
        "cs.LG"
      ]
    },
    {
      "title": "REAR: Rethinking Visual Autoregressive Models via Generator-Tokenizer Consistency Regularization",
      "authors": [
        "Qiyuan He",
        "Yicong Li",
        "Haotian Ye",
        "Jinghao Wang",
        "Xinyao Liao",
        "Pheng-Ann Heng",
        "Stefano Ermon",
        "James Zou",
        "Angela Yao"
      ],
      "abstract": "Visual autoregressive (AR) generation offers a promising path toward unifying\nvision and language models, yet its performance remains suboptimal against\ndiffusion models. Prior work often attributes this gap to tokenizer limitations\nand rasterization ordering. In this work, we identify a core bottleneck from\nthe perspective of generator-tokenizer inconsistency, i.e., the AR-generated\ntokens may not be well-decoded by the tokenizer. To address this, we propose\nreAR, a simple training strategy introducing a token-wise regularization\nobjective: when predicting the next token, the causal transformer is also\ntrained to recover the visual embedding of the current token and predict the\nembedding of the target token under a noisy context. It requires no changes to\nthe tokenizer, generation order, inference pipeline, or external models.\nDespite its simplicity, reAR substantially improves performance. On ImageNet,\nit reduces gFID from 3.02 to 1.86 and improves IS to 316.9 using a standard\nrasterization-based tokenizer. When applied to advanced tokenizers, it achieves\na gFID of 1.42 with only 177M parameters, matching the performance with larger\nstate-of-the-art diffusion models (675M).",
      "pdf_url": "http://arxiv.org/pdf/2510.04450v1",
      "arxiv_url": "http://arxiv.org/abs/2510.04450v1",
      "published": "2025-10-06",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "Efficient Latent Variable Causal Discovery: Combining Score Search and Targeted Testing",
      "authors": [
        "Joseph Ramsey",
        "Bryan Andrews"
      ],
      "abstract": "Learning causal structure from observational data is especially challenging\nwhen latent variables or selection bias are present. The Fast Causal Inference\n(FCI) algorithm addresses this setting but often performs exhaustive\nconditional independence tests across many subsets, leading to spurious\nindependence claims, extra or missing edges, and unreliable orientations. We\npresent a family of score-guided mixed-strategy causal search algorithms that\nbuild on this tradition. First, we introduce BOSS-FCI and GRaSP-FCI,\nstraightforward variants of GFCI that substitute BOSS or GRaSP for FGES,\nthereby retaining correctness while incurring different scalability tradeoffs.\nSecond, we develop FCI Targeted-testing (FCIT), a novel mixed-strategy method\nthat improves upon these variants by replacing exhaustive all-subsets testing\nwith targeted tests guided by BOSS, yielding well-formed PAGs with higher\nprecision and efficiency. Finally, we propose a simple heuristic, LV-Dumb (also\nknown as BOSS-POD), which bypasses latent-variable-specific reasoning and\ndirectly returns the PAG of the BOSS DAG. Although not strictly correct in the\nFCI sense, it scales better and often achieves superior accuracy in practice.\nSimulations and real-data analyses demonstrate that BOSS-FCI and GRaSP-FCI\nprovide sound baselines, FCIT improves both efficiency and reliability, and\nLV-Dumb offers a practical heuristic with strong empirical performance.\nTogether, these method highlight the value of score-guided and targeted\nstrategies for scalable latent-variable causal discovery.",
      "pdf_url": "http://arxiv.org/pdf/2510.04263v1",
      "arxiv_url": "http://arxiv.org/abs/2510.04263v1",
      "published": "2025-10-05",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Domain-Adapted Granger Causality for Real-Time Cross-Slice Attack Attribution in 6G Networks",
      "authors": [
        "Minh K. Quan",
        "Pubudu N. Pathirana"
      ],
      "abstract": "Cross-slice attack attribution in 6G networks faces the fundamental challenge\nof distinguishing genuine causal relationships from spurious correlations in\nshared infrastructure environments. We propose a theoretically-grounded\ndomain-adapted Granger causality framework that integrates statistical causal\ninference with network-specific resource modeling for real-time attack\nattribution. Our approach addresses key limitations of existing methods by\nincorporating resource contention dynamics and providing formal statistical\nguarantees. Comprehensive evaluation on a production-grade 6G testbed with\n1,100 empirically-validated attack scenarios demonstrates 89.2% attribution\naccuracy with sub-100ms response time, representing a statistically significant\n10.1 percentage point improvement over state-of-the-art baselines. The\nframework provides interpretable causal explanations suitable for autonomous 6G\nsecurity orchestration.",
      "pdf_url": "http://arxiv.org/pdf/2510.05165v1",
      "arxiv_url": "http://arxiv.org/abs/2510.05165v1",
      "published": "2025-10-04",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "Bridging the Gap Between Multimodal Foundation Models and World Models",
      "authors": [
        "Xuehai He"
      ],
      "abstract": "Humans understand the world through the integration of multiple sensory\nmodalities, enabling them to perceive, reason about, and imagine dynamic\nphysical processes. Inspired by this capability, multimodal foundation models\n(MFMs) have emerged as powerful tools for multimodal understanding and\ngeneration. However, today's MFMs fall short of serving as effective world\nmodels. They lack the essential ability such as perform counterfactual\nreasoning, simulate dynamics, understand the spatiotemporal information,\ncontrol generated visual outcomes, and perform multifaceted reasoning. We\ninvestigates what it takes to bridge the gap between multimodal foundation\nmodels and world models. We begin by improving the reasoning capabilities of\nMFMs through discriminative tasks and equipping MFMs with structured reasoning\nskills, such as causal inference, counterfactual thinking, and spatiotemporal\nreasoning, enabling them to go beyond surface correlations and understand\ndeeper relationships within visual and textual data. Next, we explore\ngenerative capabilities of multimodal foundation models across both image and\nvideo modalities, introducing new frameworks for structured and controllable\ngeneration. Our approaches incorporate scene graphs, multimodal conditioning,\nand multimodal alignment strategies to guide the generation process, ensuring\nconsistency with high-level semantics and fine-grained user intent. We further\nextend these techniques to controllable 4D generation, enabling interactive,\neditable, and morphable object synthesis over time and space.",
      "pdf_url": "http://arxiv.org/pdf/2510.03727v1",
      "arxiv_url": "http://arxiv.org/abs/2510.03727v1",
      "published": "2025-10-04",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "title": "GCVAMD: A Modified CausalVAE Model for Causal Age-related Macular Degeneration Risk Factor Detection and Prediction",
      "authors": [
        "Daeyoung Kim"
      ],
      "abstract": "Age Related Macular Degeneration(AMD) has been one of the most leading causes\nof permanent vision impairment in ophthalmology. Though treatments, such as\nanti VEGF drugs or photodynamic therapies, were developed to slow down the\ndegenerative process of AMD, there is still no specific cure to reverse vision\nloss caused by AMD. Thus, for AMD, detecting existence of risk factors of AMD\nor AMD itself within the patient retina in early stages is a crucial task to\nreduce the possibility of vision impairment. Apart from traditional approaches,\ndeep learning based methods, especially attention mechanism based CNNs and\nGradCAM based XAI analysis on OCT scans, exhibited successful performance in\ndistinguishing AMD retina from normal retinas, making it possible to use AI\ndriven models to aid medical diagnosis and analysis by ophthalmologists\nregarding AMD. However, though having significant success, previous works\nmostly focused on prediction performance itself, not pathologies or underlying\ncausal mechanisms of AMD, which can prohibit intervention analysis on specific\nfactors or even lead to less reliable decisions. Thus, this paper introduces a\nnovel causal AMD analysis model: GCVAMD, which incorporates a modified\nCausalVAE approach that can extract latent causal factors from only raw OCT\nimages. By considering causality in AMD detection, GCVAMD enables causal\ninference such as treatment simulation or intervention analysis regarding major\nrisk factors: drusen and neovascularization, while returning informative latent\ncausal features that can enhance downstream tasks. Results show that through\nGCVAMD, drusen status and neovascularization status can be identified with AMD\ncausal mechanisms in GCVAMD latent spaces, which can in turn be used for\nvarious tasks from AMD detection(classification) to intervention analysis.",
      "pdf_url": "http://arxiv.org/pdf/2510.02781v1",
      "arxiv_url": "http://arxiv.org/abs/2510.02781v1",
      "published": "2025-10-03",
      "categories": [
        "eess.IV",
        "cs.CV"
      ]
    }
  ]
}