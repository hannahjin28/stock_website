{
  "last_updated": "2026-01-18T01:03:45.057840",
  "papers": [
    {
      "title": "VERHallu: Evaluating and Mitigating Event Relation Hallucination in Video Large Language Models",
      "authors": [
        "Zefan Zhang",
        "Kehua Zhu",
        "Shijie Jiang",
        "Hongyuan Lu",
        "Shengkai Sun",
        "Tian Bai"
      ],
      "abstract": "Video Large Language Models (VideoLLMs) exhibit various types of hallucinations. Existing research has primarily focused on hallucinations involving the presence of events, objects, and scenes in videos, while largely neglecting event relation hallucination. In this paper, we introduce a novel benchmark for evaluating the Video Event Relation Hallucination, named VERHallu. This benchmark focuses on causal, temporal, and subevent relations between events, encompassing three types of tasks: relation classification, question answering, and counterfactual question answering, for a comprehensive evaluation of event relation hallucination. Additionally, it features counterintuitive video scenarios that deviate from typical pretraining distributions, with each sample accompanied by human-annotated candidates covering both vision-language and pure language biases. Our analysis reveals that current state-of-the-art VideoLLMs struggle with dense-event relation reasoning, often relying on prior knowledge due to insufficient use of frame-level cues. Although these models demonstrate strong grounding capabilities for key events, they often overlook the surrounding subevents, leading to an incomplete and inaccurate understanding of event relations. To tackle this, we propose a Key-Frame Propagating (KFP) strategy, which reallocates frame-level attention within intermediate layers to enhance multi-event understanding. Experiments show it effectively mitigates the event relation hallucination without affecting inference speed.",
      "pdf_url": "https://arxiv.org/pdf/2601.10010v1",
      "arxiv_url": "http://arxiv.org/abs/2601.10010v1",
      "published": "2026-01-15",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Where Knowledge Collides: A Mechanistic Study of Intra-Memory Knowledge Conflict in Language Models",
      "authors": [
        "Minh Vu Pham",
        "Hsuvas Borkakoty",
        "Yufang Hou"
      ],
      "abstract": "In language models (LMs), intra-memory knowledge conflict largely arises when inconsistent information about the same event is encoded within the model's parametric knowledge. While prior work has primarily focused on resolving conflicts between a model's internal knowledge and external resources through approaches such as fine-tuning or knowledge editing, the problem of localizing conflicts that originate during pre-training within the model's internal representations remain unexplored. In this work, we design a framework based on mechanistic interpretability methods to identify where and how conflicting knowledge from the pre-training data is encoded within LMs. Our findings contribute to a growing body of evidence that specific internal components of a language model are responsible for encoding conflicting knowledge from pre-training, and we demonstrate how mechanistic interpretability methods can be leveraged to causally intervene in and control conflicting knowledge at inference time.",
      "pdf_url": "https://arxiv.org/pdf/2601.09445v1",
      "arxiv_url": "http://arxiv.org/abs/2601.09445v1",
      "published": "2026-01-14",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Automatic debiased machine learning and sensitivity analysis for sample selection models",
      "authors": [
        "Jakob Bjelac",
        "Victor Chernozhukov",
        "Phil-Adrian Klotz",
        "Jannis Kueck",
        "Theresa M. A. Schmitz"
      ],
      "abstract": "In this paper, we extend the Riesz representation framework to causal inference under sample selection, where both treatment assignment and outcome observability are non-random. Formulating the problem in terms of a Riesz representer enables stable estimation and a transparent decomposition of omitted variable bias into three interpretable components: a data-identified scale factor, outcome confounding strength, and selection confounding strength. For estimation, we employ the ForestRiesz estimator, which accounts for selective outcome observability while avoiding the instability associated with direct propensity score inversion. We assess finite-sample performance through a simulation study and show that conventional double machine learning approaches can be highly sensitive to tuning parameters due to their reliance on inverse probability weighting, whereas the ForestRiesz estimator delivers more stable performance by leveraging automatic debiased machine learning. In an empirical application to the gender wage gap in the U.S., we find that our ForestRiesz approach yields larger treatment effect estimates than a standard double machine learning approach, suggesting that ignoring sample selection leads to an underestimation of the gender wage gap. Sensitivity analysis indicates that implausibly strong unobserved confounding would be required to overturn our results. Overall, our approach provides a unified, robust, and computationally attractive framework for causal inference under sample selection.",
      "pdf_url": "https://arxiv.org/pdf/2601.08643v1",
      "arxiv_url": "http://arxiv.org/abs/2601.08643v1",
      "published": "2026-01-13",
      "categories": [
        "econ.EM",
        "stat.ML"
      ]
    },
    {
      "title": "Relational Knowledge Distillation Using Fine-tuned Function Vectors",
      "authors": [
        "Andrea Kang",
        "Yingnian Wu",
        "Hongjing Lu"
      ],
      "abstract": "Representing relations between concepts is a core prerequisite for intelligent systems to make sense of the world. Recent work using causal mediation analysis has shown that a small set of attention heads encodes task representation in in-context learning, captured in a compact representation known as the function vector. We show that fine-tuning function vectors with only a small set of examples (about 20 word pairs) yields better performance on relation-based word-completion tasks than using the original vectors derived from causal mediation analysis. These improvements hold for both small and large language models. Moreover, the fine-tuned function vectors yield improved decoding performance for relation words and show stronger alignment with human similarity judgments of semantic relations. Next, we introduce the composite function vector - a weighted combination of fine-tuned function vectors - to extract relational knowledge and support analogical reasoning. At inference time, inserting this composite vector into LLM activations markedly enhances performance on challenging analogy problems drawn from cognitive science and SAT benchmarks. Our results highlight the potential of activation patching as a controllable mechanism for encoding and manipulating relational knowledge, advancing both the interpretability and reasoning capabilities of large language models.",
      "pdf_url": "https://arxiv.org/pdf/2601.08169v1",
      "arxiv_url": "http://arxiv.org/abs/2601.08169v1",
      "published": "2026-01-13",
      "categories": [
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "Debiasing Large Language Models via Adaptive Causal Prompting with Sketch-of-Thought",
      "authors": [
        "Bowen Li",
        "Ziqi Xu",
        "Jing Ren",
        "Renqiang Luo",
        "Xikun Zhang",
        "Xiuzhen Zhang",
        "Yongli Ren",
        "Feng Xia"
      ],
      "abstract": "Despite notable advancements in prompting methods for Large Language Models (LLMs), such as Chain-of-Thought (CoT), existing strategies still suffer from excessive token usage and limited generalisability across diverse reasoning tasks. To address these limitations, we propose an Adaptive Causal Prompting with Sketch-of-Thought (ACPS) framework, which leverages structural causal models to infer the causal effect of a query on its answer and adaptively select an appropriate intervention (i.e., standard front-door and conditional front-door adjustments). This design enables generalisable causal reasoning across heterogeneous tasks without task-specific retraining. By replacing verbose CoT with concise Sketch-of-Thought, ACPS enables efficient reasoning that significantly reduces token usage and inference cost. Extensive experiments on multiple reasoning benchmarks and LLMs demonstrate that ACPS consistently outperforms existing prompting baselines in terms of accuracy, robustness, and computational efficiency.",
      "pdf_url": "https://arxiv.org/pdf/2601.08108v1",
      "arxiv_url": "http://arxiv.org/abs/2601.08108v1",
      "published": "2026-01-13",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "The Role of Confounders and Linearity in Ecological Inference: A Reassessment",
      "authors": [
        "Shiro Kuriwaki",
        "Cory McCartan"
      ],
      "abstract": "Estimating conditional means using only the marginal means available from aggregate data is commonly known as the ecological inference problem (EI). We provide a reassessment of EI, including a new formalization of identification conditions and a demonstration of how these conditions fail to hold in common cases. The identification conditions reveal that, similar to causal inference, credible ecological inference requires controlling for confounders. The aggregation process itself creates additional structure to assist in estimation by restricting the conditional expectation function to be linear in the predictor variable. A linear model perspective also clarifies the differences between the EI methods commonly used in the literature, and when they lead to ecological fallacies. We provide an overview of new methodology which builds on both the identification and linearity results to flexibly control for confounders and yield improved ecological inferences. Finally, using datasets for common EI problems in which the ground truth is fortuitously observed, we show that, while covariates can help, all methods are prone to overestimating both racial polarization and nationalized partisan voting.",
      "pdf_url": "https://arxiv.org/pdf/2601.07668v1",
      "arxiv_url": "http://arxiv.org/abs/2601.07668v1",
      "published": "2026-01-12",
      "categories": [
        "stat.AP"
      ]
    },
    {
      "title": "Functional Synthetic Control Methods for Metric Space-Valued Outcomes",
      "authors": [
        "Ryo Okano",
        "Daisuke Kurisu"
      ],
      "abstract": "The synthetic control method (SCM) is a widely used tool for evaluating causal effects of policy changes in panel data settings. Recent studies have extended its framework to accommodate complex outcomes that take values in metric spaces, such as distributions, functions, networks, covariance matrices, and compositional data. However, due to the lack of linear structure in general metric spaces, theoretical guarantees for estimation and inference within these extended frameworks remain underdeveloped. In this study, we propose the functional synthetic control (FSC) method as an extension of the SCM for metric space-valued outcomes. To address challenges arising from the nonlinearlity of metric spaces, we leverage isometric embeddings into Hilbert spaces. Building on this approach, we develop the FSC and augmented FSC estimators for counterfactual outcomes, with the latter being a bias-corrected version of the former. We then derive their finite-sample error bounds to establish theoretical guarantees for estimation, and construct prediction sets based on these estimators to conduct inference on causal effects. We demonstrate the usefulness of the proposed framework through simulation studies and three empirical applications.",
      "pdf_url": "https://arxiv.org/pdf/2601.07539v1",
      "arxiv_url": "http://arxiv.org/abs/2601.07539v1",
      "published": "2026-01-12",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Minimum Wasserstein distance estimator under covariate shift: closed-form, super-efficiency and irregularity",
      "authors": [
        "Junjun Lang",
        "Qiong Zhang",
        "Yukun Liu"
      ],
      "abstract": "Covariate shift arises when covariate distributions differ between source and target populations while the conditional distribution of the response remains invariant, and it underlies problems in missing data and causal inference. We propose a minimum Wasserstein distance estimation framework for inference under covariate shift that avoids explicit modeling of outcome regressions or importance weights. The resulting W-estimator admits a closed-form expression and is numerically equivalent to the classical 1-nearest neighbor estimator, yielding a new optimal transport interpretation of nearest neighbor methods. We establish root-$n$ asymptotic normality and show that the estimator is not asymptotically linear, leading to super-efficiency relative to the semiparametric efficient estimator under covariate shift in certain regimes, and uniformly in missing data problems. Numerical simulations, along with an analysis of a rainfall dataset, underscore the exceptional performance of our W-estimator.",
      "pdf_url": "https://arxiv.org/pdf/2601.07282v1",
      "arxiv_url": "http://arxiv.org/abs/2601.07282v1",
      "published": "2026-01-12",
      "categories": [
        "stat.ME",
        "stat.ML"
      ]
    },
    {
      "title": "Connections as treatment: causal inference with edge interventions in networks",
      "authors": [
        "Shuli Chen",
        "Jie Hu",
        "Zhichao Jiang"
      ],
      "abstract": "Causal inference has traditionally focused on interventions at the unit level. In many applications, however, the central question concerns the causal effects of connections between units, such as transportation links, social relationships, or collaborative ties. We develop a causal framework for edge interventions in networks, where treatments correspond to the presence or absence of edges. Our framework defines causal estimands under stochastic interventions on the network structure and introduces an inverse probability weighting estimator under an unconfoundedness assumption on edge assignment. We estimate edge probabilities using exponential random graph models, a widely used class of network models. We establish consistency and asymptotic normality of the proposed estimator. Finally, we apply our methodology to China's transportation network to estimate the causal impact of railroad connections on regional economic development.",
      "pdf_url": "https://arxiv.org/pdf/2601.07267v1",
      "arxiv_url": "http://arxiv.org/abs/2601.07267v1",
      "published": "2026-01-12",
      "categories": [
        "stat.ME",
        "stat.AP"
      ]
    },
    {
      "title": "MeepleLM: A Virtual Playtester Simulating Diverse Subjective Experiences",
      "authors": [
        "Zizhen Li",
        "Chuanhao Li",
        "Yibin Wang",
        "Yukang Feng",
        "Jianwen Sun",
        "Jiaxin Ai",
        "Fanrui Zhang",
        "Mingzhu Sun",
        "Yifei Huang",
        "Kaipeng Zhang"
      ],
      "abstract": "Recent advancements have expanded the role of Large Language Models in board games from playing agents to creative co-designers. However, a critical gap remains: current systems lack the capacity to offer constructive critique grounded in the emergent user experience. Bridging this gap is fundamental for harmonizing Human-AI collaboration, as it empowers designers to refine their creations via external perspectives while steering models away from biased or unpredictable outcomes. Automating critique for board games presents two challenges: inferring the latent dynamics connecting rules to gameplay without an explicit engine, and modeling the subjective heterogeneity of diverse player groups. To address these, we curate a dataset of 1,727 structurally corrected rulebooks and 150K reviews selected via quality scoring and facet-aware sampling. We augment this data with Mechanics-Dynamics-Aesthetics (MDA) reasoning to explicitly bridge the causal gap between written rules and player experience. We further distill player personas and introduce MeepleLM, a specialized model that internalizes persona-specific reasoning patterns to accurately simulate the subjective feedback of diverse player archetypes. Experiments demonstrate that MeepleLM significantly outperforms latest commercial models (e.g., GPT-5.1, Gemini3-Pro) in community alignment and critique quality, achieving a 70% preference rate in user studies assessing utility. MeepleLM serves as a reliable virtual playtester for general interactive systems, marking a pivotal step towards audience-aligned, experience-aware Human-AI collaboration.",
      "pdf_url": "https://arxiv.org/pdf/2601.07251v1",
      "arxiv_url": "http://arxiv.org/abs/2601.07251v1",
      "published": "2026-01-12",
      "categories": [
        "cs.HC"
      ]
    }
  ]
}