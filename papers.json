{
  "last_updated": "2025-12-28T01:04:11.901419",
  "papers": [
    {
      "title": "Causal-driven attribution (CDA): Estimating channel influence without user-level data",
      "authors": [
        "Georgios Filippou",
        "Boi Mai Quach",
        "Diana Lenghel",
        "Arthur White",
        "Ashish Kumar Jha"
      ],
      "abstract": "Attribution modelling lies at the heart of marketing effectiveness, yet most existing approaches depend on user-level path data, which are increasingly inaccessible due to privacy regulations and platform restrictions. This paper introduces a Causal-Driven Attribution (CDA) framework that infers channel influence using only aggregated impression-level data, avoiding any reliance on user identifiers or click-path tracking. CDA integrates temporal causal discovery (using PCMCI) with causal effect estimation via a Structural Causal Model to recover directional channel relationships and quantify their contributions to conversions. Using large-scale synthetic data designed to replicate real marketing dynamics, we show that CDA achieves an average relative RMSE of 9.50% when given the true causal graph, and 24.23% when using the predicted graph, demonstrating strong accuracy under correct structure and meaningful signal recovery even under structural uncertainty. CDA captures cross-channel interdependencies while providing interpretable, privacy-preserving attribution insights, offering a scalable and future-proof alternative to traditional path-based models.",
      "pdf_url": "https://arxiv.org/pdf/2512.21211v1",
      "arxiv_url": "http://arxiv.org/abs/2512.21211v1",
      "published": "2025-12-24",
      "categories": [
        "stat.ML",
        "cs.LG"
      ]
    },
    {
      "title": "Hierarchical Modeling Approach to Fast and Accurate Table Recognition",
      "authors": [
        "Takaya Kawakatsu"
      ],
      "abstract": "The extraction and use of diverse knowledge from numerous documents is a pressing challenge in intelligent information retrieval. Documents contain elements that require different recognition methods. Table recognition typically consists of three subtasks, namely table structure, cell position and cell content recognition. Recent models have achieved excellent recognition with a combination of multi-task learning, local attention, and mutual learning. However, their effectiveness has not been fully explained, and they require a long period of time for inference. This paper presents a novel multi-task model that utilizes non-causal attention to capture the entire table structure, and a parallel inference algorithm for faster cell content inference. The superiority is demonstrated both visually and statistically on two large public datasets.",
      "pdf_url": "https://arxiv.org/pdf/2512.21083v1",
      "arxiv_url": "http://arxiv.org/abs/2512.21083v1",
      "published": "2025-12-24",
      "categories": [
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "title": "Clever Hans in Chemistry: Chemist Style Signals Confound Activity Prediction on Public Benchmarks",
      "authors": [
        "Andrew D. Blevins",
        "Ian K. Quigley"
      ],
      "abstract": "Can machine learning models identify which chemist made a molecule from structure alone? If so, models trained on literature data may exploit chemist intent rather than learning causal structure-activity relationships. We test this by linking CHEMBL assays to publication authors and training a 1,815-class classifier to predict authors from molecular fingerprints, achieving 60% top-5 accuracy under scaffold-based splitting. We then train an activity model that receives only a protein identifier and an author-probability vector derived from structure, with no direct access to molecular descriptors. This author-only model achieves predictive power comparable to a simple baseline that has access to structure. This reveals a \"Clever Hans\" failure mode: models can predict bioactivity largely by inferring chemist goals and favorite targets without requiring a lab-independent understanding of chemistry. We analyze the sources of this leakage, propose author-disjoint splits, and recommend dataset practices to decouple chemist intent from biological outcomes.",
      "pdf_url": "https://arxiv.org/pdf/2512.20924v1",
      "arxiv_url": "http://arxiv.org/abs/2512.20924v1",
      "published": "2025-12-24",
      "categories": [
        "q-bio.BM",
        "cs.LG",
        "physics.chem-ph"
      ]
    },
    {
      "title": "Generalization of RLVR Using Causal Reasoning as a Testbed",
      "authors": [
        "Brian Lu",
        "Hongyu Zhao",
        "Shuo Sun",
        "Hao Peng",
        "Rui Ding",
        "Hongyuan Mei"
      ],
      "abstract": "Reinforcement learning with verifiable rewards (RLVR) has emerged as a promising paradigm for post-training large language models (LLMs) on complex reasoning tasks. Yet, the conditions under which RLVR yields robust generalization remain poorly understood. This paper provides an empirical study of RLVR generalization in the setting of probabilistic inference over causal graphical models. This setting offers two natural axes along which to examine generalization: (i) the level of the probabilistic query -- associational, interventional, or counterfactual -- and (ii) the structural complexity of the query, measured by the size of its relevant subgraph. We construct datasets of causal graphs and queries spanning these difficulty axes and fine-tune Qwen-2.5-Instruct models using RLVR or supervised fine-tuning (SFT). We vary both the model scale (3B-32B) and the query level included in training. We find that RLVR yields stronger within-level and across-level generalization than SFT, but only for specific combinations of model size and training query level. Further analysis shows that RLVR's effectiveness depends on the model's initial reasoning competence. With sufficient initial competence, RLVR improves an LLM's marginalization strategy and reduces errors in intermediate probability calculations, producing substantial accuracy gains, particularly on more complex queries. These findings show that RLVR can improve specific causal reasoning subskills, with its benefits emerging only when the model has sufficient initial competence.",
      "pdf_url": "https://arxiv.org/pdf/2512.20760v1",
      "arxiv_url": "http://arxiv.org/abs/2512.20760v1",
      "published": "2025-12-23",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Information-theoretic signatures of causality in Bayesian networks and hypergraphs",
      "authors": [
        "Sung En Chiang",
        "Zhaolu Liu",
        "Robert L. Peach",
        "Mauricio Barahona"
      ],
      "abstract": "Analyzing causality in multivariate systems involves establishing how information is generated, distributed and combined, and thus requires tools that capture interactions beyond pairwise relations. Higher-order information theory provides such tools. In particular, Partial Information Decomposition (PID) allows the decomposition of the information that a set of sources provides about a target into redundant, unique, and synergistic components. Yet the mathematical connection between such higher-order information-theoretic measures and causal structure remains undeveloped. Here we establish the first theoretical correspondence between PID components and causal structure in both Bayesian networks and hypergraphs. We first show that in Bayesian networks unique information precisely characterizes direct causal neighbors, while synergy identifies collider relationships. This establishes a localist causal discovery paradigm in which the structure surrounding each variable can be recovered from its immediate informational footprint, eliminating the need for global search over graph space. Extending these results to higher-order systems, we prove that PID signatures in Bayesian hypergraphs differentiate parents, children, co-heads, and co-tails, revealing a higher-order collider effect unique to multi-tail hyperedges. We also present procedures by which our results can be used to characterize systematically the causal structure of Bayesian networks and hypergraphs. Our results position PID as a rigorous, model-agnostic foundation for inferring both pairwise and higher-order causal structure, and introduce a fundamentally local information-theoretic viewpoint on causal discovery.",
      "pdf_url": "https://arxiv.org/pdf/2512.20552v1",
      "arxiv_url": "http://arxiv.org/abs/2512.20552v1",
      "published": "2025-12-23",
      "categories": [
        "cs.IT",
        "stat.ML"
      ]
    },
    {
      "title": "ScoreMatchingRiesz: Auto-DML with Infinitesimal Classification",
      "authors": [
        "Masahiro Kato"
      ],
      "abstract": "This study proposes Riesz representer estimation methods based on score matching. The Riesz representer is a key component in debiased machine learning for constructing $\\sqrt{n}$-consistent and efficient estimators in causal inference and structural parameter estimation. To estimate the Riesz representer, direct approaches have garnered attention, such as Riesz regression and the covariate balancing propensity score. These approaches can also be interpreted as variants of direct density ratio estimation (DRE) in several applications such as average treatment effect estimation. In DRE, it is well known that flexible models can easily overfit the observed data due to the estimand and the form of the loss function. To address this issue, recent work has proposed modeling the density ratio as a product of multiple intermediate density ratios and estimating it using score-matching techniques, which are often used in the diffusion model literature. We extend score-matching-based DRE methods to Riesz representer estimation. Our proposed method not only mitigates overfitting but also provides insights for causal inference by bridging marginal effects and average policy effects through time score functions.",
      "pdf_url": "https://arxiv.org/pdf/2512.20523v1",
      "arxiv_url": "http://arxiv.org/abs/2512.20523v1",
      "published": "2025-12-23",
      "categories": [
        "econ.EM",
        "cs.LG",
        "math.ST",
        "stat.ME",
        "stat.ML"
      ]
    },
    {
      "title": "Exploring the nature of gravity with quantum information methods",
      "authors": [
        "Bruna Sahdo",
        "Natália Salomé Móller"
      ],
      "abstract": "The aim of this article is to provide an introduction to the use of quantum information methods for investigating the interface between quantum theory and gravity. To this end, we discuss the basic principles of two current research streams that use this approach. The first one explores a phenomenon known as gravitationally induced entanglement, which aims to infer whether the gravitational field responsible for the interaction between two massive bodies must be quantized or not. The second stream investigates causal structures, thereby providing indirect evidence that spacetime may exhibit non-classical behavior. Before presenting these topics, we briefly review some fundamental concepts and experiments from quantum information theory, such as the Mach-Zehnder interferometer, the Stern-Gerlach experiment, Bell inequalities and entanglement, and the language of quantum circuits.",
      "pdf_url": "https://arxiv.org/pdf/2512.20429v1",
      "arxiv_url": "http://arxiv.org/abs/2512.20429v1",
      "published": "2025-12-23",
      "categories": [
        "quant-ph",
        "gr-qc"
      ]
    },
    {
      "title": "Estimation and Inference for Causal Explainability",
      "authors": [
        "Weihan Zhang",
        "Zijun Gao"
      ],
      "abstract": "Understanding how much each variable contributes to an outcome is a central question across disciplines. A causal view of explainability is favorable for its ability in uncovering underlying mechanisms and generalizing to new contexts. Based on a family of causal explainability quantities, we develop methods for their estimation and inference. In particular, we construct a one-step correction estimator using semi-parametric efficiency theory, which explicitly leverages the independence structure of variables to reduce the asymptotic variance. For a null hypothesis on the boundary, i.e., zero explainability, we show its equivalence to Fisher's sharp null, which motivates a randomization-based inference procedure. Finally, we illustrate the empirical efficacy of our approach through simulations as well as an immigration experiment dataset, where we investigate how features and their interactions shape public opinion toward admitting immigrants.",
      "pdf_url": "https://arxiv.org/pdf/2512.20219v2",
      "arxiv_url": "http://arxiv.org/abs/2512.20219v2",
      "published": "2025-12-23",
      "categories": [
        "stat.ME",
        "stat.AP"
      ]
    },
    {
      "title": "Causal Inference with the \"Napkin Graph\"",
      "authors": [
        "Anna Guo",
        "David Benkeser",
        "Razieh Nabi"
      ],
      "abstract": "Unmeasured confounding can render identification strategies based on adjustment functionals invalid. We study the \"Napkin graph\", a causal structure that encapsulates patterns of M-bias, instrumental variables, and the classical back-door and front-door models within a single graphical framework, yet requires a nonstandard identification strategy: the average treatment effect is expressed as a ratio of two g-formulas. We develop novel estimators for this functional, including doubly robust one-step and targeted minimum loss-based estimators that remain asymptotically linear when nuisance functions are estimated at slower-than-parametric rates using machine learning. We also show how a generalized independence restriction encoded by the Napkin graph, known as a Verma constraint, can be exploited to improve efficiency, illustrating more generally how such constraints in hidden variable DAGs can inform semiparametric inference. The proposed methods are validated through simulations and applied to the Finnish Life Course study to estimate the effect of educational attainment on income. An accompanying R package, napkincausal, implements all proposed procedures.",
      "pdf_url": "https://arxiv.org/pdf/2512.19861v1",
      "arxiv_url": "http://arxiv.org/abs/2512.19861v1",
      "published": "2025-12-22",
      "categories": [
        "stat.ME",
        "stat.ML"
      ]
    },
    {
      "title": "Toward Scalable and Valid Conditional Independence Testing with Spectral Representations",
      "authors": [
        "Alek Frohlich",
        "Vladimir Kostic",
        "Karim Lounici",
        "Daniel Perazzo",
        "Massimiliano Pontil"
      ],
      "abstract": "Conditional independence (CI) is central to causal inference, feature selection, and graphical modeling, yet it is untestable in many settings without additional assumptions. Existing CI tests often rely on restrictive structural conditions, limiting their validity on real-world data. Kernel methods using the partial covariance operator offer a more principled approach but suffer from limited adaptivity, slow convergence, and poor scalability. In this work, we explore whether representation learning can help address these limitations. Specifically, we focus on representations derived from the singular value decomposition of the partial covariance operator and use them to construct a simple test statistic, reminiscent of the Hilbert-Schmidt Independence Criterion (HSIC). We also introduce a practical bi-level contrastive algorithm to learn these representations. Our theory links representation learning error to test performance and establishes asymptotic validity and power guarantees. Preliminary experiments suggest that this approach offers a practical and statistically grounded path toward scalable CI testing, bridging kernel-based theory with modern representation learning.",
      "pdf_url": "https://arxiv.org/pdf/2512.19510v1",
      "arxiv_url": "http://arxiv.org/abs/2512.19510v1",
      "published": "2025-12-22",
      "categories": [
        "cs.LG",
        "stat.ML"
      ]
    }
  ]
}