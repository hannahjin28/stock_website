{
  "last_updated": "2025-08-06T01:00:05.073511",
  "papers": [
    {
      "title": "Causality and Interpretability for Electrical Distribution System faults",
      "authors": [
        "Karthik Peddi",
        "Sai Ram Aditya Parisineni",
        "Hemanth Macharla",
        "Mayukha Pal"
      ],
      "abstract": "Causal analysis helps us understand variables that are responsible for system\nfailures. This improves fault detection and makes system more reliable. In this\nwork, we present a new method that combines causal inference with machine\nlearning to classify faults in electrical distribution systems (EDS) using\ngraph-based models. We first build causal graphs using transfer entropy (TE).\nEach fault case is represented as a graph, where the nodes are features such as\nvoltage and current, and the edges demonstrate how these features influence\neach other. Then, the graphs are classified using machine learning and\nGraphSAGE where the model learns from both the node values and the structure of\nthe graph to predict the type of fault. To make the predictions understandable,\nwe further developed an integrated approach using GNNExplainer and Captums\nIntegrated Gradients to highlight the nodes (features) that influences the most\non the final prediction. This gives us clear insights into the possible causes\nof the fault. Our experiments show high accuracy: 99.44% on the EDS fault\ndataset, which is better than state of art models. By combining causal graphs\nwith machine learning, our method not only predicts faults accurately but also\nhelps understand their root causes. This makes it a strong and practical tool\nfor improving system reliability.",
      "pdf_url": "http://arxiv.org/pdf/2508.02524v1",
      "arxiv_url": "http://arxiv.org/abs/2508.02524v1",
      "published": "2025-08-04",
      "categories": [
        "eess.SY",
        "cs.LG",
        "cs.SY"
      ]
    },
    {
      "title": "CITS: Nonparametric Statistical Causal Modeling for High-Resolution Neural Time Series",
      "authors": [
        "Rahul Biswas",
        "SuryaNarayana Sripada",
        "Somabha Mukherjee",
        "Reza Abbasi-Asl"
      ],
      "abstract": "Understanding how signals propagate through neural circuits is central to\ndeciphering brain computation. While functional connectivity captures\nstatistical associations, it does not reveal directionality or causal\nmechanisms. We introduce CITS (Causal Inference in Time Series), a\nnon-parametric method for inferring statistically causal neural circuitry from\nhigh-resolution time series data. CITS models neural dynamics using a\nstructural causal model with arbitrary Markov order and tests for time-lagged\nconditional independence using either Gaussian or distribution-free statistics.\nUnlike classical Granger Causality, which assumes linear autoregressive models\nand Gaussian noise, or the Peter-Clark algorithm, which assumes i.i.d. data and\nno temporal structure, CITS handles temporally dependent, potentially\nnon-Gaussian data with flexible testing procedures. We prove consistency under\nmild mixing assumptions and validate CITS on simulated linear, nonlinear, and\ncontinuous-time recurrent neural network data, where it outperforms\nstate-of-the-art methods. We then apply CITS to Neuropixels recordings from\nmouse brain during visual tasks. CITS uncovers interpretable, stimulus-specific\ncausal circuits linking cortical, thalamic, and hippocampal regions, consistent\nwith experimental literature. It also reveals that neurons with similar\norientation selectivity indices are more likely to be causally connected. Our\nresults demonstrate the utility of CITS in uncovering biologically meaningful\npathways and generating hypotheses for future experimental studies.",
      "pdf_url": "http://arxiv.org/pdf/2508.01920v1",
      "arxiv_url": "http://arxiv.org/abs/2508.01920v1",
      "published": "2025-08-03",
      "categories": [
        "q-bio.NC",
        "q-bio.QM",
        "stat.AP"
      ]
    },
    {
      "title": "Structure Maintained Representation Learning Neural Network for Causal Inference",
      "authors": [
        "Yang Sun",
        "Wenbin Lu",
        "Yi-Hui Zhou"
      ],
      "abstract": "Recent developments in causal inference have greatly shifted the interest\nfrom estimating the average treatment effect to the individual treatment\neffect. In this article, we improve the predictive accuracy of representation\nlearning and adversarial networks in estimating individual treatment effects by\nintroducing a structure keeper which maintains the correlation between the\nbaseline covariates and their corresponding representations in the high\ndimensional space. We train a discriminator at the end of representation layers\nto trade off representation balance and information loss. We show that the\nproposed discriminator minimizes an upper bound of the treatment estimation\nerror. We can address the tradeoff between distribution balance and information\nloss by considering the correlations between the learned representation space\nand the original covariate feature space. We conduct extensive experiments with\nsimulated and real-world observational data to show that our proposed Structure\nMaintained Representation Learning (SMRL) algorithm outperforms\nstate-of-the-art methods. We also demonstrate the algorithms on real electronic\nhealth record data from the MIMIC-III database.",
      "pdf_url": "http://arxiv.org/pdf/2508.01865v1",
      "arxiv_url": "http://arxiv.org/abs/2508.01865v1",
      "published": "2025-08-03",
      "categories": [
        "stat.ML",
        "cs.LG",
        "stat.ME"
      ]
    },
    {
      "title": "Anchoring-Based Causal Design (ABCD): Estimating the Effects of Beliefs",
      "authors": [
        "Raanan Sulitzeanu-Kenan",
        "Micha Mandel",
        "Yosef Rinott"
      ],
      "abstract": "A central challenge in any study of the effects of beliefs on outcomes, such\nas decisions and behavior, is the risk of omitted variables bias. Omitted\nvariables, frequently unmeasured or even unknown, can induce correlations\nbetween beliefs and decisions that are not genuinely causal, in which case the\nomitted variables are referred to as confounders. To address the challenge of\ncausal inference, researchers frequently rely on information provision\nexperiments to randomly manipulate beliefs. The information supplied in these\nexperiments can serve as an instrumental variable (IV), enabling causal\ninference, so long as it influences decisions exclusively through its impact on\nbeliefs. However, providing varying information to participants to shape their\nbeliefs can raise both methodological and ethical concerns. Methodological\nconcerns arise from potential violations of the exclusion restriction\nassumption. Such violations may stem from information source effects, when\nattitudes toward the source affect the outcome decision directly, thereby\nintroducing a confounder. An ethical concern arises from manipulating the\nprovided information, as it may involve deceiving participants. This paper\nproposes and empirically demonstrates a new method for treating beliefs and\nestimating their effects, the Anchoring-Based Causal Design (ABCD), which\navoids deception and source influences. ABCD combines the cognitive mechanism\nknown as anchoring with instrumental variable (IV) estimation. Instead of\nproviding substantive information, the method employs a deliberately\nnon-informative procedure in which participants compare their self-assessment\nof a concept to a randomly assigned anchor value. We present the method and the\nresults of eight experiments demonstrating its application, strengths, and\nlimitations. We conclude by discussing the potential of this design for\nadvancing experimental social science.",
      "pdf_url": "http://arxiv.org/pdf/2508.01677v1",
      "arxiv_url": "http://arxiv.org/abs/2508.01677v1",
      "published": "2025-08-03",
      "categories": [
        "econ.GN",
        "q-fin.EC",
        "stat.ME"
      ]
    },
    {
      "title": "Debiasing Machine Learning Predictions for Causal Inference Without Additional Ground Truth Data: \"One Map, Many Trials\" in Satellite-Driven Poverty Analysis",
      "authors": [
        "Markus Pettersson",
        "Connor T. Jerzak",
        "Adel Daoud"
      ],
      "abstract": "Machine learning models trained on Earth observation data, such as satellite\nimagery, have demonstrated significant promise in predicting household-level\nwealth indices, enabling the creation of high-resolution wealth maps that can\nbe leveraged across multiple causal trials. However, because standard training\nobjectives prioritize overall predictive accuracy, these predictions inherently\nsuffer from shrinkage toward the mean, leading to attenuated estimates of\ncausal treatment effects and limiting their utility in policy. Existing\ndebiasing methods, such as Prediction-Powered Inference, can handle this\nattenuation bias but require additional fresh ground-truth data at the\ndownstream stage of causal inference, which restricts their applicability in\ndata-scarce environments. Here, we introduce and evaluate two correction\nmethods -- linear calibration correction and Tweedie's correction -- that\nsubstantially reduce prediction bias without relying on newly collected labeled\ndata. Linear calibration corrects bias through a straightforward linear\ntransformation derived from held-out calibration data, whereas Tweedie's\ncorrection leverages empirical Bayes principles to directly address\nshrinkage-induced biases by exploiting score functions derived from the model's\nlearning patterns. Through analytical exercises and experiments using\nDemographic and Health Survey data, we demonstrate that the proposed methods\nmeet or outperform existing approaches that either require (a) adjustments to\ntraining pipelines or (b) additional labeled data. These approaches may\nrepresent a promising avenue for improving the reliability of causal inference\nwhen direct outcome measures are limited or unavailable, enabling a \"one map,\nmany trials\" paradigm where a single upstream data creation team produces\npredictions usable by many downstream teams across diverse ML pipelines.",
      "pdf_url": "http://arxiv.org/pdf/2508.01341v1",
      "arxiv_url": "http://arxiv.org/abs/2508.01341v1",
      "published": "2025-08-02",
      "categories": [
        "stat.ML",
        "cs.LG",
        "62C12",
        "H.3"
      ]
    },
    {
      "title": "Flow IV: Counterfactual Inference In Nonseparable Outcome Models Using Instrumental Variables",
      "authors": [
        "Marc Braun",
        "Jose M. Pe√±a",
        "Adel Daoud"
      ],
      "abstract": "To reach human level intelligence, learning algorithms need to incorporate\ncausal reasoning. But identifying causality, and particularly counterfactual\nreasoning, remains an elusive task. In this paper, we make progress on this\ntask by utilizing instrumental variables (IVs). IVs are a classic tool for\nmitigating bias from unobserved confounders when estimating causal effects.\nWhile IV methods have been extended to non-separable structural models at the\npopulation level, existing approaches to counterfactual prediction typically\nassume additive noise in the outcome. In this paper, we show that under\nstandard IV assumptions, along with the assumptions that latent noises in\ntreatment and outcome are strictly monotonic and jointly Gaussian, the\ntreatment-outcome relationship becomes uniquely identifiable from observed\ndata. This enables counterfactual inference even in nonseparable models. We\nimplement our approach by training a normalizing flow to maximize the\nlikelihood of the observed data, demonstrating accurate recovery of the\nunderlying outcome function. We call our method Flow IV.",
      "pdf_url": "http://arxiv.org/pdf/2508.01321v1",
      "arxiv_url": "http://arxiv.org/abs/2508.01321v1",
      "published": "2025-08-02",
      "categories": [
        "stat.ML",
        "cs.LG"
      ]
    },
    {
      "title": "Frugal, Flexible, Faithful: Causal Data Simulation via Frengression",
      "authors": [
        "Linying Yang",
        "Robin J. Evans",
        "Xinwei Shen"
      ],
      "abstract": "Machine learning has revitalized causal inference by combining flexible\nmodels and principled estimators, yet robust benchmarking and evaluation remain\nchallenging with real-world data. In this work, we introduce frengression, a\ndeep generative realization of the frugal parameterization that models the\njoint distribution of covariates, treatments and outcomes around the causal\nmargin of interest. Frengression provides accurate estimation and flexible,\nfaithful simulation of multivariate, time-varying data; it also enables direct\nsampling from user-specified interventional distributions. Model consistency\nand extrapolation guarantees are established, with validation on real-world\nclinical trial data demonstrating frengression's practical utility. We envision\nthis framework sparking new research into generative approaches for causal\nmargin modelling.",
      "pdf_url": "http://arxiv.org/pdf/2508.01018v1",
      "arxiv_url": "http://arxiv.org/abs/2508.01018v1",
      "published": "2025-08-01",
      "categories": [
        "stat.ME",
        "stat.ML"
      ]
    },
    {
      "title": "Harnessing the Power of Interleaving and Counterfactual Evaluation for Airbnb Search Ranking",
      "authors": [
        "Qing Zhang",
        "Alex Deng",
        "Michelle Du",
        "Huiji Gao",
        "Liwei He",
        "Sanjeev Katariya"
      ],
      "abstract": "Evaluation plays a crucial role in the development of ranking algorithms on\nsearch and recommender systems. It enables online platforms to create\nuser-friendly features that drive commercial success in a steady and effective\nmanner. The online environment is particularly conducive to applying causal\ninference techniques, such as randomized controlled experiments (known as A/B\ntest), which are often more challenging to implement in fields like medicine\nand public policy. However, businesses face unique challenges when it comes to\neffective A/B test. Specifically, achieving sufficient statistical power for\nconversion-based metrics can be time-consuming, especially for significant\npurchases like booking accommodations. While offline evaluations are quicker\nand more cost-effective, they often lack accuracy and are inadequate for\nselecting candidates for A/B test. To address these challenges, we developed\ninterleaving and counterfactual evaluation methods to facilitate rapid online\nassessments for identifying the most promising candidates for A/B tests. Our\napproach not only increased the sensitivity of experiments by a factor of up to\n100 (depending on the approach and metrics) compared to traditional A/B testing\nbut also streamlined the experimental process. The practical insights gained\nfrom usage in production can also benefit organizations with similar interests.",
      "pdf_url": "http://arxiv.org/pdf/2508.00751v1",
      "arxiv_url": "http://arxiv.org/abs/2508.00751v1",
      "published": "2025-08-01",
      "categories": [
        "cs.IR",
        "cs.AI",
        "H.3; G.3"
      ]
    },
    {
      "title": "Multi-Band Variable-Lag Granger Causality: A Unified Framework for Causal Time Series Inference across Frequencies",
      "authors": [
        "Chakattrai Sookkongwaree",
        "Tattep Lakmuang",
        "Chainarong Amornbunchornvej"
      ],
      "abstract": "Understanding causal relationships in time series is fundamental to many\ndomains, including neuroscience, economics, and behavioral science. Granger\ncausality is one of the well-known techniques for inferring causality in time\nseries. Typically, Granger causality frameworks have a strong fix-lag\nassumption between cause and effect, which is often unrealistic in complex\nsystems. While recent work on variable-lag Granger causality (VLGC) addresses\nthis limitation by allowing a cause to influence an effect with different time\nlags at each time point, it fails to account for the fact that causal\ninteractions may vary not only in time delay but also across frequency bands.\nFor example, in brain signals, alpha-band activity may influence another region\nwith a shorter delay than slower delta-band oscillations. In this work, we\nformalize Multi-Band Variable-Lag Granger Causality (MB-VLGC) and propose a\nnovel framework that generalizes traditional VLGC by explicitly modeling\nfrequency-dependent causal delays. We provide a formal definition of MB-VLGC,\ndemonstrate its theoretical soundness, and propose an efficient inference\npipeline. Extensive experiments across multiple domains demonstrate that our\nframework significantly outperforms existing methods on both synthetic and\nreal-world datasets, confirming its broad applicability to any type of time\nseries data. Code and datasets are publicly available.",
      "pdf_url": "http://arxiv.org/pdf/2508.00658v1",
      "arxiv_url": "http://arxiv.org/abs/2508.00658v1",
      "published": "2025-08-01",
      "categories": [
        "cs.AI",
        "cs.LG",
        "econ.EM",
        "stat.ME"
      ]
    },
    {
      "title": "The Missing Parts: Augmenting Fact Verification with Half-Truth Detection",
      "authors": [
        "Yixuan Tang",
        "Jincheng Wang",
        "Anthony K. H. Tung"
      ],
      "abstract": "Fact verification systems typically assess whether a claim is supported by\nretrieved evidence, assuming that truthfulness depends solely on what is\nstated. However, many real-world claims are half-truths, factually correct yet\nmisleading due to the omission of critical context. Existing models struggle\nwith such cases, as they are not designed to reason about what is left unsaid.\nWe introduce the task of half-truth detection, and propose PolitiFact-Hidden, a\nnew benchmark with 15k political claims annotated with sentence-level evidence\nalignment and inferred claim intent. To address this challenge, we present\nTRACER, a modular re-assessment framework that identifies omission-based\nmisinformation by aligning evidence, inferring implied intent, and estimating\nthe causal impact of hidden content. TRACER can be integrated into existing\nfact-checking pipelines and consistently improves performance across multiple\nstrong baselines. Notably, it boosts Half-True classification F1 by up to 16\npoints, highlighting the importance of modeling omissions for trustworthy fact\nverification.",
      "pdf_url": "http://arxiv.org/pdf/2508.00489v1",
      "arxiv_url": "http://arxiv.org/abs/2508.00489v1",
      "published": "2025-08-01",
      "categories": [
        "cs.CL"
      ]
    }
  ]
}