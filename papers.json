{
  "last_updated": "2026-01-07T00:59:18.913265",
  "papers": [
    {
      "title": "Causal inference for censored data with continuous marks",
      "authors": [
        "Lianqiang Qu",
        "Long Lv",
        "Liuquan Sun"
      ],
      "abstract": "This paper presents a framework for causal inference in the presence of censored data, where the failure time is marked by a continuous variable known as a mark. The mark can be viewed as an extension of the failure cause in the classical competing risks model where the cause of failure is replaced by a continuous mark only observed at uncensored failure times. Due to the continuous nature of the marks, observations at each specific mark are sparse, making the identification and estimation of causality a challenging task. To address this issue, we define a new mark-specific treatment effect within the potential outcomes framework and characterize its identifying conditions. We then propose a local smoothing causal estimand and establish its asymptotic properties. We evaluate our method using simulation studies as well as a real dataset from the Antibody Mediated Prevention trials.",
      "pdf_url": "https://arxiv.org/pdf/2601.01854v1",
      "arxiv_url": "http://arxiv.org/abs/2601.01854v1",
      "published": "2026-01-05",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Causal Network Recovery in Perturb-seq Experiments Using Proxy and Instrumental Variables",
      "authors": [
        "Kwangmoon Park",
        "Hongzhe Li"
      ],
      "abstract": "Emerging single-cell technologies that integrate CRISPR-based genetic perturbations with single-cell RNA sequencing, such as Perturb-seq, have substantially advanced our understanding of gene regulation and causal influence of genes. While Perturb-seq data provide valuable causal insights into gene-gene interactions, statistical concerns remain regarding unobserved confounders that may bias inference. These latent factors may arise not only from intrinsic molecular features of regulatory elements encoded in Perturb-seq experiments, but also from unobserved genes arising from cost-constrained experimental designs. Although methods for analyzing largescale Perturb-seq data are rapidly maturing, approaches that explicitly account for such unobserved confounders in learning the causal gene networks are still lacking. Here, we propose a novel method to recover causal gene networks from Perturb-seq experiments with robustness to arbitrarily omitted confounders. Our framework leverages proxy and instrumental variable strategies to exploit the rich information embedded in perturbations, enabling unbiased estimation of the underlying directed acyclic graph (DAG) of gene expressions. Simulation studies and analyses of CRISPR interference experiments of K562 cells demonstrate that our method outperforms baseline approaches that ignore unmeasured confounding, yielding more accurate and biologically relevant recovery of the true gene causal DAGs.",
      "pdf_url": "https://arxiv.org/pdf/2601.01830v1",
      "arxiv_url": "http://arxiv.org/abs/2601.01830v1",
      "published": "2026-01-05",
      "categories": [
        "stat.ME",
        "stat.AP"
      ]
    },
    {
      "title": "Model-Assisted Causal Inference for the Treatment Effect on Recurrent Events in the Presence of Terminal Events",
      "authors": [
        "Yiyuan Huang",
        "Ling Zhou",
        "Min Zhang",
        "Peter X. K. Song"
      ],
      "abstract": "This paper is motivated by evaluating the benefits of patients receiving mechanical circulatory support (MCS) devices in end-stage heart failure management inference, in which hypothesis testing for a treatment effect on the risk of recurrent events is challenged in the presence of terminal events. Existing methods based on cumulative frequency unreasonably disadvantage longer survivors as they tend to experience more recurrent events. The While-Alive-based (WA) test has provided a solution to address this survival-length-bias problem, and it performs well when the recurrent event rate holds constant over time. However, if such a constant-rate assumption is violated, the WA test can exhibit an inflated type I error and inaccurate estimation of treatment effects. To fill this methodological gap, we propose a Proportional Rate Marginal Structural Model-assisted Test (PR-MSMaT) in the causal inference framework of separable treatment effects for recurrent and terminal events. Using the simulation study, we demonstrate that our PR-MSMaT can properly control type I error while gaining power comparable to the WA test under time-varying recurrent event rates. We employ PR-MSMaT to compare different MCS devices with the postoperative risk of gastrointestinal bleeding among patients enrolled in the Interagency Registry of Mechanically Assisted Circulatory Support program.",
      "pdf_url": "https://arxiv.org/pdf/2601.01245v1",
      "arxiv_url": "http://arxiv.org/abs/2601.01245v1",
      "published": "2026-01-03",
      "categories": [
        "stat.AP",
        "q-bio.QM",
        "q-bio.TO",
        "stat.ME"
      ]
    },
    {
      "title": "Order-Constrained Spectral Causality in Multivariate Time Series",
      "authors": [
        "Alejandro Rodriguez Dominguez"
      ],
      "abstract": "We introduce an operator-theoretic framework for causal analysis in multivariate time series based on order-constrained spectral non-invariance. Directional influence is defined as sensitivity of second-order dependence operators to admissible, order-preserving temporal deformations of a designated source component, yielding an intrinsically multivariate causal notion summarized through orthogonally invariant spectral functionals. Under linear Gaussian assumptions, the criterion coincides with linear Granger causality, while beyond this regime it captures collective and nonlinear directional dependence not reflected in pairwise predictability. We establish existence, uniform consistency, and valid inference for the resulting non-smooth supremum--infimum statistics using shift-based randomization that exploits order-induced group invariance, yielding finite-sample exactness under exact invariance and asymptotic validity under weak dependence without parametric assumptions. Simulations demonstrate correct size and strong power against distributed and bulk-dominated alternatives, including nonlinear dependence missed by linear Granger tests with appropriate feature embeddings. An empirical application to a high-dimensional panel of daily financial return series spanning major asset classes illustrates system-level causal monitoring in practice. Directional organization is episodic and stress-dependent, causal propagation strengthens while remaining multi-channel, dominant causal hubs reallocate rapidly, and statistically robust transmission channels are sparse and horizon-heterogeneous even when aggregate lead--lag asymmetry is weak. The framework provides a scalable and interpretable complement to correlation-, factor-, and pairwise Granger-style analyses for complex systems.",
      "pdf_url": "https://arxiv.org/pdf/2601.01216v1",
      "arxiv_url": "http://arxiv.org/abs/2601.01216v1",
      "published": "2026-01-03",
      "categories": [
        "stat.AP",
        "math.ST",
        "q-fin.ST"
      ]
    },
    {
      "title": "XStreamVGGT: Extremely Memory-Efficient Streaming Vision Geometry Grounded Transformer with KV Cache Compression",
      "authors": [
        "Zunhai Su",
        "Weihao Ye",
        "Hansen Feng",
        "Keyu Fan",
        "Jing Zhang",
        "Dahai Yu",
        "Zhengwu Liu",
        "Ngai Wong"
      ],
      "abstract": "Learning-based 3D visual geometry models have benefited substantially from large-scale transformers. Among these, StreamVGGT leverages frame-wise causal attention for strong streaming reconstruction, but suffers from unbounded KV cache growth, leading to escalating memory consumption and inference latency as input frames accumulate. We propose XStreamVGGT, a tuning-free approach that systematically compresses the KV cache through joint pruning and quantization, enabling extremely memory-efficient streaming inference. Specifically, redundant KVs originating from multi-view inputs are pruned through efficient token importance identification, enabling a fixed memory budget. Leveraging the unique distribution of KV tensors, we incorporate KV quantization to further reduce memory consumption. Extensive evaluations show that XStreamVGGT achieves mostly negligible performance degradation while substantially reducing memory usage by 4.42$\\times$ and accelerating inference by 5.48$\\times$, enabling scalable and practical streaming 3D applications. The code is available at https://github.com/ywh187/XStreamVGGT/.",
      "pdf_url": "https://arxiv.org/pdf/2601.01204v1",
      "arxiv_url": "http://arxiv.org/abs/2601.01204v1",
      "published": "2026-01-03",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "DHI: Leveraging Diverse Hallucination Induction for Enhanced Contrastive Factuality Control in Large Language Models",
      "authors": [
        "Jiani Guo",
        "Xiangke Zeng",
        "Jie Wu",
        "Zuchao Li"
      ],
      "abstract": "Large language models (LLMs) frequently produce inaccurate or fabricated information, known as \"hallucinations,\" which compromises their reliability. Existing approaches often train an \"Evil LLM\" to deliberately generate hallucinations on curated datasets, using these induced hallucinations to guide contrastive decoding against a reliable \"positive model\" for hallucination mitigation. However, this strategy is limited by the narrow diversity of hallucinations induced, as Evil LLMs trained on specific error types tend to reproduce only these particular patterns, thereby restricting their overall effectiveness. To address these limitations, we propose DHI (Diverse Hallucination Induction), a novel training framework that enables the Evil LLM to generate a broader range of hallucination types without relying on pre-annotated hallucination data. DHI employs a modified loss function that down-weights the generation of specific factually correct tokens, encouraging the Evil LLM to produce diverse hallucinations at targeted positions while maintaining overall factual content. Additionally, we introduce a causal attention masking adaptation to reduce the impact of this penalization on the generation of subsequent tokens. During inference, we apply an adaptive rationality constraint that restricts contrastive decoding to tokens where the positive model exhibits high confidence, thereby avoiding unnecessary penalties on factually correct tokens. Extensive empirical results show that DHI achieves significant performance gains over other contrastive decoding-based approaches across multiple hallucination benchmarks.",
      "pdf_url": "https://arxiv.org/pdf/2601.01156v1",
      "arxiv_url": "http://arxiv.org/abs/2601.01156v1",
      "published": "2026-01-03",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "title": "Beyond P-Values: Importing Quantitative Finance's Risk and Regret Metrics for AI in Learning Health Systems",
      "authors": [
        "Richik Chakraborty"
      ],
      "abstract": "The increasing deployment of artificial intelligence (AI) in clinical settings challenges foundational assumptions underlying traditional frameworks of medical evidence. Classical statistical approaches, centered on randomized controlled trials, frequentist hypothesis testing, and static confidence intervals, were designed for fixed interventions evaluated under stable conditions. In contrast, AI-driven clinical systems learn continuously, adapt their behavior over time, and operate in non-stationary environments shaped by evolving populations, practices, and feedback effects. In such systems, clinical harm arises less from average error rates than from calibration drift, rare but severe failures, and the accumulation of suboptimal decisions over time.\n  In this perspective, we argue that prevailing notions of statistical significance are insufficient for characterizing evidence and safety in learning health systems. Drawing on risk-theoretic concepts from quantitative finance and online decision theory, we propose reframing medical evidence for adaptive AI systems in terms of time-indexed calibration stability, bounded downside risk, and controlled cumulative regret. We emphasize that this approach does not replace randomized trials or causal inference, but complements them by addressing dimensions of risk and uncertainty that emerge only after deployment. This framework provides a principled mathematical language for evaluating AI-driven clinical systems under continual learning and offers implications for clinical practice, research design, and regulatory oversight.",
      "pdf_url": "https://arxiv.org/pdf/2601.01116v1",
      "arxiv_url": "http://arxiv.org/abs/2601.01116v1",
      "published": "2026-01-03",
      "categories": [
        "stat.ME",
        "q-bio.QM"
      ]
    },
    {
      "title": "Fair Policy Learning under Bipartite Network Interference: Learning Fair and Cost-Effective Environmental Policies",
      "authors": [
        "Raphael C. Kim",
        "Rachel C. Nethery",
        "Kevin L. Chen",
        "Falco J. Bargagli-Stoffi"
      ],
      "abstract": "Numerous studies have shown the harmful effects of airborne pollutants on human health. Vulnerable groups and communities often bear a disproportionately larger health burden due to exposure to airborne pollutants. Thus, there is a need to design policies that effectively reduce the public health burdens while ensuring cost-effective policy interventions. Designing policies that optimally benefit the population while ensuring equity between groups under cost constraints is a challenging statistical and causal inference problem. In the context of environmental policy this is further complicated by the fact that interventions target emission sources but health impacts occur in potentially distant communities due to atmospheric pollutant transport -- a setting known as bipartite network interference (BNI). To address these issues, we propose a fair policy learning approach under BNI. Our approach allows to learn cost-effective policies under fairness constraints even accounting for complex BNI data structures. We derive asymptotic properties and demonstrate finite sample performance via Monte Carlo simulations. Finally, we apply the proposed method to a real-world dataset linking power plant scrubber installations to Medicare health records for more than 2 million individuals in the U.S. Our method determine fair scrubber allocations to reduce mortality under fairness and cost constraints.",
      "pdf_url": "https://arxiv.org/pdf/2601.00531v1",
      "arxiv_url": "http://arxiv.org/abs/2601.00531v1",
      "published": "2026-01-02",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Bio-inspired Agentic Self-healing Framework for Resilient Distributed Computing Continuum Systems",
      "authors": [
        "Alaa Saleh",
        "Praveen Kumar Donta",
        "Roberto Morabito",
        "Sasu Tarkoma",
        "Anders Lindgren",
        "Qiyang Zhang",
        "Schahram Dustdar",
        "Susanna Pirttikangas",
        "Lauri Lov√©n"
      ],
      "abstract": "Human biological systems sustain life through extraordinary resilience, continually detecting damage, orchestrating targeted responses, and restoring function through self-healing. Inspired by these capabilities, this paper introduces ReCiSt, a bio-inspired agentic self-healing framework designed to achieve resilience in Distributed Computing Continuum Systems (DCCS). Modern DCCS integrate heterogeneous computing resources, ranging from resource-constrained IoT devices to high-performance cloud infrastructures, and their inherent complexity, mobility, and dynamic operating conditions expose them to frequent faults that disrupt service continuity. These challenges underscore the need for scalable, adaptive, and self-regulated resilience strategies. ReCiSt reconstructs the biological phases of Hemostasis, Inflammation, Proliferation, and Remodeling into the computational layers Containment, Diagnosis, Meta-Cognitive, and Knowledge for DCCS. These four layers perform autonomous fault isolation, causal diagnosis, adaptive recovery, and long-term knowledge consolidation through Language Model (LM)-powered agents. These agents interpret heterogeneous logs, infer root causes, refine reasoning pathways, and reconfigure resources with minimal human intervention. The proposed ReCiSt framework is evaluated on public fault datasets using multiple LMs, and no baseline comparison is included due to the scarcity of similar approaches. Nevertheless, our results, evaluated under different LMs, confirm ReCiSt's self-healing capabilities within tens of seconds with minimum of 10% of agent CPU usage. Our results also demonstrated depth of analysis to over come uncertainties and amount of micro-agents invoked to achieve resilience.",
      "pdf_url": "https://arxiv.org/pdf/2601.00339v1",
      "arxiv_url": "http://arxiv.org/abs/2601.00339v1",
      "published": "2026-01-01",
      "categories": [
        "cs.AI",
        "cs.DC",
        "cs.ET",
        "cs.MA",
        "cs.NE"
      ]
    },
    {
      "title": "Identification and Estimation under Multiple Versions of Treatment: Mixture-of-Experts Approach",
      "authors": [
        "Kohei Yoshikawa",
        "Shuichi Kawano"
      ],
      "abstract": "The Stable Unit Treatment Value Assumption (SUTVA) includes the condition that there are no multiple versions of treatment in causal inference. Though we could not control the implementation of treatment in observational studies, multiple versions may exist in the treatment. It has been pointed out that ignoring such multiple versions of treatment can lead to biased estimates of causal effects, but a causal inference framework that explicitly deals with the unbiased identification and estimation of version-specific causal effects has not been fully developed yet. Thus, obtaining a deeper understanding for mechanisms of the complex treatments is difficult. In this paper, we introduce the Mixture-of-Experts framework into causal inference and develop a methodology for estimating the causal effects of latent versions. This approach enables explicit estimation of version-specific causal effects even if the versions are not observed. Numerical experiments demonstrate the effectiveness of the proposed method.",
      "pdf_url": "https://arxiv.org/pdf/2601.00287v1",
      "arxiv_url": "http://arxiv.org/abs/2601.00287v1",
      "published": "2026-01-01",
      "categories": [
        "stat.ME",
        "stat.ML"
      ]
    }
  ]
}