{
  "last_updated": "2025-05-21T00:54:19.295085",
  "papers": [
    {
      "title": "Machine learning the first stage in 2SLS: Practical guidance from bias decomposition and simulation",
      "authors": [
        "Connor Lennon",
        "Edward Rubin",
        "Glen Waddell"
      ],
      "abstract": "Machine learning (ML) primarily evolved to solve \"prediction problems.\" The\nfirst stage of two-stage least squares (2SLS) is a prediction problem,\nsuggesting potential gains from ML first-stage assistance. However, little\nguidance exists on when ML helps 2SLS$\\unicode{x2014}$or when it hurts. We\ninvestigate the implications of inserting ML into 2SLS, decomposing the bias\ninto three informative components. Mechanically, ML-in-2SLS procedures face\nissues common to prediction and causal-inference settings$\\unicode{x2014}$and\ntheir interaction. Through simulation, we show linear ML methods (e.g.,\npost-Lasso) work well, while nonlinear methods (e.g., random forests, neural\nnets) generate substantial bias in second-stage\nestimates$\\unicode{x2014}$potentially exceeding the bias of endogenous OLS.",
      "pdf_url": "http://arxiv.org/pdf/2505.13422v1",
      "arxiv_url": "http://arxiv.org/abs/2505.13422v1",
      "published": "2025-05-19",
      "categories": [
        "econ.EM",
        "cs.LG",
        "stat.AP",
        "stat.ML"
      ]
    },
    {
      "title": "FEALLM: Advancing Facial Emotion Analysis in Multimodal Large Language Models with Emotional Synergy and Reasoning",
      "authors": [
        "Zhuozhao Hu",
        "Kaishen Yuan",
        "Xin Liu",
        "Zitong Yu",
        "Yuan Zong",
        "Jingang Shi",
        "Huanjing Yue",
        "Jingyu Yang"
      ],
      "abstract": "Facial Emotion Analysis (FEA) plays a crucial role in visual affective\ncomputing, aiming to infer a person's emotional state based on facial data.\nScientifically, facial expressions (FEs) result from the coordinated movement\nof facial muscles, which can be decomposed into specific action units (AUs)\nthat provide detailed emotional insights. However, traditional methods often\nstruggle with limited interpretability, constrained generalization and\nreasoning abilities. Recently, Multimodal Large Language Models (MLLMs) have\nshown exceptional performance in various visual tasks, while they still face\nsignificant challenges in FEA due to the lack of specialized datasets and their\ninability to capture the intricate relationships between FEs and AUs. To\naddress these issues, we introduce a novel FEA Instruction Dataset that\nprovides accurate and aligned FE and AU descriptions and establishes causal\nreasoning relationships between them, followed by constructing a new benchmark,\nFEABench. Moreover, we propose FEALLM, a novel MLLM architecture designed to\ncapture more detailed facial information, enhancing its capability in FEA\ntasks. Our model demonstrates strong performance on FEABench and impressive\ngeneralization capability through zero-shot evaluation on various datasets,\nincluding RAF-DB, AffectNet, BP4D, and DISFA, showcasing its robustness and\neffectiveness in FEA tasks. The dataset and code will be available at\nhttps://github.com/953206211/FEALLM.",
      "pdf_url": "http://arxiv.org/pdf/2505.13419v1",
      "arxiv_url": "http://arxiv.org/abs/2505.13419v1",
      "published": "2025-05-19",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "From What Ifs to Insights: Counterfactuals in Causal Inference vs. Explainable AI",
      "authors": [
        "Galit Shmueli",
        "David Martens",
        "Jaewon Yoo",
        "Travis Greene"
      ],
      "abstract": "Counterfactuals play a pivotal role in the two distinct data science fields\nof causal inference (CI) and explainable artificial intelligence (XAI). While\nthe core idea behind counterfactuals remains the same in both fields--the\nexamination of what would have happened under different circumstances--there\nare key differences in how they are used and interpreted. We introduce a formal\ndefinition that encompasses the multi-faceted concept of the counterfactual in\nCI and XAI. We then discuss how counterfactuals are used, evaluated, generated,\nand operationalized in CI vs. XAI, highlighting conceptual and practical\ndifferences. By comparing and contrasting the two, we hope to identify\nopportunities for cross-fertilization across CI and XAI.",
      "pdf_url": "http://arxiv.org/pdf/2505.13324v1",
      "arxiv_url": "http://arxiv.org/abs/2505.13324v1",
      "published": "2025-05-19",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "econ.EM",
        "stat.ME"
      ]
    },
    {
      "title": "MAGI-1: Autoregressive Video Generation at Scale",
      "authors": [
        "Sand. ai",
        "Hansi Teng",
        "Hongyu Jia",
        "Lei Sun",
        "Lingzhi Li",
        "Maolin Li",
        "Mingqiu Tang",
        "Shuai Han",
        "Tianning Zhang",
        "W. Q. Zhang",
        "Weifeng Luo",
        "Xiaoyang Kang",
        "Yuchen Sun",
        "Yue Cao",
        "Yunpeng Huang",
        "Yutong Lin",
        "Yuxin Fang",
        "Zewei Tao",
        "Zheng Zhang",
        "Zhongshu Wang",
        "Zixun Liu",
        "Dai Shi",
        "Guoli Su",
        "Hanwen Sun",
        "Hong Pan",
        "Jie Wang",
        "Jiexin Sheng",
        "Min Cui",
        "Min Hu",
        "Ming Yan",
        "Shucheng Yin",
        "Siran Zhang",
        "Tingting Liu",
        "Xianping Yin",
        "Xiaoyu Yang",
        "Xin Song",
        "Xuan Hu",
        "Yankai Zhang",
        "Yuqiao Li"
      ],
      "abstract": "We present MAGI-1, a world model that generates videos by autoregressively\npredicting a sequence of video chunks, defined as fixed-length segments of\nconsecutive frames. Trained to denoise per-chunk noise that increases\nmonotonically over time, MAGI-1 enables causal temporal modeling and naturally\nsupports streaming generation. It achieves strong performance on image-to-video\n(I2V) tasks conditioned on text instructions, providing high temporal\nconsistency and scalability, which are made possible by several algorithmic\ninnovations and a dedicated infrastructure stack. MAGI-1 facilitates\ncontrollable generation via chunk-wise prompting and supports real-time,\nmemory-efficient deployment by maintaining constant peak inference cost,\nregardless of video length. The largest variant of MAGI-1 comprises 24 billion\nparameters and supports context lengths of up to 4 million tokens,\ndemonstrating the scalability and robustness of our approach. The code and\nmodels are available at https://github.com/SandAI-org/MAGI-1 and\nhttps://github.com/SandAI-org/MagiAttention. The product can be accessed at\nhttps://sand.ai.",
      "pdf_url": "http://arxiv.org/pdf/2505.13211v1",
      "arxiv_url": "http://arxiv.org/abs/2505.13211v1",
      "published": "2025-05-19",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Quantum Algorithms for Causal Estimands",
      "authors": [
        "Rishi Goel",
        "Casey R. Myers",
        "Sally Shrapnel"
      ],
      "abstract": "Modern machine learning methods typically fail to adequately capture causal\ninformation. Consequently, such models do not handle data distributional\nshifts, are vulnerable to adversarial examples, and often learn spurious\ncorrelations. Causal machine learning, or causal inference, aims to solve these\nissues by estimating the expected outcome of counterfactual events, using\nobservational and/or interventional data, where causal relationships are\ntypically depicted as directed acyclic graphs. It is an open question as to\nwhether these causal algorithms provide opportunities for quantum enhancement.\nIn this paper we consider a recently developed family of non-parametric,\ncontinuous causal estimators and derive quantum algorithms for these tasks.\nKernel evaluation and large matrix inversion are critical sub-routines of these\nclassical algorithms, which makes them particularly amenable to a quantum\ntreatment. Unlike other quantum machine learning algorithms, closed form\nsolutions for the estimators exist, negating the need for gradient evaluation\nand variational learning. We describe several new hybrid quantum-classical\nalgorithms and show that uniform consistency of the estimators is retained.\nFurthermore, if one is satisfied with a quantum state output that is\nproportional to the true causal estimand, then these algorithms inherit the\nexponential complexity advantages given by quantum linear system solvers.",
      "pdf_url": "http://arxiv.org/pdf/2505.12873v1",
      "arxiv_url": "http://arxiv.org/abs/2505.12873v1",
      "published": "2025-05-19",
      "categories": [
        "quant-ph"
      ]
    },
    {
      "title": "Double machine learning to estimate the effects of multiple treatments and their interactions",
      "authors": [
        "Qingyan Xiang",
        "Yubai Yuan",
        "Dongyuan Song",
        "Usman J. Wudil",
        "Muktar H. Aliyu",
        "C. William Wester",
        "Bryan E. Shepherd"
      ],
      "abstract": "Causal inference literature has extensively focused on binary treatments,\nwith relatively fewer methods developed for multi-valued treatments. In\nparticular, methods for multiple simultaneously assigned treatments remain\nunderstudied despite their practical importance. This paper introduces two\nsettings: (1) estimating the effects of multiple treatments of different types\n(binary, categorical, and continuous) and the effects of treatment\ninteractions, and (2) estimating the average treatment effect across categories\nof multi-valued regimens. To obtain robust estimates for both settings, we\npropose a class of methods based on the Double Machine Learning (DML)\nframework. Our methods are well-suited for complex settings of multiple\ntreatments/regimens, using machine learning to model confounding relationships\nwhile overcoming regularization and overfitting biases through Neyman\northogonality and cross-fitting. To our knowledge, this work is the first to\napply machine learning for robust estimation of interaction effects in the\npresence of multiple treatments. We further establish the asymptotic\ndistribution of our estimators and derive variance estimators for statistical\ninference. Extensive simulations demonstrate the performance of our methods.\nFinally, we apply the methods to study the effect of three treatments on\nHIV-associated kidney disease in an adult HIV cohort of 2455 participants in\nNigeria.",
      "pdf_url": "http://arxiv.org/pdf/2505.12617v1",
      "arxiv_url": "http://arxiv.org/abs/2505.12617v1",
      "published": "2025-05-19",
      "categories": [
        "stat.ME",
        "stat.AP"
      ]
    },
    {
      "title": "SurveillanceVQA-589K: A Benchmark for Comprehensive Surveillance Video-Language Understanding with Large Models",
      "authors": [
        "Bo Liu",
        "Pengfei Qiao",
        "Minhan Ma",
        "Xuange Zhang",
        "Yinan Tang",
        "Peng Xu",
        "Kun Liu",
        "Tongtong Yuan"
      ],
      "abstract": "Understanding surveillance video content remains a critical yet underexplored\nchallenge in vision-language research, particularly due to its real-world\ncomplexity, irregular event dynamics, and safety-critical implications. In this\nwork, we introduce SurveillanceVQA-589K, the largest open-ended video question\nanswering benchmark tailored to the surveillance domain. The dataset comprises\n589,380 QA pairs spanning 12 cognitively diverse question types, including\ntemporal reasoning, causal inference, spatial understanding, and anomaly\ninterpretation, across both normal and abnormal video scenarios. To construct\nthe benchmark at scale, we design a hybrid annotation pipeline that combines\ntemporally aligned human-written captions with Large Vision-Language\nModel-assisted QA generation using prompt-based techniques. We also propose a\nmulti-dimensional evaluation protocol to assess contextual, temporal, and\ncausal comprehension. We evaluate eight LVLMs under this framework, revealing\nsignificant performance gaps, especially in causal and anomaly-related tasks,\nunderscoring the limitations of current models in real-world surveillance\ncontexts. Our benchmark provides a practical and comprehensive resource for\nadvancing video-language understanding in safety-critical applications such as\nintelligent monitoring, incident analysis, and autonomous decision-making.",
      "pdf_url": "http://arxiv.org/pdf/2505.12589v1",
      "arxiv_url": "http://arxiv.org/abs/2505.12589v1",
      "published": "2025-05-19",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "Estimation of Treatment Harm Rate via Partitioning",
      "authors": [
        "Wei Liang",
        "Changbao Wu"
      ],
      "abstract": "In causal inference with binary outcomes, there is a growing interest in\nestimation of treatment harm rate (THR), which is a measure of treatment risk\nand reveals treatment effect heterogeneity in a subpopulation. The THR is\ngenerally non-identifiable even for randomized controlled trials (RCTs), and\nexisting works focus primarily on the estimation of the THR under either\nuntestable identification or ambiguous model assumptions. We develop a class of\npartitioning-based bounds for the THR based on data from RCTs with two distinct\nfeatures: Our proposed bounds effectively use available auxiliary covariates\ninformation and the bounds can be consistently estimated without relying on any\nuntestable or ambiguous model assumptions. Finite sample performances of our\nproposed interval estimators along with a conservatively extended confidence\ninterval for the THR are evaluated through Monte Carlo simulation studies. An\napplication of the proposed methods to the ACTG 175 data is presented. A Python\npackage named partbte for the partitioning-based algorithm has been developed\nand is available on https://github.com/w62liang/partition-te.",
      "pdf_url": "http://arxiv.org/pdf/2505.12209v1",
      "arxiv_url": "http://arxiv.org/abs/2505.12209v1",
      "published": "2025-05-18",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Causal Machine Learning in IoT-based Engineering Problems: A Tool Comparison in the Case of Household Energy Consumption",
      "authors": [
        "Nikolaos-Lysias Kosioris",
        "Sotirios Nikoletseas",
        "Gavrilis Filios",
        "Stefanos Panagiotou"
      ],
      "abstract": "The rapid increase in computing power and the ability to store Big Data in\nthe infrastructure has enabled predictions in a large variety of domains by\nMachine Learning. However, in many cases, existing Machine Learning tools are\nconsidered insufficient or incorrect since they exploit only probabilistic\ndependencies rather than inference logic. Causal Machine Learning methods seem\nto close this gap. In this paper, two prevalent tools based on Causal Machine\nLearning methods are compared, as well as their mathematical underpinning\nbackground. The operation of the tools is demonstrated by examining their\nresponse to 18 queries, based on the IDEAL Household Energy Dataset, published\nby the University of Edinburgh. First, it was important to evaluate the causal\nrelations assumption that allowed the use of this approach; this was based on\nthe preexisting scientific knowledge of the domain and was implemented by use\nof the in-built validation tools. Results were encouraging and may easily be\nextended to other domains.",
      "pdf_url": "http://arxiv.org/pdf/2505.12147v1",
      "arxiv_url": "http://arxiv.org/abs/2505.12147v1",
      "published": "2025-05-17",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "Attribution Projection Calculus: A Novel Framework for Causal Inference in Bayesian Networks",
      "authors": [
        "M Ruhul Amin"
      ],
      "abstract": "This paper introduces Attribution Projection Calculus (AP-Calculus), a novel\nmathematical framework for determining causal relationships in structured\nBayesian networks. We investigate a specific network architecture with source\nnodes connected to destination nodes through intermediate nodes, where each\ninput maps to a single label with maximum marginal probability. We prove that\nfor each label, exactly one intermediate node acts as a deconfounder while\nothers serve as confounders, enabling optimal attribution of features to their\ncorresponding labels. The framework formalizes the dual nature of intermediate\nnodes as both confounders and deconfounders depending on the context, and\nestablishes separation functions that maximize distinctions between\nintermediate representations. We demonstrate that the proposed network\narchitecture is optimal for causal inference compared to alternative\nstructures, including those based on Pearl's causal framework. AP-Calculus\nprovides a comprehensive mathematical foundation for analyzing feature-label\nattributions, managing spurious correlations, quantifying information gain,\nensuring fairness, and evaluating uncertainty in prediction models, including\nlarge language models. Theoretical verification shows that AP-Calculus not only\nextends but can also subsume traditional do-calculus for many practical\napplications, offering a more direct approach to causal inference in supervised\nlearning contexts.",
      "pdf_url": "http://arxiv.org/pdf/2505.12094v1",
      "arxiv_url": "http://arxiv.org/abs/2505.12094v1",
      "published": "2025-05-17",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT",
        "stat.ML",
        "60E10, 62R07, 68Q32, 68T07, 94A16",
        "F.2.2; G.3; I.1.2; I.2.6"
      ]
    }
  ]
}