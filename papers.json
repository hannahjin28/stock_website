{
  "last_updated": "2025-12-06T00:53:06.686570",
  "papers": [
    {
      "title": "Learning Causality for Longitudinal Data",
      "authors": [
        "Mouad EL Bouchattaoui"
      ],
      "abstract": "This thesis develops methods for causal inference and causal representation learning (CRL) in high-dimensional, time-varying data.\n  The first contribution introduces the Causal Dynamic Variational Autoencoder (CDVAE), a model for estimating Individual Treatment Effects (ITEs) by capturing unobserved heterogeneity in treatment response driven by latent risk factors that affect only outcomes. CDVAE comes with theoretical guarantees on valid latent adjustment and generalization bounds for ITE error. Experiments on synthetic and real datasets show that CDVAE outperforms baselines, and that state-of-the-art models greatly improve when augmented with its latent substitutes, approaching oracle performance without access to true adjustment variables.\n  The second contribution proposes an efficient framework for long-term counterfactual regression based on RNNs enhanced with Contrastive Predictive Coding (CPC) and InfoMax. It captures long-range dependencies under time-varying confounding while avoiding the computational cost of transformers, achieving state-of-the-art results and introducing CPC into causal inference.\n  The third contribution advances CRL by addressing how latent causes manifest in observed variables. We introduce a model-agnostic interpretability layer based on the geometry of the decoder Jacobian. A sparse self-expression prior induces modular, possibly overlapping groups of observed features aligned with shared latent influences. We provide recovery guarantees in both disjoint and overlapping settings and show that meaningful latent-to-observed structure can be recovered without anchor features or single-parent assumptions. Scalable Jacobian-based regularization techniques are also developed.",
      "pdf_url": "https://arxiv.org/pdf/2512.04980v1",
      "arxiv_url": "http://arxiv.org/abs/2512.04980v1",
      "published": "2025-12-04",
      "categories": [
        "stat.ML",
        "cs.IT",
        "cs.LG"
      ]
    },
    {
      "title": "Live Avatar: Streaming Real-time Audio-Driven Avatar Generation with Infinite Length",
      "authors": [
        "Yubo Huang",
        "Hailong Guo",
        "Fangtai Wu",
        "Shifeng Zhang",
        "Shijie Huang",
        "Qijun Gan",
        "Lin Liu",
        "Sirui Zhao",
        "Enhong Chen",
        "Jiaming Liu",
        "Steven Hoi"
      ],
      "abstract": "Existing diffusion-based video generation methods are fundamentally constrained by sequential computation and long-horizon inconsistency, limiting their practical adoption in real-time, streaming audio-driven avatar synthesis. We present Live Avatar, an algorithm-system co-designed framework that enables efficient, high-fidelity, and infinite-length avatar generation using a 14-billion-parameter diffusion model. Our approach introduces Timestep-forcing Pipeline Parallelism (TPP), a distributed inference paradigm that pipelines denoising steps across multiple GPUs, effectively breaking the autoregressive bottleneck and ensuring stable, low-latency real-time streaming. To further enhance temporal consistency and mitigate identity drift and color artifacts, we propose the Rolling Sink Frame Mechanism (RSFM), which maintains sequence fidelity by dynamically recalibrating appearance using a cached reference image. Additionally, we leverage Self-Forcing Distribution Matching Distillation to facilitate causal, streamable adaptation of large-scale models without sacrificing visual quality. Live Avatar demonstrates state-of-the-art performance, reaching 20 FPS end-to-end generation on 5 H800 GPUs, and, to the best of our knowledge, is the first to achieve practical, real-time, high-fidelity avatar generation at this scale. Our work establishes a new paradigm for deploying advanced diffusion models in industrial long-form video synthesis applications.",
      "pdf_url": "https://arxiv.org/pdf/2512.04677v1",
      "arxiv_url": "http://arxiv.org/abs/2512.04677v1",
      "published": "2025-12-04",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "Addressing Logical Fallacies In Scientific Reasoning From Large Language Models: Towards a Dual-Inference Training Framework",
      "authors": [
        "Peter B. Walker",
        "Hannah Davidson",
        "Aiden Foster",
        "Matthew Lienert",
        "Thomas Pardue",
        "Dale Russell"
      ],
      "abstract": "Large Language Models (LLMs) have transformed natural language processing and hold growing promise for advancing science, healthcare, and decision-making. Yet their training paradigms remain dominated by affirmation-based inference, akin to \\textit{modus ponens}, where accepted premises yield predicted consequents. While effective for generative fluency, this one-directional approach leaves models vulnerable to logical fallacies, adversarial manipulation, and failures in causal reasoning. This paper makes two contributions. First, it demonstrates how existing LLMs from major platforms exhibit systematic weaknesses when reasoning in scientific domains with negation, counterexamples, or faulty premises \\footnote{Code to recreate these experiments are at https://github.com/hannahdavidsoncollege-maker/ScientificReasoningForEnvironment-MedicineWithLLMs. Second, it introduces a dual-reasoning training framework that integrates affirmative generation with structured counterfactual denial. Grounded in formal logic, cognitive science, and adversarial training, this training paradigm formalizes a computational analogue of ``denying the antecedent'' as a mechanism for disconfirmation and robustness. By coupling generative synthesis with explicit negation-aware objectives, the framework enables models that not only affirm valid inferences but also reject invalid ones, yielding systems that are more resilient, interpretable, and aligned with human reasoning.",
      "pdf_url": "https://arxiv.org/pdf/2512.04228v1",
      "arxiv_url": "http://arxiv.org/abs/2512.04228v1",
      "published": "2025-12-03",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "GaussDetect-LiNGAM:Causal Direction Identification without Gaussianity test",
      "authors": [
        "Ziyi Ding",
        "Xiao-Ping Zhang"
      ],
      "abstract": "We propose GaussDetect-LiNGAM, a novel approach for bivariate causal discovery that eliminates the need for explicit Gaussianity tests by leveraging a fundamental equivalence between noise Gaussianity and residual independence in the reverse regression. Under the standard LiNGAM assumptions of linearity, acyclicity, and exogeneity, we prove that the Gaussianity of the forward-model noise is equivalent to the independence between the regressor and residual in the reverse model. This theoretical insight allows us to replace fragile and sample-sensitive Gaussianity tests with robust kernel-based independence tests. Experimental results validate the equivalence and demonstrate that GaussDetect-LiNGAM maintains high consistency across diverse noise types and sample sizes, while reducing the number of tests per decision (TPD). Our method enhances both the efficiency and practical applicability of causal inference, making LiNGAM more accessible and reliable in real-world scenarios.",
      "pdf_url": "https://arxiv.org/pdf/2512.03428v1",
      "arxiv_url": "http://arxiv.org/abs/2512.03428v1",
      "published": "2025-12-03",
      "categories": [
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "title": "Assumption-Lean Differential Variance Inference for Heterogeneous Treatment Effect Detection",
      "authors": [
        "Philippe A. Boileau",
        "Hani Zaki",
        "Gabriele Lileikyte",
        "Niklas Nielsen",
        "Patrick R. Lawler",
        "Mireille E. Schnitzer"
      ],
      "abstract": "The conditional average treatment effect (CATE) is frequently estimated to refute the homogeneous treatment effect assumption. Under this assumption, all units making up the population under study experience identical benefit from a given treatment. Uncovering heterogeneous treatment effects through inference about the CATE, however, requires that covariates truly modifying the treatment effect be reliably collected at baseline. CATE-based techniques will necessarily fail to detect violations when effect modifiers are omitted from the data due to, for example, resource constraints. Severe measurement error has a similar impact. To address these limitations, we prove that the homogeneous treatment effect assumption can be gauged through inference about contrasts of the potential outcomes' variances. We derive causal machine learning estimators of these contrasts and study their asymptotic properties. We establish that these estimators are doubly robust and asymptotically linear under mild conditions, permitting formal hypothesis testing about the homogeneous treatment effect assumption even when effect modifiers are missing or mismeasured. Numerical experiments demonstrate that these estimators' asymptotic guarantees are approximately achieved in experimental and observational data alike. These inference procedures are then used to detect heterogeneous treatment effects in the re-analysis of randomized controlled trials investigating targeted temperature management in cardiac arrest patients.",
      "pdf_url": "https://arxiv.org/pdf/2512.03254v1",
      "arxiv_url": "http://arxiv.org/abs/2512.03254v1",
      "published": "2025-12-02",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "The BEAT-CF Causal Model: A model for guiding the design of trials and observational analyses of cystic fibrosis exacerbations",
      "authors": [
        "Steven Mascaro",
        "Owen Woodberry",
        "Charlie McLeod",
        "Mitch Messer",
        "Hiran Selvadurai",
        "Yue Wu",
        "Andre Schultz",
        "Thomas L Snelling"
      ],
      "abstract": "Loss of lung function in cystic fibrosis (CF) occurs progressively, punctuated by acute pulmonary exacerbations (PEx) in which abrupt declines in lung function are not fully recovered. A key component of CF management over the past half century has been the treatment of PEx to slow lung function decline. This has been credited with improvements in survival for people with CF (PwCF), but there is no consensus on the optimal approach to PEx management. BEAT-CF (Bayesian evidence-adaptive treatment of CF) was established to build an evidence-informed knowledge base for CF management. The BEAT-CF causal model is a directed acyclic graph (DAG) and Bayesian network (BN) for PEx that aims to inform the design and analysis of clinical trials comparing the effectiveness of alternative approaches to PEx management. The causal model describes relationships between background risk factors, treatments, and pathogen colonisation of the airways that affect the outcome of an individual PEx episode. The key factors, outcomes, and causal relationships were elicited from CF clinical experts and together represent current expert understanding of the pathophysiology of a PEx episode, guiding the design of data collection and studies and enabling causal inference. Here, we present the DAG that documents this understanding, along with the processes used in its development, providing transparency around our trial design and study processes, as well as a reusable framework for others.",
      "pdf_url": "https://arxiv.org/pdf/2512.03110v1",
      "arxiv_url": "http://arxiv.org/abs/2512.03110v1",
      "published": "2025-12-02",
      "categories": [
        "q-bio.QM",
        "cs.AI"
      ]
    },
    {
      "title": "SpriteHand: Real-Time Versatile Hand-Object Interaction with Autoregressive Video Generation",
      "authors": [
        "Zisu Li",
        "Hengye Lyu",
        "Jiaxin Shi",
        "Yufeng Zeng",
        "Mingming Fan",
        "Hanwang Zhang",
        "Chen Liang"
      ],
      "abstract": "Modeling and synthesizing complex hand-object interactions remains a significant challenge, even for state-of-the-art physics engines. Conventional simulation-based approaches rely on explicitly defined rigid object models and pre-scripted hand gestures, making them inadequate for capturing dynamic interactions with non-rigid or articulated entities such as deformable fabrics, elastic materials, hinge-based structures, furry surfaces, or even living creatures. In this paper, we present SpriteHand, an autoregressive video generation framework for real-time synthesis of versatile hand-object interaction videos across a wide range of object types and motion patterns. SpriteHand takes as input a static object image and a video stream in which the hands are imagined to interact with the virtual object embedded in a real-world scene, and generates corresponding hand-object interaction effects in real time. Our model employs a causal inference architecture for autoregressive generation and leverages a hybrid post-training approach to enhance visual realism and temporal coherence. Our 1.3B model supports real-time streaming generation at around 18 FPS and 640x368 resolution, with an approximate 150 ms latency on a single NVIDIA RTX 5090 GPU, and more than a minute of continuous output. Experiments demonstrate superior visual quality, physical plausibility, and interaction fidelity compared to both generative and engine-based baselines.",
      "pdf_url": "https://arxiv.org/pdf/2512.01960v1",
      "arxiv_url": "http://arxiv.org/abs/2512.01960v1",
      "published": "2025-12-01",
      "categories": [
        "cs.CV",
        "cs.HC"
      ]
    },
    {
      "title": "Mitigating Gender Bias in Depression Detection via Counterfactual Inference",
      "authors": [
        "Mingxuan Hu",
        "Hongbo Ma",
        "Xinlan Wu",
        "Ziqi Liu",
        "Jiaqi Liu",
        "Yangbin Chen"
      ],
      "abstract": "Audio-based depression detection models have demonstrated promising performance but often suffer from gender bias due to imbalanced training data. Epidemiological statistics show a higher prevalence of depression in females, leading models to learn spurious correlations between gender and depression. Consequently, models tend to over-diagnose female patients while underperforming on male patients, raising significant fairness concerns. To address this, we propose a novel Counterfactual Debiasing Framework grounded in causal inference. We construct a causal graph to model the decision-making process and identify gender bias as the direct causal effect of gender on the prediction. During inference, we employ counterfactual inference to estimate and subtract this direct effect, ensuring the model relies primarily on authentic acoustic pathological features. Extensive experiments on the DAIC-WOZ dataset using two advanced acoustic backbones demonstrate that our framework not only significantly reduces gender bias but also improves overall detection performance compared to existing debiasing strategies.",
      "pdf_url": "https://arxiv.org/pdf/2512.01834v1",
      "arxiv_url": "http://arxiv.org/abs/2512.01834v1",
      "published": "2025-12-01",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ]
    },
    {
      "title": "CauSight: Learning to Supersense for Visual Causal Discovery",
      "authors": [
        "Yize Zhang",
        "Meiqi Chen",
        "Sirui Chen",
        "Bo Peng",
        "Yanxi Zhang",
        "Tianyu Li",
        "Chaochao Lu"
      ],
      "abstract": "Causal thinking enables humans to understand not just what is seen, but why it happens. To replicate this capability in modern AI systems, we introduce the task of visual causal discovery. It requires models to infer cause-and-effect relations among visual entities across diverse scenarios instead of merely perceiving their presence. To this end, we first construct the Visual Causal Graph dataset (VCG-32K), a large-scale collection of over 32,000 images annotated with entity-level causal graphs, and further develop CauSight, a novel vision-language model to perform visual causal discovery through causally aware reasoning. Our training recipe integrates three components: (1) training data curation from VCG-32K, (2) Tree-of-Causal-Thought (ToCT) for synthesizing reasoning trajectories, and (3) reinforcement learning with a designed causal reward to refine the reasoning policy. Experiments show that CauSight outperforms GPT-4.1 on visual causal discovery, achieving over a threefold performance boost (21% absolute gain). Our code, model, and dataset are fully open-sourced at project page: https://github.com/OpenCausaLab/CauSight.",
      "pdf_url": "https://arxiv.org/pdf/2512.01827v1",
      "arxiv_url": "http://arxiv.org/abs/2512.01827v1",
      "published": "2025-12-01",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "Probabilistic Neuro-Symbolic Reasoning for Sparse Historical Data: A Framework Integrating Bayesian Inference, Causal Models, and Game-Theoretic Allocation",
      "authors": [
        "Saba Kublashvili"
      ],
      "abstract": "Modeling historical events poses fundamental challenges for machine learning: extreme data scarcity (N << 100), heterogeneous and noisy measurements, missing counterfactuals, and the requirement for human interpretable explanations. We present HistoricalML, a probabilistic neuro-symbolic framework that addresses these challenges through principled integration of (1) Bayesian uncertainty quantification to separate epistemic from aleatoric uncertainty, (2) structural causal models for counterfactual reasoning under confounding, (3) cooperative game theory (Shapley values) for fair allocation modeling, and (4) attention based neural architectures for context dependent factor weighting. We provide theoretical analysis showing that our approach achieves consistent estimation in the sparse data regime when strong priors from domain knowledge are available, and that Shapley based allocation satisfies axiomatic fairness guarantees that pure regression approaches cannot provide. We instantiate the framework on two historical case studies: the 19th century partition of Africa (N = 7 colonial powers) and the Second Punic War (N = 2 factions). Our model identifies Germany's +107.9 percent discrepancy as a quantifiable structural tension preceding World War I, with tension factor 36.43 and 0.79 naval arms race correlation. For the Punic Wars, Monte Carlo battle simulations achieve a 57.3 percent win probability for Carthage at Cannae and 57.8 percent for Rome at Zama, aligning with historical outcomes. Counterfactual analysis reveals that Carthaginian political support (support score 6.4 vs Napoleon's 7.1), rather than military capability, was the decisive factor.",
      "pdf_url": "https://arxiv.org/pdf/2512.01723v1",
      "arxiv_url": "http://arxiv.org/abs/2512.01723v1",
      "published": "2025-12-01",
      "categories": [
        "cs.AI",
        "cs.GT",
        "math.PR"
      ]
    }
  ]
}