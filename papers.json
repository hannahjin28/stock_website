{
  "last_updated": "2025-05-06T00:52:59.709120",
  "papers": [
    {
      "title": "Design-Based Inference under Random Potential Outcomes via Riesz Representation",
      "authors": [
        "Yukai Yang"
      ],
      "abstract": "We introduce a general framework for design-based causal inference that\naccommodates stochastic potential outcomes, thereby extending the classical\nNeyman-Rubin setup in which outcomes are treated as fixed. In our formulation,\neach unit's potential outcome is modelled as a function $\\tilde{y}_i(z,\n\\omega)$, where $\\omega$ denotes latent randomness external to the treatment\nassignment. Building on recent work that connects design-based estimation with\nthe Riesz representation theorem, we construct causal estimators by embedding\npotential outcomes in a Hilbert space and defining treatment effects as linear\nfunctionals. This allows us to derive unbiased and consistent estimators, even\nwhen potential outcomes exhibit random variation. The framework retains the key\nadvantage of design-based analysis, namely, the use of a known randomisation\nscheme for identification, while enabling inference in settings with inherent\nstochasticity. We establish large-sample properties under local dependence,\nprovide a variance estimator compatible with sparse dependency structures, and\nillustrate the method through a simulation. Our results unify design-based\nreasoning with random-outcome modelling, broadening the applicability of causal\ninference in complex experimental environments.",
      "pdf_url": "http://arxiv.org/pdf/2505.01324v1",
      "arxiv_url": "http://arxiv.org/abs/2505.01324v1",
      "published": "2025-05-02",
      "categories": [
        "stat.ME",
        "econ.EM",
        "math.ST",
        "stat.TH",
        "62G20, 62K99, 62D05"
      ]
    },
    {
      "title": "Robust Root Cause Diagnosis using In-Distribution Interventions",
      "authors": [
        "Lokesh Nagalapatti",
        "Ashutosh Srivastava",
        "Sunita Sarawagi",
        "Amit Sharma"
      ],
      "abstract": "Diagnosing the root cause of an anomaly in a complex interconnected system is\na pressing problem in today's cloud services and industrial operations. We\npropose In-Distribution Interventions (IDI), a novel algorithm that predicts\nroot cause as nodes that meet two criteria: 1) **Anomaly:** root cause nodes\nshould take on anomalous values; 2) **Fix:** had the root cause nodes assumed\nusual values, the target node would not have been anomalous. Prior methods of\nassessing the fix condition rely on counterfactuals inferred from a Structural\nCausal Model (SCM) trained on historical data. But since anomalies are rare and\nfall outside the training distribution, the fitted SCMs yield unreliable\ncounterfactual estimates. IDI overcomes this by relying on interventional\nestimates obtained by solely probing the fitted SCM at in-distribution inputs.\nWe present a theoretical analysis comparing and bounding the errors in\nassessing the fix condition using interventional and counterfactual estimates.\nWe then conduct experiments by systematically varying the SCM's complexity to\ndemonstrate the cases where IDI's interventional approach outperforms the\ncounterfactual approach and vice versa. Experiments on both synthetic and\nPetShop RCD benchmark datasets demonstrate that \\our\\ consistently identifies\ntrue root causes more accurately and robustly than nine existing\nstate-of-the-art RCD baselines. Code is released at\nhttps://github.com/nlokeshiisc/IDI_release.",
      "pdf_url": "http://arxiv.org/pdf/2505.00930v1",
      "arxiv_url": "http://arxiv.org/abs/2505.00930v1",
      "published": "2025-05-02",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "Q-Learning with Clustered-SMART (cSMART) Data: Examining Moderators in the Construction of Clustered Adaptive Interventions",
      "authors": [
        "Yao Song",
        "Kelly Speth",
        "Amy Kilbourne",
        "Andrew Quanbeck",
        "Daniel Almirall",
        "Lu Wang"
      ],
      "abstract": "A clustered adaptive intervention (cAI) is a pre-specified sequence of\ndecision rules that guides practitioners on how best - and based on which\nmeasures - to tailor cluster-level intervention to improve outcomes at the\nlevel of individuals within the clusters. A clustered sequential multiple\nassignment randomized trial (cSMART) is a type of trial that is used to inform\nthe empirical development of a cAI. The most common type of secondary aim in a\ncSMART focuses on assessing causal effect moderation by candidate tailoring\nvariables. We introduce a clustered Q-learning framework with the M-out-of-N\nCluster Bootstrap using data from a cSMART to evaluate whether a set of\ncandidate tailoring variables may be useful in defining an optimal cAI. This\napproach could construct confidence intervals (CI) with near-nominal coverage\nto assess parameters indexing the causal effect moderation function.\nSpecifically, it allows reliable inferences concerning the utility of candidate\ntailoring variables in constructing a cAI that maximizes a mean end-of-study\noutcome even when \"non-regularity\", a well-known challenge exists. Simulations\ndemonstrate the numerical performance of the proposed method across varying\nnon-regularity conditions and investigate the impact of varying number of\nclusters and intra-cluster correlation coefficient on CI coverage. Methods are\napplied on ADEPT dataset to inform the construction of a clinic-level cAI for\nimproving evidence-based practice in treating mood disorders.",
      "pdf_url": "http://arxiv.org/pdf/2505.00822v1",
      "arxiv_url": "http://arxiv.org/abs/2505.00822v1",
      "published": "2025-05-01",
      "categories": [
        "stat.ME",
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "title": "Dual Filter: A Mathematical Framework for Inference using Transformer-like Architectures",
      "authors": [
        "Heng-Sheng Chang",
        "Prashant G. Mehta"
      ],
      "abstract": "This paper presents a mathematical framework for causal nonlinear prediction\nin settings where observations are generated from an underlying hidden Markov\nmodel (HMM). Both the problem formulation and the proposed solution are\nmotivated by the decoder-only transformer architecture, in which a finite\nsequence of observations (tokens) is mapped to the conditional probability of\nthe next token. Our objective is not to construct a mathematical model of a\ntransformer. Rather, our interest lies in deriving, from first principles,\ntransformer-like architectures that solve the prediction problem for which the\ntransformer is designed. The proposed framework is based on an original optimal\ncontrol approach, where the prediction objective (MMSE) is reformulated as an\noptimal control problem. An analysis of the optimal control problem is\npresented leading to a fixed-point equation on the space of probability\nmeasures. To solve the fixed-point equation, we introduce the dual filter, an\niterative algorithm that closely parallels the architecture of decoder-only\ntransformers. These parallels are discussed in detail along with the\nrelationship to prior work on mathematical modeling of transformers as\ntransport on the space of probability measures. Numerical experiments are\nprovided to illustrate the performance of the algorithm using parameter values\nused in researchscale transformer models.",
      "pdf_url": "http://arxiv.org/pdf/2505.00818v1",
      "arxiv_url": "http://arxiv.org/abs/2505.00818v1",
      "published": "2025-05-01",
      "categories": [
        "cs.LG",
        "cs.SY",
        "eess.SY",
        "math.PR"
      ]
    },
    {
      "title": "On the Mechanistic Interpretability of Neural Networks for Causality in Bio-statistics",
      "authors": [
        "Jean-Baptiste A. Conan"
      ],
      "abstract": "Interpretable insights from predictive models remain critical in\nbio-statistics, particularly when assessing causality, where classical\nstatistical and machine learning methods often provide inherent clarity. While\nNeural Networks (NNs) offer powerful capabilities for modeling complex\nbiological data, their traditional \"black-box\" nature presents challenges for\nvalidation and trust in high-stakes health applications. Recent advances in\nMechanistic Interpretability (MI) aim to decipher the internal computations\nlearned by these networks. This work investigates the application of MI\ntechniques to NNs within the context of causal inference for bio-statistics.\n  We demonstrate that MI tools can be leveraged to: (1) probe and validate the\ninternal representations learned by NNs, such as those estimating nuisance\nfunctions in frameworks like Targeted Minimum Loss-based Estimation (TMLE); (2)\ndiscover and visualize the distinct computational pathways employed by the\nnetwork to process different types of inputs, potentially revealing how\nconfounders and treatments are handled; and (3) provide methodologies for\ncomparing the learned mechanisms and extracted insights across statistical,\nmachine learning, and NN models, fostering a deeper understanding of their\nrespective strengths and weaknesses for causal bio-statistical analysis.",
      "pdf_url": "http://arxiv.org/pdf/2505.00555v1",
      "arxiv_url": "http://arxiv.org/abs/2505.00555v1",
      "published": "2025-05-01",
      "categories": [
        "stat.AP",
        "cs.AI"
      ]
    },
    {
      "title": "Geodesic Synthetic Control Methods for Random Objects and Functional Data",
      "authors": [
        "Daisuke Kurisu",
        "Yidong Zhou",
        "Taisuke Otsu",
        "Hans-Georg MÃ¼ller"
      ],
      "abstract": "We introduce a geodesic synthetic control method for causal inference that\nextends existing synthetic control methods to scenarios where outcomes are\nelements in a geodesic metric space rather than scalars. Examples of such\noutcomes include distributions, compositions, networks, trees and functional\ndata, among other data types that can be viewed as elements of a geodesic\nmetric space given a suitable metric. We extend this further to geodesic\nsynthetic difference-in-differences that builds on the established synthetic\ndifference-in-differences for Euclidean outcomes. This estimator generalizes\nboth the geodesic synthetic control method and a previously proposed geodesic\ndifference-in-differences method and exhibits a double robustness property. The\nproposed geodesic synthetic control method is illustrated through comprehensive\nsimulation studies and applications to the employment composition changes\nfollowing the 2011 Great East Japan Earthquake, and the impact of abortion\nliberalization policy on fertility patterns in East Germany. We illustrate the\nproposed geodesic synthetic difference-in-differences by studying the\nconsequences of the Soviet Union's collapse on age-at-death distributions for\nmales and females.",
      "pdf_url": "http://arxiv.org/pdf/2505.00331v1",
      "arxiv_url": "http://arxiv.org/abs/2505.00331v1",
      "published": "2025-05-01",
      "categories": [
        "stat.ME",
        "62D20, 62R20"
      ]
    },
    {
      "title": "A Unifying Framework for Robust and Efficient Inference with Unstructured Data",
      "authors": [
        "Jacob Carlson",
        "Melissa Dell"
      ],
      "abstract": "This paper presents a general framework for conducting efficient and robust\ninference on parameters derived from unstructured data, which include text,\nimages, audio, and video. Economists have long incorporated data extracted from\ntexts and images into their analyses, a practice that has accelerated with\nadvancements in deep neural networks. However, neural networks do not\ngenerically produce unbiased predictions, potentially propagating bias to\nestimators that use their outputs. To address this challenge, we reframe\ninference with unstructured data as a missing structured data problem, where\nstructured data are imputed from unstructured inputs using deep neural\nnetworks. This perspective allows us to apply classic results from\nsemiparametric inference, yielding valid, efficient, and robust estimators\nbased on unstructured data. We formalize this approach with MARS (Missing At\nRandom Structured Data), a unifying framework that integrates and extends\nexisting methods for debiased inference using machine learning predictions,\nlinking them to a variety of older, familiar problems such as causal inference.\nWe develop robust and efficient estimators for both descriptive and causal\nestimands and address challenges such as inference using aggregated and\ntransformed predictions from unstructured data. Importantly, MARS applies to\ncommon empirical settings that have received limited attention in the existing\nliterature. Finally, we reanalyze prominent studies that use unstructured data,\ndemonstrating the practical value of MARS.",
      "pdf_url": "http://arxiv.org/pdf/2505.00282v1",
      "arxiv_url": "http://arxiv.org/abs/2505.00282v1",
      "published": "2025-05-01",
      "categories": [
        "econ.EM",
        "cs.LG"
      ]
    },
    {
      "title": "Inference for max-linear Bayesian networks with noise",
      "authors": [
        "Mark Adams",
        "Kamillo Ferry",
        "Ruriko Yoshida"
      ],
      "abstract": "Max-Linear Bayesian Networks (MLBNs) provide a powerful framework for causal\ninference in extreme-value settings; we consider MLBNs with noise parameters\nwith a given topology in terms of the max-plus algebra by taking its logarithm.\nThen, we show that an estimator of a parameter for each edge in a directed\nacyclic graph (DAG) is distributed normally. We end this paper with\ncomputational experiments with the expectation and maximization (EM) algorithm\nand quadratic optimization.",
      "pdf_url": "http://arxiv.org/pdf/2505.00229v1",
      "arxiv_url": "http://arxiv.org/abs/2505.00229v1",
      "published": "2025-05-01",
      "categories": [
        "stat.ML",
        "cs.LG",
        "math.OC",
        "math.ST",
        "stat.TH",
        "14T90, 62A09, 62H30, 90C20, 90C90"
      ]
    },
    {
      "title": "Doubly robust augmented weighting estimators for the analysis of externally controlled single-arm trials and unanchored indirect treatment comparisons",
      "authors": [
        "Harlan Campbell",
        "Antonio Remiro-AzÃ³car"
      ],
      "abstract": "Externally controlled single-arm trials are critical to assess treatment\nefficacy across therapeutic indications for which randomized controlled trials\nare not feasible. A closely-related research design, the unanchored indirect\ntreatment comparison, is often required for disconnected treatment networks in\nhealth technology assessment. We present a unified causal inference framework\nfor both research designs. We develop a novel estimator that augments a popular\nweighting approach based on entropy balancing -- matching-adjusted indirect\ncomparison (MAIC) -- by fitting a model for the conditional outcome\nexpectation. The predictions of the outcome model are combined with the entropy\nbalancing MAIC weights. While the standard MAIC estimator is singly robust\nwhere the outcome model is non-linear, our augmented MAIC approach is doubly\nrobust, providing increased robustness against model misspecification. This is\ndemonstrated in a simulation study with binary outcomes and a logistic outcome\nmodel, where the augmented estimator demonstrates its doubly robust property,\nwhile exhibiting higher precision than all non-augmented weighting estimators\nand near-identical precision to G-computation. We describe the extension of our\nestimator to the setting with unavailable individual participant data for the\nexternal control, illustrating it through an applied example. Our findings\nreinforce the understanding that entropy balancing-based approaches have\ndesirable properties compared to standard ``modeling'' approaches to weighting,\nbut should be augmented to improve protection against bias and guarantee double\nrobustness.",
      "pdf_url": "http://arxiv.org/pdf/2505.00113v1",
      "arxiv_url": "http://arxiv.org/abs/2505.00113v1",
      "published": "2025-04-30",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Assessing Racial Disparities in Healthcare Expenditures Using Causal Path-Specific Effects",
      "authors": [
        "Xiaxian Ou",
        "Xinwei He",
        "David Benkeser",
        "Razieh Nabi"
      ],
      "abstract": "Racial disparities in healthcare expenditures are well-documented, yet the\nunderlying drivers remain complex and require further investigation. This study\nemploys causal and counterfactual path-specific effects to quantify how various\nfactors, including socioeconomic status, insurance access, health behaviors,\nand health status, mediate these disparities. Using data from the Medical\nExpenditures Panel Survey, we estimate how expenditures would differ under\ncounterfactual scenarios in which the values of specific mediators were aligned\nacross racial groups along selected causal pathways. A key challenge in this\nanalysis is ensuring robustness against model misspecification while addressing\nthe zero-inflation and right-skewness of healthcare expenditures. For reliable\ninference, we derive asymptotically linear estimators by integrating influence\nfunction-based techniques with flexible machine learning methods, including\nsuper learners and a two-part model tailored to the zero-inflated, right-skewed\nnature of healthcare expenditures.",
      "pdf_url": "http://arxiv.org/pdf/2504.21688v1",
      "arxiv_url": "http://arxiv.org/abs/2504.21688v1",
      "published": "2025-04-30",
      "categories": [
        "stat.AP",
        "stat.ME",
        "stat.ML"
      ]
    }
  ]
}