{
  "last_updated": "2026-02-06T01:07:56.057145",
  "papers": [
    {
      "title": "Addressing Corpus Knowledge Poisoning Attacks on RAG Using Sparse Attention",
      "authors": [
        "Sagie Dekel",
        "Moshe Tennenholtz",
        "Oren Kurland"
      ],
      "abstract": "Retrieval Augmented Generation (RAG) is a highly effective paradigm for keeping LLM-based responses up-to-date and reducing the likelihood of hallucinations. Yet, RAG was recently shown to be quite vulnerable to corpus knowledge poisoning: an attacker injects misleading documents to the corpus to steer an LLMs' output to an undesired response. We argue that the standard causal attention mechanism in LLMs enables harmful cross-document interactions, specifically in cases of attacks. Accordingly, we introduce a novel defense approach for RAG: Sparse Document Attention RAG (SDAG). This is a block-sparse attention mechanism that disallows cross-attention between retrieved documents. SDAG requires a minimal inference-time change to the attention mask; furthermore, no fine-tuning or additional architectural changes are needed. We present an empirical evaluation of LLM-based question answering (QA) with a variety of attack strategies on RAG. We show that our SDAG method substantially outperforms the standard causal attention mechanism in terms of attack success rate. We further demonstrate the clear merits of integrating SDAG with state-of-the-art RAG defense methods. Specifically, the integration results in performance that is statistically significantly better than the state-of-the-art.",
      "pdf_url": "https://arxiv.org/pdf/2602.04711v1",
      "arxiv_url": "http://arxiv.org/abs/2602.04711v1",
      "published": "2026-02-04",
      "categories": [
        "cs.IR",
        "cs.AI"
      ]
    },
    {
      "title": "$C$-$ΔΘ$: Circuit-Restricted Weight Arithmetic for Selective Refusal",
      "authors": [
        "Aditya Kasliwal",
        "Pratinav Seth",
        "Vinay Kumar Sankarapu"
      ],
      "abstract": "Modern deployments require LLMs to enforce safety policies at scale, yet many controls rely on inference-time interventions that add recurring compute cost and serving complexity. Activation steering is widely used, but it requires runtime hooks and scales cost with the number of generations; conditional variants improve selectivity by gating when steering is applied but still retain an inference-time control path. We ask whether selective refusal can be moved entirely offline: can a mechanistic understanding of category-specific refusal be distilled into a circuit-restricted weight update that deploys as a standard checkpoint? We propose C-Δθ: Circuit Restricted Weight Arithmetic, which (i) localizes refusal-causal computation as a sparse circuit using EAP-IG and (ii) computes a constrained weight update ΔθC supported only on that circuit (typically <5% of parameters). Applying ΔθC yields a drop-in edited checkpoint with no inference-time hooks, shifting cost from per-request intervention to a one-time offline update. We evaluate category-targeted selectivity and capability retention on refusal and utility benchmarks.",
      "pdf_url": "https://arxiv.org/pdf/2602.04521v1",
      "arxiv_url": "http://arxiv.org/abs/2602.04521v1",
      "published": "2026-02-04",
      "categories": [
        "cs.CL",
        "cs.ET"
      ]
    },
    {
      "title": "OAT: Ordered Action Tokenization",
      "authors": [
        "Chaoqi Liu",
        "Xiaoshen Han",
        "Jiawei Gao",
        "Yue Zhao",
        "Haonan Chen",
        "Yilun Du"
      ],
      "abstract": "Autoregressive policies offer a compelling foundation for scalable robot learning by enabling discrete abstraction, token-level reasoning, and flexible inference. However, applying autoregressive modeling to continuous robot actions requires an effective action tokenization scheme. Existing approaches either rely on analytical discretization methods that produce prohibitively long token sequences, or learned latent tokenizers that lack structure, limiting their compatibility with next-token prediction. In this work, we identify three desiderata for action tokenization - high compression, total decodability, and a left-to-right causally ordered token space - and introduce Ordered Action Tokenization (OAT), a learned action tokenizer that satisfies all three. OAT discretizes action chunks into an ordered sequence of tokens using transformer with registers, finite scalar quantization, and ordering-inducing training mechanisms. The resulting token space aligns naturally with autoregressive generation and enables prefix-based detokenization, yielding an anytime trade-off between inference cost and action fidelity. Across more than 20 tasks spanning four simulation benchmarks and real-world settings, autoregressive policies equipped with OAT consistently outperform prior tokenization schemes and diffusion-based baselines, while offering significantly greater flexibility at inference time.",
      "pdf_url": "https://arxiv.org/pdf/2602.04215v1",
      "arxiv_url": "http://arxiv.org/abs/2602.04215v1",
      "published": "2026-02-04",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Efficient Subgroup Analysis via Optimal Trees with Global Parameter Fusion",
      "authors": [
        "Zhongming Xie",
        "Joseph Giorgio",
        "Jingshen Wang"
      ],
      "abstract": "Identifying and making statistical inferences on differential treatment effects (commonly known as subgroup analysis in clinical research) is central to precision health. Subgroup analysis allows practitioners to pinpoint populations for whom a treatment is especially beneficial or protective, thereby advancing targeted interventions. Tree based recursive partitioning methods are widely used for subgroup analysis due to their interpretability. Nevertheless, these approaches encounter significant limitations, including suboptimal partitions induced by greedy heuristics and overfitting from locally estimated splits, especially under limited sample sizes. To address these limitations, we propose a fused optimal causal tree method that leverages mixed integer optimization (MIO) to facilitate precise subgroup identification. Our approach ensures globally optimal partitions and introduces a parameter fusion constraint to facilitate information sharing across related subgroups. This design substantially improves subgroup discovery accuracy and enhances statistical efficiency. We provide theoretical guarantees by rigorously establishing out of sample risk bounds and comparing them with those of classical tree based methods. Empirically, our method consistently outperforms popular baselines in simulations. Finally, we demonstrate its practical utility through a case study on the Health and Aging Brain Study Health Disparities (HABS-HD) dataset, where our approach yields clinically meaningful insights.",
      "pdf_url": "https://arxiv.org/pdf/2602.04077v1",
      "arxiv_url": "http://arxiv.org/abs/2602.04077v1",
      "published": "2026-02-03",
      "categories": [
        "stat.ML",
        "cs.LG"
      ]
    },
    {
      "title": "Causal Inference for the Effect of Code Coverage on Bug Introduction",
      "authors": [
        "Lukas Schulte",
        "Gordon Fraser",
        "Steffen Herbold"
      ],
      "abstract": "Context: Code coverage is widely used as a software quality assurance measure. However, its effect, and specifically the advisable dose, are disputed in both the research and engineering communities. Prior work reports only correlational associations, leaving results vulnerable to confounding factors. Objective: We aim to quantify the causal effect of code coverage (exposure) on bug introduction (outcome) in the context of mature JavaScript and TypeScript open source projects, addressing both the overall effect and its variance across coverage levels. Method: We construct a causal directed acyclic graph to identify confounders within the software engineering process, modeling key variables from the source code, issue- and review systems, and continuous integration. Using generalized propensity score adjustment, we will apply doubly robust regression-based causal inference for continuous exposure to a novel dataset of bug-introducing and non-bug-introducing changes. We estimate the average treatment effect and dose-response relationship to examine potential non-linear patterns (e.g., thresholds or diminishing returns) within the projects of our dataset.",
      "pdf_url": "https://arxiv.org/pdf/2602.03585v1",
      "arxiv_url": "http://arxiv.org/abs/2602.03585v1",
      "published": "2026-02-03",
      "categories": [
        "cs.SE"
      ]
    },
    {
      "title": "Causal Inference on Networks under Misspecified Exposure Mappings: A Partial Identification Framework",
      "authors": [
        "Maresa Schröder",
        "Miruna Oprescu",
        "Stefan Feuerriegel",
        "Nathan Kallus"
      ],
      "abstract": "Estimating treatment effects in networks is challenging, as each potential outcome depends on the treatments of all other nodes in the network. To overcome this difficulty, existing methods typically impose an exposure mapping that compresses the treatment assignments in the network into a low-dimensional summary. However, if this mapping is misspecified, standard estimators for direct and spillover effects can be severely biased. We propose a novel partial identification framework for causal inference on networks to assess the robustness of treatment effects under misspecifications of the exposure mapping. Specifically, we derive sharp upper and lower bounds on direct and spillover effects under such misspecifications. As such, our framework presents a novel application of causal sensitivity analysis to exposure mappings. We instantiate our framework for three canonical exposure settings widely used in practice: (i) weighted means of the neighborhood treatments, (ii) threshold-based exposure mappings, and (iii) truncated neighborhood interference in the presence of higher-order spillovers. Furthermore, we develop orthogonal estimators for these bounds and prove that the resulting bound estimates are valid, sharp, and efficient. Our experiments show the bounds remain informative and provide reliable conclusions under misspecification of exposure mappings.",
      "pdf_url": "https://arxiv.org/pdf/2602.03459v1",
      "arxiv_url": "http://arxiv.org/abs/2602.03459v1",
      "published": "2026-02-03",
      "categories": [
        "cs.LG",
        "stat.ME"
      ]
    },
    {
      "title": "Causal structures of turbulent skin-friction drag in wall-bounded turbulent flows",
      "authors": [
        "Yunchao Zhao",
        "Yitong Fan",
        "Weipeng Li"
      ],
      "abstract": "Understanding the mechanism of turbulent skin-friction drag (TSD) generation is of fundamental and practical importance for designing effective drag reduction strategies. However, many previous studies adopted correlation analysis to reveal the causal map between turbulent motions and TSD generation, an approach that is potentially risky as correlation does not necessarily imply causation. In this study, a novel causal inference method called Liang-Kleeman information flow (LKIF) is utilized for the first time to identify the velocity-induced causal structures related to TSD generation in a turbulent channel flow. The statistical properties of the causal structures are comprehensively investigated. The positive and negative causal structures, defined by their signs and respectively associated with an increase and decrease in TSD information entropy, promote and suppress the generation of extreme TSD. Particularly, we find that the underlying physics of causal structures is essentially associated with the processes of streamwise streaks and rolls approaching or receding from the extreme events. Results indicate that the physics-informed LKIF framework can reveal a more explicit and interpretable causal relationship than correlation analysis.",
      "pdf_url": "https://arxiv.org/pdf/2602.03187v1",
      "arxiv_url": "http://arxiv.org/abs/2602.03187v1",
      "published": "2026-02-03",
      "categories": [
        "physics.flu-dyn"
      ]
    },
    {
      "title": "The Trigger in the Haystack: Extracting and Reconstructing LLM Backdoor Triggers",
      "authors": [
        "Blake Bullwinkel",
        "Giorgio Severi",
        "Keegan Hines",
        "Amanda Minnich",
        "Ram Shankar Siva Kumar",
        "Yonatan Zunger"
      ],
      "abstract": "Detecting whether a model has been poisoned is a longstanding problem in AI security. In this work, we present a practical scanner for identifying sleeper agent-style backdoors in causal language models. Our approach relies on two key findings: first, sleeper agents tend to memorize poisoning data, making it possible to leak backdoor examples using memory extraction techniques. Second, poisoned LLMs exhibit distinctive patterns in their output distributions and attention heads when backdoor triggers are present in the input. Guided by these observations, we develop a scalable backdoor scanning methodology that assumes no prior knowledge of the trigger or target behavior and requires only inference operations. Our scanner integrates naturally into broader defensive strategies and does not alter model performance. We show that our method recovers working triggers across multiple backdoor scenarios and a broad range of models and fine-tuning methods.",
      "pdf_url": "https://arxiv.org/pdf/2602.03085v1",
      "arxiv_url": "http://arxiv.org/abs/2602.03085v1",
      "published": "2026-02-03",
      "categories": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "title": "Membership Inference Attacks from Causal Principles",
      "authors": [
        "Mathieu Even",
        "Clément Berenfeld",
        "Linus Bleistein",
        "Tudor Cebere",
        "Julie Josse",
        "Aurélien Bellet"
      ],
      "abstract": "Membership Inference Attacks (MIAs) are widely used to quantify training data memorization and assess privacy risks. Standard evaluation requires repeated retraining, which is computationally costly for large models. One-run methods (single training with randomized data inclusion) and zero-run methods (post hoc evaluation) are often used instead, though their statistical validity remains unclear. To address this gap, we frame MIA evaluation as a causal inference problem, defining memorization as the causal effect of including a data point in the training set. This novel formulation reveals and formalizes key sources of bias in existing protocols: one-run methods suffer from interference between jointly included points, while zero-run evaluations popular for LLMs are confounded by non-random membership assignment. We derive causal analogues of standard MIA metrics and propose practical estimators for multi-run, one-run, and zero-run regimes with non-asymptotic consistency guarantees. Experiments on real-world data show that our approach enables reliable memorization measurement even when retraining is impractical and under distribution shift, providing a principled foundation for privacy evaluation in modern AI systems.",
      "pdf_url": "https://arxiv.org/pdf/2602.02819v1",
      "arxiv_url": "http://arxiv.org/abs/2602.02819v1",
      "published": "2026-02-02",
      "categories": [
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "title": "Disentangling spatial interference and spatial confounding biases in causal inference",
      "authors": [
        "Isqeel Ogunsola",
        "Olatunji Johnson"
      ],
      "abstract": "Spatial interference and spatial confounding are two major issues inhibiting precise causal estimates when dealing with observational spatial data. Moreover, the definition and interpretation of spatial confounding remain arguable in the literature. In this paper, our goal is to provide clarity in a novel way on misconception and issues around spatial confounding from Directed Acyclic Graph (DAG) perspective and to disentangle both direct, indirect spatial confounding and spatial interference based on bias induced on causal estimates. Also, existing analyses of spatial confounding bias typically rely on Normality assumptions for treatments and confounders, assumptions that are often violated in practice. Relaxing these assumptions, we derive analytical expressions for spatial confounding bias under more general distributional settings using Poisson as example . We showed that the choice of spatial weights, the distribution of the treatment, and the magnitude of interference critically determine the extent of bias due to spatial interference. We further demonstrate that direct and indirect spatial confounding can be disentangled, with both the weight matrix and the nature of exposure playing central roles in determining the magnitude of indirect bias. Theoretical results are supported by simulation studies and an application to real-world spatial data. In future, parametric frameworks for concomitantly adjusting for spatial interference, direct and indirect spatial confounding for both direct and mediated effects estimation will be developed.",
      "pdf_url": "https://arxiv.org/pdf/2602.02777v1",
      "arxiv_url": "http://arxiv.org/abs/2602.02777v1",
      "published": "2026-02-02",
      "categories": [
        "stat.ME"
      ]
    }
  ]
}