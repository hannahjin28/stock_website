{
  "last_updated": "2025-05-18T00:57:36.112017",
  "papers": [
    {
      "title": "Closure and Complexity of Temporal Causality",
      "authors": [
        "Mishel Carelli",
        "Bernd Finkbeiner",
        "Julian Siber"
      ],
      "abstract": "Temporal causality defines what property causes some observed temporal\nbehavior (the effect) in a given computation, based on a counterfactual\nanalysis of similar computations. In this paper, we study its closure\nproperties and the complexity of computing causes. For the former, we establish\nthat safety, reachability, and recurrence properties are all closed under\ncausal inference: If the effect is from one of these property classes, then the\ncause for this effect is from the same class. We also show that persistence and\nobligation properties are not closed in this way. These results rest on a\ntopological characterization of causes which makes them applicable to a wide\nrange of similarity relations between computations. Finally, our complexity\nanalysis establishes improved upper bounds for computing causes for safety,\nreachability, and recurrence properties. We also present the first lower bounds\nfor all of the classes.",
      "pdf_url": "http://arxiv.org/pdf/2505.10186v1",
      "arxiv_url": "http://arxiv.org/abs/2505.10186v1",
      "published": "2025-05-15",
      "categories": [
        "cs.LO"
      ]
    },
    {
      "title": "Forests for Differences: Robust Causal Inference Beyond Parametric DiD",
      "authors": [
        "Hugo Gobato Souto",
        "Francisco Louzada Neto"
      ],
      "abstract": "This paper introduces the Difference-in-Differences Bayesian Causal Forest\n(DiD-BCF), a novel non-parametric model addressing key challenges in DiD\nestimation, such as staggered adoption and heterogeneous treatment effects.\nDiD-BCF provides a unified framework for estimating Average (ATE),\nGroup-Average (GATE), and Conditional Average Treatment Effects (CATE). A core\ninnovation, its Parallel Trends Assumption (PTA)-based reparameterization,\nenhances estimation accuracy and stability in complex panel data settings.\nExtensive simulations demonstrate DiD-BCF's superior performance over\nestablished benchmarks, particularly under non-linearity, selection biases, and\neffect heterogeneity. Applied to U.S. minimum wage policy, the model uncovers\nsignificant conditional treatment effect heterogeneity related to county\npopulation, insights obscured by traditional methods. DiD-BCF offers a robust\nand versatile tool for more nuanced causal inference in modern DiD\napplications.",
      "pdf_url": "http://arxiv.org/pdf/2505.09706v1",
      "arxiv_url": "http://arxiv.org/abs/2505.09706v1",
      "published": "2025-05-14",
      "categories": [
        "stat.ME",
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "title": "Language Agents Mirror Human Causal Reasoning Biases. How Can We Help Them Think Like Scientists?",
      "authors": [
        "Anthony GX-Chen",
        "Dongyan Lin",
        "Mandana Samiei",
        "Doina Precup",
        "Blake A. Richards",
        "Rob Fergus",
        "Kenneth Marino"
      ],
      "abstract": "Language model (LM) agents are increasingly used as autonomous\ndecision-makers who need to actively gather information to guide their\ndecisions. A crucial cognitive skill for such agents is the efficient\nexploration and understanding of the causal structure of the world -- key to\nrobust, scientifically grounded reasoning. Yet, it remains unclear whether LMs\npossess this capability or exhibit systematic biases leading to erroneous\nconclusions. In this work, we examine LMs' ability to explore and infer causal\nrelationships, using the well-established \"Blicket Test\" paradigm from\ndevelopmental psychology. We find that LMs reliably infer the common, intuitive\ndisjunctive causal relationships but systematically struggle with the unusual,\nyet equally (or sometimes even more) evidenced conjunctive ones. This\n\"disjunctive bias\" persists across model families, sizes, and prompting\nstrategies, and performance further declines as task complexity increases.\nInterestingly, an analogous bias appears in human adults, suggesting that LMs\nmay have inherited deep-seated reasoning heuristics from their training data.\nTo this end, we quantify similarities between LMs and humans, finding that LMs\nexhibit adult-like inference profiles (but not children-like). Finally, we\npropose a test-time sampling method which explicitly samples and eliminates\nhypotheses about causal relationships from the LM. This scalable approach\nsignificantly reduces the disjunctive bias and moves LMs closer to the goal of\nscientific, causally rigorous reasoning.",
      "pdf_url": "http://arxiv.org/pdf/2505.09614v1",
      "arxiv_url": "http://arxiv.org/abs/2505.09614v1",
      "published": "2025-05-14",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Moving towards informative and actionable social media research",
      "authors": [
        "Joseph B. Bak-Coleman",
        "Stephan Lewandowsky",
        "Philipp Lorenz-Spreen",
        "Arvind Narayanan",
        "Amy Orben",
        "Lisa Oswald"
      ],
      "abstract": "Social media is nearly ubiquitous in modern life, and concerns have been\nraised about its putative societal impacts, ranging from undermining mental\nhealth and exacerbating polarization to fomenting violence and disrupting\ndemocracy. Despite extensive research, consensus on these effects remains\nelusive, with observational studies often highlighting concerns while\nrandomized controlled trials (RCTs) yield conflicting or null findings. This\nreview examines how the complexity inherent in social systems can account for\nsuch discrepancies, emphasizing that emergent societal and long-term outcomes\ncannot be readily inferred from individual-level effects. In complex systems,\nsuch as social networks, feedback loops, hysteresis, multi-scale dynamics, and\nnon-linearity limit the utility of approaches for assessing causality that are\notherwise robust in simpler contexts. Revisiting large-scale experiments, we\nexplore how null or conflicting findings may reflect these complexities rather\nthan a true absence of effects. Even in cases where the methods are\nappropriate, assessing the net impacts of social media provides little\nactionable insight given that eliminating social media is not a realistic\noption for whole populations. We argue that progress will require a\ncomplexity-minded approach focused on specific design choices of online\nplatforms that triangulates experimental, observational and theoretical\nmethods.",
      "pdf_url": "http://arxiv.org/pdf/2505.09254v1",
      "arxiv_url": "http://arxiv.org/abs/2505.09254v1",
      "published": "2025-05-14",
      "categories": [
        "cs.SI",
        "nlin.AO"
      ]
    },
    {
      "title": "Modeling Interdependent Cybersecurity Threats Using Bayesian Networks: A Case Study on In-Vehicle Infotainment Systems",
      "authors": [
        "Sangita Sridar"
      ],
      "abstract": "Cybersecurity threats are increasingly marked by interdependence,\nuncertainty, and evolving complexity challenges that traditional assessment\nmethods such as CVSS, STRIDE, and attack trees fail to adequately capture. This\npaper reviews the application of Bayesian Networks (BNs) in cybersecurity risk\nmodeling, highlighting their capacity to represent probabilistic dependencies,\nintegrate diverse threat indicators, and support reasoning under uncertainty. A\nstructured case study is presented in which a STRIDE-based attack tree for an\nautomotive In-Vehicle Infotainment (IVI) system is transformed into a Bayesian\nNetwork. Logical relationships are encoded using Conditional Probability Tables\n(CPTs), and threat likelihoods are derived from normalized DREAD scores. The\nmodel enables not only probabilistic inference of system compromise likelihood\nbut also supports causal analysis using do-calculus and local sensitivity\nanalysis to identify high-impact vulnerabilities. These analyses provide\ninsight into the most influential nodes within the threat propagation chain,\ninforming targeted mitigation strategies. While demonstrating the potential of\nBNs for dynamic and context-aware risk assessment, the study also outlines\nlimitations related to scalability, reliance on expert input, static structure\nassumptions, and limited temporal modeling. The paper concludes by advocating\nfor future enhancements through Dynamic Bayesian Networks, structure learning,\nand adaptive inference to better support real-time cybersecurity\ndecision-making in complex environments.",
      "pdf_url": "http://arxiv.org/pdf/2505.09048v1",
      "arxiv_url": "http://arxiv.org/abs/2505.09048v1",
      "published": "2025-05-14",
      "categories": [
        "cs.CR"
      ]
    },
    {
      "title": "Modern causal inference approaches to improve power for subgroup analysis in randomized controlled trials",
      "authors": [
        "Antonio D'Alessandro",
        "Jiyu Kim",
        "Samrachana Adhikari",
        "Donald Goff",
        "Falco Bargagli Stoffi",
        "Michele Santacatterina"
      ],
      "abstract": "In randomized controlled trials (RCTs), subgroup analyses are often planned\nto evaluate the heterogeneity of treatment effects within pre-specified\nsubgroups of interest. However, these analyses frequently have small sample\nsizes, reducing the power to detect heterogeneous effects. A way to increase\npower is by borrowing external data from similar RCTs or observational studies.\nIn this project, we target the conditional average treatment effect (CATE) as\nthe estimand of interest, provide identification assumptions, and propose a\ndoubly robust estimator that uses machine learning and Bayesian nonparametric\ntechniques. Borrowing data, however, may present the additional challenge of\npractical violations of the positivity assumption, the conditional probability\nof receiving treatment in the external data source may be small, leading to\nlarge inverse weights and erroneous inferences, thus negating the potential\npower gains from borrowing external data. To overcome this challenge, we also\npropose a covariate balancing approach, an automated debiased machine learning\n(DML) estimator, and a calibrated DML estimator. We show improved power in\nvarious simulations and offer practical recommendations for the application of\nthe proposed methods. Finally, we apply them to evaluate the effectiveness of\ncitalopram, a drug commonly used to treat depression, for negative symptoms in\nfirst-episode schizophrenia patients across subgroups defined by duration of\nuntreated psychosis, using data from two RCTs and an observational study.",
      "pdf_url": "http://arxiv.org/pdf/2505.08960v1",
      "arxiv_url": "http://arxiv.org/abs/2505.08960v1",
      "published": "2025-05-13",
      "categories": [
        "stat.ME",
        "62P10"
      ]
    },
    {
      "title": "AC-Reason: Towards Theory-Guided Actual Causality Reasoning with Large Language Models",
      "authors": [
        "Yanxi Zhang",
        "Xin Cong",
        "Zhong Zhang",
        "Xiao Liu",
        "Dongyan Zhao",
        "Yesai Wu"
      ],
      "abstract": "Actual causality (AC), a fundamental aspect of causal reasoning (CR), is\nresponsible for attribution and responsibility assignment in real-world\nscenarios. However, existing LLM-based methods lack grounding in formal AC\ntheory, resulting in limited interpretability. Therefore, we propose AC-Reason,\na semi-formal reasoning framework that identifies causally relevant events\nwithin an AC scenario, infers the values of their formal causal factors (e.g.,\nsufficiency, necessity, and normality), and answers AC queries via a\ntheory-guided algorithm with explanations. While AC-Reason does not explicitly\nconstruct a causal graph, it operates over variables in the underlying causal\nstructure to support principled reasoning. To enable comprehensive evaluation,\nwe introduce AC-Bench, a new benchmark built upon and substantially extending\nBig-Bench Hard Causal Judgment (BBH-CJ). AC-Bench comprises ~1K carefully\nannotated samples, each with detailed reasoning steps and focuses solely on\nactual causation. The case study shows that synthesized samples in AC-Bench\npresent greater challenges for LLMs. Extensive experiments on BBH-CJ and\nAC-Bench show that AC-Reason consistently improves LLM performance over\nbaselines. On BBH-CJ, all tested LLMs surpass the average human rater accuracy\nof 69.60%, with GPT-4 + AC-Reason achieving 75.04%. On AC-Bench, GPT-4 +\nAC-Reason again achieves the highest accuracy of 71.82%. AC-Bench further\nenables fine-grained analysis of reasoning faithfulness, revealing that only\nQwen-2.5-72B-Instruct, Claude-3.5-Sonnet, and GPT-4o exhibit faithful\nreasoning, whereas GPT-4 tends to exploit shortcuts. Finally, our ablation\nstudy proves that integrating AC theory into LLMs is highly effective, with the\nproposed algorithm contributing the most significant performance gains.",
      "pdf_url": "http://arxiv.org/pdf/2505.08750v1",
      "arxiv_url": "http://arxiv.org/abs/2505.08750v1",
      "published": "2025-05-13",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "title": "Assumption-robust Causal Inference",
      "authors": [
        "Aditya Ghosh",
        "Dominik Rothenhäusler"
      ],
      "abstract": "In observational causal inference, it is common to encounter multiple\nadjustment sets that appear equally plausible. It is often untestable which of\nthese adjustment sets are valid to adjust for (i.e., satisfies ignorability).\nThis discrepancy can pose practical challenges as it is typically unclear how\nto reconcile multiple, possibly conflicting estimates of the average treatment\neffect (ATE). A naive approach is to report the whole range (convex hull of the\nunion) of the resulting confidence intervals. However, the width of this\ninterval might not shrink to zero in large samples and can be unnecessarily\nwide in real applications. To address this issue, we propose a summary\nprocedure that generates a single estimate, one confidence interval, and\nidentifies a set of units for which the causal effect estimate remains valid,\nprovided at least one adjustment set is valid. The width of our proposed\nconfidence interval shrinks to zero with sample size at $n^{-1/2}$ rate, unlike\nthe original range which is of constant order. Thus, our assumption-robust\napproach enables reliable causal inference on the ATE even in scenarios where\nmost of the adjustment sets are invalid. Admittedly, this robustness comes at a\ncost: our inferential guarantees apply to a target population close to, but\ndifferent from, the one originally intended. We use synthetic and real-data\nexamples to demonstrate that our proposed procedure provides substantially\ntighter confidence intervals for the ATE as compared to the whole range. In\nparticular, for a real-world dataset on 401(k) retirement plans our method\nproduces a confidence interval 50\\% shorter than the whole range of confidence\nintervals based on multiple adjustment sets.",
      "pdf_url": "http://arxiv.org/pdf/2505.08729v1",
      "arxiv_url": "http://arxiv.org/abs/2505.08729v1",
      "published": "2025-05-13",
      "categories": [
        "stat.ME",
        "econ.EM"
      ]
    },
    {
      "title": "Bayesian Estimation of Causal Effects Using Proxies of a Latent Interference Network",
      "authors": [
        "Bar Weinstein",
        "Daniel Nevo"
      ],
      "abstract": "Network interference occurs when treatments assigned to some units affect the\noutcomes of others. Traditional approaches often assume that the observed\nnetwork correctly specifies the interference structure. However, in practice,\nresearchers frequently only have access to proxy measurements of the\ninterference network due to limitations in data collection or potential\nmismatches between measured networks and actual interference pathways. In this\npaper, we introduce a framework for estimating causal effects when only proxy\nnetworks are available. Our approach leverages a structural causal model that\naccommodates diverse proxy types, including noisy measurements, multiple data\nsources, and multilayer networks, and defines causal effects as interventions\non population-level treatments. Since the true interference network is latent,\nestimation poses significant challenges. To overcome them, we develop a\nBayesian inference framework. We propose a Block Gibbs sampler with Locally\nInformed Proposals to update the latent network, thereby efficiently exploring\nthe high-dimensional posterior space composed of both discrete and continuous\nparameters. We illustrate the performance of our method through numerical\nexperiments, demonstrating its accuracy in recovering causal effects even when\nonly proxies of the interference network are available.",
      "pdf_url": "http://arxiv.org/pdf/2505.08395v1",
      "arxiv_url": "http://arxiv.org/abs/2505.08395v1",
      "published": "2025-05-13",
      "categories": [
        "stat.ME",
        "stat.AP",
        "stat.CO",
        "stat.ML",
        "stat.OT"
      ]
    },
    {
      "title": "Empowering Vision Transformers with Multi-Scale Causal Intervention for Long-Tailed Image Classification",
      "authors": [
        "Xiaoshuo Yan",
        "Zhaochuan Li",
        "Lei Meng",
        "Zhuang Qi",
        "Wei Wu",
        "Zixuan Li",
        "Xiangxu Meng"
      ],
      "abstract": "Causal inference has emerged as a promising approach to mitigate long-tail\nclassification by handling the biases introduced by class imbalance. However,\nalong with the change of advanced backbone models from Convolutional Neural\nNetworks (CNNs) to Visual Transformers (ViT), existing causal models may not\nachieve an expected performance gain. This paper investigates the influence of\nexisting causal models on CNNs and ViT variants, highlighting that ViT's global\nfeature representation makes it hard for causal methods to model associations\nbetween fine-grained features and predictions, which leads to difficulties in\nclassifying tail classes with similar visual appearance. To address these\nissues, this paper proposes TSCNet, a two-stage causal modeling method to\ndiscover fine-grained causal associations through multi-scale causal\ninterventions. Specifically, in the hierarchical causal representation learning\nstage (HCRL), it decouples the background and objects, applying backdoor\ninterventions at both the patch and feature level to prevent model from using\nclass-irrelevant areas to infer labels which enhances fine-grained causal\nrepresentation. In the counterfactual logits bias calibration stage (CLBC), it\nrefines the optimization of model's decision boundary by adaptive constructing\ncounterfactual balanced data distribution to remove the spurious associations\nin the logits caused by data distribution. Extensive experiments conducted on\nvarious long-tail benchmarks demonstrate that the proposed TSCNet can eliminate\nmultiple biases introduced by data imbalance, which outperforms existing\nmethods.",
      "pdf_url": "http://arxiv.org/pdf/2505.08173v1",
      "arxiv_url": "http://arxiv.org/abs/2505.08173v1",
      "published": "2025-05-13",
      "categories": [
        "cs.CV"
      ]
    }
  ]
}