{
  "last_updated": "2026-01-01T01:04:31.787282",
  "papers": [
    {
      "title": "Stream-DiffVSR: Low-Latency Streamable Video Super-Resolution via Auto-Regressive Diffusion",
      "authors": [
        "Hau-Shiang Shiu",
        "Chin-Yang Lin",
        "Zhixiang Wang",
        "Chi-Wei Hsiao",
        "Po-Fan Yu",
        "Yu-Chih Chen",
        "Yu-Lun Liu"
      ],
      "abstract": "Diffusion-based video super-resolution (VSR) methods achieve strong perceptual quality but remain impractical for latency-sensitive settings due to reliance on future frames and expensive multi-step denoising. We propose Stream-DiffVSR, a causally conditioned diffusion framework for efficient online VSR. Operating strictly on past frames, it combines a four-step distilled denoiser for fast inference, an Auto-regressive Temporal Guidance (ARTG) module that injects motion-aligned cues during latent denoising, and a lightweight temporal-aware decoder with a Temporal Processor Module (TPM) that enhances detail and temporal coherence. Stream-DiffVSR processes 720p frames in 0.328 seconds on an RTX4090 GPU and significantly outperforms prior diffusion-based methods. Compared with the online SOTA TMP, it boosts perceptual quality (LPIPS +0.095) while reducing latency by over 130x. Stream-DiffVSR achieves the lowest latency reported for diffusion-based VSR, reducing initial delay from over 4600 seconds to 0.328 seconds, thereby making it the first diffusion VSR method suitable for low-latency online deployment. Project page: https://jamichss.github.io/stream-diffvsr-project-page/",
      "pdf_url": "https://arxiv.org/pdf/2512.23709v1",
      "arxiv_url": "http://arxiv.org/abs/2512.23709v1",
      "published": "2025-12-29",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "Propensity Patchwork Kriging for Scalable Inference on Heterogeneous Treatment Effects",
      "authors": [
        "Hajime Ogawa",
        "Shonosuke Sugasawa"
      ],
      "abstract": "Gaussian process-based models are attractive for estimating heterogeneous treatment effects (HTE), but their computational cost limits scalability in causal inference settings. In this work, we address this challenge by extending Patchwork Kriging into the causal inference framework. Our proposed method partitions the data according to the estimated propensity score and applies Patchwork Kriging to enforce continuity of HTE estimates across adjacent regions. By imposing continuity constraints only along the propensity score dimension, rather than the full covariate space, the proposed approach substantially reduces computational cost while avoiding discontinuities inherent in simple local approximations. The resulting method can be interpreted as a smoothing extension of stratification and provides an efficient approach to HTE estimation. The proposed method is demonstrated through simulation studies and a real data application.",
      "pdf_url": "https://arxiv.org/pdf/2512.23467v1",
      "arxiv_url": "http://arxiv.org/abs/2512.23467v1",
      "published": "2025-12-29",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Probabilistic Modelling is Sufficient for Causal Inference",
      "authors": [
        "Bruno Mlodozeniec",
        "David Krueger",
        "Richard E. Turner"
      ],
      "abstract": "Causal inference is a key research area in machine learning, yet confusion reigns over the tools needed to tackle it. There are prevalent claims in the machine learning literature that you need a bespoke causal framework or notation to answer causal questions. In this paper, we want to make it clear that you \\emph{can} answer any causal inference question within the realm of probabilistic modelling and inference, without causal-specific tools or notation. Through concrete examples, we demonstrate how causal questions can be tackled by writing down the probability of everything. Lastly, we reinterpret causal tools as emerging from standard probabilistic modelling and inference, elucidating their necessity and utility.",
      "pdf_url": "https://arxiv.org/pdf/2512.23408v1",
      "arxiv_url": "http://arxiv.org/abs/2512.23408v1",
      "published": "2025-12-29",
      "categories": [
        "stat.ML",
        "cs.LG",
        "stat.ME"
      ]
    },
    {
      "title": "Is Chain-of-Thought Really Not Explainability? Chain-of-Thought Can Be Faithful without Hint Verbalization",
      "authors": [
        "Kerem Zaman",
        "Shashank Srivastava"
      ],
      "abstract": "Recent work, using the Biasing Features metric, labels a CoT as unfaithful if it omits a prompt-injected hint that affected the prediction. We argue this metric confuses unfaithfulness with incompleteness, the lossy compression needed to turn distributed transformer computation into a linear natural language narrative. On multi-hop reasoning tasks with Llama-3 and Gemma-3, many CoTs flagged as unfaithful by Biasing Features are judged faithful by other metrics, exceeding 50% in some models. With a new faithful@k metric, we show that larger inference-time token budgets greatly increase hint verbalization (up to 90% in some settings), suggesting much apparent unfaithfulness is due to tight token limits. Using Causal Mediation Analysis, we further show that even non-verbalized hints can causally mediate prediction changes through the CoT. We therefore caution against relying solely on hint-based evaluations and advocate a broader interpretability toolkit, including causal mediation and corruption-based metrics.",
      "pdf_url": "https://arxiv.org/pdf/2512.23032v1",
      "arxiv_url": "http://arxiv.org/abs/2512.23032v1",
      "published": "2025-12-28",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Causal-Policy Forest for End-to-End Policy Learning",
      "authors": [
        "Masahiro Kato"
      ],
      "abstract": "This study proposes an end-to-end algorithm for policy learning in causal inference. We observe data consisting of covariates, treatment assignments, and outcomes, where only the outcome corresponding to the assigned treatment is observed. The goal of policy learning is to train a policy from the observed data, where a policy is a function that recommends an optimal treatment for each individual, to maximize the policy value. In this study, we first show that maximizing the policy value is equivalent to minimizing the mean squared error for the conditional average treatment effect (CATE) under $\\{-1, 1\\}$ restricted regression models. Based on this finding, we modify the causal forest, an end-to-end CATE estimation algorithm, for policy learning. We refer to our algorithm as the causal-policy forest. Our algorithm has three advantages. First, it is a simple modification of an existing, widely used CATE estimation method, therefore, it helps bridge the gap between policy learning and CATE estimation in practice. Second, while existing studies typically estimate nuisance parameters for policy learning as a separate task, our algorithm trains the policy in a more end-to-end manner. Third, as in standard decision trees and random forests, we train the models efficiently, avoiding computational intractability.",
      "pdf_url": "https://arxiv.org/pdf/2512.22846v1",
      "arxiv_url": "http://arxiv.org/abs/2512.22846v1",
      "published": "2025-12-28",
      "categories": [
        "econ.EM",
        "cs.LG",
        "math.ST",
        "stat.ME",
        "stat.ML"
      ]
    },
    {
      "title": "WeDLM: Reconciling Diffusion Language Models with Standard Causal Attention for Fast Inference",
      "authors": [
        "Aiwei Liu",
        "Minghua He",
        "Shaoxun Zeng",
        "Sijun Zhang",
        "Linhao Zhang",
        "Chuhan Wu",
        "Wei Jia",
        "Yuan Liu",
        "Xiao Zhou",
        "Jie Zhou"
      ],
      "abstract": "Autoregressive (AR) generation is the standard decoding paradigm for Large Language Models (LLMs), but its token-by-token nature limits parallelism at inference time. Diffusion Language Models (DLLMs) offer parallel decoding by recovering multiple masked tokens per step; however, in practice they often fail to translate this parallelism into deployment speed gains over optimized AR engines (e.g., vLLM). A key reason is that many DLLMs rely on bidirectional attention, which breaks standard prefix KV caching and forces repeated contextualization, undermining efficiency. We propose WeDLM, a diffusion decoding framework built entirely on standard causal attention to make parallel generation prefix-cache friendly. The core idea is to let each masked position condition on all currently observed tokens while keeping a strict causal mask, achieved by Topological Reordering that moves observed tokens to the physical prefix while preserving their logical positions. Building on this property, we introduce a streaming decoding procedure that continuously commits confident tokens into a growing left-to-right prefix and maintains a fixed parallel workload, avoiding the stop-and-wait behavior common in block diffusion methods. Experiments show that WeDLM preserves the quality of strong AR backbones while delivering substantial speedups, approaching 3x on challenging reasoning benchmarks and up to 10x in low-entropy generation regimes; critically, our comparisons are against AR baselines served by vLLM under matched deployment settings, demonstrating that diffusion-style decoding can outperform an optimized AR engine in practice.",
      "pdf_url": "https://arxiv.org/pdf/2512.22737v1",
      "arxiv_url": "http://arxiv.org/abs/2512.22737v1",
      "published": "2025-12-28",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "title": "Lightweight Inference-Time Personalization for Frozen Knowledge Graph Embeddings",
      "authors": [
        "Ozan Oguztuzun",
        "Cerag Oguztuzun"
      ],
      "abstract": "Foundation models for knowledge graphs (KGs) achieve strong cohort-level performance in link prediction, yet fail to capture individual user preferences; a key disconnect between general relational reasoning and personalized ranking. We propose GatedBias, a lightweight inference-time personalization framework that adapts frozen KG embeddings to individual user contexts without retraining or compromising global accuracy. Our approach introduces structure-gated adaptation: profile-specific features combine with graph-derived binary gates to produce interpretable, per-entity biases, requiring only ${\\sim}300$ trainable parameters. We evaluate GatedBias on two benchmark datasets (Amazon-Book and Last-FM), demonstrating statistically significant improvements in alignment metrics while preserving cohort performance. Counterfactual perturbation experiments validate causal responsiveness; entities benefiting from specific preference signals show 6--30$\\times$ greater rank improvements when those signals are boosted. These results show that personalized adaptation of foundation models can be both parameter-efficient and causally verifiable, bridging general knowledge representations with individual user needs.",
      "pdf_url": "https://arxiv.org/pdf/2512.22398v1",
      "arxiv_url": "http://arxiv.org/abs/2512.22398v1",
      "published": "2025-12-26",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Knot Forcing: Taming Autoregressive Video Diffusion Models for Real-time Infinite Interactive Portrait Animation",
      "authors": [
        "Steven Xiao",
        "Xindi Zhang",
        "Dechao Meng",
        "Qi Wang",
        "Peng Zhang",
        "Bang Zhang"
      ],
      "abstract": "Real-time portrait animation is essential for interactive applications such as virtual assistants and live avatars, requiring high visual fidelity, temporal coherence, ultra-low latency, and responsive control from dynamic inputs like reference images and driving signals. While diffusion-based models achieve strong quality, their non-causal nature hinders streaming deployment. Causal autoregressive video generation approaches enable efficient frame-by-frame generation but suffer from error accumulation, motion discontinuities at chunk boundaries, and degraded long-term consistency. In this work, we present a novel streaming framework named Knot Forcing for real-time portrait animation that addresses these challenges through three key designs: (1) a chunk-wise generation strategy with global identity preservation via cached KV states of the reference image and local temporal modeling using sliding window attention; (2) a temporal knot module that overlaps adjacent chunks and propagates spatio-temporal cues via image-to-video conditioning to smooth inter-chunk motion transitions; and (3) A \"running ahead\" mechanism that dynamically updates the reference frame's temporal coordinate during inference, keeping its semantic context ahead of the current rollout frame to support long-term coherence. Knot Forcing enables high-fidelity, temporally consistent, and interactive portrait animation over infinite sequences, achieving real-time performance with strong visual stability on consumer-grade GPUs.",
      "pdf_url": "https://arxiv.org/pdf/2512.21734v2",
      "arxiv_url": "http://arxiv.org/abs/2512.21734v2",
      "published": "2025-12-25",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "Enabling Conversational Behavior Reasoning Capabilities in Full-Duplex Speech",
      "authors": [
        "Shuchang Pan",
        "Siddharth Banerjee",
        "Dhruv Hebbar",
        "Siddhant Patel",
        "Akshaj Gupta",
        "Kan Jen Cheng",
        "Hanjo Kim",
        "Zeyi Austin Li",
        "Martin Q. Ma",
        "Tingle Li",
        "Gopala Anumanchipalli",
        "Jiachen Lian"
      ],
      "abstract": "Human conversation is organized by an implicit chain of thoughts that manifests as timed speech acts. Capturing this causal pathway is key to building natural full-duplex interactive systems. We introduce a framework that enables reasoning over conversational behaviors by modeling this process as causal inference within a Graph-of-Thoughts (GoT). Our approach formalizes the intent-to-action pathway with a hierarchical labeling scheme, predicting high-level communicative intents and low-level speech acts to learn their causal and temporal dependencies. To train this system, we develop a hybrid corpus that pairs controllable, event-rich simulations with human-annotated rationales and real conversational speech. The GoT framework structures streaming predictions as an evolving graph, enabling a multimodal transformer to forecast the next speech act, generate concise justifications for its decisions, and dynamically refine its reasoning. Experiments on both synthetic and real duplex dialogues show that the framework delivers robust behavior detection, produces interpretable reasoning chains, and establishes a foundation for benchmarking conversational reasoning in full duplex spoken dialogue systems.",
      "pdf_url": "https://arxiv.org/pdf/2512.21706v1",
      "arxiv_url": "http://arxiv.org/abs/2512.21706v1",
      "published": "2025-12-25",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "CausalFSFG: Rethinking Few-Shot Fine-Grained Visual Categorization from Causal Perspective",
      "authors": [
        "Zhiwen Yang",
        "Jinglin Xu",
        "Yuxin Pen"
      ],
      "abstract": "Few-shot fine-grained visual categorization (FS-FGVC) focuses on identifying various subcategories within a common superclass given just one or few support examples. Most existing methods aim to boost classification accuracy by enriching the extracted features with discriminative part-level details. However, they often overlook the fact that the set of support samples acts as a confounding variable, which hampers the FS-FGVC performance by introducing biased data distribution and misguiding the extraction of discriminative features. To address this issue, we propose a new causal FS-FGVC (CausalFSFG) approach inspired by causal inference for addressing biased data distributions through causal intervention. Specifically, based on the structural causal model (SCM), we argue that FS-FGVC infers the subcategories (i.e., effect) from the inputs (i.e., cause), whereas both the few-shot condition disturbance and the inherent fine-grained nature (i.e., large intra-class variance and small inter-class variance) lead to unobservable variables that bring spurious correlations, compromising the final classification performance. To further eliminate the spurious correlations, our CausalFSFG approach incorporates two key components: (1) Interventional multi-scale encoder (IMSE) conducts sample-level interventions, (2) Interventional masked feature reconstruction (IMFR) conducts feature-level interventions, which together reveal real causalities from inputs to subcategories. Extensive experiments and thorough analyses on the widely-used public datasets, including CUB-200-2011, Stanford Dogs, and Stanford Cars, demonstrate that our CausalFSFG achieves new state-of-the-art performance. The code is available at https://github.com/PKU-ICST-MIPL/CausalFSFG_TMM.",
      "pdf_url": "https://arxiv.org/pdf/2512.21617v1",
      "arxiv_url": "http://arxiv.org/abs/2512.21617v1",
      "published": "2025-12-25",
      "categories": [
        "cs.CV"
      ]
    }
  ]
}