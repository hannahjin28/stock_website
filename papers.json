{
  "last_updated": "2025-03-10T00:40:21.250629",
  "papers": [
    {
      "title": "Compositional Causal Reasoning Evaluation in Language Models",
      "authors": [
        "Jacqueline R. M. A. Maasch",
        "Alihan Hüyük",
        "Xinnuo Xu",
        "Aditya V. Nori",
        "Javier Gonzalez"
      ],
      "abstract": "Causal reasoning and compositional reasoning are two core aspirations in\ngenerative AI. Measuring the extent of these behaviors requires principled\nevaluation methods. We explore a unified perspective that considers both\nbehaviors simultaneously, termed compositional causal reasoning (CCR): the\nability to infer how causal measures compose and, equivalently, how causal\nquantities propagate through graphs. We instantiate a framework for the\nsystematic evaluation of CCR for the average treatment effect and the\nprobability of necessity and sufficiency. As proof of concept, we demonstrate\nthe design of CCR tasks for language models in the LLama, Phi, and GPT\nfamilies. On a math word problem, our framework revealed a range of\ntaxonomically distinct error patterns. Additionally, CCR errors increased with\nthe complexity of causal paths for all models except o1.",
      "pdf_url": "http://arxiv.org/pdf/2503.04556v1",
      "arxiv_url": "http://arxiv.org/abs/2503.04556v1",
      "published": "2025-03-06",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "A Spatiotemporal, Quasi-experimental Causal Inference Approach to Characterize the Effects of Global Plastic Waste Export and Burning on Air Quality Using Remotely Sensed Data",
      "authors": [
        "Ellen M. Considine",
        "Rachel C. Nethery"
      ],
      "abstract": "Open burning of plastic waste may pose a significant threat to global health\nby degrading air quality, but quantitative research on this problem -- crucial\nfor policy making -- has previously been stunted by lack of data. Critically,\nmany low- and middle-income countries, where open burning is of greatest\nconcern, have little to no air quality monitoring. Here, we propose an\napproach, at the intersection of modern causal inference and environmental data\nscience, to leverage remotely sensed data products combined with spatiotemporal\ncausal analytic techniques to evaluate the impact of large-scale plastic waste\npolicies on air quality. Throughout, we use the case study of Indonesia before\nand after 2018, when China halted its import of plastic waste, resulting in\ndiversion of this massive waste stream to other countries in the East Asia &\nPacific region, including Indonesia. We tailor cutting-edge statistical methods\nto this setting, estimating effects of the increase in plastic waste imports on\nfine particulate matter near waste dump sites in Indonesia and allowing effects\nto vary as a function of the site's proximity to ports (from which\ninternational plastic waste enters the country), which serves as an induced\ncontinuous exposure or \"dose\" of treatment. We observe a statistically\nsignificant increase in monthly fine particulate matter concentrations near\ndump sites after China's ban took effect (2018-2019) compared to concentrations\nexpected under business-as-usual (2012-2017), with increases ranging from\n0.76--1.72$\\mu$g/m$^3$ (15--34\\% of the World Health Organization's recommended\nlimit for exposure on an annual basis) depending on the site's port proximity,\nat sites with port proximity above the 20th quantile. Sites with lower port\nproximity had smaller and not statistically significant effects.",
      "pdf_url": "http://arxiv.org/pdf/2503.04491v1",
      "arxiv_url": "http://arxiv.org/abs/2503.04491v1",
      "published": "2025-03-06",
      "categories": [
        "stat.AP",
        "stat.ME"
      ]
    },
    {
      "title": "Causally Reliable Concept Bottleneck Models",
      "authors": [
        "Giovanni De Felice",
        "Arianna Casanova Flores",
        "Francesco De Santis",
        "Silvia Santini",
        "Johannes Schneider",
        "Pietro Barbiero",
        "Alberto Termine"
      ],
      "abstract": "Concept-based models are an emerging paradigm in deep learning that\nconstrains the inference process to operate through human-interpretable\nconcepts, facilitating explainability and human interaction. However, these\narchitectures, on par with popular opaque neural models, fail to account for\nthe true causal mechanisms underlying the target phenomena represented in the\ndata. This hampers their ability to support causal reasoning tasks, limits\nout-of-distribution generalization, and hinders the implementation of fairness\nconstraints. To overcome these issues, we propose \\emph{Causally reliable\nConcept Bottleneck Models} (C$^2$BMs), a class of concept-based architectures\nthat enforce reasoning through a bottleneck of concepts structured according to\na model of the real-world causal mechanisms. We also introduce a pipeline to\nautomatically learn this structure from observational data and\n\\emph{unstructured} background knowledge (e.g., scientific literature).\nExperimental evidence suggest that C$^2$BM are more interpretable, causally\nreliable, and improve responsiveness to interventions w.r.t. standard opaque\nand concept-based models, while maintaining their accuracy.",
      "pdf_url": "http://arxiv.org/pdf/2503.04363v1",
      "arxiv_url": "http://arxiv.org/abs/2503.04363v1",
      "published": "2025-03-06",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Large Language Models for Zero-shot Inference of Causal Structures in Biology",
      "authors": [
        "Izzy Newsham",
        "Luka Kovačević",
        "Richard Moulange",
        "Nan Rosemary Ke",
        "Sach Mukherjee"
      ],
      "abstract": "Genes, proteins and other biological entities influence one another via\ncausal molecular networks. Causal relationships in such networks are mediated\nby complex and diverse mechanisms, through latent variables, and are often\nspecific to cellular context. It remains challenging to characterise such\nnetworks in practice. Here, we present a novel framework to evaluate large\nlanguage models (LLMs) for zero-shot inference of causal relationships in\nbiology. In particular, we systematically evaluate causal claims obtained from\nan LLM using real-world interventional data. This is done over one hundred\nvariables and thousands of causal hypotheses. Furthermore, we consider several\nprompting and retrieval-augmentation strategies, including large, and\npotentially conflicting, collections of scientific articles. Our results show\nthat with tailored augmentation and prompting, even relatively small LLMs can\ncapture meaningful aspects of causal structure in biological systems. This\nsupports the notion that LLMs could act as orchestration tools in biological\ndiscovery, by helping to distil current knowledge in ways amenable to\ndownstream analysis. Our approach to assessing LLMs with respect to\nexperimental data is relevant for a broad range of problems at the intersection\nof causal learning, LLMs and scientific discovery.",
      "pdf_url": "http://arxiv.org/pdf/2503.04347v1",
      "arxiv_url": "http://arxiv.org/abs/2503.04347v1",
      "published": "2025-03-06",
      "categories": [
        "cs.LG",
        "q-bio.GN"
      ]
    },
    {
      "title": "LEDiT: Your Length-Extrapolatable Diffusion Transformer without Positional Encoding",
      "authors": [
        "Shen Zhang",
        "Yaning Tan",
        "Siyuan Liang",
        "Zhaowei Chen",
        "Linze Li",
        "Ge Wu",
        "Yuhao Chen",
        "Shuheng Li",
        "Zhenyu Zhao",
        "Caihua Chen",
        "Jiajun Liang",
        "Yao Tang"
      ],
      "abstract": "Diffusion transformers(DiTs) struggle to generate images at resolutions\nhigher than their training resolutions. The primary obstacle is that the\nexplicit positional encodings(PE), such as RoPE, need extrapolation which\ndegrades performance when the inference resolution differs from training. In\nthis paper, we propose a Length-Extrapolatable Diffusion Transformer(LEDiT), a\nsimple yet powerful architecture to overcome this limitation. LEDiT needs no\nexplicit PEs, thereby avoiding extrapolation. The key innovations of LEDiT are\nintroducing causal attention to implicitly impart global positional information\nto tokens, while enhancing locality to precisely distinguish adjacent tokens.\nExperiments on 256x256 and 512x512 ImageNet show that LEDiT can scale the\ninference resolution to 512x512 and 1024x1024, respectively, while achieving\nbetter image quality compared to current state-of-the-art length extrapolation\nmethods(NTK-aware, YaRN). Moreover, LEDiT achieves strong extrapolation\nperformance with just 100K steps of fine-tuning on a pretrained DiT,\ndemonstrating its potential for integration into existing text-to-image DiTs.\nProject page: https://shenzhang2145.github.io/ledit/",
      "pdf_url": "http://arxiv.org/pdf/2503.04344v2",
      "arxiv_url": "http://arxiv.org/abs/2503.04344v2",
      "published": "2025-03-06",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "Spatial-Temporal Perception with Causal Inference for Naturalistic Driving Action Recognition",
      "authors": [
        "Qing Chang",
        "Wei Dai",
        "Zhihao Shuai",
        "Limin Yu",
        "Yutao Yue"
      ],
      "abstract": "Naturalistic driving action recognition is essential for vehicle cabin\nmonitoring systems. However, the complexity of real-world backgrounds presents\nsignificant challenges for this task, and previous approaches have struggled\nwith practical implementation due to their limited ability to observe subtle\nbehavioral differences and effectively learn inter-frame features from video.\nIn this paper, we propose a novel Spatial-Temporal Perception (STP)\narchitecture that emphasizes both temporal information and spatial\nrelationships between key objects, incorporating a causal decoder to perform\nbehavior recognition and temporal action localization. Without requiring\nmultimodal input, STP directly extracts temporal and spatial distance features\nfrom RGB video clips. Subsequently, these dual features are jointly encoded by\nmaximizing the expected likelihood across all possible permutations of the\nfactorization order. By integrating temporal and spatial features at different\nscales, STP can perceive subtle behavioral changes in challenging scenarios.\nAdditionally, we introduce a causal-aware module to explore relationships\nbetween video frame features, significantly enhancing detection efficiency and\nperformance. We validate the effectiveness of our approach using two publicly\navailable driver distraction detection benchmarks. The results demonstrate that\nour framework achieves state-of-the-art performance.",
      "pdf_url": "http://arxiv.org/pdf/2503.04078v1",
      "arxiv_url": "http://arxiv.org/abs/2503.04078v1",
      "published": "2025-03-06",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "How Balanced Should Causal Covariates Be?",
      "authors": [
        "Shiva Kaul",
        "Min-Gyu Kim"
      ],
      "abstract": "Covariate balancing is a popular technique for controlling confounding in\nobservational studies. It finds weights for the treatment group which are close\nto uniform, but make the group's covariate means (approximately) equal to those\nof the entire sample. A crucial question is: how approximate should the\nbalancing be, in order to minimize the error of the final estimate? Current\nguidance is derived from heuristic or asymptotic analyses, which are\nuninformative when the size of the sample is small compared to the number of\ncovariates. This paper presents the first rigorous, nonasymptotic analysis of\ncovariate balancing; specifically, we use PAC-Bayesian techniques to derive\nvalid, finite-sample confidence intervals for the treatment effect. More\ngenerally, we prove these guarantees for a flexible form of covariate balancing\nwhere the regularization parameters weighting the tradeoff between bias\n(imbalance) and variance (divergence from uniform) are optimized, not fixed.\nThis gives rise to a new balancing algorithm which empirically delivers\nsuperior adaptivity. Our overall contribution is to make covariate balancing a\nmore reliable method for causal inference.",
      "pdf_url": "http://arxiv.org/pdf/2503.03860v1",
      "arxiv_url": "http://arxiv.org/abs/2503.03860v1",
      "published": "2025-03-05",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Causal language jumps in clinical practice guidelines for diabetes management",
      "authors": [
        "Keling Wang",
        "Chang Wei",
        "Jeremy A. Labrecque"
      ],
      "abstract": "Clinical practice guidelines are designed to guide clinical practice and\ninvolve causal language. Sometimes guidelines make or require stronger causal\nclaims than those in the references they rely on, a phenomenon we refer to as\n'causal language jump'. We evaluated the strength of expressed causation in\ndiabetes guidelines and the evidence they reference to assess the pattern of\njumps. We randomly sampled 300 guideline statements from four diabetes\nguidelines. We rated the causation strength in the statements and the\ndependence on causation in recommendations supported by these statements using\nexisting scales. Among the causal statements, the cited original studies were\nsimilarly assessed. We also assessed how well they report target trial\nemulation (TTE) components as a proxy for reliability. Of the sampled\nstatements, 114 (38.0%) were causal, and 76 (66.7%) expressed strong causation.\n27.2% (31/114) of causal guideline statements demonstrated a \"causal language\njump\", and 34.9% (29/83) of guideline recommendations cannot be effectively\nsupported. Of the 53 eligible studies for TTE rating, most did not report\ntreatment assignment and causal contrast in detail. Our findings suggest causal\nlanguage jumps were common among diabetes guidelines. While these jumps are\nsometimes inevitable, they should always be supported by good causal inference\npractices.",
      "pdf_url": "http://arxiv.org/pdf/2503.03557v1",
      "arxiv_url": "http://arxiv.org/abs/2503.03557v1",
      "published": "2025-03-05",
      "categories": [
        "stat.AP",
        "stat.ME"
      ]
    },
    {
      "title": "The Ejection of Transient Jets in Swift J1727.8-1613 Revealed by Time-Dependent Visibility Modelling",
      "authors": [
        "Callan M. Wood",
        "James C. A. Miller-Jones",
        "Arash Bahramian",
        "Steven J. Tingay",
        "He-Xin Liu",
        "Diego Altamirano",
        "Rob Fender",
        "Elmar Körding",
        "Dipankar Maitra",
        "Sera Markoff",
        "David M. Russell",
        "Thomas D. Russell",
        "Craig L. Sarazin",
        "Gregory R. Sivakoff",
        "Roberto Soria",
        "Alexandra J. Tetarenko",
        "Valeriu Tudose"
      ],
      "abstract": "High angular resolution radio observations of relativistic jets are necessary\nto understand the causal connection between accretion and jet ejection in low\nmass X-ray binaries. Images from these observations can be difficult to\nreconstruct due to the rapid intra-observational motion and variability of\ntransient jets. We have developed a time-dependent visibility model fitting and\nself-calibration procedure and applied it to a single four-hour VLBA\nobservation of the low-mass X-ray binary Swift J1727.8-1613 during the bright\nflaring period of its 2023 outburst. This allowed us to detect and model a\nslightly resolved self-absorbed compact core, as well as three downstream\ntransient jet knots. We were able to precisely measure the proper motion and\nflux density variability of these three jet knots, as well as (for the first\ntime) their intra-observational expansion. Using simultaneous multi-frequency\ndata, we were also able to measure the spectral index of the furthest\ndownstream jet knot, and the core, as well as the frequency-dependent core\nshift between 2.3 and 8.3 GHz. Using these measurements, we inferred the\nejection dates of the three jet knots, including one to within $\\pm40$ minutes,\nwhich is one of the most precise ever measured. The ejection of the transient\njet knots coincided with a bright X-ray flare and a drastic change in the X-ray\nspectral and timing properties as seen by HXMT, which is the clearest\nassociation ever seen between the launching of transient relativistic jets in\nan X-ray binary and a sudden change in the X-ray properties of the accretion\ninflow.",
      "pdf_url": "http://arxiv.org/pdf/2503.03073v1",
      "arxiv_url": "http://arxiv.org/abs/2503.03073v1",
      "published": "2025-03-05",
      "categories": [
        "astro-ph.HE"
      ]
    },
    {
      "title": "Out-of-Distribution Generalization on Graphs via Progressive Inference",
      "authors": [
        "Yiming Xu",
        "Bin Shi",
        "Zhen Peng",
        "Huixiang Liu",
        "Bo Dong",
        "Chen Chen"
      ],
      "abstract": "The development and evaluation of graph neural networks (GNNs) generally\nfollow the independent and identically distributed (i.i.d.) assumption. Yet\nthis assumption is often untenable in practice due to the uncontrollable data\ngeneration mechanism. In particular, when the data distribution shows a\nsignificant shift, most GNNs would fail to produce reliable predictions and may\neven make decisions randomly. One of the most promising solutions to improve\nthe model generalization is to pick out causal invariant parts in the input\ngraph. Nonetheless, we observe a significant distribution gap between the\ncausal parts learned by existing methods and the ground truth, leading to\nundesirable performance. In response to the above issues, this paper presents\nGPro, a model that learns graph causal invariance with progressive inference.\nSpecifically, the complicated graph causal invariant learning is decomposed\ninto multiple intermediate inference steps from easy to hard, and the\nperception of GPro is continuously strengthened through a progressive inference\nprocess to extract causal features that are stable to distribution shifts. We\nalso enlarge the training distribution by creating counterfactual samples to\nenhance the capability of the GPro in capturing the causal invariant parts.\nExtensive experiments demonstrate that our proposed GPro outperforms the\nstate-of-the-art methods by 4.91% on average. For datasets with more severe\ndistribution shifts, the performance improvement can be up to 6.86%.",
      "pdf_url": "http://arxiv.org/pdf/2503.02988v1",
      "arxiv_url": "http://arxiv.org/abs/2503.02988v1",
      "published": "2025-03-04",
      "categories": [
        "cs.LG"
      ]
    }
  ]
}