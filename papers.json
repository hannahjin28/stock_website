{
  "last_updated": "2026-02-11T01:20:40.401447",
  "papers": [
    {
      "title": "State policy heterogeneity analyses: considerations and proposals",
      "authors": [
        "Max Rubinstein",
        "Megan S. Schuler",
        "Elizabeth A. Stuart",
        "Bradley D. Stein",
        "Max Griswold",
        "Elizabeth M. Stone",
        "Beth Ann Griffin"
      ],
      "abstract": "State-level policy studies often conduct heterogeneity analyses that quantify how treatment effects vary across state characteristics. These analyses may be used to inform state-specific policy decisions, or to infer how the effect of a policy changes in combination with other state characteristics. However, in state-level settings with varied contexts and policy landscapes, multiple versions of similar policies, and differential policy implementation, the causal quantities targeted by these analyses may not align with the inferential goals. This paper clarifies these issues by distinguishing several causal estimands relevant to heterogeneity analyses in state-policy settings, including state-specific treatment effects (ITE), conditional average treatment effects (CATE), and controlled direct effects (CDE). We argue that the CATE is often the easiest to identify and estimate, but may not be the most policy relevant target of inference. Moreover, the widespread practice of coarsening distinct policies or implementations into a single indicator further complicates the interpretation of these analyses. Motivated by these limitations, we propose bounding ITEs as an alternative inferential goal, yielding ranges for each state's policy effect under explicit assumptions that quantify deviations from the ideal identifying conditions. These bounds target a well-defined and policy-relevant quantity, the effect for specific states. We develop this approach within a difference-in-differences framework and discuss how sensitivity parameters may be informed using pre-treatment data. Through simulations we demonstrate that bounding state-specific effects can more reliably determine the sign of the ITEs than CATE estimates. We then illustrate this method to examine the effect of the Affordable Care Act Medicaid expansion on high-volume buprenorphine prescribing.",
      "pdf_url": "https://arxiv.org/pdf/2602.08643v1",
      "arxiv_url": "http://arxiv.org/abs/2602.08643v1",
      "published": "2026-02-09",
      "categories": [
        "stat.ME",
        "stat.AP"
      ]
    },
    {
      "title": "CauScale: Neural Causal Discovery at Scale",
      "authors": [
        "Bo Peng",
        "Sirui Chen",
        "Jiaguo Tian",
        "Yu Qiao",
        "Chaochao Lu"
      ],
      "abstract": "Causal discovery is essential for advancing data-driven fields such as scientific AI and data analysis, yet existing approaches face significant time- and space-efficiency bottlenecks when scaling to large graphs. To address this challenge, we present CauScale, a neural architecture designed for efficient causal discovery that scales inference to graphs with up to 1000 nodes. CauScale improves time efficiency via a reduction unit that compresses data embeddings and improves space efficiency by adopting tied attention weights to avoid maintaining axis-specific attention maps. To keep high causal discovery accuracy, CauScale adopts a two-stream design: a data stream extracts relational evidence from high-dimensional observations, while a graph stream integrates statistical graph priors and preserves key structural signals. CauScale successfully scales to 500-node graphs during training, where prior work fails due to space limitations. Across testing data with varying graph scales and causal mechanisms, CauScale achieves 99.6% mAP on in-distribution data and 84.4% on out-of-distribution data, while delivering 4-13,000 times inference speedups over prior methods. Our project page is at https://github.com/OpenCausaLab/CauScale.",
      "pdf_url": "https://arxiv.org/pdf/2602.08629v1",
      "arxiv_url": "http://arxiv.org/abs/2602.08629v1",
      "published": "2026-02-09",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "title": "Towards Reliable Social A/B Testing: Spillover-Contained Clustering with Robust Post-Experiment Analysis",
      "authors": [
        "Xu Min",
        "Zhaoxu Yang",
        "Kaixuan Tan",
        "Juan Yan",
        "Xunbin Xiong",
        "Zihao Zhu",
        "Kaiyu Zhu",
        "Fenglin Cui",
        "Yang Yang",
        "Sihua Yang",
        "Jianhui Bu"
      ],
      "abstract": "A/B testing is the foundation of decision-making in online platforms, yet social products often suffer from network interference: user interactions cause treatment effects to spill over into the control group. Such spillovers bias causal estimates and undermine experimental conclusions. Existing approaches face key limitations: user-level randomization ignores network structure, while cluster-based methods often rely on general-purpose clustering that is not tailored for spillover containment and has difficulty balancing unbiasedness and statistical power at scale. We propose a spillover-contained experimentation framework with two stages. In the pre-experiment stage, we build social interaction graphs and introduce a Balanced Louvain algorithm that produces stable, size-balanced clusters while minimizing cross-cluster edges, enabling reliable cluster-based randomization. In the post-experiment stage, we develop a tailored CUPAC estimator that leverages pre-experiment behavioral covariates to reduce the variance induced by cluster-level assignment, thereby improving statistical power. Together, these components provide both structural spillover containment and robust statistical inference. We validate our approach through large-scale social sharing experiments on Kuaishou, a platform serving hundreds of millions of users. Results show that our method substantially reduces spillover and yields more accurate assessments of social strategies than traditional user-level designs, establishing a reliable and scalable framework for networked A/B testing.",
      "pdf_url": "https://arxiv.org/pdf/2602.08569v1",
      "arxiv_url": "http://arxiv.org/abs/2602.08569v1",
      "published": "2026-02-09",
      "categories": [
        "cs.SI",
        "cs.IR"
      ]
    },
    {
      "title": "Causal Schrödinger Bridges: Constrained Optimal Transport on Structural Manifolds",
      "authors": [
        "Rui Wu",
        "Li YongJun"
      ],
      "abstract": "Generative modeling typically seeks the path of least action via deterministic flows (ODE). While effective for in-distribution tasks, we argue that these deterministic paths become brittle under causal interventions, which often require transporting probability mass across low-density regions (\"off-manifold\") where the vector field is ill-defined. This leads to numerical instability and spurious correlations. In this work, we introduce the Causal Schrödinger Bridge (CSB), a framework that reformulates counterfactual inference as Entropic Optimal Transport. Unlike deterministic approaches that require strict invertibility, CSB leverages diffusion processes (SDEs) to robustly \"tunnel\" through support mismatches while strictly enforcing structural admissibility constraints. We prove the Structural Decomposition Theorem, showing that the global high-dimensional bridge factorizes into local, robust transitions. Empirical validation on high-dimensional interventions (Morpho-MNIST) demonstrates that CSB significantly outperforms deterministic baselines in structural consistency, particularly in regimes of strong, out-of-distribution treatments.",
      "pdf_url": "https://arxiv.org/pdf/2602.08535v1",
      "arxiv_url": "http://arxiv.org/abs/2602.08535v1",
      "published": "2026-02-09",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "Estimating Aleatoric Uncertainty in the Causal Treatment Effect",
      "authors": [
        "Liyuan Xu",
        "Bijan Mazaheri"
      ],
      "abstract": "Previous work on causal inference has primarily focused on averages and conditional averages of treatment effects, with significantly less attention on variability and uncertainty in individual treatment responses. In this paper, we introduce the variance of the treatment effect (VTE) and conditional variance of treatment effect (CVTE) as the natural measure of aleatoric uncertainty inherent in treatment responses, and we demonstrate that these quantities are identifiable from observed data under mild assumptions, even in the presence of unobserved confounders. We further propose nonparametric kernel-based estimators for VTE and CVTE, and our theoretical analysis establishes their convergence. We also test the performance of our method through extensive empirical experiments on both synthetic and semi-simulated datasets, where it demonstrates superior or comparable performance to naive baselines.",
      "pdf_url": "https://arxiv.org/pdf/2602.08461v1",
      "arxiv_url": "http://arxiv.org/abs/2602.08461v1",
      "published": "2026-02-09",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "Estimation Strategies for Causal Decomposition Analysis with Allowability Specifications",
      "authors": [
        "John W. Jackson",
        "Ting-Hsuan Chang",
        "Aster Meche",
        "Trang Q. Nguyen"
      ],
      "abstract": "Causal decomposition analysis (CDA) is an approach for modeling the impact of hypothetical interventions to reduce disparities. It is useful for identifying foci that future interventions, including multilevel and multimodal interventions, could focus on to reduce disparities. Based within the potential outcomes framework, CDA has a causal interpretation when the identifying assumptions are met. CDA also allows an analyst to consider which covariates are allowable (i.e., fair) for defining the disparity in the outcome and in the point of intervention, so that its interpretation is also meaningful. While the incorporation of causal inference and allowability promotes robustness, transparency, and dialogue in disparities research, it can lead to challenges in estimation such as the need to correctly model densities. Also, how CDA differs from commonly used estimators may not be clear, which may limit its uptake. To address these challenges, we provide a tour of estimation strategies for CDA, reviewing existing proposals and introducing novel estimators that overcome key estimation challenges. Among them we introduce what we call \"bridging\" estimators that avoid directly modeling any density, and weighted sequential regression estimators that are multiply robust. Additionally, we provide diagnostics to assess the quality of the nuisance density models and weighting functions they rely on. We formally establish the estimators' robustness to model mis-specification, demonstrate their performance through a simulation study based on real data, and apply them to study disparities in hypertension control using electronic health records in a large healthcare system.",
      "pdf_url": "https://arxiv.org/pdf/2602.07825v1",
      "arxiv_url": "http://arxiv.org/abs/2602.07825v1",
      "published": "2026-02-08",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Emergent Structured Representations Support Flexible In-Context Inference in Large Language Models",
      "authors": [
        "Ningyu Xu",
        "Qi Zhang",
        "Xipeng Qiu",
        "Xuanjing Huang"
      ],
      "abstract": "Large language models (LLMs) exhibit emergent behaviors suggestive of human-like reasoning. While recent work has identified structured, human-like conceptual representations within these models, it remains unclear whether they functionally rely on such representations for reasoning. Here we investigate the internal processing of LLMs during in-context concept inference. Our results reveal a conceptual subspace emerging in middle to late layers, whose representational structure persists across contexts. Using causal mediation analyses, we demonstrate that this subspace is not merely an epiphenomenon but is functionally central to model predictions, establishing its causal role in inference. We further identify a layer-wise progression where attention heads in early-to-middle layers integrate contextual cues to construct and refine the subspace, which is subsequently leveraged by later layers to generate predictions. Together, these findings provide evidence that LLMs dynamically construct and use structured, latent representations in context for inference, offering insights into the computational processes underlying flexible adaptation.",
      "pdf_url": "https://arxiv.org/pdf/2602.07794v1",
      "arxiv_url": "http://arxiv.org/abs/2602.07794v1",
      "published": "2026-02-08",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Disentangled Instrumental Variables for Causal Inference with Networked Observational Data",
      "authors": [
        "Zhirong Huang",
        "Debo Cheng",
        "Guixian Zhang",
        "Yi Wang",
        "Jiuyong Li",
        "Shichao Zhang"
      ],
      "abstract": "Instrumental variables (IVs) are crucial for addressing unobservable confounders, yet their stringent exogeneity assumptions pose significant challenges in networked data. Existing methods typically rely on modelling neighbour information when recovering IVs, thereby inevitably mixing shared environment-induced endogenous correlations and individual-specific exogenous variation, leading the resulting IVs to inherit dependence on unobserved confounders and to violate exogeneity. To overcome this challenge, we propose $\\underline{Dis}$entangled $\\underline{I}$nstrumental $\\underline{V}$ariables (DisIV) framework, a novel method for causal inference based on networked observational data with latent confounders. DisIV exploits network homogeneity as an inductive bias and employs a structural disentanglement mechanism to extract individual-specific components that serve as latent IVs. The causal validity of the extracted IVs is constrained through explicit orthogonality and exclusion conditions. Extensive semi-synthetic experiments on real-world datasets demonstrate that DisIV consistently outperforms state-of-the-art baselines in causal effect estimation under network-induced confounding.",
      "pdf_url": "https://arxiv.org/pdf/2602.07765v1",
      "arxiv_url": "http://arxiv.org/abs/2602.07765v1",
      "published": "2026-02-08",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Contextualization or Rationalization? The Effect of Causal Priors on Data Visualization Interpretation",
      "authors": [
        "Arran Zeyu Wang",
        "David Borland",
        "Estella Calcaterra",
        "David Gotz"
      ],
      "abstract": "Understanding how individuals interpret charts is a crucial concern for visual data communication. This imperative has motivated a number of studies, including past work demonstrating that causal priors -- a priori beliefs about causal relationships between concepts -- can have significant influences on the perceived strength of variable relationships inferred from visualizations. This paper builds on these previous results, demonstrating that causal priors can also influence the types of patterns that people perceive as the most salient within ambiguous scatterplots that have roughly equal evidence for trend and cluster patterns. Using a mixed-design approach that combines a large-scale online experiment for breadth of findings with an in-person think-aloud study for analytical depth, we investigated how users' interpretations are influenced by the interplay between causal priors and the visualized data patterns. Our analysis suggests two archetypal reasoning behaviors through which people often make their observations: contextualization, in which users accept a visual pattern that aligns with causal priors and use their existing knowledge to enrich interpretation, and rationalization, in which users encounter a pattern that conflicts with causal priors and attempt to explain away the discrepancy by invoking external factors, such as positing confounding variables or data selection bias. These findings provide initial evidence highlighting the critical role of causal priors in shaping high-level visualization comprehension, and introduce a vocabulary for describing how users reason about data that either confirms or challenges prior beliefs of causality.",
      "pdf_url": "https://arxiv.org/pdf/2602.07748v1",
      "arxiv_url": "http://arxiv.org/abs/2602.07748v1",
      "published": "2026-02-08",
      "categories": [
        "cs.HC"
      ]
    },
    {
      "title": "Inference under First-Order Degeneracy",
      "authors": [
        "Xinyue Bei",
        "Manu Navjeevan"
      ],
      "abstract": "We study inference in models where a transformation of parameters exhibits first-order degeneracy -- that is, its gradient is zero or close to zero, making the standard delta method invalid. A leading example is causal mediation analysis, where the indirect effect is a product of coefficients and the gradient degenerates near the origin. In these local regions of degeneracy the limiting behaviors of plug-in estimators depend on nuisance parameters that are not consistently estimable. We show that this failure is intrinsic -- around points of degeneracy, both regular and quantile-unbiased estimation are impossible. Despite these restrictions, we develop minimum-distance methods that deliver uniformly valid confidence intervals. We establish sufficient conditions under which standard chi-square critical values remain valid, and propose a simple bootstrap procedure when they are not. We demonstrate favorable power in simulations and in an empirical application linking teacher gender attitudes to student outcomes.",
      "pdf_url": "https://arxiv.org/pdf/2602.07377v1",
      "arxiv_url": "http://arxiv.org/abs/2602.07377v1",
      "published": "2026-02-07",
      "categories": [
        "econ.EM"
      ]
    }
  ]
}