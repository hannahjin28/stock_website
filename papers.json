{
  "last_updated": "2025-11-08T00:50:06.538838",
  "papers": [
    {
      "title": "Dynamic causal discovery in Alzheimer's disease through latent pseudotime modelling",
      "authors": [
        "Natalia Glazman",
        "Jyoti Mangal",
        "Pedro Borges",
        "Sebastien Ourselin",
        "M. Jorge Cardoso"
      ],
      "abstract": "The application of causal discovery to diseases like Alzheimer's (AD) is\nlimited by the static graph assumptions of most methods; such models cannot\naccount for an evolving pathophysiology, modulated by a latent disease\npseudotime. We propose to apply an existing latent variable model to real-world\nAD data, inferring a pseudotime that orders patients along a data-driven\ndisease trajectory independent of chronological age, then learning how causal\nrelationships evolve. Pseudotime outperformed age in predicting diagnosis (AUC\n0.82 vs 0.59). Incorporating minimal, disease-agnostic background knowledge\nsubstantially improved graph accuracy and orientation. Our framework reveals\ndynamic interactions between novel (NfL, GFAP) and established AD markers,\nenabling practical causal discovery despite violated assumptions.",
      "pdf_url": "http://arxiv.org/pdf/2511.04619v1",
      "arxiv_url": "http://arxiv.org/abs/2511.04619v1",
      "published": "2025-11-06",
      "categories": [
        "stat.AP",
        "cs.CE",
        "cs.LG"
      ]
    },
    {
      "title": "Extracting Causal Relations in Deep Knowledge Tracing",
      "authors": [
        "Kevin Hong",
        "Kia Karbasi",
        "Gregory Pottie"
      ],
      "abstract": "A longstanding goal in computational educational research is to develop\nexplainable knowledge tracing (KT) models. Deep Knowledge Tracing (DKT), which\nleverages a Recurrent Neural Network (RNN) to predict student knowledge and\nperformance on exercises, has been proposed as a major advancement over\ntraditional KT methods. Several studies suggest that its performance gains stem\nfrom its ability to model bidirectional relationships between different\nknowledge components (KCs) within a course, enabling the inference of a\nstudent's understanding of one KC from their performance on others. In this\npaper, we challenge this prevailing explanation and demonstrate that DKT's\nstrength lies in its implicit ability to model prerequisite relationships as a\ncausal structure, rather than bidirectional relationships. By pruning exercise\nrelation graphs into Directed Acyclic Graphs (DAGs) and training DKT on causal\nsubsets of the Assistments dataset, we show that DKT's predictive capabilities\nalign strongly with these causal structures. Furthermore, we propose an\nalternative method for extracting exercise relation DAGs using DKT's learned\nrepresentations and provide empirical evidence supporting our claim. Our\nfindings suggest that DKT's effectiveness is largely driven by its capacity to\napproximate causal dependencies between KCs rather than simple relational\nmappings.",
      "pdf_url": "http://arxiv.org/pdf/2511.03948v1",
      "arxiv_url": "http://arxiv.org/abs/2511.03948v1",
      "published": "2025-11-06",
      "categories": [
        "cs.AI",
        "cs.HC",
        "I.2.6; K.3.1"
      ]
    },
    {
      "title": "Tutorial Debriefing: Applied Statistical Causal Inference in Requirements Engineering",
      "authors": [
        "Julian Frattini",
        "Hans-Martin Heyn",
        "Robert Feldt",
        "Richard Torkar"
      ],
      "abstract": "As any scientific discipline, the software engineering (SE) research\ncommunity strives to contribute to the betterment of the target population of\nour research: software producers and consumers. We will only achieve this\nbetterment if we manage to transfer the knowledge acquired during research into\npractice. This transferal of knowledge may come in the form of tools,\nprocesses, and guidelines for software developers. However, the value of these\ncontributions hinges on the assumption that applying them causes an improvement\nof the development process, user experience, or other performance metrics. Such\na promise requires evidence of causal relationships between an exposure or\nintervention (i.e., the contributed tool, process or guideline) and an outcome\n(i.e., performance metrics). A straight-forward approach to obtaining this\nevidence is via controlled experiments in which a sample of a population is\nrandomly divided into a group exposed to the new tool, process, or guideline,\nand a control group. However, such randomized control trials may not be\nlegally, ethically, or logistically feasible. In these cases, we need a\nreliable process for statistical causal inference (SCI) from observational\ndata.",
      "pdf_url": "http://arxiv.org/pdf/2511.03875v1",
      "arxiv_url": "http://arxiv.org/abs/2511.03875v1",
      "published": "2025-11-05",
      "categories": [
        "cs.SE"
      ]
    },
    {
      "title": "Higher-Order Causal Structure Learning with Additive Models",
      "authors": [
        "James Enouen",
        "Yujia Zheng",
        "Ignavier Ng",
        "Yan Liu",
        "Kun Zhang"
      ],
      "abstract": "Causal structure learning has long been the central task of inferring causal\ninsights from data. Despite the abundance of real-world processes exhibiting\nhigher-order mechanisms, however, an explicit treatment of interactions in\ncausal discovery has received little attention. In this work, we focus on\nextending the causal additive model (CAM) to additive models with higher-order\ninteractions. This second level of modularity we introduce to the structure\nlearning problem is most easily represented by a directed acyclic hypergraph\nwhich extends the DAG. We introduce the necessary definitions and theoretical\ntools to handle the novel structure we introduce and then provide\nidentifiability results for the hyper DAG, extending the typical Markov\nequivalence classes. We next provide insights into why learning the more\ncomplex hypergraph structure may actually lead to better empirical results. In\nparticular, more restrictive assumptions like CAM correspond to easier-to-learn\nhyper DAGs and better finite sample complexity. We finally develop an extension\nof the greedy CAM algorithm which can handle the more complex hyper DAG search\nspace and demonstrate its empirical usefulness in synthetic experiments.",
      "pdf_url": "http://arxiv.org/pdf/2511.03831v1",
      "arxiv_url": "http://arxiv.org/abs/2511.03831v1",
      "published": "2025-11-05",
      "categories": [
        "cs.LG",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ]
    },
    {
      "title": "Bayesian Causal Effect Estimation for Categorical Data using Staged Tree Models",
      "authors": [
        "Andrea Cremaschi",
        "Manuele Leonelli",
        "Gherardo Varando"
      ],
      "abstract": "We propose a fully Bayesian approach for causal inference with multivariate\ncategorical data based on staged tree models, a class of probabilistic\ngraphical models capable of representing asymmetric and context-specific\ndependencies. To account for uncertainty in both structure and parameters, we\nintroduce a flexible family of prior distributions over staged trees. These\ninclude product partition models to encourage parsimony, a novel distance-based\nprior to promote interpretable dependence patterns, and an extension that\nincorporates continuous covariates into the learning process. Posterior\ninference is achieved via a tailored Markov Chain Monte Carlo algorithm with\nsplit-and-merge moves, yielding posterior samples of staged trees from which\naverage treatment effects and uncertainty measures are derived. Posterior\nsummaries and uncertainty measures are obtained via techniques from the\nBayesian nonparametrics literature. Two case studies on electronic fetal\nmonitoring and cesarean delivery and on anthracycline therapy and cardiac\ndysfunction in breast cancer illustrate the methods.",
      "pdf_url": "http://arxiv.org/pdf/2511.03399v1",
      "arxiv_url": "http://arxiv.org/abs/2511.03399v1",
      "published": "2025-11-05",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "UnCLe: Towards Scalable Dynamic Causal Discovery in Non-linear Temporal Systems",
      "authors": [
        "Tingzhu Bi",
        "Yicheng Pan",
        "Xinrui Jiang",
        "Huize Sun",
        "Meng Ma",
        "Ping Wang"
      ],
      "abstract": "Uncovering cause-effect relationships from observational time series is\nfundamental to understanding complex systems. While many methods infer static\ncausal graphs, real-world systems often exhibit dynamic causality-where\nrelationships evolve over time. Accurately capturing these temporal dynamics\nrequires time-resolved causal graphs. We propose UnCLe, a novel deep learning\nmethod for scalable dynamic causal discovery. UnCLe employs a pair of Uncoupler\nand Recoupler networks to disentangle input time series into semantic\nrepresentations and learns inter-variable dependencies via auto-regressive\nDependency Matrices. It estimates dynamic causal influences by analyzing\ndatapoint-wise prediction errors induced by temporal perturbations. Extensive\nexperiments demonstrate that UnCLe not only outperforms state-of-the-art\nbaselines on static causal discovery benchmarks but, more importantly, exhibits\na unique capability to accurately capture and represent evolving temporal\ncausality in both synthetic and real-world dynamic systems (e.g., human\nmotion). UnCLe offers a promising approach for revealing the underlying,\ntime-varying mechanisms of complex phenomena.",
      "pdf_url": "http://arxiv.org/pdf/2511.03168v1",
      "arxiv_url": "http://arxiv.org/abs/2511.03168v1",
      "published": "2025-11-05",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "Adaptive Orthogonalization for Stable Estimation of the Effects of Time-Varying Treatments",
      "authors": [
        "Yige Li",
        "María de los Angeles Resa",
        "José R. Zubizarreta"
      ],
      "abstract": "Inferring the causal effects of time-varying treatments is often hindered by\nhighly variable inverse propensity weights, particularly in settings with\nlimited covariate overlap. Building on the key framework of Imai and Ratkovic\n(2015), we establish sufficient balancing conditions for identification in\nlongitudinal studies of treatment effects and propose a novel estimator that\ndirectly targets features of counterfactual or potential covariates. Instead of\nbalancing observed covariates, our method balances the components of covariates\nthat are orthogonal to their history, thereby isolating the new information at\neach time point. This strategy directly targets the joint distribution of\npotential covariates and prioritizes features that are most relevant to the\noutcome. We prove that the resulting estimator for the mean potential outcome\nis consistent and asymptotically normal, even in settings where standard\ninverse propensity weighting fails. Extensive simulations show that our\nestimator attains efficiency comparable to that of g-computation while\nproviding superior robustness to model misspecification. We apply our method to\na longitudinal study of private versus public schooling in Chile, demonstrating\nits stability and interpretability in estimating their effects on university\nadmission scores.",
      "pdf_url": "http://arxiv.org/pdf/2511.02971v1",
      "arxiv_url": "http://arxiv.org/abs/2511.02971v1",
      "published": "2025-11-04",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Peer effect analysis with latent processes",
      "authors": [
        "Vincent Starck"
      ],
      "abstract": "I study peer effects that arise from irreversible decisions in the absence of\na standard social equilibrium. I model a latent sequence of decisions in\ncontinuous time and obtain a closed-form expression for the likelihood, which\nallows to estimate proposed causal estimands. The method avoids regression on\nconditional expectations or linear-in-means regression -- and thus\nreflection-type problems (Manski, 1993) or simultaneity issues -- by modeling\nthe (unobserved) realized direction of causality, whose probability is\nidentified. Under a parsimonious parametric specification, I introduce a peer\neffect parameter meant to capture the causal influence of first-movers on their\npeers. Various forms of peer effect heterogeneity can be accommodated.\nParameters are shown to be consistently estimated by maximum likelihood methods\nand lend themselves to standard inference.",
      "pdf_url": "http://arxiv.org/pdf/2511.02764v1",
      "arxiv_url": "http://arxiv.org/abs/2511.02764v1",
      "published": "2025-11-04",
      "categories": [
        "econ.EM"
      ]
    },
    {
      "title": "Agentic World Modeling for 6G: Near-Real-Time Generative State-Space Reasoning",
      "authors": [
        "Farhad Rezazadeh",
        "Hatim Chergui",
        "Merouane Debbah",
        "Houbing Song",
        "Dusit Niyato",
        "Lingjia Liu"
      ],
      "abstract": "We argue that sixth-generation (6G) intelligence is not fluent token\nprediction but the capacity to imagine and choose -- to simulate future\nscenarios, weigh trade-offs, and act with calibrated uncertainty. We reframe\nopen radio access network (O-RAN) near-real-time (Near-RT) control via\ncounterfactual dynamics and a world modeling (WM) paradigm that learns an\naction-conditioned generative state space. This enables quantitative \"what-if\"\nforecasting beyond large language models (LLMs) as the primary modeling\nprimitive. Actions such as physical resource blocks (PRBs) are treated as\nfirst-class control inputs in a causal world model, and both aleatoric and\nepistemic uncertainty are modeled for prediction and what-if analysis. An\nagentic, model predictive control (MPC)-based cross-entropy method (CEM)\nplanner operates over short horizons, using prior-mean rollouts within\ndata-driven PRB bounds to maximize a deterministic reward. The model couples\nmulti-scale structured state-space mixtures (MS3M) with a compact stochastic\nlatent to form WM-MS3M, summarizing key performance indicators (KPIs) histories\nand predicting next-step KPIs under hypothetical PRB sequences. On realistic\nO-RAN traces, WM-MS3M cuts mean absolute error (MAE) by 1.69% versus MS3M with\n32% fewer parameters and similar latency, and achieves 35-80% lower root mean\nsquared error (RMSE) than attention/hybrid baselines with 2.3-4.1x faster\ninference, enabling rare-event simulation and offline policy screening.",
      "pdf_url": "http://arxiv.org/pdf/2511.02748v1",
      "arxiv_url": "http://arxiv.org/abs/2511.02748v1",
      "published": "2025-11-04",
      "categories": [
        "cs.NI",
        "cs.LG"
      ]
    },
    {
      "title": "A Bayesian Inference of Hybrid Stars with Large Quark Cores",
      "authors": [
        "Milena Albino",
        "Tuhin Malik",
        "Márcio Ferreira",
        "Constança Providência"
      ],
      "abstract": "Neutron stars (NSs) are interesting objects capable of reaching densities\nunattainable on Earth. The properties of matter under these conditions remain a\nmystery. Exotic matter, including quark matter, may be present in the NS core.\nIn this work, we explore the possible compositions of NS cores, in particular,\nthe possible existence of large quark cores. We use the Relativistic Mean Field\n(RMF) model with nonlinear terms for the hadron phase and the\nNambu-Jona-Lasinio (NJL) model and Mean Field Theory of Quantum Chromodynamics\n(MFTQCD) for the quark phase. Through Bayesian inference, we obtain different\nsets of equations: four sets with hybrid equations (three using the NJL model\nand the other using the MFTQCD model), and one set with only the hadron phase.\nWe impose constraints regarding the properties of nuclear matter, X-ray\nobservational data from NICER, perturbative QCD (pQCD) calculations, and\ncausality on all sets. One set of hybrid NJL equations of state was also\nconstrained by adding the GW170817 detection. All sets can describe\nobservational data and theoretical restrictions. The MFTQCD allows for a phase\ntransition to quark matter at lower densities compared to the NJL models. The\nMFTQCD model indicates that NSs with 1.4 solar mass have quark matter in their\ninner core. However, NJL models suggest that it is more probable that 1.4 solar\nmass NSs do not contain quark matter. Both the MFTQCD and NJL models agree that\nthere is quark matter in 2 solar mass NSs. It is discussed that hybrid stars\nwith a stiff quark equation of state could explain a larger radius of more\nmassive stars, such as two solar mass stars, with respect to the canonical NS.",
      "pdf_url": "http://arxiv.org/pdf/2511.02653v1",
      "arxiv_url": "http://arxiv.org/abs/2511.02653v1",
      "published": "2025-11-04",
      "categories": [
        "nucl-th",
        "astro-ph.HE",
        "gr-qc",
        "hep-ph"
      ]
    }
  ]
}