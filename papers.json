{
  "last_updated": "2025-03-29T00:48:45.082573",
  "papers": [
    {
      "title": "ClusterSC: Advancing Synthetic Control with Donor Selection",
      "authors": [
        "Saeyoung Rho",
        "Andrew Tang",
        "Noah Bergam",
        "Rachel Cummings",
        "Vishal Misra"
      ],
      "abstract": "In causal inference with observational studies, synthetic control (SC) has\nemerged as a prominent tool. SC has traditionally been applied to\naggregate-level datasets, but more recent work has extended its use to\nindividual-level data. As they contain a greater number of observed units, this\nshift introduces the curse of dimensionality to SC. To address this, we propose\nCluster Synthetic Control (ClusterSC), based on the idea that groups of\nindividuals may exist where behavior aligns internally but diverges between\ngroups. ClusterSC incorporates a clustering step to select only the relevant\ndonors for the target. We provide theoretical guarantees on the improvements\ninduced by ClusterSC, supported by empirical demonstrations on synthetic and\nreal-world datasets. The results indicate that ClusterSC consistently\noutperforms classical SC approaches.",
      "pdf_url": "http://arxiv.org/pdf/2503.21629v1",
      "arxiv_url": "http://arxiv.org/abs/2503.21629v1",
      "published": "2025-03-27",
      "categories": [
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "title": "Inferring Treatment Effects in Large Panels by Uncovering Latent Similarities",
      "authors": [
        "Ben Deaner",
        "Chen-Wei Hsiang",
        "Andrei Zeleneev"
      ],
      "abstract": "The presence of unobserved confounders is one of the main challenges in\nidentifying treatment effects. In this paper, we propose a new approach to\ncausal inference using panel data with large large $N$ and $T$. Our approach\nimputes the untreated potential outcomes for treated units using the outcomes\nfor untreated individuals with similar values of the latent confounders. In\norder to find units with similar latent characteristics, we utilize long\npre-treatment histories of the outcomes. Our analysis is based on a\nnonparametric, nonlinear, and nonseparable factor model for untreated potential\noutcomes and treatments. The model satisfies minimal smoothness requirements.\nWe impute both missing counterfactual outcomes and propensity scores using\nkernel smoothing based on the constructed measure of latent similarity between\nunits, and demonstrate that our estimates can achieve the optimal nonparametric\nrate of convergence up to log terms. Using these estimates, we construct a\ndoubly robust estimator of the period-specifc average treatment effect on the\ntreated (ATT), and provide conditions, under which this estimator is\n$\\sqrt{N}$-consistent, and asymptotically normal and unbiased. Our simulation\nstudy demonstrates that our method provides accurate inference for a wide range\nof data generating processes.",
      "pdf_url": "http://arxiv.org/pdf/2503.20769v2",
      "arxiv_url": "http://arxiv.org/abs/2503.20769v2",
      "published": "2025-03-26",
      "categories": [
        "econ.EM"
      ]
    },
    {
      "title": "Treatment Effects Inference with High-Dimensional Instruments and Control Variables",
      "authors": [
        "Xiduo Chen",
        "Xingdong Feng",
        "Antonio F. Galvao",
        "Yeheng Ge"
      ],
      "abstract": "Obtaining valid treatment effect inferences remains a challenging problem\nwhen dealing with numerous instruments and non-sparse control variables. In\nthis paper, we propose a novel ridge regularization-based instrumental\nvariables method for estimation and inference in the presence of both\nhigh-dimensional instrumental variables and high-dimensional control variables.\nThese methods are applicable both with and without sparsity assumptions. To\naddress the bias caused by high-dimensional instruments, we introduce a\ntwo-step procedure incorporating a data-splitting strategy. We establish\nstatistical properties of the estimator, including consistency and asymptotic\nnormality. Furthermore, we develop statistical inference procedures by\nproviding a consistent estimator for the asymptotic variance of the estimator.\nThe finite sample performance of the proposed method is evaluated through\nnumerical simulations. Results indicate that the new estimator consistently\noutperforms existing sparsity-based approaches across various settings,\noffering valuable insights for more complex scenarios. Finally, we provide an\nempirical application estimating the causal effect of schooling on earnings by\naddressing potential endogeneity through the use of high-dimensional\ninstrumental variables and high-dimensional covariates.",
      "pdf_url": "http://arxiv.org/pdf/2503.20149v1",
      "arxiv_url": "http://arxiv.org/abs/2503.20149v1",
      "published": "2025-03-26",
      "categories": [
        "econ.EM"
      ]
    },
    {
      "title": "Functional structural equation models with out-of-sample guarantees",
      "authors": [
        "Philip Kennerberg",
        "Ernst C. Wit"
      ],
      "abstract": "Statistical learning methods typically assume that the training and test data\noriginate from the same distribution, enabling effective risk minimization.\nHowever, real-world applications frequently involve distributional shifts,\nleading to poor model generalization. To address this, recent advances in\ncausal inference and robust learning have introduced strategies such as\ninvariant causal prediction and anchor regression. While these approaches have\nbeen explored for traditional structural equation models (SEMs), their\nextension to functional systems remains limited. This paper develops a risk\nminimization framework for functional SEMs using linear, potentially unbounded\noperators. We introduce a functional worst-risk minimization approach, ensuring\nrobust predictive performance across shifted environments. Our key contribution\nis a novel worst-risk decomposition theorem, which expresses the maximum\nout-of-sample risk in terms of observed environments. We establish conditions\nfor the existence and uniqueness of the worst-risk minimizer and provide\nconsistent estimation procedures. Empirical results on functional systems\nillustrate the advantages of our method in mitigating distributional shifts.\nThese findings contribute to the growing literature on robust functional\nregression and causal learning, offering practical guarantees for out-of-sample\ngeneralization in dynamic environments.",
      "pdf_url": "http://arxiv.org/pdf/2503.20072v1",
      "arxiv_url": "http://arxiv.org/abs/2503.20072v1",
      "published": "2025-03-25",
      "categories": [
        "math.ST",
        "stat.ME",
        "stat.TH",
        "62R10"
      ]
    },
    {
      "title": "Causal Bayesian Optimization with Unknown Graphs",
      "authors": [
        "Jean Durand",
        "Yashas Annadani",
        "Stefan Bauer",
        "Sonali Parbhoo"
      ],
      "abstract": "Causal Bayesian Optimization (CBO) is a methodology designed to optimize an\noutcome variable by leveraging known causal relationships through targeted\ninterventions. Traditional CBO methods require a fully and accurately specified\ncausal graph, which is a limitation in many real-world scenarios where such\ngraphs are unknown. To address this, we propose a new method for the CBO\nframework that operates without prior knowledge of the causal graph. Consistent\nwith causal bandit theory, we demonstrate through theoretical analysis and that\nfocusing on the direct causal parents of the target variable is sufficient for\noptimization, and provide empirical validation in the context of CBO.\nFurthermore we introduce a new method that learns a Bayesian posterior over the\ndirect parents of the target variable. This allows us to optimize the outcome\nvariable while simultaneously learning the causal structure. Our contributions\ninclude a derivation of the closed-form posterior distribution for the linear\ncase. In the nonlinear case where the posterior is not tractable, we present a\nGaussian Process (GP) approximation that still enables CBO by inferring the\nparents of the outcome variable. The proposed method performs competitively\nwith existing benchmarks and scales well to larger graphs, making it a\npractical tool for real-world applications where causal information is\nincomplete.",
      "pdf_url": "http://arxiv.org/pdf/2503.19554v1",
      "arxiv_url": "http://arxiv.org/abs/2503.19554v1",
      "published": "2025-03-25",
      "categories": [
        "stat.ML",
        "cs.LG"
      ]
    },
    {
      "title": "Body Discovery of Embodied AI",
      "authors": [
        "Zhe Sun",
        "Pengfei Tian",
        "Xiaozhu Hu",
        "Xiaoyu Zhao",
        "Huiying Li",
        "Zhenliang Zhang"
      ],
      "abstract": "In the pursuit of realizing artificial general intelligence (AGI), the\nimportance of embodied artificial intelligence (AI) becomes increasingly\napparent. Following this trend, research integrating robots with AGI has become\nprominent. As various kinds of embodiments have been designed, adaptability to\ndiverse embodiments will become important to AGI. We introduce a new challenge,\ntermed \"Body Discovery of Embodied AI\", focusing on tasks of recognizing\nembodiments and summarizing neural signal functionality. The challenge\nencompasses the precise definition of an AI body and the intricate task of\nidentifying embodiments in dynamic environments, where conventional approaches\noften prove inadequate. To address these challenges, we apply causal inference\nmethod and evaluate it by developing a simulator tailored for testing\nalgorithms with virtual environments. Finally, we validate the efficacy of our\nalgorithms through empirical testing, demonstrating their robust performance in\nvarious scenarios based on virtual environments.",
      "pdf_url": "http://arxiv.org/pdf/2503.19941v1",
      "arxiv_url": "http://arxiv.org/abs/2503.19941v1",
      "published": "2025-03-25",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.NE"
      ]
    },
    {
      "title": "Causal Links Between Anthropogenic Emissions and Air Pollution Dynamics in Delhi",
      "authors": [
        "Sourish Das",
        "Sudeep Shukla",
        "Alka Yadav",
        "Anirban Chakraborti"
      ],
      "abstract": "Air pollution poses significant health and environmental challenges,\nparticularly in rapidly urbanizing regions. Delhi-National Capital Region\nexperiences air pollution episodes due to complex interactions between\nanthropogenic emissions and meteorological conditions. Understanding the causal\ndrivers of key pollutants such as $PM_{2.5}$ and ground $O_3$ is crucial for\ndeveloping effective mitigation strategies. This study investigates the causal\nlinks of anthropogenic emissions on $PM_{2.5}$ and $O_3$ concentrations using\npredictive modeling and causal inference techniques. Integrating\nhigh-resolution air quality data from Jan 2018 to Aug 2023 across 32 monitoring\nstations, we develop predictive regression models that incorporate\nmeteorological variables (temperature and relative humidity), pollutant\nconcentrations ($NO_2, SO_2, CO$), and seasonal harmonic components to capture\nboth diurnal and annual cycles. Here, we show that reductions in anthropogenic\nemissions lead to significant decreases in $PM_{2.5}$ levels, whereas their\neffect on $O_3$ remains marginal and statistically insignificant. To address\nspatial heterogeneity, we employ Gaussian Process modeling. Further, we use\nGranger causality analysis and counterfactual simulation to establish direct\ncausal links. Validation using real-world data from the COVID-19 lockdown\nconfirms that reduced emissions led to a substantial drop in $PM_{2.5}$ but\nonly a slight, insignificant change in $O_3$. The findings highlight the\nnecessity of targeted emission reduction policies while emphasizing the need\nfor integrated strategies addressing both particulate and ozone pollution.\nThese insights are crucial for policymakers designing air pollution\ninterventions in other megacities, and offer a scalable methodology for\ntackling complex urban air pollution through data-driven decision-making.",
      "pdf_url": "http://arxiv.org/pdf/2503.18912v1",
      "arxiv_url": "http://arxiv.org/abs/2503.18912v1",
      "published": "2025-03-24",
      "categories": [
        "stat.AP",
        "physics.ao-ph",
        "physics.soc-ph",
        "stat.ML"
      ]
    },
    {
      "title": "A Causal Adjustment Module for Debiasing Scene Graph Generation",
      "authors": [
        "Li Liu",
        "Shuzhou Sun",
        "Shuaifeng Zhi",
        "Fan Shi",
        "Zhen Liu",
        "Janne Heikkilä",
        "Yongxiang Liu"
      ],
      "abstract": "While recent debiasing methods for Scene Graph Generation (SGG) have shown\nimpressive performance, these efforts often attribute model bias solely to the\nlong-tail distribution of relationships, overlooking the more profound causes\nstemming from skewed object and object pair distributions. In this paper, we\nemploy causal inference techniques to model the causality among these observed\nskewed distributions. Our insight lies in the ability of causal inference to\ncapture the unobservable causal effects between complex distributions, which is\ncrucial for tracing the roots of model bias. Specifically, we introduce the\nMediator-based Causal Chain Model (MCCM), which, in addition to modeling\ncausality among objects, object pairs, and relationships, incorporates mediator\nvariables, i.e., cooccurrence distribution, for complementing the causality.\nFollowing this, we propose the Causal Adjustment Module (CAModule) to estimate\nthe modeled causal structure, using variables from MCCM as inputs to produce a\nset of adjustment factors aimed at correcting biased model predictions.\nMoreover, our method enables the composition of zero-shot relationships,\nthereby enhancing the model's ability to recognize such relationships.\nExperiments conducted across various SGG backbones and popular benchmarks\ndemonstrate that CAModule achieves state-of-the-art mean recall rates, with\nsignificant improvements also observed on the challenging zero-shot recall rate\nmetric.",
      "pdf_url": "http://arxiv.org/pdf/2503.17862v1",
      "arxiv_url": "http://arxiv.org/abs/2503.17862v1",
      "published": "2025-03-22",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "A Roadmap Towards Improving Multi-Agent Reinforcement Learning With Causal Discovery And Inference",
      "authors": [
        "Giovanni Briglia",
        "Stefano Mariani",
        "Franco Zambonelli"
      ],
      "abstract": "Causal reasoning is increasingly used in Reinforcement Learning (RL) to\nimprove the learning process in several dimensions: efficacy of learned\npolicies, efficiency of convergence, generalisation capabilities, safety and\ninterpretability of behaviour. However, applications of causal reasoning to\nMulti-Agent RL (MARL) are still mostly unexplored. In this paper, we take the\nfirst step in investigating the opportunities and challenges of applying causal\nreasoning in MARL. We measure the impact of a simple form of causal\naugmentation in state-of-the-art MARL scenarios increasingly requiring\ncooperation, and with state-of-the-art MARL algorithms exploiting various\ndegrees of collaboration between agents. Then, we discuss the positive as well\nas negative results achieved, giving us the chance to outline the areas where\nfurther research may help to successfully transfer causal RL to the multi-agent\nsetting.",
      "pdf_url": "http://arxiv.org/pdf/2503.17803v1",
      "arxiv_url": "http://arxiv.org/abs/2503.17803v1",
      "published": "2025-03-22",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA",
        "stat.ME"
      ]
    },
    {
      "title": "Causal Inference based Transfer Learning with LLMs: An Efficient Framework for Industrial RUL Prediction",
      "authors": [
        "Yan Chen",
        "Cheng Liu"
      ],
      "abstract": "Accurate prediction of Remaining Useful Life (RUL) for complex industrial\nmachinery is critical for the reliability and maintenance of mechatronic\nsystems, but it is challenged by high-dimensional, noisy sensor data. We\npropose the Causal-Informed Data Pruning Framework (CIDPF), which pioneers the\nuse of causal inference to identify sensor signals with robust causal\nrelationships to RUL through PCMCI-based stability analysis, while a Gaussian\nMixture Model (GMM) screens for anomalies. By training on only 10% of the\npruned data, CIDPF fine-tunes pre-trained Large Language Models (LLMs) using\nparameter-efficient strategies, reducing training time by 90% compared to\ntraditional approaches. Experiments on the N-CMAPSS dataset demonstrate that\nCIDPF achieves a 26% lower RMSE than existing methods and a 25% improvement\nover full-data baselines, showcasing superior accuracy and computational\nefficiency in industrial mechatronic systems. The framework's adaptability to\nmulti-condition scenarios further underscores its practicality for industrial\ndeployment.",
      "pdf_url": "http://arxiv.org/pdf/2503.17686v1",
      "arxiv_url": "http://arxiv.org/abs/2503.17686v1",
      "published": "2025-03-22",
      "categories": [
        "eess.SP"
      ]
    }
  ]
}