{
  "last_updated": "2025-06-27T00:55:58.523836",
  "papers": [
    {
      "title": "DiffuCoder: Understanding and Improving Masked Diffusion Models for Code Generation",
      "authors": [
        "Shansan Gong",
        "Ruixiang Zhang",
        "Huangjie Zheng",
        "Jiatao Gu",
        "Navdeep Jaitly",
        "Lingpeng Kong",
        "Yizhe Zhang"
      ],
      "abstract": "Diffusion large language models (dLLMs) are compelling alternatives to\nautoregressive (AR) models because their denoising models operate over the\nentire sequence. The global planning and iterative refinement features of dLLMs\nare particularly useful for code generation. However, current training and\ninference mechanisms for dLLMs in coding are still under-explored. To demystify\nthe decoding behavior of dLLMs and unlock their potential for coding, we\nsystematically investigate their denoising processes and reinforcement learning\n(RL) methods. We train a 7B dLLM, \\textbf{DiffuCoder}, on 130B tokens of code.\nUsing this model as a testbed, we analyze its decoding behavior, revealing how\nit differs from that of AR models: (1) dLLMs can decide how causal their\ngeneration should be without relying on semi-AR decoding, and (2) increasing\nthe sampling temperature diversifies not only token choices but also their\ngeneration order. This diversity creates a rich search space for RL rollouts.\nFor RL training, to reduce the variance of token log-likelihood estimates and\nmaintain training efficiency, we propose \\textbf{coupled-GRPO}, a novel\nsampling scheme that constructs complementary mask noise for completions used\nin training. In our experiments, coupled-GRPO significantly improves\nDiffuCoder's performance on code generation benchmarks (+4.4\\% on EvalPlus) and\nreduces reliance on AR bias during decoding. Our work provides deeper insight\ninto the machinery of dLLM generation and offers an effective, diffusion-native\nRL training framework. https://github.com/apple/ml-diffucoder.",
      "pdf_url": "http://arxiv.org/pdf/2506.20639v2",
      "arxiv_url": "http://arxiv.org/abs/2506.20639v2",
      "published": "2025-06-25",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "title": "Causal Inference for Latent Outcomes Learned with Factor Models",
      "authors": [
        "Jenna M. Landy",
        "Dafne Zorzetto",
        "Roberta De Vito",
        "Giovanni Parmigiani"
      ],
      "abstract": "In many fields$\\unicode{x2013}$including genomics, epidemiology, natural\nlanguage processing, social and behavioral sciences, and\neconomics$\\unicode{x2013}$it is increasingly important to address causal\nquestions in the context of factor models or representation learning. In this\nwork, we investigate causal effects on $\\textit{latent outcomes}$ derived from\nhigh-dimensional observed data using nonnegative matrix factorization. To the\nbest of our knowledge, this is the first study to formally address causal\ninference in this setting. A central challenge is that estimating a latent\nfactor model can cause an individual's learned latent outcome to depend on\nother individuals' treatments, thereby violating the standard causal inference\nassumption of no interference. We formalize this issue as\n$\\textit{learning-induced interference}$ and distinguish it from interference\npresent in a data-generating process. To address this, we propose a novel,\nintuitive, and theoretically grounded algorithm to estimate causal effects on\nlatent outcomes while mitigating learning-induced interference and improving\nestimation efficiency. We establish theoretical guarantees for the consistency\nof our estimator and demonstrate its practical utility through simulation\nstudies and an application to cancer mutational signature analysis. All\nbaseline and proposed methods are available in our open-source R package, ${\\tt\ncausalLFO}$.",
      "pdf_url": "http://arxiv.org/pdf/2506.20549v1",
      "arxiv_url": "http://arxiv.org/abs/2506.20549v1",
      "published": "2025-06-25",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Anytime-Valid Inference in Adaptive Experiments: Covariate Adjustment and Balanced Power",
      "authors": [
        "Daniel Molitor",
        "Samantha Gold"
      ],
      "abstract": "Adaptive experiments have become central to modern experimental design,\nenabling researchers to efficiently identify optimal treatments, improve\nstatistical power, and maximize respondent welfare. However, adaptive\nexperiments compromise valid inference and leave sub-optimal treatments\nunderpowered. We introduce two methodological advances for adaptive\nexperimentation. First, covariate-adjusted Mixture Adaptive Design (MADCovar)\nachieves substantial improvements in average treatment effect (ATE) precision\nby incorporating covariate adjustment within an anytime-valid inference\nframework. Second, power-modified MAD (MADMod) reallocates sample to\nunderpowered treatment arms, improving statistical power across all treatments\nwhile maintaining error control. Both methods provide anytime-valid guarantees,\nenabling continuous monitoring without inflating Type 1 error rates. Simulation\nstudies and empirical analyses demonstrate that MADCovar delivers significant\nprecision gains and that MADMod ensures robust inference even for suboptimal\ntreatments. Together, these methods address key limitations of adaptive\nexperiments and equip researchers with practical tools for precise and reliable\ncausal inference. Our proposed methods are implemented through an open-source\nsoftware package.",
      "pdf_url": "http://arxiv.org/pdf/2506.20523v1",
      "arxiv_url": "http://arxiv.org/abs/2506.20523v1",
      "published": "2025-06-25",
      "categories": [
        "stat.ME",
        "econ.EM",
        "stat.CO"
      ]
    },
    {
      "title": "The Role of Partisan Culture in Mental Health Language Online",
      "authors": [
        "Sachin R. Pendse",
        "Ben Rochford",
        "Neha Kumar",
        "Munmun De Choudhury"
      ],
      "abstract": "The impact of culture on how people express distress in online support\ncommunities is increasingly a topic of interest within Computer Supported\nCooperative Work (CSCW) and Human-Computer Interaction (HCI). In the United\nStates, distinct cultures have emerged from each of the two dominant political\nparties, forming a primary lens by which people navigate online and offline\nworlds. We examine whether partisan culture may play a role in how U.S.\nRepublican and Democrat users of online mental health support communities\nexpress distress. We present a large-scale observational study of 2,184,356\nposts from 8,916 statistically matched Republican, Democrat, and unaffiliated\nonline support community members. We utilize methods from causal inference to\nstatistically match partisan users along covariates that correspond with\ndemographic attributes and platform use, in order to create comparable cohorts\nfor analysis. We then leverage methods from natural language processing to\nunderstand how partisan expressions of distress compare between these sets of\nclosely matched opposing partisans, and between closely matched partisans and\ntypical support community members. Our data spans January 2013 to December\n2022, a period of both rising political polarization and mental health\nconcerns. We find that partisan culture does play into expressions of distress,\nunderscoring the importance of considering partisan cultural differences in the\ndesign of online support community platforms.",
      "pdf_url": "http://arxiv.org/pdf/2506.20377v1",
      "arxiv_url": "http://arxiv.org/abs/2506.20377v1",
      "published": "2025-06-25",
      "categories": [
        "cs.HC",
        "cs.CY",
        "cs.SI"
      ]
    },
    {
      "title": "Causal Operator Discovery in Partial Differential Equations via Counterfactual Physics-Informed Neural Networks",
      "authors": [
        "Ronald Katende"
      ],
      "abstract": "We develop a principled framework for discovering causal structure in partial\ndifferential equations (PDEs) using physics-informed neural networks and\ncounterfactual perturbations. Unlike classical residual minimization or sparse\nregression methods, our approach quantifies operator-level necessity through\nfunctional interventions on the governing dynamics. We introduce causal\nsensitivity indices and structural deviation metrics to assess the influence of\ncandidate differential operators within neural surrogates. Theoretically, we\nprove exact recovery of the causal operator support under restricted isometry\nor mutual coherence conditions, with residual bounds guaranteeing\nidentifiability. Empirically, we validate the framework on both synthetic and\nreal-world datasets across climate dynamics, tumor diffusion, and ocean flows.\nOur method consistently recovers governing operators even under noise,\nredundancy, and data scarcity, outperforming standard PINNs and DeepONets in\nstructural fidelity. This work positions causal PDE discovery as a tractable\nand interpretable inference task grounded in structural causal models and\nvariational residual analysis.",
      "pdf_url": "http://arxiv.org/pdf/2506.20181v1",
      "arxiv_url": "http://arxiv.org/abs/2506.20181v1",
      "published": "2025-06-25",
      "categories": [
        "cs.LG",
        "cs.NA",
        "math.NA"
      ]
    },
    {
      "title": "Causal mediation analysis for longitudinal and survival data in continuous time using Bayesian non-parametric joint models",
      "authors": [
        "Saurabh Bhandari",
        "Michael J. Daniels",
        "Juned Siddique"
      ],
      "abstract": "Observational cohort data is an important source of information for\nunderstanding the causal effects of treatments on survival and the degree to\nwhich these effects are mediated through changes in disease-related risk\nfactors. However, these analyses are often complicated by irregular data\ncollection intervals and the presence of longitudinal confounders and\nmediators. We propose a causal mediation framework that jointly models\nlongitudinal exposures, confounders, mediators, and time-to-event outcomes as\ncontinuous functions of age. This framework for longitudinal covariate\ntrajectories enables statistical inference even at ages where the subject's\ncovariate measurements are unavailable. The observed data distribution in our\nframework is modeled using an enriched Dirichlet process mixture (EDPM) model.\nUsing data from the Atherosclerosis Risk in Communities cohort study, we apply\nour methods to assess how medication -- prescribed to target cardiovascular\ndisease (CVD) risk factors -- affects the time-to-CVD death.",
      "pdf_url": "http://arxiv.org/pdf/2506.20058v1",
      "arxiv_url": "http://arxiv.org/abs/2506.20058v1",
      "published": "2025-06-24",
      "categories": [
        "stat.ME",
        "stat.AP"
      ]
    },
    {
      "title": "Quantum Neural Networks for Propensity Score Estimation and Survival Analysis in Observational Biomedical Studies",
      "authors": [
        "Vojtěch Novák",
        "Ivan Zelinka",
        "Lenka Přibylová",
        "Lubomír Martínek"
      ],
      "abstract": "This study investigates the application of quantum neural networks (QNNs) for\npropensity score estimation to address selection bias in comparing survival\noutcomes between laparoscopic and open surgical techniques in a cohort of 1177\ncolorectal carcinoma patients treated at University Hospital Ostrava\n(2001-2009). Using a dataset with 77 variables, including patient demographics\nand tumor characteristics, we developed QNN-based propensity score models\nfocusing on four key covariates (Age, Sex, Stage, BMI). The QNN architecture\nemployed a linear ZFeatureMap for data encoding, a SummedPaulis operator for\npredictions, and the Covariance Matrix Adaptation Evolution Strategy (CMA-ES)\nfor robust, gradient-free optimization in noisy quantum environments. Variance\nregularization was integrated to mitigate quantum measurement noise, with\nsimulations conducted under exact, sampling (1024 shots), and noisy hardware\n(FakeManhattanV2) conditions. QNNs, particularly with simulated hardware noise,\noutperformed classical logistic regression and gradient boosted machines in\nsmall samples (AUC up to 0.750 for n=100), with noise modeling enhancing\npredictive stability. Propensity score matching and weighting, optimized via\ngenetic matching and matching weights, achieved covariate balance with\nstandardized mean differences of 0.0849 and 0.0869, respectively. Survival\nanalyses using Kaplan-Meier estimation, Cox proportional hazards, and Aalen\nadditive regression revealed no significant survival differences\npost-adjustment (p-values 0.287-0.851), indicating confounding bias in\nunadjusted outcomes. These results highlight QNNs' potential, enhanced by\nCMA-ES and noise-aware strategies, to improve causal inference in biomedical\nresearch, particularly for small-sample, high-dimensional datasets.",
      "pdf_url": "http://arxiv.org/pdf/2506.19973v1",
      "arxiv_url": "http://arxiv.org/abs/2506.19973v1",
      "published": "2025-06-24",
      "categories": [
        "quant-ph",
        "cs.AI",
        "stat.ML",
        "62H30, 62P10, 68T05, 81P68",
        "I.2.6; J.3; I.5.4; F.4.1"
      ]
    },
    {
      "title": "Causal-Aware Intelligent QoE Optimization for VR Interaction with Adaptive Keyframe Extraction",
      "authors": [
        "Ziru Zhang",
        "Jiadong Yu",
        "Danny H. K. Tsang"
      ],
      "abstract": "The optimization of quality of experience (QoE) in multi-user virtual reality\n(VR) interactions demands a delicate balance between ultra-low latency,\nhigh-fidelity motion synchronization, and equitable resource allocation. While\nadaptive keyframe extraction mitigates transmission overhead, existing\napproaches often overlook the causal relationships among allocated bandwidth,\nCPU frequency, and user perception, limiting QoE gains. This paper proposes an\nintelligent framework to maximize QoE by integrating adaptive keyframe\nextraction with causal-aware reinforcement learning (RL). First, a novel QoE\nmetric is formulated using the Weber-Fechner Law, combining perceptual\nsensitivity, attention-driven priorities, and motion reconstruction accuracy.\nThe QoE optimization problem is then modeled as a mixed integer programming\n(MIP) task, jointly optimizing keyframe ratios, bandwidth, and computational\nresources under horizon-fairness constraints. We propose Partial State Causal\nDeep Deterministic Policy Gradient (PS-CDDPG), which integrates the Deep\nDeterministic Policy Gradient (DDPG) method with causal influence detection. By\nleveraging causal information regarding how QoE is influenced and determined by\nvarious actions, we explore actions guided by weights calculated from causal\ninference (CI), which in turn improves training efficiency. Experiments\nconducted with the CMU Motion Capture Database demonstrate that our framework\nsignificantly reduces interactive latency, enhances QoE, and maintains\nfairness, achieving superior performance compared to benchmark methods.",
      "pdf_url": "http://arxiv.org/pdf/2506.19890v1",
      "arxiv_url": "http://arxiv.org/abs/2506.19890v1",
      "published": "2025-06-24",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Bayesian Evolutionary Swarm Architecture: A Formal Epistemic System Grounded in Truth-Based Competition",
      "authors": [
        "Craig Steven Wright"
      ],
      "abstract": "We introduce a mathematically rigorous framework for an artificial\nintelligence system composed of probabilistic agents evolving through\nstructured competition and belief revision. The architecture, grounded in\nBayesian inference, measure theory, and population dynamics, defines agent\nfitness as a function of alignment with a fixed external oracle representing\nground truth. Agents compete in a discrete-time environment, adjusting\nposterior beliefs through observed outcomes, with higher-rated agents\nreproducing and lower-rated agents undergoing extinction. Ratings are updated\nvia pairwise truth-aligned utility comparisons, and belief updates preserve\nmeasurable consistency and stochastic convergence. We introduce hash-based\ncryptographic identity commitments to ensure traceability, alongside causal\ninference operators using do-calculus. Formal theorems on convergence,\nrobustness, and evolutionary stability are provided. The system establishes\ntruth as an evolutionary attractor, demonstrating that verifiable knowledge\narises from adversarial epistemic pressure within a computable, self-regulating\nswarm.",
      "pdf_url": "http://arxiv.org/pdf/2506.19191v1",
      "arxiv_url": "http://arxiv.org/abs/2506.19191v1",
      "published": "2025-06-23",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.GT",
        "math.LO",
        "68T05, 68Q87, 03E20",
        "I.2.6; I.2.3; F.1.1"
      ]
    },
    {
      "title": "Inferring Diffusion Structures of Heterogeneous Network Cascade",
      "authors": [
        "Yubai Yuan",
        "Siyu Huang",
        "Abdul Basit Adeel"
      ],
      "abstract": "Network cascade refers to diffusion processes in which outcome changes within\npart of an interconnected population trigger a sequence of changes across the\nentire network. These cascades are governed by underlying diffusion networks,\nwhich are often latent. Inferring such networks is critical for understanding\ncascade pathways, uncovering Granger causality of interaction mechanisms among\nindividuals, and enabling tasks such as forecasting or maximizing information\npropagation. In this project, we propose a novel double mixture directed graph\nmodel for inferring multi-layer diffusion networks from cascade data. The\nproposed model represents cascade pathways as a mixture of diffusion networks\nacross different layers, effectively capturing the strong heterogeneity present\nin real-world cascades. Additionally, the model imposes layer-specific\nstructural constraints, enabling diffusion networks at different layers to\ncapture complementary cascading patterns at the population level. A key\nadvantage of our model is its convex formulation, which allows us to establish\nboth statistical and computational guarantees for the resulting diffusion\nnetwork estimates. We conduct extensive simulation studies to demonstrate the\nmodel's performance in recovering diverse diffusion structures. Finally, we\napply the proposed method to analyze cascades of research topics in the social\nsciences across U.S. universities, revealing the underlying diffusion networks\nof research topic propagation among institutions.",
      "pdf_url": "http://arxiv.org/pdf/2506.19142v1",
      "arxiv_url": "http://arxiv.org/abs/2506.19142v1",
      "published": "2025-06-23",
      "categories": [
        "cs.SI",
        "stat.ML"
      ]
    }
  ]
}