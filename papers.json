{
  "last_updated": "2026-02-14T01:09:51.306652",
  "papers": [
    {
      "title": "GPT-4o Lacks Core Features of Theory of Mind",
      "authors": [
        "John Muchovej",
        "Amanda Royka",
        "Shane Lee",
        "Julian Jara-Ettinger"
      ],
      "abstract": "Do Large Language Models (LLMs) possess a Theory of Mind (ToM)? Research into this question has focused on evaluating LLMs against benchmarks and found success across a range of social tasks. However, these evaluations do not test for the actual representations posited by ToM: namely, a causal model of mental states and behavior. Here, we use a cognitively-grounded definition of ToM to develop and test a new evaluation framework. Specifically, our approach probes whether LLMs have a coherent, domain-general, and consistent model of how mental states cause behavior -- regardless of whether that model matches a human-like ToM. We find that even though LLMs succeed in approximating human judgments in a simple ToM paradigm, they fail at a logically equivalent task and exhibit low consistency between their action predictions and corresponding mental state inferences. As such, these findings suggest that the social proficiency exhibited by LLMs is not the result of an domain-general or consistent ToM.",
      "pdf_url": "https://arxiv.org/pdf/2602.12150v1",
      "arxiv_url": "http://arxiv.org/abs/2602.12150v1",
      "published": "2026-02-12",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "U-Former ODE: Fast Probabilistic Forecasting of Irregular Time Series",
      "authors": [
        "Ilya Kuleshov",
        "Alexander Marusov",
        "Alexey Zaytsev"
      ],
      "abstract": "Probabilistic forecasting of irregularly sampled time series is crucial in domains such as healthcare and finance, yet it remains a formidable challenge. Existing Neural Controlled Differential Equation (Neural CDE) approaches, while effective at modelling continuous dynamics, suffer from slow, inherently sequential computation, which restricts scalability and limits access to global context. We introduce UFO (U-Former ODE), a novel architecture that seamlessly integrates the parallelizable, multiscale feature extraction of U-Nets, the powerful global modelling of Transformers, and the continuous-time dynamics of Neural CDEs. By constructing a fully causal, parallelizable model, UFO achieves a global receptive field while retaining strong sensitivity to local temporal dynamics. Extensive experiments on five standard benchmarks -- covering both regularly and irregularly sampled time series -- demonstrate that UFO consistently outperforms ten state-of-the-art neural baselines in predictive accuracy. Moreover, UFO delivers up to 15$\\times$ faster inference compared to conventional Neural CDEs, with consistently strong performance on long and highly multivariate sequences.",
      "pdf_url": "https://arxiv.org/pdf/2602.11738v1",
      "arxiv_url": "http://arxiv.org/abs/2602.11738v1",
      "published": "2026-02-12",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "WebTestPilot: Agentic End-to-End Web Testing against Natural Language Specification by Inferring Oracles with Symbolized GUI Elements",
      "authors": [
        "Xiwen Teoh",
        "Yun Lin",
        "Duc-Minh Nguyen",
        "Ruofei Ren",
        "Wenjie Zhang",
        "Jin Song Dong"
      ],
      "abstract": "Visual language model (VLM) agents show great promise in automating end-to-end (E2E) web testing against requirements in natural language. However, the probabilistic nature of language models can have inherent hallucinations. Therefore, given a detected inconsistency between the requirement and the web application, it is hard to distinguish whether it stems from the hallucination or a real application bug. Addressing this issue presents two core technical challenges: the implicit oracle inference challenge, where the agent must act as its own oracle to implicitly decide if the application's behavior is correct without guidance, and the probabilistic inference challenge, where an LLM's inconsistent reasoning undermines its trustworthiness as an oracle. Existing LLM-based approaches fail to capture such implicit oracles, either by treating any page navigation that doesn't crash as a success, or by checking each state in isolation, thus missing bugs dependent on context from prior steps.\n  We introduce WebTestPilot, an LLM-based agent designed to address these challenges. WebTestPilot uses (1) a symbolization layer which detects and symbolizes critical GUI elements on the web application into symbols (i.e., variables) and (2) translates natural language specification into a sequence of steps, each of which is equipped with inferred pre- and post-conditions over the symbols as an oracle. This oracle captures data, temporal, and causal dependencies, enabling the validation of implicit requirements. To advance research in this area, we build a benchmark of bug-injected web apps for evaluating NL-to-E2E testing. The results show that WebTestPilot achieves a task completion rate of 99%, with 96% precision and 96% recall in bug detection, outperforming the best baseline (+70 precision, +27 recall). The agent generalizes across diverse natural language inputs and model scales.",
      "pdf_url": "https://arxiv.org/pdf/2602.11724v1",
      "arxiv_url": "http://arxiv.org/abs/2602.11724v1",
      "published": "2026-02-12",
      "categories": [
        "cs.SE"
      ]
    },
    {
      "title": "Analytical Search",
      "authors": [
        "Yiteng Tu",
        "Shuo Miao",
        "Weihang Su",
        "Yiqun Liu",
        "Qingyao Ai"
      ],
      "abstract": "Analytical information needs, such as trend analysis and causal impact assessment, are prevalent across various domains including law, finance, science, and much more. However, existing information retrieval paradigms, whether based on relevance-oriented document ranking or retrieval-augmented generation (RAG) with large language models (LLMs), often struggle to meet the end-to-end requirements of such tasks at the corpus scale. They either emphasize information finding rather than end-to-end problem solving, or simply treat everything as naive question answering, offering limited control over reasoning, evidence usage, and verifiability. As a result, they struggle to support analytical queries that have diverse utility concepts and high accountability requirements.\n  In this paper, we propose analytical search as a distinct and emerging search paradigm designed to fulfill these analytical information needs. Analytical search reframes search as an evidence-governed, process-oriented analytical workflow that explicitly models analytical intent, retrieves evidence for fusion, and produces verifiable conclusions through structured, multi-step inference. We position analytical search in contrast to existing paradigms, and present a unified system framework that integrates query understanding, recall-oriented retrieval, reasoning-aware fusion, and adaptive verification. We also discuss potential research directions for the construction of analytical search engines. In this way, we highlight the conceptual significance and practical importance of analytical search and call on efforts toward the next generation of search engines that support analytical information needs.",
      "pdf_url": "https://arxiv.org/pdf/2602.11581v1",
      "arxiv_url": "http://arxiv.org/abs/2602.11581v1",
      "published": "2026-02-12",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "CausalAgent: A Conversational Multi-Agent System for End-to-End Causal Inference",
      "authors": [
        "Jiawei Zhu",
        "Wei Chen",
        "Ruichu Cai"
      ],
      "abstract": "Causal inference holds immense value in fields such as healthcare, economics, and social sciences. However, traditional causal analysis workflows impose significant technical barriers, requiring researchers to possess dual backgrounds in statistics and computer science, while manually selecting algorithms, handling data quality issues, and interpreting complex results. To address these challenges, we propose CausalAgent, a conversational multi-agent system for end-to-end causal inference. The system innovatively integrates Multi-Agent Systems (MAS), Retrieval-Augmented Generation (RAG), and the Model Context Protocol (MCP) to achieve automation from data cleaning and causal structure learning to bias correction and report generation through natural language interaction. Users need only upload a dataset and pose questions in natural language to receive a rigorous, interactive analysis report. As a novel user-centered human-AI collaboration paradigm, CausalAgent explicitly models the analysis workflow. By leveraging interactive visualizations, it significantly lowers the barrier to entry for causal analysis while ensuring the rigor and interpretability of the process.",
      "pdf_url": "https://arxiv.org/pdf/2602.11527v1",
      "arxiv_url": "http://arxiv.org/abs/2602.11527v1",
      "published": "2026-02-12",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Causal-JEPA: Learning World Models through Object-Level Latent Interventions",
      "authors": [
        "Heejeong Nam",
        "Quentin Le Lidec",
        "Lucas Maes",
        "Yann LeCun",
        "Randall Balestriero"
      ],
      "abstract": "World models require robust relational understanding to support prediction, reasoning, and control. While object-centric representations provide a useful abstraction, they are not sufficient to capture interaction-dependent dynamics. We therefore propose C-JEPA, a simple and flexible object-centric world model that extends masked joint embedding prediction from image patches to object-centric representations. By applying object-level masking that requires an object's state to be inferred from other objects, C-JEPA induces latent interventions with counterfactual-like effects and prevents shortcut solutions, making interaction reasoning essential. Empirically, C-JEPA leads to consistent gains in visual question answering, with an absolute improvement of about 20\\% in counterfactual reasoning compared to the same architecture without object-level masking. On agent control tasks, C-JEPA enables substantially more efficient planning by using only 1\\% of the total latent input features required by patch-based world models, while achieving comparable performance. Finally, we provide a formal analysis demonstrating that object-level masking induces a causal inductive bias via latent interventions. Our code is available at https://github.com/galilai-group/cjepa.",
      "pdf_url": "https://arxiv.org/pdf/2602.11389v1",
      "arxiv_url": "http://arxiv.org/abs/2602.11389v1",
      "published": "2026-02-11",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "A Doubly Robust Machine Learning Approach for Disentangling Treatment Effect Heterogeneity with Functional Outcomes",
      "authors": [
        "Filippo Salmaso",
        "Lorenzo Testa",
        "Francesca Chiaromonte"
      ],
      "abstract": "Causal inference is paramount for understanding the effects of interventions, yet extracting personalized insights from increasingly complex data remains a significant challenge for modern machine learning. This is the case, in particular, when considering functional outcomes observed over a continuous domain (e.g., time, or space). Estimation of heterogeneous treatment effects, known as CATE, has emerged as a crucial tool for personalized decision-making, but existing meta-learning frameworks are largely limited to scalar outcomes, failing to provide satisfying results in scientific applications that leverage the rich, continuous information encoded in functional data. Here, we introduce FOCaL (Functional Outcome Causal Learning), a novel, doubly robust meta-learner specifically engineered to estimate a functional heterogeneous treatment effect (F-CATE). FOCaL integrates advanced functional regression techniques for both outcome modeling and functional pseudo-outcome reconstruction, thereby enabling the direct and robust estimation of F-CATE. We provide a rigorous theoretical derivation of FOCaL, demonstrate its performance and robustness compared to existing non-robust functional methods through comprehensive simulation studies, and illustrate its practical utility on diverse real-world functional datasets. FOCaL advances the capabilities of machine intelligence to infer nuanced, individualized causal effects from complex data, paving the way for more precise and trustworthy AI systems in personalized medicine, adaptive policy design, and fundamental scientific discovery.",
      "pdf_url": "https://arxiv.org/pdf/2602.11118v1",
      "arxiv_url": "http://arxiv.org/abs/2602.11118v1",
      "published": "2026-02-11",
      "categories": [
        "stat.ME",
        "stat.ML"
      ]
    },
    {
      "title": "Causal Effect Estimation with Learned Instrument Representations",
      "authors": [
        "Frances Dean",
        "Jenna Fields",
        "Radhika Bhalerao",
        "Marie Charpignon",
        "Ahmed Alaa"
      ],
      "abstract": "Instrumental variable (IV) methods mitigate bias from unobserved confounding in observational causal inference but rely on the availability of a valid instrument, which can often be difficult or infeasible to identify in practice. In this paper, we propose a representation learning approach that constructs instrumental representations from observed covariates, which enable IV-based estimation even in the absence of an explicit instrument. Our model (ZNet) achieves this through an architecture that mirrors the structural causal model of IVs; it decomposes the ambient feature space into confounding and instrumental components, and is trained by enforcing empirical moment conditions corresponding to the defining properties of valid instruments (i.e., relevance, exclusion restriction, and instrumental unconfoundedness). Importantly, ZNet is compatible with a wide range of downstream two-stage IV estimators of causal effects. Our experiments demonstrate that ZNet can (i) recover ground-truth instruments when they already exist in the ambient feature space and (ii) construct latent instruments in the embedding space when no explicit IVs are available. This suggests that ZNet can be used as a ``plug-and-play'' module for causal inference in general observational settings, regardless of whether the (untestable) assumption of unconfoundedness is satisfied.",
      "pdf_url": "https://arxiv.org/pdf/2602.10370v1",
      "arxiv_url": "http://arxiv.org/abs/2602.10370v1",
      "published": "2026-02-10",
      "categories": [
        "stat.ML",
        "cs.LG",
        "stat.ME"
      ]
    },
    {
      "title": "Optimizing precision in stepped-wedge designs via machine learning and quadratic inference functions",
      "authors": [
        "Liangbo Lyu",
        "Bingkai Wang"
      ],
      "abstract": "Stepped-wedge designs are increasingly used in randomized experiments to accommodate logistical and ethical constraints by staggering treatment roll-out over time. Despite their popularity, existing analytical methods largely rely on parametric models with linear covariate adjustment and prespecified correlation structures, which may limit achievable precision in practice. We propose a new class of estimators for the causal average treatment effect in stepped-wedge designs that optimizes precision through flexible, machine-learning-based covariate adjustment to capture complex outcome-covariate relationships, together with quadratic inference functions to adaptively learn the correlation structure. We establish consistency and asymptotic normality under mild conditions requiring only $L_2$ convergence of nuisance estimators, even under model misspecification, and characterize when the estimator attains the minimal asymptotic variance. Moreover, we prove that the proposed estimator never reduces efficiency relative to an independence working correlation. The proposed method further accommodates treatment-effect heterogeneity across both exposure duration and calendar time. Finally, we demonstrate our methods through simulation studies and reanalyses of two empirical studies that differ substantially in research area and key design parameters.",
      "pdf_url": "https://arxiv.org/pdf/2602.10348v1",
      "arxiv_url": "http://arxiv.org/abs/2602.10348v1",
      "published": "2026-02-10",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Stop Training for the Worst: Progressive Unmasking Accelerates Masked Diffusion Training",
      "authors": [
        "Jaeyeon Kim",
        "Jonathan Geuter",
        "David Alvarez-Melis",
        "Sham Kakade",
        "Sitan Chen"
      ],
      "abstract": "Masked Diffusion Models (MDMs) have emerged as a promising approach for generative modeling in discrete spaces. By generating sequences in any order and allowing for parallel decoding, they enable fast inference and strong performance on non-causal tasks. However, this flexibility comes with a training complexity trade-off: MDMs train on an exponentially large set of masking patterns, which is not only computationally expensive, but also creates a train--test mismatch between the random masks used in training and the highly structured masks induced by inference-time unmasking. In this work, we propose Progressive UnMAsking (PUMA), a simple modification of the forward masking process that aligns training-time and inference-time masking patterns, thereby focusing optimization on inference-aligned masks and speeding up training. Empirically, PUMA speeds up pretraining at the 125M scale by $\\approx 2.5\\times$ and offers complementary advantages on top of common recipes like autoregressive initialization. We open-source our codebase at https://github.com/JaeyeonKim01/PUMA.",
      "pdf_url": "https://arxiv.org/pdf/2602.10314v1",
      "arxiv_url": "http://arxiv.org/abs/2602.10314v1",
      "published": "2026-02-10",
      "categories": [
        "cs.LG"
      ]
    }
  ]
}