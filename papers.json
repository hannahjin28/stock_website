{
  "last_updated": "2025-11-01T00:55:59.416809",
  "papers": [
    {
      "title": "A Unified Theory for Causal Inference: Direct Debiased Machine Learning via Bregman-Riesz Regression",
      "authors": [
        "Masahiro Kato"
      ],
      "abstract": "This note introduces a unified theory for causal inference that integrates\nRiesz regression, covariate balancing, density-ratio estimation (DRE), targeted\nmaximum likelihood estimation (TMLE), and the matching estimator in average\ntreatment effect (ATE) estimation. In ATE estimation, the balancing weights and\nthe regression functions of the outcome play important roles, where the\nbalancing weights are referred to as the Riesz representer, bias-correction\nterm, and clever covariates, depending on the context. Riesz regression,\ncovariate balancing, DRE, and the matching estimator are methods for estimating\nthe balancing weights, where Riesz regression is essentially equivalent to DRE\nin the ATE context, the matching estimator is a special case of DRE, and DRE is\nin a dual relationship with covariate balancing. TMLE is a method for\nconstructing regression function estimators such that the leading bias term\nbecomes zero. Nearest Neighbor Matching is equivalent to Least Squares Density\nRatio Estimation and Riesz Regression.",
      "pdf_url": "http://arxiv.org/pdf/2510.26783v1",
      "arxiv_url": "http://arxiv.org/abs/2510.26783v1",
      "published": "2025-10-30",
      "categories": [
        "stat.ML",
        "cs.LG",
        "econ.EM",
        "math.ST",
        "stat.ME",
        "stat.TH"
      ]
    },
    {
      "title": "Assessment of the conditional exchangeability assumption in causal machine learning models: a simulation study",
      "authors": [
        "Gerard T. Portela",
        "Jason B. Gibbons",
        "Sebastian Schneeweiss",
        "Rishi J. Desai"
      ],
      "abstract": "Observational studies developing causal machine learning (ML) models for the\nprediction of individualized treatment effects (ITEs) seldom conduct empirical\nevaluations to assess the conditional exchangeability assumption. We aimed to\nevaluate the performance of these models under conditional exchangeability\nviolations and the utility of negative control outcomes (NCOs) as a diagnostic.\nWe conducted a simulation study to examine confounding bias in ITE estimates\ngenerated by causal forest and X-learner models under varying conditions,\nincluding the presence or absence of true heterogeneity. We simulated data to\nreflect real-world scenarios with differing levels of confounding, sample size,\nand NCO confounding structures. We then estimated and compared subgroup-level\ntreatment effects on the primary outcome and NCOs across settings with and\nwithout unmeasured confounding. When conditional exchangeability was violated,\ncausal forest and X-learner models failed to recover true treatment effect\nheterogeneity and, in some cases, falsely indicated heterogeneity when there\nwas none. NCOs successfully identified subgroups affected by unmeasured\nconfounding. Even when NCOs did not perfectly satisfy its ideal assumptions, it\nremained informative, flagging potential bias in subgroup level estimates,\nthough not always pinpointing the subgroup with the largest confounding.\nViolations of conditional exchangeability substantially limit the validity of\nITE estimates from causal ML models in routinely collected observational data.\nNCOs serve a useful empirical diagnostic tool for detecting subgroup-specific\nunmeasured confounding and should be incorporated into causal ML workflows to\nsupport the credibility of individualized inference.",
      "pdf_url": "http://arxiv.org/pdf/2510.26700v1",
      "arxiv_url": "http://arxiv.org/abs/2510.26700v1",
      "published": "2025-10-30",
      "categories": [
        "stat.ML",
        "cs.LG"
      ]
    },
    {
      "title": "Encoder-Decoder or Decoder-Only? Revisiting Encoder-Decoder Large Language Model",
      "authors": [
        "Biao Zhang",
        "Yong Cheng",
        "Siamak Shakeri",
        "Xinyi Wang",
        "Min Ma",
        "Orhan Firat"
      ],
      "abstract": "Recent large language model (LLM) research has undergone an architectural\nshift from encoder-decoder modeling to nowadays the dominant decoder-only\nmodeling. This rapid transition, however, comes without a rigorous comparative\nanalysis especially \\textit{from the scaling perspective}, raising concerns\nthat the potential of encoder-decoder models may have been overlooked. To fill\nthis gap, we revisit encoder-decoder LLM (RedLLM), enhancing it with recent\nrecipes from decoder-only LLM (DecLLM). We conduct a comprehensive comparison\nbetween RedLLM, pretrained with prefix language modeling (LM), and DecLLM,\npretrained with causal LM, at different model scales, ranging from $\\sim$150M\nto $\\sim$8B. Using RedPajama V1 (1.6T tokens) for pretraining and FLAN for\ninstruction tuning, our experiments show that RedLLM produces compelling\nscaling properties and surprisingly strong performance. While DecLLM is overall\nmore compute-optimal during pretraining, RedLLM demonstrates comparable scaling\nand context length extrapolation capabilities. After instruction tuning, RedLLM\nachieves comparable and even better results on various downstream tasks while\nenjoying substantially better inference efficiency. We hope our findings could\ninspire more efforts on re-examining RedLLM, unlocking its potential for\ndeveloping powerful and efficient LLMs.",
      "pdf_url": "http://arxiv.org/pdf/2510.26622v1",
      "arxiv_url": "http://arxiv.org/abs/2510.26622v1",
      "published": "2025-10-30",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "title": "Discovering Causal Relationships Between Time Series With Spatial Structure",
      "authors": [
        "Rebecca F. Supple",
        "Hannah Worthington",
        "Ben Swallow"
      ],
      "abstract": "Causal discovery is the subfield of causal inference concerned with\nestimating the structure of cause-and-effect relationships in a system of\ninterrelated variables, as opposed to quantifying the strength of causal\neffects. As interest in causal discovery builds in fields such as ecology,\npublic health, and environmental sciences where data is regularly collected\nwith spatial and temporal structures, approaches must evolve to manage\nautocorrelation and complex confounding. As it stands, the few proposed causal\ndiscovery algorithms for spatiotemporal data require summarizing across\nlocations, ignore spatial autocorrelation, and/or scale poorly to high\ndimensions. Here, we introduce our developing framework that extends\ntime-series causal discovery to systems with spatial structure, building upon\nwork on causal discovery across contexts and methods for handling spatial\nconfounding in causal effect estimation. We close by outlining remaining gaps\nin the literature and directions for future research.",
      "pdf_url": "http://arxiv.org/pdf/2510.26485v1",
      "arxiv_url": "http://arxiv.org/abs/2510.26485v1",
      "published": "2025-10-30",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "In Defense of the Pre-Test: Valid Inference when Testing Violations of Parallel Trends for Difference-in-Differences",
      "authors": [
        "Jonas M. Mikhaeil",
        "Christopher Harshaw"
      ],
      "abstract": "The difference-in-differences (DID) research design is a key identification\nstrategy which allows researchers to estimate causal effects under the parallel\ntrends assumption. While the parallel trends assumption is counterfactual and\ncannot be tested directly, researchers often examine pre-treatment periods to\ncheck whether the time trends are parallel before treatment is administered.\nRecently, researchers have been cautioned against using preliminary tests which\naim to detect violations of parallel trends in the pre-treatment period. In\nthis paper, we argue that preliminary testing can -- and should -- play an\nimportant role within the DID research design. We propose a new and more\nsubstantively appropriate conditional extrapolation assumption, which requires\nan analyst to conduct a preliminary test to determine whether the severity of\npre-treatment parallel trend violations falls below an acceptable level before\nextrapolation to the post-treatment period is justified. This stands in\ncontrast to prior work which can be interpreted as either setting the\nacceptable level to be exactly zero (in which case preliminary tests lack\npower) or assuming that extrapolation is always justified (in which case\npreliminary tests are not required). Under mild assumptions on how close the\nactual violation is to the acceptable level, we provide a consistent\npreliminary test as well confidence intervals which are valid when conditioned\non the result of the test. The conditional coverage of these intervals\novercomes a common critique made against the use of preliminary testing within\nthe DID research design. We use real data as well as numerical simulations to\nillustrate the performance of the proposed methods.",
      "pdf_url": "http://arxiv.org/pdf/2510.26470v1",
      "arxiv_url": "http://arxiv.org/abs/2510.26470v1",
      "published": "2025-10-30",
      "categories": [
        "stat.ME",
        "econ.EM"
      ]
    },
    {
      "title": "Representation-Level Counterfactual Calibration for Debiased Zero-Shot Recognition",
      "authors": [
        "Pei Peng",
        "MingKun Xie",
        "Hang Hao",
        "Tong Jin",
        "ShengJun Huang"
      ],
      "abstract": "Object-context shortcuts remain a persistent challenge in vision-language\nmodels, undermining zero-shot reliability when test-time scenes differ from\nfamiliar training co-occurrences. We recast this issue as a causal inference\nproblem and ask: Would the prediction remain if the object appeared in a\ndifferent environment? To answer this at inference time, we estimate object and\nbackground expectations within CLIP's representation space, and synthesize\ncounterfactual embeddings by recombining object features with diverse\nalternative contexts sampled from external datasets, batch neighbors, or\ntext-derived descriptions. By estimating the Total Direct Effect and simulating\nintervention, we further subtract background-only activation, preserving\nbeneficial object-context interactions while mitigating hallucinated scores.\nWithout retraining or prompt design, our method substantially improves both\nworst-group and average accuracy on context-sensitive benchmarks, establishing\na new zero-shot state of the art. Beyond performance, our framework provides a\nlightweight representation-level counterfactual approach, offering a practical\ncausal avenue for debiased and reliable multimodal reasoning.",
      "pdf_url": "http://arxiv.org/pdf/2510.26466v1",
      "arxiv_url": "http://arxiv.org/abs/2510.26466v1",
      "published": "2025-10-30",
      "categories": [
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "title": "Chain-of-Thought Hijacking",
      "authors": [
        "Jianli Zhao",
        "Tingchen Fu",
        "Rylan Schaeffer",
        "Mrinank Sharma",
        "Fazl Barez"
      ],
      "abstract": "Large reasoning models (LRMs) achieve higher task performance by allocating\nmore inference-time compute, and prior works suggest this scaled reasoning may\nalso strengthen safety by improving refusal. Yet we find the opposite: the same\nreasoning can be used to bypass safeguards. We introduce Chain-of-Thought\nHijacking, a jailbreak attack on reasoning models. The attack pads harmful\nrequests with long sequences of harmless puzzle reasoning. Across HarmBench,\nCoT Hijacking reaches a 99%, 94%, 100%, and 94% attack success rate (ASR) on\nGemini 2.5 Pro, GPT o4 mini, Grok 3 mini, and Claude 4 Sonnet, respectively -\nfar exceeding prior jailbreak methods for LRMs. To understand the effectiveness\nof our attack, we turn to a mechanistic analysis, which shows that mid layers\nencode the strength of safety checking, while late layers encode the\nverification outcome. Long benign CoT dilutes both signals by shifting\nattention away from harmful tokens. Targeted ablations of attention heads\nidentified by this analysis causally decrease refusal, confirming their role in\na safety subnetwork. These results show that the most interpretable form of\nreasoning - explicit CoT - can itself become a jailbreak vector when combined\nwith final-answer cues. We release prompts, outputs, and judge decisions to\nfacilitate replication.",
      "pdf_url": "http://arxiv.org/pdf/2510.26418v1",
      "arxiv_url": "http://arxiv.org/abs/2510.26418v1",
      "published": "2025-10-30",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "$Λ$vCF: Extending $Λ$CDM into a Unified Model with Particle Creation",
      "authors": [
        "Vishnu A Pai",
        "Titus K Mathew"
      ],
      "abstract": "We present a novel extended version of the $\\Lambda$CDM model that provides\nanalytical solution for Hubble parameter uniting all epochs of cosmic evolution\nstarting from inflation to late-acceleration, with intermediate radiation and\nmatter-dominated epochs. This is achieved by relaxing the perfect fluid\nassumption in the standard model and considering a general viscous cosmic fluid\n(vCF) with non-zero particle creation rate and evolving adiabatic equation of\nstate. Transition points of the Universe and the finite boundary connecting\nthem is exactly determined. We then propose a novel method to determine the\nearly-time viscous coefficient and inflation energy scale using the Cosmic Mode\nIndex value postulated by Padmanabhan. Considering the data from the Planck\n2018 analysis, this yields an inflationary Hubble parameter of\n$H_{I}\\approx10^{13}$\\,GeV. An equivalent scalar-field description for the\ninflationary epoch is then constructed and inferences are made regarding the\nnature of inflation. Notably, we find that the model describes an\nultra-slow-roll hilltop inflation scenario with a graceful exit to\nradiation-dominated epoch. Subsequently, we show that bulk viscosity in this\nmodel can be expressed as Israel-Stewart equation in relativistic dissipative\nhydrodynamics with an appropriate underlying viscous coefficient and relaxation\ntime that satisfy the causality constraint in its extreme limit. Finally, by\ncomparing the evolution of this causal relation and its Navier-Stokes\ncounterpart, we infer that the evolution from inflation to radiation era\nsignifies a fluid transitioning from viscoelastic to pseudoplastic behavior.",
      "pdf_url": "http://arxiv.org/pdf/2510.26366v1",
      "arxiv_url": "http://arxiv.org/abs/2510.26366v1",
      "published": "2025-10-30",
      "categories": [
        "astro-ph.CO",
        "gr-qc"
      ]
    },
    {
      "title": "Which Way Does Time Flow? A Psychophysics-Grounded Evaluation for Vision-Language Models",
      "authors": [
        "Shiho Matta",
        "Lis Kanashiro Pereira",
        "Peitao Han",
        "Fei Cheng",
        "Shigeru Kitazawa"
      ],
      "abstract": "Modern vision-language models (VLMs) excel at many multimodal tasks, yet\ntheir grasp of temporal information in video remains weak and, crucially,\nunder-evaluated. We probe this gap with a deceptively simple but revealing\nchallenge: judging the arrow of time (AoT)-whether a short clip is played\nforward or backward. We introduce AoT-PsyPhyBENCH, a psychophysically validated\nbenchmark that tests whether VLMs can infer temporal direction in natural\nvideos using the same stimuli and behavioral baselines established for humans.\nOur comprehensive evaluation of open-weight and proprietary, reasoning and\nnon-reasoning VLMs reveals that most models perform near chance, and even the\nbest lag far behind human accuracy on physically irreversible processes (e.g.,\nfree fall, diffusion/explosion) and causal manual actions (division/addition)\nthat humans recognize almost instantly. These results highlight a fundamental\ngap in current multimodal systems: while they capture rich visual-semantic\ncorrelations, they lack the inductive biases required for temporal continuity\nand causal understanding. We release the code and data for AoT-PsyPhyBENCH to\nencourage further progress in the physical and temporal reasoning capabilities\nof VLMs.",
      "pdf_url": "http://arxiv.org/pdf/2510.26241v1",
      "arxiv_url": "http://arxiv.org/abs/2510.26241v1",
      "published": "2025-10-30",
      "categories": [
        "cs.CV",
        "cs.CL"
      ]
    },
    {
      "title": "Causal Inference with Groupwise Matching",
      "authors": [
        "Ratzanyel Rincón",
        "Kyungchul Song"
      ],
      "abstract": "This paper examines methods of causal inference based on groupwise matching\nwhen we observe multiple large groups of individuals over several periods. We\nformulate causal inference validity through a generalized matching condition,\ngeneralizing the parallel trend assumption in difference-in-differences\ndesigns. We show that difference-in-differences, synthetic control, and\nsynthetic difference-in-differences designs are distinguished by the specific\nmatching conditions that they invoke. Through regret analysis, we demonstrate\nthat difference-in-differences and synthetic control with differencing are\ncomplementary; the former dominates the latter if and only if the latter's\nextrapolation error exceeds the former's matching error up to a term vanishing\nat the parametric rate. The analysis also reveals that synthetic control with\ndifferencing is equivalent to difference-in-differences when the parallel trend\nassumption holds for both the pre-treatment and post-treatment periods. We\ndevelop a statistical inference procedure based on synthetic control with\ndifferencing and present an empirical application demonstrating its usefulness.",
      "pdf_url": "http://arxiv.org/pdf/2510.26106v1",
      "arxiv_url": "http://arxiv.org/abs/2510.26106v1",
      "published": "2025-10-30",
      "categories": [
        "econ.EM"
      ]
    }
  ]
}