{
  "last_updated": "2025-04-30T00:52:36.484927",
  "papers": [
    {
      "title": "Inference with few treated units",
      "authors": [
        "Luis Alvarez",
        "Bruno Ferman",
        "Kaspar WÃ¼thrich"
      ],
      "abstract": "In many causal inference applications, only one or a few units (or clusters\nof units) are treated. An important challenge in such settings is that standard\ninference methods that rely on asymptotic theory may be unreliable, even when\nthe total number of units is large. This survey reviews and categorizes\ninference methods that are designed to accommodate few treated units,\nconsidering both cross-sectional and panel data methods. We discuss trade-offs\nand connections between different approaches. In doing so, we propose slight\nmodifications to improve the finite-sample validity of some methods, and we\nalso provide theoretical justifications for existing heuristic approaches that\nhave been proposed in the literature.",
      "pdf_url": "http://arxiv.org/pdf/2504.19841v1",
      "arxiv_url": "http://arxiv.org/abs/2504.19841v1",
      "published": "2025-04-28",
      "categories": [
        "econ.EM"
      ]
    },
    {
      "title": "Selective randomization inference for subgroup effects with continuous biomarkers",
      "authors": [
        "Zijun Gao"
      ],
      "abstract": "Randomization tests are a popular method for testing causal effects in\nclinical trials with finite-sample validity. In the presence of heterogeneous\ntreatment effects, it is often of interest to select a subgroup that benefits\nfrom the treatment, frequently by choosing a cutoff for a continuous biomarker.\nHowever, selecting the cutoff and testing the effect on the same data may fail\nto control the type I error. To address this, we propose using \"self-contained\"\nmethods for selecting biomarker-based subgroups (cutoffs) and applying\nconditioning to construct valid randomization tests for the subgroup effect.\nCompared to sample-splitting-based randomization tests, our proposal is fully\ndeterministic, uses the entire selected subgroup for inference, and is thus\nmore powerful. Moreover, we demonstrate scenarios where our procedure achieves\npower comparable to a randomization test with oracle knowledge of the\nbenefiting subgroup. In addition, our procedure is as computationally efficient\nas standard randomization tests. Empirically, we illustrate the effectiveness\nof our method on simulated datasets and the German Breast Cancer Study.",
      "pdf_url": "http://arxiv.org/pdf/2504.19380v1",
      "arxiv_url": "http://arxiv.org/abs/2504.19380v1",
      "published": "2025-04-27",
      "categories": [
        "stat.ME",
        "stat.AP"
      ]
    },
    {
      "title": "ReLU integral probability metric and its applications",
      "authors": [
        "Yuha Park",
        "Kunwoong Kim",
        "Insung Kong",
        "Yongdai Kim"
      ],
      "abstract": "We propose a parametric integral probability metric (IPM) to measure the\ndiscrepancy between two probability measures. The proposed IPM leverages a\nspecific parametric family of discriminators, such as single-node neural\nnetworks with ReLU activation, to effectively distinguish between\ndistributions, making it applicable in high-dimensional settings. By optimizing\nover the parameters of the chosen discriminator class, the proposed IPM\ndemonstrates that its estimators have good convergence rates and can serve as a\nsurrogate for other IPMs that use smooth nonparametric discriminator classes.\nWe present an efficient algorithm for practical computation, offering a simple\nimplementation and requiring fewer hyperparameters. Furthermore, we explore its\napplications in various tasks, such as covariate balancing for causal inference\nand fair representation learning. Across such diverse applications, we\ndemonstrate that the proposed IPM provides strong theoretical guarantees, and\nempirical experiments show that it achieves comparable or even superior\nperformance to other methods.",
      "pdf_url": "http://arxiv.org/pdf/2504.18897v1",
      "arxiv_url": "http://arxiv.org/abs/2504.18897v1",
      "published": "2025-04-26",
      "categories": [
        "stat.ML",
        "cs.LG",
        "stat.ME"
      ]
    },
    {
      "title": "Causality-Driven Neural Network Repair: Challenges and Opportunities",
      "authors": [
        "Fatemeh Vares",
        "Brittany Johnson"
      ],
      "abstract": "Deep Neural Networks (DNNs) often rely on statistical correlations rather\nthan causal reasoning, limiting their robustness and interpretability. While\ntesting methods can identify failures, effective debugging and repair remain\nchallenging. This paper explores causal inference as an approach primarily for\nDNN repair, leveraging causal debugging, counterfactual analysis, and\nstructural causal models (SCMs) to identify and correct failures. We discuss in\nwhat ways these techniques support fairness, adversarial robustness, and\nbackdoor mitigation by providing targeted interventions. Finally, we discuss\nkey challenges, including scalability, generalization, and computational\nefficiency, and outline future directions for integrating causality-driven\ninterventions to enhance DNN reliability.",
      "pdf_url": "http://arxiv.org/pdf/2504.17946v1",
      "arxiv_url": "http://arxiv.org/abs/2504.17946v1",
      "published": "2025-04-24",
      "categories": [
        "cs.LG",
        "D.2.2; I.2.6"
      ]
    },
    {
      "title": "Fast Autoregressive Models for Continuous Latent Generation",
      "authors": [
        "Tiankai Hang",
        "Jianmin Bao",
        "Fangyun Wei",
        "Dong Chen"
      ],
      "abstract": "Autoregressive models have demonstrated remarkable success in sequential data\ngeneration, particularly in NLP, but their extension to continuous-domain image\ngeneration presents significant challenges. Recent work, the masked\nautoregressive model (MAR), bypasses quantization by modeling per-token\ndistributions in continuous spaces using a diffusion head but suffers from slow\ninference due to the high computational cost of the iterative denoising\nprocess. To address this, we propose the Fast AutoRegressive model (FAR), a\nnovel framework that replaces MAR's diffusion head with a lightweight shortcut\nhead, enabling efficient few-step sampling while preserving autoregressive\nprinciples. Additionally, FAR seamlessly integrates with causal Transformers,\nextending them from discrete to continuous token generation without requiring\narchitectural modifications. Experiments demonstrate that FAR achieves\n$2.3\\times$ faster inference than MAR while maintaining competitive FID and IS\nscores. This work establishes the first efficient autoregressive paradigm for\nhigh-fidelity continuous-space image generation, bridging the critical gap\nbetween quality and scalability in visual autoregressive modeling.",
      "pdf_url": "http://arxiv.org/pdf/2504.18391v1",
      "arxiv_url": "http://arxiv.org/abs/2504.18391v1",
      "published": "2025-04-24",
      "categories": [
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "title": "ExOSITO: Explainable Off-Policy Learning with Side Information for Intensive Care Unit Blood Test Orders",
      "authors": [
        "Zongliang Ji",
        "Andre Carlos Kajdacsy-Balla Amaral",
        "Anna Goldenberg",
        "Rahul G. Krishnan"
      ],
      "abstract": "Ordering a minimal subset of lab tests for patients in the intensive care\nunit (ICU) can be challenging. Care teams must balance between ensuring the\navailability of the right information and reducing the clinical burden and\ncosts associated with each lab test order. Most in-patient settings experience\nfrequent over-ordering of lab tests, but are now aiming to reduce this burden\non both hospital resources and the environment. This paper develops a novel\nmethod that combines off-policy learning with privileged information to\nidentify the optimal set of ICU lab tests to order. Our approach, EXplainable\nOff-policy learning with Side Information for ICU blood Test Orders (ExOSITO)\ncreates an interpretable assistive tool for clinicians to order lab tests by\nconsidering both the observed and predicted future status of each patient. We\npose this problem as a causal bandit trained using offline data and a reward\nfunction derived from clinically-approved rules; we introduce a novel learning\nframework that integrates clinical knowledge with observational data to bridge\nthe gap between the optimal and logging policies. The learned policy function\nprovides interpretable clinical information and reduces costs without omitting\nany vital lab orders, outperforming both a physician's policy and prior\napproaches to this practical problem.",
      "pdf_url": "http://arxiv.org/pdf/2504.17277v1",
      "arxiv_url": "http://arxiv.org/abs/2504.17277v1",
      "published": "2025-04-24",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Target trial emulation without matching: a more efficient approach for evaluating vaccine effectiveness using observational data",
      "authors": [
        "Emily Wu",
        "Elizabeth Rogawski McQuade",
        "Mats Stensrud",
        "Razieh Nabi",
        "David Benkeser"
      ],
      "abstract": "Real-world vaccine effectiveness has increasingly been studied using\nmatching-based approaches, particularly in observational cohort studies\nfollowing the target trial emulation framework. Although matching is appealing\nin its simplicity, it suffers important limitations in terms of clarity of the\ntarget estimand and the efficiency or precision with which is it estimated.\nScientifically justified causal estimands of vaccine effectiveness may be\ndifficult to define owing to the fact that vaccine uptake varies over calendar\ntime when infection dynamics may also be rapidly changing. We propose a causal\nestimand of vaccine effectiveness that summarizes vaccine effectiveness over\ncalendar time, similar to how vaccine efficacy is summarized in a randomized\ncontrolled trial. We describe the identification of our estimand, including its\nunderlying assumptions, and propose simple-to-implement estimators based on two\nhazard regression models. We apply our proposed estimator in simulations and in\na study to assess the effectiveness of the Pfizer-BioNTech COVID-19 vaccine to\nprevent infections with SARS-CoV2 in children 5-11 years old. In both settings,\nwe find that our proposed estimator yields similar scientific inferences while\nproviding significant efficiency gains over commonly used matching-based\nestimators.",
      "pdf_url": "http://arxiv.org/pdf/2504.17104v1",
      "arxiv_url": "http://arxiv.org/abs/2504.17104v1",
      "published": "2025-04-23",
      "categories": [
        "stat.ME",
        "stat.AP"
      ]
    },
    {
      "title": "Distilling semantically aware orders for autoregressive image generation",
      "authors": [
        "Rishav Pramanik",
        "Antoine Poupon",
        "Juan A. Rodriguez",
        "Masih Aminbeidokhti",
        "David Vazquez",
        "Christopher Pal",
        "Zhaozheng Yin",
        "Marco Pedersoli"
      ],
      "abstract": "Autoregressive patch-based image generation has recently shown competitive\nresults in terms of image quality and scalability. It can also be easily\nintegrated and scaled within Vision-Language models. Nevertheless,\nautoregressive models require a defined order for patch generation. While a\nnatural order based on the dictation of the words makes sense for text\ngeneration, there is no inherent generation order that exists for image\ngeneration. Traditionally, a raster-scan order (from top-left to bottom-right)\nguides autoregressive image generation models. In this paper, we argue that\nthis order is suboptimal, as it fails to respect the causality of the image\ncontent: for instance, when conditioned on a visual description of a sunset, an\nautoregressive model may generate clouds before the sun, even though the color\nof clouds should depend on the color of the sun and not the inverse. In this\nwork, we show that first by training a model to generate patches in\nany-given-order, we can infer both the content and the location (order) of each\npatch during generation. Secondly, we use these extracted orders to finetune\nthe any-given-order model to produce better-quality images. Through our\nexperiments, we show on two datasets that this new generation method produces\nbetter images than the traditional raster-scan approach, with similar training\ncosts and no extra annotations.",
      "pdf_url": "http://arxiv.org/pdf/2504.17069v1",
      "arxiv_url": "http://arxiv.org/abs/2504.17069v1",
      "published": "2025-04-23",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Using Causal Inference to Test Systems with Hidden and Interacting Variables: An Evaluative Case Study",
      "authors": [
        "Michael Foster",
        "Robert M. Hierons",
        "Donghwan Shin",
        "Neil Walkinshaw",
        "Christopher Wild"
      ],
      "abstract": "Software systems with large parameter spaces, nondeterminism and high\ncomputational cost are challenging to test. Recently, software testing\ntechniques based on causal inference have been successfully applied to systems\nthat exhibit such characteristics, including scientific models and autonomous\ndriving systems. One significant limitation is that these are restricted to\ntest properties where all of the variables involved can be observed and where\nthere are no interactions between variables. In practice, this is rarely\nguaranteed; the logging infrastructure may not be available to record all of\nthe necessary runtime variable values, and it can often be the case that an\noutput of the system can be affected by complex interactions between variables.\nTo address this, we leverage two additional concepts from causal inference,\nnamely effect modification and instrumental variable methods. We build these\nconcepts into an existing causal testing tool and conduct an evaluative case\nstudy which uses the concepts to test three system-level requirements of CARLA,\na high-fidelity driving simulator widely used in autonomous vehicle development\nand testing. The results show that we can obtain reliable test outcomes without\nrequiring large amounts of highly controlled test data or instrumentation of\nthe code, even when variables interact with each other and are not recorded in\nthe test data.",
      "pdf_url": "http://arxiv.org/pdf/2504.16526v2",
      "arxiv_url": "http://arxiv.org/abs/2504.16526v2",
      "published": "2025-04-23",
      "categories": [
        "cs.SE"
      ]
    },
    {
      "title": "Robust Causal Inference for EHR-based Studies of Point Exposures with Missingness in Eligibility Criteria",
      "authors": [
        "Luke Benz",
        "Rajarshi Mukherjee",
        "Rui Wang",
        "David Arterburn",
        "Heidi Fischer",
        "Catherine Lee",
        "Susan M. Shortreed",
        "Sebastien Haneuse",
        "Alexander W. Levis"
      ],
      "abstract": "Missingness in variables that define study eligibility criteria is a seldom\naddressed challenge in electronic health record (EHR)-based settings. It is\ntypically the case that patients with incomplete eligibility information are\nexcluded from analysis without consideration of (implicit) assumptions that are\nbeing made, leaving study conclusions subject to potential selection bias. In\nan effort to ascertain eligibility for more patients, researchers may look back\nfurther in time prior to study baseline, and in using outdated values of\neligibility-defining covariates may inappropriately be including individuals\nwho, unbeknownst to the researcher, fail to meet eligibility at baseline. To\nthe best of our knowledge, however, very little work has been done to mitigate\nthese concerns. We propose a robust and efficient estimator of the causal\naverage treatment effect on the treated, defined in the study eligible\npopulation, in cohort studies where eligibility-defining covariates are missing\nat random. The approach facilitates the use of flexible machine-learning\nstrategies for component nuisance functions while maintaining appropriate\nconvergence rates for valid asymptotic inference. EHR data from Kaiser\nPermanente are used as motivation as well as a basis for extensive simulations\nthat verify robustness properties under various degrees of model\nmisspecification. The data are also used to demonstrate the use of the method\nto analyze differences between two common bariatric surgical interventions for\nlong-term weight and glycemic outcomes among a cohort of severely obese\npatients with type II diabetes mellitus.",
      "pdf_url": "http://arxiv.org/pdf/2504.16230v1",
      "arxiv_url": "http://arxiv.org/abs/2504.16230v1",
      "published": "2025-04-22",
      "categories": [
        "stat.ME",
        "stat.AP"
      ]
    }
  ]
}