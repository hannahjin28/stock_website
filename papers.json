{
  "last_updated": "2025-02-14T00:45:01.471726",
  "papers": [
    {
      "title": "Difference-in-Differences and Changes-in-Changes with Sample Selection",
      "authors": [
        "Javier Viviens"
      ],
      "abstract": "Sample selection arises endogenously in causal research when the treatment\naffects whether certain units are observed. It is a common pitfall in\nlongitudinal studies, particularly in settings where treatment assignment is\nconfounded. In this paper, I highlight the drawbacks of one of the most popular\nidentification strategies in such settings: Difference-in-Differences (DiD).\nSpecifically, I employ principal stratification analysis to show that the\nconventional ATT estimand may not be well defined, and the DiD estimand cannot\nbe interpreted causally without additional assumptions. To address these\nissues, I develop an identification strategy to partially identify causal\neffects on the subset of units with well-defined and observed outcomes under\nboth treatment regimes. I adapt Lee bounds to the Changes-in-Changes (CiC)\nsetting (Athey & Imbens, 2006), leveraging the time dimension of the data to\nrelax the unconfoundedness assumption in the original trimming strategy of Lee\n(2009). This setting has the DiD identification strategy as a particular case,\nwhich I also implement in the paper. Additionally, I explore how to leverage\nmultiple sources of sample selection to relax the monotonicity assumption in\nLee (2009), which may be of independent interest. Alongside the identification\nstrategy, I present estimators and inference results. I illustrate the\nrelevance of the proposed methodology by analyzing a job training program in\nColombia.",
      "pdf_url": "http://arxiv.org/pdf/2502.08614v1",
      "arxiv_url": "http://arxiv.org/abs/2502.08614v1",
      "published": "2025-02-12",
      "categories": [
        "econ.EM"
      ]
    },
    {
      "title": "Causal Analysis of ASR Errors for Children: Quantifying the Impact of Physiological, Cognitive, and Extrinsic Factors",
      "authors": [
        "Vishwanath Pratap Singh",
        "Md. Sahidullah",
        "Tomi Kinnunen"
      ],
      "abstract": "The increasing use of children's automatic speech recognition (ASR) systems\nhas spurred research efforts to improve the accuracy of models designed for\nchildren's speech in recent years. The current approach utilizes either\nopen-source speech foundation models (SFMs) directly or fine-tuning them with\nchildren's speech data. These SFMs, whether open-source or fine-tuned for\nchildren, often exhibit higher word error rates (WERs) compared to adult\nspeech. However, there is a lack of systemic analysis of the cause of this\ndegraded performance of SFMs. Understanding and addressing the reasons behind\nthis performance disparity is crucial for improving the accuracy of SFMs for\nchildren's speech. Our study addresses this gap by investigating the causes of\naccuracy degradation and the primary contributors to WER in children's speech.\nIn the first part of the study, we conduct a comprehensive benchmarking study\non two self-supervised SFMs (Wav2Vec2.0 and Hubert) and two weakly supervised\nSFMs (Whisper and MMS) across various age groups on two children speech\ncorpora, establishing the raw data for the causal inference analysis in the\nsecond part. In the second part of the study, we analyze the impact of\nphysiological factors (age, gender), cognitive factors (pronunciation ability),\nand external factors (vocabulary difficulty, background noise, and word count)\non SFM accuracy in children's speech using causal inference. The results\nindicate that physiology (age) and particular external factor (number of words\nin audio) have the highest impact on accuracy, followed by background noise and\npronunciation ability. Fine-tuning SFMs on children's speech reduces\nsensitivity to physiological and cognitive factors, while sensitivity to the\nnumber of words in audio persists.\n  Keywords: Children's ASR, Speech Foundational Models, Causal Inference,\nPhysiology, Cognition, Pronunciation",
      "pdf_url": "http://arxiv.org/pdf/2502.08587v1",
      "arxiv_url": "http://arxiv.org/abs/2502.08587v1",
      "published": "2025-02-12",
      "categories": [
        "eess.AS"
      ]
    },
    {
      "title": "Tutorial for Surrogate Endpoint Validation Using Joint modeling and Mediation Analysis",
      "authors": [
        "Quentin Le Coent",
        "Virginie Rondeau",
        "Catherine Legrand"
      ],
      "abstract": "The use of valid surrogate endpoints is an important stake in clinical\nresearch to help reduce both the duration and cost of a clinical trial and\nspeed up the evaluation of interesting treatments. Several methods have been\nproposed in the statistical literature to validate putative surrogate\nendpoints. Two main approaches have been proposed: the meta-analytic approach\nand the mediation analysis approach. The former uses data from meta-analyses to\nderive associations measures between the surrogate and the final endpoint at\nthe individual and trial levels. The latter rather uses the proportion of the\ntreatment effect on the final endpoint through the surrogate as a measure of\nsurrogacy in a causal inference framework. Both approaches have remained\nseparated as the meta-analytic approach does not estimate the treatment effect\non the final endpoint through the surrogate while the mediation analysis\napproach have been limited to single-trial setting. However, these two\napproaches are complementary. In this work we propose an approach that combines\nthe meta-analytic and mediation analysis approaches using joint modeling for\nsurrogate validation. We focus on the cases where the final endpoint is a\ntime-to-event endpoint (such as time-to-death) and the surrogate is either a\ntime-to-event or a longitudinal biomarker. Two new joint models were proposed\ndepending on the nature of the surrogate. These model are implemented in the R\npackage frailtypack. We illustrate the developed approaches in three\napplications on real datasets in oncology.",
      "pdf_url": "http://arxiv.org/pdf/2502.08443v1",
      "arxiv_url": "http://arxiv.org/abs/2502.08443v1",
      "published": "2025-02-12",
      "categories": [
        "stat.ME",
        "stat.AP",
        "stat.CO"
      ]
    },
    {
      "title": "Individualised Treatment Effects Estimation with Composite Treatments and Composite Outcomes",
      "authors": [
        "Vinod Kumar Chauhan",
        "Lei Clifton",
        "Gaurav Nigam",
        "David A. Clifton"
      ],
      "abstract": "Estimating individualised treatment effect (ITE) -- that is the causal effect\nof a set of variables (also called exposures, treatments, actions, policies, or\ninterventions), referred to as \\textit{composite treatments}, on a set of\noutcome variables of interest, referred to as \\textit{composite outcomes}, for\na unit from observational data -- remains a fundamental problem in causal\ninference with applications across disciplines, such as healthcare, economics,\neducation, social science, marketing, and computer science. Previous work in\ncausal machine learning for ITE estimation is limited to simple settings, like\nsingle treatments and single outcomes. This hinders their use in complex\nreal-world scenarios; for example, consider studying the effect of different\nICU interventions, such as beta-blockers and statins for a patient admitted for\nheart surgery, on different outcomes of interest such as atrial fibrillation\nand in-hospital mortality. The limited research into composite treatments and\noutcomes is primarily due to data scarcity for all treatments and outcomes. To\naddress the above challenges, we propose a novel and innovative\nhypernetwork-based approach, called \\emph{H-Learner}, to solve ITE estimation\nunder composite treatments and composite outcomes, which tackles the data\nscarcity issue by dynamically sharing information across treatments and\noutcomes. Our empirical analysis with binary and arbitrary composite treatments\nand outcomes demonstrates the effectiveness of the proposed approach compared\nto existing methods.",
      "pdf_url": "http://arxiv.org/pdf/2502.08282v1",
      "arxiv_url": "http://arxiv.org/abs/2502.08282v1",
      "published": "2025-02-12",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "ACCESS : A Benchmark for Abstract Causal Event Discovery and Reasoning",
      "authors": [
        "Vy Vo",
        "Lizhen Qu",
        "Tao Feng",
        "Yuncheng Hua",
        "Xiaoxi Kang",
        "Songhai Fan",
        "Tim Dwyer",
        "Lay-Ki Soon",
        "Gholamreza Haffari"
      ],
      "abstract": "Identifying cause-and-effect relationships is critical to understanding\nreal-world dynamics and ultimately causal reasoning. Existing methods for\nidentifying event causality in NLP, including those based on Large Language\nModels (LLMs), exhibit difficulties in out-of-distribution settings due to the\nlimited scale and heavy reliance on lexical cues within available benchmarks.\nModern benchmarks, inspired by probabilistic causal inference, have attempted\nto construct causal graphs of events as a robust representation of causal\nknowledge, where \\texttt{CRAB} \\citep{romanou2023crab} is one such recent\nbenchmark along this line. In this paper, we introduce \\texttt{ACCESS}, a\nbenchmark designed for discovery and reasoning over abstract causal events.\nUnlike existing resources, \\texttt{ACCESS} focuses on causality of everyday\nlife events on the abstraction level. We propose a pipeline for identifying\nabstractions for event generalizations from \\texttt{GLUCOSE}\n\\citep{mostafazadeh-etal-2020-glucose}, a large-scale dataset of implicit\ncommonsense causal knowledge, from which we subsequently extract $1,4$K causal\npairs. Our experiments highlight the ongoing challenges of using statistical\nmethods and/or LLMs for automatic abstraction identification and causal\ndiscovery in NLP. Nonetheless, we demonstrate that the abstract causal\nknowledge provided in \\texttt{ACCESS} can be leveraged for enhancing QA\nreasoning performance in LLMs.",
      "pdf_url": "http://arxiv.org/pdf/2502.08148v1",
      "arxiv_url": "http://arxiv.org/abs/2502.08148v1",
      "published": "2025-02-12",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Simulating Longitudinal Data from Marginal Structural Models",
      "authors": [
        "Xi Lin",
        "Daniel de Vassimon Manela",
        "Chase Mathis",
        "Jens Magelund Tarp",
        "Robin J. Evans"
      ],
      "abstract": "Simulating longitudinal data from specified marginal structural models is a\ncrucial but challenging task for evaluating causal inference methods and\ndesigning clinical trials. While data generation typically proceeds in a fully\nconditional manner using structural equations according to a temporal ordering,\nmarginal structural models require capturing causal effects that are marginal\nover time-dependent confounders, making it difficult to align conditional\ndistributions with target marginal quantities. To address this, we propose a\nflexible and efficient algorithm for simulating longitudinal data that adheres\nexactly to a specified marginal structural model. Recognizing the importance of\ntime-to-event outcomes in clinical trials, we extend the method to accommodate\nsurvival models. Compared to existing approaches, our method offers several key\nadvantages: it enables exact simulation from a known causal model rather than\nrelying on approximations; it avoids imposing restrictive assumptions on the\ndata-generating process; and it is efficient as we need only evaluate analytic\nfunctions. This last benefit contrasts with methods that use computationally\nintensive techniques such as Monte Carlo approximations or numerical\nintegration. Through simulation studies replicating realistic scenarios, we\nvalidate the method's accuracy and utility. Our method will allow researchers\nto effectively simulate data with target causal structures for their specific\nscenarios.",
      "pdf_url": "http://arxiv.org/pdf/2502.07991v1",
      "arxiv_url": "http://arxiv.org/abs/2502.07991v1",
      "published": "2025-02-11",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Training Sparse Mixture Of Experts Text Embedding Models",
      "authors": [
        "Zach Nussbaum",
        "Brandon Duderstadt"
      ],
      "abstract": "Transformer-based text embedding models have improved their performance on\nbenchmarks like MIRACL and BEIR by increasing their parameter counts. However,\nthis scaling approach introduces significant deployment challenges, including\nincreased inference latency and memory usage. These challenges are particularly\nsevere in retrieval-augmented generation (RAG) applications, where large\nmodels' increased memory requirements constrain dataset ingestion capacity, and\ntheir higher latency directly impacts query-time performance. While causal\nlanguage models have addressed similar efficiency challenges using Mixture of\nExperts (MoE) architectures, this approach hasn't been successfully adapted to\nthe general text embedding setting. In this paper, we introduce Nomic Embed v2,\nthe first general purpose MoE text embedding model. Our model outperforms\nmodels in the same parameter class on both monolingual and multilingual\nbenchmarks while also maintaining competitive performance with models twice its\nsize. We open-source all code, models, and evaluation data to ensure full\nreproducibility of our training pipeline.",
      "pdf_url": "http://arxiv.org/pdf/2502.07972v1",
      "arxiv_url": "http://arxiv.org/abs/2502.07972v1",
      "published": "2025-02-11",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ]
    },
    {
      "title": "Distributional Instrumental Variable Method",
      "authors": [
        "Anastasiia Holovchak",
        "Sorawit Saengkyongam",
        "Nicolai Meinshausen",
        "Xinwei Shen"
      ],
      "abstract": "The instrumental variable (IV) approach is commonly used to infer causal\neffects in the presence of unmeasured confounding. Conventional IV models\ncommonly make the additive noise assumption, which is hard to ensure in\npractice, but also typically lack flexibility if the causal effects are\ncomplex. Further, the vast majority of the existing methods aims to estimate\nthe mean causal effects only, a few other methods focus on the quantile\neffects. This work aims for estimation of the entire interventional\ndistribution. We propose a novel method called distributional instrumental\nvariables (DIV), which leverages generative modelling in a nonlinear\ninstrumental variable setting. We establish identifiability of the\ninterventional distribution under general assumptions and demonstrate an\n`under-identified' case where DIV can identify the causal effects while\ntwo-step least squares fails to. Our empirical results show that the DIV method\nperforms well for a broad range of simulated data, exhibiting advantages over\nexisting IV approaches in terms of the identifiability and estimation error of\nthe mean or quantile treatment effects. Furthermore, we apply DIV to an\neconomic data set to examine the causal relation between institutional quality\nand economic development and our results that closely align with the original\nstudy. We also apply DIV to a single-cell data set, where we study the\ngeneralizability and stability in predicting gene expression under unseen\ninterventions. The software implementations of DIV are available in R and\nPython.",
      "pdf_url": "http://arxiv.org/pdf/2502.07641v1",
      "arxiv_url": "http://arxiv.org/abs/2502.07641v1",
      "published": "2025-02-11",
      "categories": [
        "stat.ME",
        "stat.ML"
      ]
    },
    {
      "title": "Causal-Informed Contrastive Learning: Towards Bias-Resilient Pre-training under Concept Drift",
      "authors": [
        "Xiaoyu Yang",
        "Jie Lu",
        "En Yu"
      ],
      "abstract": "The evolution of large-scale contrastive pre-training propelled by top-tier\ndatasets has reached a transition point in the scaling law. Consequently,\nsustaining and enhancing a model's pre-training capabilities in drift\nenvironments have surfaced as a notable challenge. In this paper, we initially\nuncover that contrastive pre-training methods are significantly impacted by\nconcept drift wherein distributions change unpredictably, resulting in notable\nbiases in the feature space of the pre-trained model. Empowered by causal\ninference, we construct a structural causal graph to analyze the impact of\nconcept drift to contrastive pre-training systemically, and propose the causal\ninterventional contrastive objective. Upon achieving this, we devise a\nresilient contrastive pre-training approach to accommodate the data stream of\nconcept drift, with simple and scalable implementation. Extensive experiments\non various downstream tasks demonstrate our resilient contrastive pre-training\neffectively mitigates the bias stemming from the concept drift data stream.\nCodes are available at https://anonymous.4open.science/r/ResilientCL/.",
      "pdf_url": "http://arxiv.org/pdf/2502.07620v1",
      "arxiv_url": "http://arxiv.org/abs/2502.07620v1",
      "published": "2025-02-11",
      "categories": [
        "cs.LG",
        "cs.CV"
      ]
    },
    {
      "title": "Distilling heterogeneous treatment effects: Stable subgroup estimation in causal inference",
      "authors": [
        "Melody Huang",
        "Tiffany M. Tang",
        "Ana M. Kenney"
      ],
      "abstract": "Recent methodological developments have introduced new black-box approaches\nto better estimate heterogeneous treatment effects; however, these methods fall\nshort of providing interpretable characterizations of the underlying\nindividuals who may be most at risk or benefit most from receiving the\ntreatment, thereby limiting their practical utility. In this work, we introduce\na novel method, causal distillation trees (CDT), to estimate interpretable\nsubgroups. CDT allows researchers to fit any machine learning model of their\nchoice to estimate the individual-level treatment effect, and then leverages a\nsimple, second-stage tree-based model to \"distill\" the estimated treatment\neffect into meaningful subgroups. As a result, CDT inherits the improvements in\npredictive performance from black-box machine learning models while preserving\nthe interpretability of a simple decision tree. We derive theoretical\nguarantees for the consistency of the estimated subgroups using CDT, and\nintroduce stability-driven diagnostics for researchers to evaluate the quality\nof the estimated subgroups. We illustrate our proposed method on a randomized\ncontrolled trial of antiretroviral treatment for HIV from the AIDS Clinical\nTrials Group Study 175 and show that CDT out-performs state-of-the-art\napproaches in constructing stable, clinically relevant subgroups.",
      "pdf_url": "http://arxiv.org/pdf/2502.07275v1",
      "arxiv_url": "http://arxiv.org/abs/2502.07275v1",
      "published": "2025-02-11",
      "categories": [
        "stat.ME"
      ]
    }
  ]
}