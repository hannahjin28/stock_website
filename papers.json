{
  "last_updated": "2025-04-23T00:51:38.657666",
  "papers": [
    {
      "title": "Causal DAG Summarization (Full Version)",
      "authors": [
        "Anna Zeng",
        "Michael Cafarella",
        "Batya Kenig",
        "Markos Markakis",
        "Brit Youngmann",
        "Babak Salimi"
      ],
      "abstract": "Causal inference aids researchers in discovering cause-and-effect\nrelationships, leading to scientific insights. Accurate causal estimation\nrequires identifying confounding variables to avoid false discoveries. Pearl's\ncausal model uses causal DAGs to identify confounding variables, but incorrect\nDAGs can lead to unreliable causal conclusions. However, for high dimensional\ndata, the causal DAGs are often complex beyond human verifiability. Graph\nsummarization is a logical next step, but current methods for general-purpose\ngraph summarization are inadequate for causal DAG summarization. This paper\naddresses these challenges by proposing a causal graph summarization objective\nthat balances graph simplification for better understanding while retaining\nessential causal information for reliable inference. We develop an efficient\ngreedy algorithm and show that summary causal DAGs can be directly used for\ninference and are more robust to misspecification of assumptions, enhancing\nrobustness for causal inference. Experimenting with six real-life datasets, we\ncompared our algorithm to three existing solutions, showing its effectiveness\nin handling high-dimensional data and its ability to generate summary DAGs that\nensure both reliable causal inference and robustness against misspecifications.",
      "pdf_url": "http://arxiv.org/pdf/2504.14937v1",
      "arxiv_url": "http://arxiv.org/abs/2504.14937v1",
      "published": "2025-04-21",
      "categories": [
        "cs.LG",
        "cs.DB",
        "stat.ME"
      ]
    },
    {
      "title": "Causality for Natural Language Processing",
      "authors": [
        "Zhijing Jin"
      ],
      "abstract": "Causal reasoning is a cornerstone of human intelligence and a critical\ncapability for artificial systems aiming to achieve advanced understanding and\ndecision-making. This thesis delves into various dimensions of causal reasoning\nand understanding in large language models (LLMs). It encompasses a series of\nstudies that explore the causal inference skills of LLMs, the mechanisms behind\ntheir performance, and the implications of causal and anticausal learning for\nnatural language processing (NLP) tasks. Additionally, it investigates the\napplication of causal reasoning in text-based computational social science,\nspecifically focusing on political decision-making and the evaluation of\nscientific impact through citations. Through novel datasets, benchmark tasks,\nand methodological frameworks, this work identifies key challenges and\nopportunities to improve the causal capabilities of LLMs, providing a\ncomprehensive foundation for future research in this evolving field.",
      "pdf_url": "http://arxiv.org/pdf/2504.14530v1",
      "arxiv_url": "http://arxiv.org/abs/2504.14530v1",
      "published": "2025-04-20",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ]
    },
    {
      "title": "Dynamic Regularized CBDT: Variance-Calibrated Causal Boosting for Interpretable Heterogeneous Treatment Effects",
      "authors": [
        "Yichen Liu"
      ],
      "abstract": "Heterogeneous treatment effect estimation in high-stakes applications demands\nmodels that simultaneously optimize precision, interpretability, and\ncalibration. Many existing tree-based causal inference techniques, however,\nexhibit high estimation errors when applied to observational data because they\nstruggle to capture complex interactions among factors and rely on static\nregularization schemes. In this work, we propose Dynamic Regularized Causal\nBoosted Decision Trees (CBDT), a novel framework that integrates variance\nregularization and average treatment effect calibration into the loss function\nof gradient boosted decision trees. Our approach dynamically updates the\nregularization parameters using gradient statistics to better balance the\nbias-variance tradeoff. Extensive experiments on standard benchmark datasets\nand real-world clinical data demonstrate that the proposed method significantly\nimproves estimation accuracy while maintaining reliable coverage of true\ntreatment effects. In an intensive care unit patient triage study, the method\nsuccessfully identified clinically actionable rules and achieved high accuracy\nin treatment effect estimation. The results validate that dynamic\nregularization can effectively tighten error bounds and enhance both predictive\nperformance and model interpretability.",
      "pdf_url": "http://arxiv.org/pdf/2504.13733v1",
      "arxiv_url": "http://arxiv.org/abs/2504.13733v1",
      "published": "2025-04-18",
      "categories": [
        "cs.LG",
        "stat.ML",
        "68T05, 62H12, 90C30",
        "I.2.6; G.3; I.5.1"
      ]
    },
    {
      "title": "Inverse Inference on Cooperative Control of Networked Dynamical Systems",
      "authors": [
        "Yushan Li",
        "Jianping He",
        "Dimos V. Dimarogonas"
      ],
      "abstract": "Recent years have witnessed the rapid advancement of understanding the\ncontrol mechanism of networked dynamical systems (NDSs), which are governed by\ncomponents such as nodal dynamics and topology. This paper reveals that the\ncritical components in continuous-time state feedback cooperative control of\nNDSs can be inferred merely from discrete observations. In particular, we\nadvocate a bi-level inference framework to estimate the global closed-loop\nsystem and extract the components, respectively. The novelty lies in bridging\nthe gap from discrete observations to the continuous-time model and effectively\ndecoupling the concerned components. Specifically, in the first level, we\ndesign a causality-based estimator for the discrete-time closed-loop system\nmatrix, which can achieve asymptotically unbiased performance when the NDS is\nstable. In the second level, we introduce a matrix logarithm based method to\nrecover the continuous-time counterpart matrix, providing new sampling period\nguarantees and establishing the recovery error bound. By utilizing graph\nproperties of the NDS, we develop least square based procedures to decouple the\nconcerned components with up to a scalar ambiguity. Furthermore, we employ\ninverse optimal control techniques to reconstruct the objective function\ndriving the control process, deriving necessary conditions for the solutions.\nNumerical simulations demonstrate the effectiveness of the proposed method.",
      "pdf_url": "http://arxiv.org/pdf/2504.13701v1",
      "arxiv_url": "http://arxiv.org/abs/2504.13701v1",
      "published": "2025-04-18",
      "categories": [
        "eess.SY",
        "cs.MA",
        "cs.SY"
      ]
    },
    {
      "title": "MR-MAGIC: Robust Causal Inference Using Many Weak Genetic Interactions",
      "authors": [
        "Di Zhang",
        "Minhao Yao",
        "Zhonghua Liu",
        "Baoluo Sun"
      ],
      "abstract": "Mendelian randomization (MR) studies commonly use genetic variants as\ninstrumental variables to estimate causal effects of exposures on outcomes.\nHowever, the presence of invalid instruments-even when numerous-can lead to\nbiased causal estimates. We propose a novel identification strategy that\nremains valid even when all candidate instruments are invalid by leveraging\ngenetic interactions that collectively explain substantial exposure variation.\nRecognizing that individual interaction effects may be weak, we develop\nMR-MAGIC (Mendelian Randomization with MAny weak Genetic Interactions for\nCausality), a robust method that simultaneously addresses instrument invalidity\nand improves estimation efficiency. MR-MAGIC provides consistent and\nasymptotically normal estimates under a many-weak-interactions asymptotic\nframework. Comprehensive simulations and applications to UK Biobank data\ndemonstrate that MR-MAGIC outperforms conventional MR methods in practice,\noffering reliable causal inference when standard approaches fail.",
      "pdf_url": "http://arxiv.org/pdf/2504.13565v1",
      "arxiv_url": "http://arxiv.org/abs/2504.13565v1",
      "published": "2025-04-18",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Bayesian Model Averaging in Causal Instrumental Variable Models",
      "authors": [
        "Gregor Steiner",
        "Mark Steel"
      ],
      "abstract": "Instrumental variables are a popular tool to infer causal effects under\nunobserved confounding, but choosing suitable instruments is challenging in\npractice. We propose gIVBMA, a Bayesian model averaging procedure that\naddresses this challenge by averaging across different sets of instrumental\nvariables and covariates in a structural equation model. Our approach extends\nprevious work through a scale-invariant prior structure and accommodates\nnon-Gaussian outcomes and treatments, offering greater flexibility than\nexisting methods. The computational strategy uses conditional Bayes factors to\nupdate models separately for the outcome and treatments. We prove that this\nmodel selection procedure is consistent. By explicitly accounting for model\nuncertainty, gIVBMA allows instruments and covariates to switch roles and\nprovides robustness against invalid instruments. In simulation experiments,\ngIVBMA outperforms current state-of-the-art methods. We demonstrate its\nusefulness in two empirical applications: the effects of malaria and\ninstitutions on income per capita and the returns to schooling. A software\nimplementation of gIVBMA is available in Julia.",
      "pdf_url": "http://arxiv.org/pdf/2504.13520v1",
      "arxiv_url": "http://arxiv.org/abs/2504.13520v1",
      "published": "2025-04-18",
      "categories": [
        "stat.ME",
        "econ.EM",
        "math.ST",
        "stat.TH"
      ]
    },
    {
      "title": "Eco-efficiency as a Catalyst for Citizen Co-production: Evidence from Chinese Cities",
      "authors": [
        "Ruiyu Zhang",
        "Lin Nie",
        "Ce Zhao",
        "Xin Zhao"
      ],
      "abstract": "We examine whether higher eco-efficiency encourages local governments to\nco-produce environmental solutions with citizens. Using Chinese provincial data\nand advanced textual analysis, we find that high eco-efficiency strongly\npredicts more collaborative responses to environmental complaints. Causal\ninference suggests that crossing a threshold of eco-efficiency increases\nco-production probabilities by about 24 percentage points, indicating\neco-efficiency's potential as a catalyst for participatory environmental\ngovernance.",
      "pdf_url": "http://arxiv.org/pdf/2504.13290v1",
      "arxiv_url": "http://arxiv.org/abs/2504.13290v1",
      "published": "2025-04-17",
      "categories": [
        "econ.GN",
        "q-fin.EC"
      ]
    },
    {
      "title": "Causal-Copilot: An Autonomous Causal Analysis Agent",
      "authors": [
        "Xinyue Wang",
        "Kun Zhou",
        "Wenyi Wu",
        "Har Simrat Singh",
        "Fang Nan",
        "Songyao Jin",
        "Aryan Philip",
        "Saloni Patnaik",
        "Hou Zhu",
        "Shivam Singh",
        "Parjanya Prashant",
        "Qian Shen",
        "Biwei Huang"
      ],
      "abstract": "Causal analysis plays a foundational role in scientific discovery and\nreliable decision-making, yet it remains largely inaccessible to domain experts\ndue to its conceptual and algorithmic complexity. This disconnect between\ncausal methodology and practical usability presents a dual challenge: domain\nexperts are unable to leverage recent advances in causal learning, while causal\nresearchers lack broad, real-world deployment to test and refine their methods.\nTo address this, we introduce Causal-Copilot, an autonomous agent that\noperationalizes expert-level causal analysis within a large language model\nframework. Causal-Copilot automates the full pipeline of causal analysis for\nboth tabular and time-series data -- including causal discovery, causal\ninference, algorithm selection, hyperparameter optimization, result\ninterpretation, and generation of actionable insights. It supports interactive\nrefinement through natural language, lowering the barrier for non-specialists\nwhile preserving methodological rigor. By integrating over 20 state-of-the-art\ncausal analysis techniques, our system fosters a virtuous cycle -- expanding\naccess to advanced causal methods for domain experts while generating rich,\nreal-world applications that inform and advance causal theory. Empirical\nevaluations demonstrate that Causal-Copilot achieves superior performance\ncompared to existing baselines, offering a reliable, scalable, and extensible\nsolution that bridges the gap between theoretical sophistication and real-world\napplicability in causal analysis. A live interactive demo of Causal-Copilot is\navailable at https://causalcopilot.com/.",
      "pdf_url": "http://arxiv.org/pdf/2504.13263v2",
      "arxiv_url": "http://arxiv.org/abs/2504.13263v2",
      "published": "2025-04-17",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Covariate balancing estimation and model selection for difference-in-differences approach",
      "authors": [
        "Takamichi Baba",
        "Yoshiyuki Ninomiya"
      ],
      "abstract": "In causal inference, remarkable progress has been made in\ndifference-in-differences (DID) approaches to estimate the average effect of\ntreatment on the treated (ATT). Of these, the semiparametric DID (SDID)\napproach incorporates a propensity score analysis into the DID setup. Supposing\nthat the ATT is a function of covariates, we estimate it by weighting the\ninverse of the propensity score. As one method to make the estimation robust to\nthe propensity score modeling, we incorporate covariate balancing. Then, by\nattentively constructing the moment conditions used in the covariate balancing,\nwe show that the proposed estimator has doubly robustness. In addition to the\nestimation, model selection is also addressed. In practice, covariate selection\nis an essential task in statistical analysis, but even in the basic setting of\nthe SDID approach, there are no reasonable information criteria. Therefore, we\nderive a model selection criterion as an asymptotically bias-corrected\nestimator of risk based on the loss function used in the SDID estimation. As a\nresult, we show that a penalty term is derived that is considerably different\nfrom almost twice the number of parameters that often appears in AIC-type\ninformation criteria. Numerical experiments show that the proposed method\nestimates the ATT robustly compared to the method using propensity scores given\nby the maximum likelihood estimation (MLE), and that the proposed criterion\nclearly reduces the risk targeted in the SDID approach compared to the\nintuitive generalization of the existing information criterion. In addition,\nreal data analysis confirms that there is a large difference between the\nresults of the proposed method and the existing method.",
      "pdf_url": "http://arxiv.org/pdf/2504.13057v1",
      "arxiv_url": "http://arxiv.org/abs/2504.13057v1",
      "published": "2025-04-17",
      "categories": [
        "stat.ME",
        "62D20"
      ]
    },
    {
      "title": "Information Gain-Guided Causal Intervention for Autonomous Debiasing Large Language Models",
      "authors": [
        "Zhouhao Sun",
        "Xiao Ding",
        "Li Du",
        "Yunpeng Xu",
        "Yixuan Ma",
        "Yang Zhao",
        "Bing Qin",
        "Ting Liu"
      ],
      "abstract": "Despite significant progress, recent studies indicate that current large\nlanguage models (LLMs) may still capture dataset biases and utilize them during\ninference, leading to the poor generalizability of LLMs. However, due to the\ndiversity of dataset biases and the insufficient nature of bias suppression\nbased on in-context learning, the effectiveness of previous prior\nknowledge-based debiasing methods and in-context learning based automatic\ndebiasing methods is limited. To address these challenges, we explore the\ncombination of causal mechanisms with information theory and propose an\ninformation gain-guided causal intervention debiasing (IGCIDB) framework. This\nframework first utilizes an information gain-guided causal intervention method\nto automatically and autonomously balance the distribution of\ninstruction-tuning dataset. Subsequently, it employs a standard supervised\nfine-tuning process to train LLMs on the debiased dataset. Experimental results\nshow that IGCIDB can effectively debias LLM to improve its generalizability\nacross different tasks.",
      "pdf_url": "http://arxiv.org/pdf/2504.12898v1",
      "arxiv_url": "http://arxiv.org/abs/2504.12898v1",
      "published": "2025-04-17",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    }
  ]
}