{
  "last_updated": "2025-08-30T00:47:31.536766",
  "papers": [
    {
      "title": "CogVLA: Cognition-Aligned Vision-Language-Action Model via Instruction-Driven Routing & Sparsification",
      "authors": [
        "Wei Li",
        "Renshan Zhang",
        "Rui Shao",
        "Jie He",
        "Liqiang Nie"
      ],
      "abstract": "Recent Vision-Language-Action (VLA) models built on pre-trained\nVision-Language Models (VLMs) require extensive post-training, resulting in\nhigh computational overhead that limits scalability and deployment.We propose\nCogVLA, a Cognition-Aligned Vision-Language-Action framework that leverages\ninstruction-driven routing and sparsification to improve both efficiency and\nperformance. CogVLA draws inspiration from human multimodal coordination and\nintroduces a 3-stage progressive architecture. 1) Encoder-FiLM based\nAggregation Routing (EFA-Routing) injects instruction information into the\nvision encoder to selectively aggregate and compress dual-stream visual tokens,\nforming a instruction-aware latent representation. 2) Building upon this\ncompact visual encoding, LLM-FiLM based Pruning Routing (LFP-Routing)\nintroduces action intent into the language model by pruning\ninstruction-irrelevant visually grounded tokens, thereby achieving token-level\nsparsity. 3) To ensure that compressed perception inputs can still support\naccurate and coherent action generation, we introduce V-L-A Coupled Attention\n(CAtten), which combines causal vision-language attention with bidirectional\naction parallel decoding. Extensive experiments on the LIBERO benchmark and\nreal-world robotic tasks demonstrate that CogVLA achieves state-of-the-art\nperformance with success rates of 97.4% and 70.0%, respectively, while reducing\ntraining costs by 2.5-fold and decreasing inference latency by 2.8-fold\ncompared to OpenVLA. CogVLA is open-sourced and publicly available at\nhttps://github.com/JiuTian-VL/CogVLA.",
      "pdf_url": "http://arxiv.org/pdf/2508.21046v1",
      "arxiv_url": "http://arxiv.org/abs/2508.21046v1",
      "published": "2025-08-28",
      "categories": [
        "cs.CV",
        "cs.RO"
      ]
    },
    {
      "title": "ChainReaction! Structured Approach with Causal Chains as Intermediate Representations for Improved and Explainable Causal Video Question Answering",
      "authors": [
        "Paritosh Parmar",
        "Eric Peh",
        "Basura Fernando"
      ],
      "abstract": "Existing Causal-Why Video Question Answering (VideoQA) models often struggle\nwith higher-order reasoning, relying on opaque, monolithic pipelines that\nentangle video understanding, causal inference, and answer generation. These\nblack-box approaches offer limited interpretability and tend to depend on\nshallow heuristics. We propose a novel, modular framework that explicitly\ndecouples causal reasoning from answer generation, introducing natural language\ncausal chains as interpretable intermediate representations. Inspired by human\ncognitive models, these structured cause-effect sequences bridge low-level\nvideo content with high-level causal reasoning, enabling transparent and\nlogically coherent inference. Our two-stage architecture comprises a Causal\nChain Extractor (CCE) that generates causal chains from video-question pairs,\nand a Causal Chain-Driven Answerer (CCDA) that produces answers grounded in\nthese chains. To address the lack of annotated reasoning traces, we introduce a\nscalable method for generating high-quality causal chains from existing\ndatasets using large language models. We also propose CauCo, a new evaluation\nmetric for causality-oriented captioning. Experiments on three large-scale\nbenchmarks demonstrate that our approach not only outperforms state-of-the-art\nmodels, but also yields substantial gains in explainability, user trust, and\ngeneralization -- positioning the CCE as a reusable causal reasoning engine\nacross diverse domains. Project page:\nhttps://paritoshparmar.github.io/chainreaction/",
      "pdf_url": "http://arxiv.org/pdf/2508.21010v1",
      "arxiv_url": "http://arxiv.org/abs/2508.21010v1",
      "published": "2025-08-28",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.LG"
      ]
    },
    {
      "title": "When Is Causal Inference Possible? A Statistical Test for Unmeasured Confounding",
      "authors": [
        "Muye Liu",
        "Jun Xie"
      ],
      "abstract": "This paper clarifies a fundamental difference between causal inference and\ntraditional statistical inference by formalizing a mathematical distinction\nbetween their respective parameters. We connect two major approaches to causal\ninference, the potential outcomes framework and causal structure graphs, which\nare typically studied separately. While the unconfoundedness assumption in the\npotential outcomes framework cannot be assessed from an observational dataset\nalone, causal structure graphs help explain when causal effects are\nidentifiable through graphical models. We propose a statistical test to assess\nthe unconfoundedness assumption, equivalent to the absence of unmeasured\nconfounding, by comparing two datasets: a randomized controlled trial and an\nobservational study. The test controls the Type I error probability, and we\nanalyze its power under linear models. Our approach provides a practical method\nto evaluate when real-world data are suitable for causal inference.",
      "pdf_url": "http://arxiv.org/pdf/2508.20366v1",
      "arxiv_url": "http://arxiv.org/abs/2508.20366v1",
      "published": "2025-08-28",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Dynamic Synthetic Controls vs. Panel-Aware Double Machine Learning for Geo-Level Marketing Impact Estimation",
      "authors": [
        "Sang Su Lee",
        "Vineeth Loganathan",
        "Vijay Raghavan"
      ],
      "abstract": "Accurately quantifying geo-level marketing lift in two-sided marketplaces is\nchallenging: the Synthetic Control Method (SCM) often exhibits high power yet\nsystematically under-estimates effect size, while panel-style Double Machine\nLearning (DML) is seldom benchmarked against SCM. We build an open, fully\ndocumented simulator that mimics a typical large-scale geo roll-out: N_unit\nregional markets are tracked for T_pre weeks before launch and for a further\nT_post-week campaign window, allowing all key parameters to be varied by the\nuser and probe both families under five stylized stress tests: 1) curved\nbaseline trends, 2) heterogeneous response lags, 3) treated-biased shocks, 4) a\nnon-linear outcome link, and 5) a drifting control group trend.\n  Seven estimators are evaluated: three standard Augmented SCM (ASC) variants\nand four panel-DML flavors (TWFE, CRE/Mundlak, first-difference, and\nwithin-group). Across 100 replications per scenario, ASC models consistently\ndemonstrate severe bias and near-zero coverage in challenging scenarios\ninvolving nonlinearities or external shocks. By contrast, panel-DML variants\ndramatically reduce this bias and restore nominal 95%-CI coverage, proving far\nmore robust.\n  The results indicate that while ASC provides a simple baseline, it is\nunreliable in common, complex situations. We therefore propose a\n'diagnose-first' framework where practitioners first identify the primary\nbusiness challenge (e.g., nonlinear trends, response lags) and then select the\nspecific DML model best suited for that scenario, providing a more robust and\nreliable blueprint for analyzing geo-experiments.",
      "pdf_url": "http://arxiv.org/pdf/2508.20335v1",
      "arxiv_url": "http://arxiv.org/abs/2508.20335v1",
      "published": "2025-08-28",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "Stochastic Gradients under Nuisances",
      "authors": [
        "Facheng Yu",
        "Ronak Mehta",
        "Alex Luedtke",
        "Zaid Harchaoui"
      ],
      "abstract": "Stochastic gradient optimization is the dominant learning paradigm for a\nvariety of scenarios, from classical supervised learning to modern\nself-supervised learning. We consider stochastic gradient algorithms for\nlearning problems whose objectives rely on unknown nuisance parameters, and\nestablish non-asymptotic convergence guarantees. Our results show that, while\nthe presence of a nuisance can alter the optimum and upset the optimization\ntrajectory, the classical stochastic gradient algorithm may still converge\nunder appropriate conditions, such as Neyman orthogonality. Moreover, even when\nNeyman orthogonality is not satisfied, we show that an algorithm variant with\napproximately orthogonalized updates (with an approximately orthogonalized\ngradient oracle) may achieve similar convergence rates. Examples from\northogonal statistical learning/double machine learning and causal inference\nare discussed.",
      "pdf_url": "http://arxiv.org/pdf/2508.20326v1",
      "arxiv_url": "http://arxiv.org/abs/2508.20326v1",
      "published": "2025-08-28",
      "categories": [
        "stat.ML",
        "cs.LG",
        "math.OC"
      ]
    },
    {
      "title": "Towards Enhancing Data Equity in Public Health Data Science",
      "authors": [
        "Yiran Wang",
        "Alicia E. Boyd",
        "Lillian Rountree",
        "Yi Ren",
        "Kate Nyhan",
        "Ruchit Nagar",
        "Jackson Higginbottom",
        "Megan L. Ranney",
        "Harsh Parikh",
        "Bhramar Mukherjee"
      ],
      "abstract": "Data-driven decisions shape public health policies and practice, yet\npersistent disparities in data representation skew insights and undermine\ninterventions. To address this, we advance a structured roadmap that integrates\npublic health data science with computer science and is grounded in\nreflexivity. We adopt data equity as a guiding concept: ensuring the fair and\ninclusive representation, collection, and use of data to prevent the\nintroduction or exacerbation of systemic biases that could lead to invalid\ndownstream inference and decisions. To underscore urgency, we present three\npublic health cases where non-representative datasets and skewed knowledge\nimpede decisions across diverse subgroups. These challenges echo themes in two\nliteratures: public health highlights gaps in high-quality data for specific\npopulations, while computer science and statistics contribute criteria and\nmetrics for diagnosing bias in data and models. Building on these foundations,\nwe propose a working definition of public health data equity and a structured\nself-audit framework. Our framework integrates core computational principles\n(fairness, accountability, transparency, ethics, privacy, confidentiality) with\nkey public health considerations (selection bias, representativeness,\ngeneralizability, causality, information bias) to guide equitable practice\nacross the data life cycle, from study design and data collection to\nmeasurement, analysis, interpretation, and translation. Embedding data equity\nin routine practice offers a practical path for ensuring that data-driven\npolicies, artificial intelligence, and emerging technologies improve health\noutcomes for all. Finally, we emphasize the critical understanding that,\nalthough data equity is an essential first step, it does not inherently\nguarantee information, learning, or decision equity.",
      "pdf_url": "http://arxiv.org/pdf/2508.20301v1",
      "arxiv_url": "http://arxiv.org/abs/2508.20301v1",
      "published": "2025-08-27",
      "categories": [
        "stat.AP"
      ]
    },
    {
      "title": "Latent Variable Modeling for Robust Causal Effect Estimation",
      "authors": [
        "Tetsuro Morimura",
        "Tatsushi Oka",
        "Yugo Suzuki",
        "Daisuke Moriwaki"
      ],
      "abstract": "Latent variable models provide a powerful framework for incorporating and\ninferring unobserved factors in observational data. In causal inference, they\nhelp account for hidden factors influencing treatment or outcome, thereby\naddressing challenges posed by missing or unmeasured covariates. This paper\nproposes a new framework that integrates latent variable modeling into the\ndouble machine learning (DML) paradigm to enable robust causal effect\nestimation in the presence of such hidden factors. We consider two scenarios:\none where a latent variable affects only the outcome, and another where it may\ninfluence both treatment and outcome. To ensure tractability, we incorporate\nlatent variables only in the second stage of DML, separating representation\nlearning from latent inference. We demonstrate the robustness and effectiveness\nof our method through extensive experiments on both synthetic and real-world\ndatasets.",
      "pdf_url": "http://arxiv.org/pdf/2508.20259v1",
      "arxiv_url": "http://arxiv.org/abs/2508.20259v1",
      "published": "2025-08-27",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "Ego-centric Predictive Model Conditioned on Hand Trajectories",
      "authors": [
        "Binjie Zhang",
        "Mike Zheng Shou"
      ],
      "abstract": "In egocentric scenarios, anticipating both the next action and its visual\noutcome is essential for understanding human-object interactions and for\nenabling robotic planning. However, existing paradigms fall short of jointly\nmodeling these aspects. Vision-Language-Action (VLA) models focus on action\nprediction but lack explicit modeling of how actions influence the visual\nscene, while video prediction models generate future frames without\nconditioning on specific actions, often resulting in implausible or\ncontextually inconsistent outcomes. To bridge this gap, we propose a unified\ntwo-stage predictive framework that jointly models action and visual future in\negocentric scenarios, conditioned on hand trajectories. In the first stage, we\nperform consecutive state modeling to process heterogeneous inputs (visual\nobservations, language, and action history) and explicitly predict future hand\ntrajectories. In the second stage, we introduce causal cross-attention to fuse\nmulti-modal cues, leveraging inferred action signals to guide an image-based\nLatent Diffusion Model (LDM) for frame-by-frame future video generation. Our\napproach is the first unified model designed to handle both egocentric human\nactivity understanding and robotic manipulation tasks, providing explicit\npredictions of both upcoming actions and their visual consequences. Extensive\nexperiments on Ego4D, BridgeData, and RLBench demonstrate that our method\noutperforms state-of-the-art baselines in both action prediction and future\nvideo synthesis.",
      "pdf_url": "http://arxiv.org/pdf/2508.19852v2",
      "arxiv_url": "http://arxiv.org/abs/2508.19852v2",
      "published": "2025-08-27",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "Whom We Trust, What We Fear: COVID-19 Fear and the Politics of Information",
      "authors": [
        "Daniele Baccega",
        "Paolo Castagno",
        "Antonio Fernández Anta",
        "Juan Marcos Ramirez",
        "Matteo Sereno"
      ],
      "abstract": "The COVID-19 pandemic triggered not only a global health crisis but also an\ninfodemic, an overload of information from diverse sources influencing public\nperception and emotional responses. In this context, fear emerged as a central\nemotional reaction, shaped by both media exposure and demographic factors. In\nthis study, we analyzed the relationship between individuals' self-reported\nlevels of fear about COVID-19 and the information sources they rely on, across\nnine source categories, including medical experts, government institutions,\nmedia, and personal networks. In particular, we defined a score that ranks fear\nlevels based on self-reported concerns about the pandemic, collected through\nthe Delphi CTIS survey in the United States between May 2021 and June 2022. We\nfound that both fear levels and information source usage closely follow\nCOVID-19 infection trends, exhibit strong correlations within each group (fear\nlevels across sources are strongly correlated, as are patterns of source\nusage), and vary significantly across demographic groups, particularly by age\nand education. Applying causal inference methods, we showed that the type of\ninformation source significantly affects individuals' fear levels. Furthermore,\nwe demonstrated that information source preferences can reliably match the\npolitical orientation of U.S. states. These findings highlight the importance\nof information ecosystem dynamics in shaping emotional and behavioral responses\nduring large-scale crises.",
      "pdf_url": "http://arxiv.org/pdf/2508.20146v1",
      "arxiv_url": "http://arxiv.org/abs/2508.20146v1",
      "published": "2025-08-27",
      "categories": [
        "cs.SI",
        "cs.CY"
      ]
    },
    {
      "title": "Understanding Spatial Regression Models from a Weighting Perspective in an Observational Study of Superfund Remediation",
      "authors": [
        "Sophie M. Woodward",
        "Francesca Dominici",
        "Jose R. Zubizarreta"
      ],
      "abstract": "Superfund sites are locations in the United States with high levels of\nenvironmental toxicants, often resulting from industrial activity or improper\nwaste management. Given mounting evidence linking prenatal environmental\nexposures to adverse birth outcomes, estimating the impact of Superfund\nremediation is of substantial policy relevance. A widespread approach is to fit\na spatial regression, i.e., a linear regression of the outcome (e.g., birth\nweight) on binary treatment (e.g., indicator for Superfund site remediation)\nand covariates, along with a spatially structured error term to account for\nunmeasured spatial confounding. Despite this common practice, it remains\nunclear to what extent spatial regression models account for unmeasured spatial\nconfounding in finite samples and whether such adjustments can be reformulated\nwithin a design-based framework for causal inference. To fill this knowledge\ngap, we introduce a weighting framework that encompasses three canonical types\nof spatial regression models: random effects, conditional autoregressive, and\nGaussian process models. This framework yields new insights into how spatial\nregression models build causal contrasts between treated and control units.\nSpecifically, we show that: 1) the spatially autocorrelated error term produces\napproximate balance on a hidden set of covariates, thereby adjusting for a\nspecific class of unmeasured confounders; and 2) the error covariance structure\ncan be equivalently expressed as regressors in a linear model. We also\nintroduce a new average treatment effect estimator that simultaneously accounts\nfor multiple forms of unmeasured spatial confounding, as well as diagnostics\nthat enhance interpretability. In a study of Superfund remediation, our\napproach illuminates the role of design-based adjustment for confounding and\nprovides guidance for evaluating environmental interventions in spatial\nsettings.",
      "pdf_url": "http://arxiv.org/pdf/2508.19572v1",
      "arxiv_url": "http://arxiv.org/abs/2508.19572v1",
      "published": "2025-08-27",
      "categories": [
        "stat.ME",
        "stat.AP"
      ]
    }
  ]
}