{
  "last_updated": "2025-03-06T00:47:42.113989",
  "papers": [
    {
      "title": "PanelMatch: Matching Methods for Causal Inference with Time-Series Cross-Section Data",
      "authors": [
        "Adam Rauh",
        "In Song Kim",
        "Kosuke Imai"
      ],
      "abstract": "Analyzing time-series cross-sectional (also known as longitudinal or panel)\ndata is an important process across a number of fields, including the social\nsciences, economics, finance, and medicine. PanelMatch is an R package that\nimplements a set of tools enabling researchers to apply matching methods for\ncausal inference with time-series cross-sectional data. Relative to other\ncommonly used methods for longitudinal analyses, like regression with fixed\neffects, the matching-based approach implemented in PanelMatch makes fewer\nparametric assumptions and offers more diagnostics. In this paper, we discuss\nthe PanelMatch package, showing users a recommended pipeline for doing causal\ninference analysis with it and highlighting useful diagnostic and visualization\ntools.",
      "pdf_url": "http://arxiv.org/pdf/2503.02073v1",
      "arxiv_url": "http://arxiv.org/abs/2503.02073v1",
      "published": "2025-03-03",
      "categories": [
        "stat.ME",
        "stat.AP"
      ]
    },
    {
      "title": "Learning Exposure Mapping Functions for Inferring Heterogeneous Peer Effects",
      "authors": [
        "Shishir Adhikari",
        "Sourav Medya",
        "Elena Zheleva"
      ],
      "abstract": "In causal inference, interference refers to the phenomenon in which the\nactions of peers in a network can influence an individual's outcome. Peer\neffect refers to the difference in counterfactual outcomes of an individual for\ndifferent levels of peer exposure, the extent to which an individual is exposed\nto the treatments, actions, or behaviors of peers. Estimating peer effects\nrequires deciding how to represent peer exposure. Typically, researchers define\nan exposure mapping function that aggregates peer treatments and outputs peer\nexposure. Most existing approaches for defining exposure mapping functions\nassume peer exposure based on the number or fraction of treated peers. Recent\nstudies have investigated more complex functions of peer exposure which capture\nthat different peers can exert different degrees of influence. However, none of\nthese works have explicitly considered the problem of automatically learning\nthe exposure mapping function. In this work, we focus on learning this function\nfor the purpose of estimating heterogeneous peer effects, where heterogeneity\nrefers to the variation in counterfactual outcomes for the same peer exposure\nbut different individual's contexts. We develop EgoNetGNN, a graph neural\nnetwork (GNN)-based method, to automatically learn the appropriate exposure\nmapping function allowing for complex peer influence mechanisms that, in\naddition to peer treatments, can involve the local neighborhood structure and\nedge attributes. We show that GNN models that use peer exposure based on the\nnumber or fraction of treated peers or learn peer exposure naively face\ndifficulty accounting for such influence mechanisms. Our comprehensive\nevaluation on synthetic and semi-synthetic network data shows that our method\nis more robust to different unknown underlying influence mechanisms when\nestimating heterogeneous peer effects when compared to state-of-the-art\nbaselines.",
      "pdf_url": "http://arxiv.org/pdf/2503.01722v1",
      "arxiv_url": "http://arxiv.org/abs/2503.01722v1",
      "published": "2025-03-03",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SI"
      ]
    },
    {
      "title": "ProRCA: A Causal Python Package for Actionable Root Cause Analysis in Real-world Business Scenarios",
      "authors": [
        "Ahmed Dawoud",
        "Shravan Talupula"
      ],
      "abstract": "Root Cause Analysis (RCA) is becoming ever more critical as modern systems\ngrow in complexity, volume of data, and interdependencies. While traditional\nRCA methods frequently rely on correlation-based or rule-based techniques,\nthese approaches can prove inadequate in highly dynamic, multi-layered\nenvironments. In this paper, we present a pathway-tracing package built on the\nDoWhy causal inference library. Our method integrates conditional anomaly\nscoring, noise-based attribution, and depth-first path exploration to reveal\nmulti-hop causal chains. By systematically tracing entire causal pathways from\nan observed anomaly back to the initial triggers, our approach provides a\ncomprehensive, end-to-end RCA solution. Experimental evaluations with synthetic\nanomaly injections demonstrate the package's ability to accurately isolate\ntriggers and rank root causes by their overall significance.",
      "pdf_url": "http://arxiv.org/pdf/2503.01475v1",
      "arxiv_url": "http://arxiv.org/abs/2503.01475v1",
      "published": "2025-03-03",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Causal Tree Extraction from Medical Case Reports: A Novel Task for Experts-like Text Comprehension",
      "authors": [
        "Sakiko Yahata",
        "Zhen Wan",
        "Fei Cheng",
        "Sadao Kurohashi",
        "Hisahiko Sato",
        "Ryozo Nagai"
      ],
      "abstract": "Extracting causal relationships from a medical case report is essential for\ncomprehending the case, particularly its diagnostic process. Since the\ndiagnostic process is regarded as a bottom-up inference, causal relationships\nin cases naturally form a multi-layered tree structure. The existing tasks,\nsuch as medical relation extraction, are insufficient for capturing the causal\nrelationships of an entire case, as they treat all relations equally without\nconsidering the hierarchical structure inherent in the diagnostic process.\nThus, we propose a novel task, Causal Tree Extraction (CTE), which receives a\ncase report and generates a causal tree with the primary disease as the root,\nproviding an intuitive understanding of a case's diagnostic process.\nSubsequently, we construct a Japanese case report CTE dataset, J-Casemap,\npropose a generation-based CTE method that outperforms the baseline by 20.2\npoints in the human evaluation, and introduce evaluation metrics that reflect\nclinician preferences. Further experiments also show that J-Casemap enhances\nthe performance of solving other medical tasks, such as question answering.",
      "pdf_url": "http://arxiv.org/pdf/2503.01302v1",
      "arxiv_url": "http://arxiv.org/abs/2503.01302v1",
      "published": "2025-03-03",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "title": "ACTIVA: Amortized Causal Effect Estimation without Graphs via Transformer-based Variational Autoencoder",
      "authors": [
        "Andreas Sauter",
        "Saber Salehkaleybar",
        "Aske Plaat",
        "Erman Acar"
      ],
      "abstract": "Predicting the distribution of outcomes under hypothetical interventions is\ncrucial in domains like healthcare, economics, and policy-making. Current\nmethods often rely on strong assumptions, such as known causal graphs or\nparametric models, and lack amortization across problem instances, limiting\ntheir practicality. We propose a novel transformer-based conditional\nvariational autoencoder architecture, named ACTIVA, that extends causal\ntransformer encoders to predict causal effects as mixtures of Gaussians. Our\nmethod requires no causal graph and predicts interventional distributions given\nonly observational data and a queried intervention. By amortizing over many\nsimulated instances, it enables zero-shot generalization to novel datasets\nwithout retraining. Experiments demonstrate accurate predictions for synthetic\nand semi-synthetic data, showcasing the effectiveness of our graph-free,\namortized causal inference approach.",
      "pdf_url": "http://arxiv.org/pdf/2503.01290v1",
      "arxiv_url": "http://arxiv.org/abs/2503.01290v1",
      "published": "2025-03-03",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Architectural and Inferential Inductive Biases For Exchangeable Sequence Modeling",
      "authors": [
        "Daksh Mittal",
        "Ang Li",
        "Tzu-Ching Yen",
        "Daniel Guetta",
        "Hongseok Namkoong"
      ],
      "abstract": "Autoregressive models have emerged as a powerful framework for modeling\nexchangeable sequences - i.i.d. observations when conditioned on some latent\nfactor - enabling direct modeling of uncertainty from missing data (rather than\na latent). Motivated by the critical role posterior inference plays as a\nsubroutine in decision-making (e.g., active learning, bandits), we study the\ninferential and architectural inductive biases that are most effective for\nexchangeable sequence modeling. For the inference stage, we highlight a\nfundamental limitation of the prevalent single-step generation approach:\ninability to distinguish between epistemic and aleatoric uncertainty. Instead,\na long line of works in Bayesian statistics advocates for multi-step\nautoregressive generation; we demonstrate this \"correct approach\" enables\nsuperior uncertainty quantification that translates into better performance on\ndownstream decision-making tasks. This naturally leads to the next question:\nwhich architectures are best suited for multi-step inference? We identify a\nsubtle yet important gap between recently proposed Transformer architectures\nfor exchangeable sequences (Muller et al., 2022; Nguyen & Grover, 2022; Ye &\nNamkoong, 2024), and prove that they in fact cannot guarantee exchangeability\ndespite introducing significant computational overhead. We illustrate our\nfindings using controlled synthetic settings, demonstrating how custom\narchitectures can significantly underperform standard causal masks,\nunderscoring the need for new architectural innovations.",
      "pdf_url": "http://arxiv.org/pdf/2503.01215v1",
      "arxiv_url": "http://arxiv.org/abs/2503.01215v1",
      "published": "2025-03-03",
      "categories": [
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "title": "Time-Varying Causal Survival Learning",
      "authors": [
        "Xiang Meng",
        "Iavor Bojinov"
      ],
      "abstract": "This work bridges the gap between staggered adoption designs and survival\nanalysis to estimate causal effects in settings with time-varying treatments,\naddressing a fundamental challenge in medical research exemplified by the\nStanford Heart Transplant study. In medical interventions, particularly organ\ntransplantation, the timing of treatment varies significantly across patients\ndue to factors such as donor availability and patient readiness, introducing\npotential bias in treatment effect estimation if not properly accounted for. We\nidentify conditions under which staggered adoption assumptions can justify the\nuse of survival analysis techniques for causal inference with time-varying\ntreatments. By establishing this connection, we enable the use of existing\nsurvival analysis methods while maintaining causal interpretability.\nFurthermore, we enhance estimation performance by incorporating double machine\nlearning methods, improving efficiency when handling complex relationships\nbetween patient characteristics and survival outcomes. Through both simulation\nstudies and application to heart transplant data, our approach demonstrates\nsuperior performance compared to traditional methods, reducing bias and\noffering theoretical guarantees for improved efficiency in survival analysis\nsettings.",
      "pdf_url": "http://arxiv.org/pdf/2503.00730v1",
      "arxiv_url": "http://arxiv.org/abs/2503.00730v1",
      "published": "2025-03-02",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Causal Inference on Outcomes Learned from Text",
      "authors": [
        "Iman Modarressi",
        "Jann Spiess",
        "Amar Venugopal"
      ],
      "abstract": "We propose a machine-learning tool that yields causal inference on text in\nrandomized trials. Based on a simple econometric framework in which text may\ncapture outcomes of interest, our procedure addresses three questions: First,\nis the text affected by the treatment? Second, which outcomes is the effect on?\nAnd third, how complete is our description of causal effects? To answer all\nthree questions, our approach uses large language models (LLMs) that suggest\nsystematic differences across two groups of text documents and then provides\nvalid inference based on costly validation. Specifically, we highlight the need\nfor sample splitting to allow for statistical validation of LLM outputs, as\nwell as the need for human labeling to validate substantive claims about how\ndocuments differ across groups. We illustrate the tool in a proof-of-concept\napplication using abstracts of academic manuscripts.",
      "pdf_url": "http://arxiv.org/pdf/2503.00725v1",
      "arxiv_url": "http://arxiv.org/abs/2503.00725v1",
      "published": "2025-03-02",
      "categories": [
        "econ.EM",
        "cs.CL",
        "cs.LG",
        "stat.ME"
      ]
    },
    {
      "title": "Learning Conditional Average Treatment Effects in Regression Discontinuity Designs using Bayesian Additive Regression Trees",
      "authors": [
        "Rafael Alcantara",
        "P. Richard Hahn",
        "Carlos Carvalho",
        "Hedibert Lopes"
      ],
      "abstract": "BART (Bayesian additive regression trees) has been established as a leading\nsupervised learning method, particularly in the field of causal inference. This\npaper explores the use of BART models for learning conditional average\ntreatment effects (CATE) from regression discontinuity designs, where treatment\nassignment is based on whether an observed covariate (called the running\nvariable) exceeds a pre-specified threshold. A purpose-built version of BART\nthat uses linear regression leaf models (of the running variable and treatment\nassignment dummy) is shown to out-perform off-the-shelf BART implementations as\nwell as a local polynomial regression approach and a CART-based approach. The\nnew method is evaluated in thorough simulation studies as well as an empirical\napplication looking at the effect of academic probation on student performance.",
      "pdf_url": "http://arxiv.org/pdf/2503.00326v1",
      "arxiv_url": "http://arxiv.org/abs/2503.00326v1",
      "published": "2025-03-01",
      "categories": [
        "stat.ME",
        "stat.ML"
      ]
    },
    {
      "title": "Persuasion Should be Double-Blind: A Multi-Domain Dialogue Dataset With Faithfulness Based on Causal Theory of Mind",
      "authors": [
        "Dingyi Zhang",
        "Deyu Zhou"
      ],
      "abstract": "Persuasive dialogue plays a pivotal role in human communication, influencing\nvarious domains. Recent persuasive dialogue datasets often fail to align with\nreal-world interpersonal interactions, leading to unfaithful representations.\nFor instance, unrealistic scenarios may arise, such as when the persuadee\nexplicitly instructs the persuader on which persuasion strategies to employ,\nwith each of the persuadee's questions corresponding to a specific strategy for\nthe persuader to follow. This issue can be attributed to a violation of the\n\"Double Blind\" condition, where critical information is fully shared between\nparticipants. In actual human interactions, however, key information such as\nthe mental state of the persuadee and the persuasion strategies of the\npersuader is not directly accessible. The persuader must infer the persuadee's\nmental state using Theory of Mind capabilities and construct arguments that\nalign with the persuadee's motivations. To address this gap, we introduce\nToMMA, a novel multi-agent framework for dialogue generation that is guided by\ncausal Theory of Mind. This framework ensures that information remains\nundisclosed between agents, preserving \"double-blind\" conditions, while causal\nToM directs the persuader's reasoning, enhancing alignment with human-like\npersuasion dynamics. Consequently, we present CToMPersu, a multi-domain,\nmulti-turn persuasive dialogue dataset that tackles both double-blind and\nlogical coherence issues, demonstrating superior performance across multiple\nmetrics and achieving better alignment with real human dialogues. Our dataset\nand prompts are available at https://github.com/DingyiZhang/ToMMA-CToMPersu .",
      "pdf_url": "http://arxiv.org/pdf/2502.21297v1",
      "arxiv_url": "http://arxiv.org/abs/2502.21297v1",
      "published": "2025-02-28",
      "categories": [
        "cs.CL"
      ]
    }
  ]
}