{
  "last_updated": "2025-08-15T00:56:29.789602",
  "papers": [
    {
      "title": "Embodied Tactile Perception of Soft Objects Properties",
      "authors": [
        "Anirvan Dutta",
        "Alexis WM Devillard",
        "Zhihuan Zhang",
        "Xiaoxiao Cheng",
        "Etienne Burdet"
      ],
      "abstract": "To enable robots to develop human-like fine manipulation, it is essential to\nunderstand how mechanical compliance, multi-modal sensing, and purposeful\ninteraction jointly shape tactile perception. In this study, we use a dedicated\nmodular e-Skin with tunable mechanical compliance and multi-modal sensing\n(normal, shear forces and vibrations) to systematically investigate how sensing\nembodiment and interaction strategies influence robotic perception of objects.\nLeveraging a curated set of soft wave objects with controlled viscoelastic and\nsurface properties, we explore a rich set of palpation primitives-pressing,\nprecession, sliding that vary indentation depth, frequency, and directionality.\nIn addition, we propose the latent filter, an unsupervised, action-conditioned\ndeep state-space model of the sophisticated interaction dynamics and infer\ncausal mechanical properties into a structured latent space. This provides\ngeneralizable and in-depth interpretable representation of how embodiment and\ninteraction determine and influence perception. Our investigation demonstrates\nthat multi-modal sensing outperforms uni-modal sensing. It highlights a nuanced\ninteraction between the environment and mechanical properties of e-Skin, which\nshould be examined alongside the interaction by incorporating temporal\ndynamics.",
      "pdf_url": "http://arxiv.org/pdf/2508.09836v1",
      "arxiv_url": "http://arxiv.org/abs/2508.09836v1",
      "published": "2025-08-13",
      "categories": [
        "cs.RO"
      ]
    },
    {
      "title": "Structured Kernel Regression VAE: A Computationally Efficient Surrogate for GP-VAEs in ICA",
      "authors": [
        "Yuan-Hao Wei",
        "Fu-Hao Deng",
        "Lin-Yong Cui",
        "Yan-Jie Sun"
      ],
      "abstract": "The interpretability of generative models is considered a key factor in\ndemonstrating their effectiveness and controllability. The generated data are\nbelieved to be determined by latent variables that are not directly observable.\nTherefore, disentangling, decoupling, decomposing, causal inference, or\nperforming Independent Component Analysis (ICA) in the latent variable space\nhelps uncover the independent factors that influence the attributes or features\naffecting the generated outputs, thereby enhancing the interpretability of\ngenerative models. As a generative model, Variational Autoencoders (VAEs)\ncombine with variational Bayesian inference algorithms. Using VAEs, the inverse\nprocess of ICA can be equivalently framed as a variational inference process.\nIn some studies, Gaussian processes (GPs) have been introduced as priors for\neach dimension of latent variables in VAEs, structuring and separating each\ndimension from temporal or spatial perspectives, and encouraging different\ndimensions to control various attributes of the generated data. However, GPs\nimpose a significant computational burden, resulting in substantial resource\nconsumption when handling large datasets. Essentially, GPs model different\ntemporal or spatial structures through various kernel functions. Structuring\nthe priors of latent variables via kernel functions-so that different kernel\nfunctions model the correlations among sequence points within different latent\ndimensions-is at the core of achieving disentanglement in VAEs. The proposed\nStructured Kernel Regression VAE (SKR-VAE) leverages this core idea in a more\nefficient way, avoiding the costly kernel matrix inversion required in GPs.\nThis research demonstrates that, while maintaining ICA performance, SKR-VAE\nachieves greater computational efficiency and significantly reduced\ncomputational burden compared to GP-VAE.",
      "pdf_url": "http://arxiv.org/pdf/2508.09721v1",
      "arxiv_url": "http://arxiv.org/abs/2508.09721v1",
      "published": "2025-08-13",
      "categories": [
        "stat.ML",
        "cs.LG"
      ]
    },
    {
      "title": "TimeMKG: Knowledge-Infused Causal Reasoning for Multivariate Time Series Modeling",
      "authors": [
        "Yifei Sun",
        "Junming Liu",
        "Ding Wang",
        "Yirong Chen",
        "Xuefeng Yan"
      ],
      "abstract": "Multivariate time series data typically comprises two distinct modalities:\nvariable semantics and sampled numerical observations. Traditional time series\nmodels treat variables as anonymous statistical signals, overlooking the rich\nsemantic information embedded in variable names and data descriptions. However,\nthese textual descriptors often encode critical domain knowledge that is\nessential for robust and interpretable modeling. Here we present TimeMKG, a\nmultimodal causal reasoning framework that elevates time series modeling from\nlow-level signal processing to knowledge informed inference. TimeMKG employs\nlarge language models to interpret variable semantics and constructs structured\nMultivariate Knowledge Graphs that capture inter-variable relationships. A\ndual-modality encoder separately models the semantic prompts, generated from\nknowledge graph triplets, and the statistical patterns from historical time\nseries. Cross-modality attention aligns and fuses these representations at the\nvariable level, injecting causal priors into downstream tasks such as\nforecasting and classification, providing explicit and interpretable priors to\nguide model reasoning. The experiment in diverse datasets demonstrates that\nincorporating variable-level knowledge significantly improves both predictive\nperformance and generalization.",
      "pdf_url": "http://arxiv.org/pdf/2508.09630v1",
      "arxiv_url": "http://arxiv.org/abs/2508.09630v1",
      "published": "2025-08-13",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Goal Discovery with Causal Capacity for Efficient Reinforcement Learning",
      "authors": [
        "Yan Yu",
        "Yaodong Yang",
        "Zhengbo Lu",
        "Chengdong Ma",
        "Wengang Zhou",
        "Houqiang Li"
      ],
      "abstract": "Causal inference is crucial for humans to explore the world, which can be\nmodeled to enable an agent to efficiently explore the environment in\nreinforcement learning. Existing research indicates that establishing the\ncausality between action and state transition will enhance an agent to reason\nhow a policy affects its future trajectory, thereby promoting directed\nexploration. However, it is challenging to measure the causality due to its\nintractability in the vast state-action space of complex scenarios. In this\npaper, we propose a novel Goal Discovery with Causal Capacity (GDCC) framework\nfor efficient environment exploration. Specifically, we first derive a\nmeasurement of causality in state space, \\emph{i.e.,} causal capacity, which\nrepresents the highest influence of an agent's behavior on future trajectories.\nAfter that, we present a Monte Carlo based method to identify critical points\nin discrete state space and further optimize this method for continuous\nhigh-dimensional environments. Those critical points are used to uncover where\nthe agent makes important decisions in the environment, which are then regarded\nas our subgoals to guide the agent to make exploration more purposefully and\nefficiently. Empirical results from multi-objective tasks demonstrate that\nstates with high causal capacity align with our expected subgoals, and our GDCC\nachieves significant success rate improvements compared to baselines.",
      "pdf_url": "http://arxiv.org/pdf/2508.09624v1",
      "arxiv_url": "http://arxiv.org/abs/2508.09624v1",
      "published": "2025-08-13",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Over-Squashing in GNNs and Causal Inference of Rewiring Strategies",
      "authors": [
        "Danial Saber",
        "Amirali Salehi-Abari"
      ],
      "abstract": "Graph neural networks (GNNs) have exhibited state-of-the-art performance\nacross wide-range of domains such as recommender systems, material design, and\ndrug repurposing. Yet message-passing GNNs suffer from over-squashing --\nexponential compression of long-range information from distant nodes -- which\nlimits expressivity. Rewiring techniques can ease this bottleneck; but their\npractical impacts are unclear due to the lack of a direct empirical\nover-squashing metric. We propose a rigorous, topology-focused method for\nassessing over-squashing between node pairs using the decay rate of their\nmutual sensitivity. We then extend these pairwise assessments to four\ngraph-level statistics (prevalence, intensity, variability, extremity).\nCoupling these metrics with a within-graph causal design, we quantify how\nrewiring strategies affect over-squashing on diverse graph- and\nnode-classification benchmarks. Our extensive empirical analyses show that most\ngraph classification datasets suffer from over-squashing (but to various\nextents), and rewiring effectively mitigates it -- though the degree of\nmitigation, and its translation into performance gains, varies by dataset and\nmethod. We also found that over-squashing is less notable in node\nclassification datasets, where rewiring often increases over-squashing, and\nperformance variations are uncorrelated with over-squashing changes. These\nfindings suggest that rewiring is most beneficial when over-squashing is both\nsubstantial and corrected with restraint -- while overly aggressive rewiring,\nor rewiring applied to minimally over-squashed graphs, is unlikely to help and\nmay even harm performance. Our plug-and-play diagnostic tool lets practitioners\ndecide -- before any training -- whether rewiring is likely to pay off.",
      "pdf_url": "http://arxiv.org/pdf/2508.09265v1",
      "arxiv_url": "http://arxiv.org/abs/2508.09265v1",
      "published": "2025-08-12",
      "categories": [
        "cs.LG",
        "stat.ME"
      ]
    },
    {
      "title": "Efficient Statistical Estimation for Sequential Adaptive Experiments with Implications for Adaptive Designs",
      "authors": [
        "Wenxin Zhang",
        "Mark van der Laan"
      ],
      "abstract": "Adaptive experimental designs have gained popularity in clinical trials and\nonline experiments. Unlike traditional, fixed experimental designs, adaptive\ndesigns can dynamically adjust treatment randomization probabilities and other\ndesign features in response to data accumulated sequentially during the\nexperiment. These adaptations are useful to achieve diverse objectives,\nincluding reducing uncertainty in the estimation of causal estimands or\nincreasing participants' chances of receiving better treatments during the\nexperiment. At the end of the experiment, it is often desirable to answer\ncausal questions from the observed data. However, the adaptive nature of such\nexperiments and the resulting dependence among observations pose significant\nchallenges to providing valid statistical inference and efficient estimation of\ncausal estimands. Building upon the Targeted Maximum Likelihood Estimator\n(TMLE) framework tailored for adaptive designs (van der Laan, 2008), we\nintroduce a new adaptive-design-likelihood-based TMLE (ADL-TMLE) to estimate a\nvariety of causal estimands from adaptive experiment data. We establish\nasymptotic normality and semiparametric efficiency of ADL-TMLE under relaxed\npositivity and design stabilization assumptions for adaptive experiments.\nMotivated by efficiency results, we further propose a novel adaptive design\naimed at minimizing the variance of estimators based on data generated under\nthat design. Using the average treatment effect as a representative example,\nsimulation studies show that ADL-TMLE demonstrates superior variance-reduction\nperformance across different types of adaptive experiments, and that the\nproposed adaptive design attains lower variance than the standard\nefficiency-oriented adaptive design. Finally, we generalize this estimation and\ndesign framework to broader settings with longitudinal structures.",
      "pdf_url": "http://arxiv.org/pdf/2508.09135v1",
      "arxiv_url": "http://arxiv.org/abs/2508.09135v1",
      "published": "2025-08-12",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Link Prediction for Event Logs in the Process Industry",
      "authors": [
        "Anastasia Zhukova",
        "Thomas Walton",
        "Christian E. Matt",
        "Bela Gipp"
      ],
      "abstract": "Knowledge management (KM) is vital in the process industry for optimizing\noperations, ensuring safety, and enabling continuous improvement through\neffective use of operational data and past insights. A key challenge in this\ndomain is the fragmented nature of event logs in shift books, where related\nrecords, e.g., entries documenting issues related to equipment or processes and\nthe corresponding solutions, may remain disconnected. This fragmentation\nhinders the recommendation of previous solutions to the users. To address this\nproblem, we investigate record linking (RL) as link prediction, commonly\nstudied in graph-based machine learning, by framing it as a cross-document\ncoreference resolution (CDCR) task enhanced with natural language inference\n(NLI) and semantic text similarity (STS) by shifting it into the causal\ninference (CI). We adapt CDCR, traditionally applied in the news domain, into\nan RL model to operate at the passage level, similar to NLI and STS, while\naccommodating the process industry's specific text formats, which contain\nunstructured text and structured record attributes. Our RL model outperformed\nthe best versions of NLI- and STS-driven baselines by 28% (11.43 points) and\n27% (11.21 points), respectively. Our work demonstrates how domain adaptation\nof the state-of-the-art CDCR models, enhanced with reasoning capabilities, can\nbe effectively tailored to the process industry, improving data quality and\nconnectivity in shift logs.",
      "pdf_url": "http://arxiv.org/pdf/2508.09096v1",
      "arxiv_url": "http://arxiv.org/abs/2508.09096v1",
      "published": "2025-08-12",
      "categories": [
        "cs.CL",
        "cs.IR"
      ]
    },
    {
      "title": "Nonparametric Bayesian Multi-Treatment Mixture Cure Survival Model with Application in Pediatric Oncology",
      "authors": [
        "Peter Chang",
        "John Kairalla",
        "Arkaprava Roy"
      ],
      "abstract": "Heterogeneous treatment effect estimation is critical in oncology,\nparticularly in multi-arm trials with overlapping therapeutic components and\nlong-term survivors. These shared mechanisms pose a central challenge to\nidentifying causal effects in precision medicine. We propose a novel\ncovariate-dependent nonparametric Bayesian multi-treatment cure survival model\nthat jointly accounts for common structures among treatments and cure\nfractions. Through latent link functions, our model leverages sharing among\ntreatments through a flexible modeling approach, enabling individualized\nsurvival inference. We adopt a Bayesian route for inference and implement an\nefficient MCMC algorithm for approximating the posterior. Simulation studies\ndemonstrate the method's robustness and superiority in various specification\nscenarios. Finally, application to the AALL0434 trial reveals clinically\nmeaningful differences in survival across methotrexate-based regimens and their\nassociations with different covariates, underscoring its practical utility for\nlearning treatment effects in real-world pediatric oncology data.",
      "pdf_url": "http://arxiv.org/pdf/2508.08975v3",
      "arxiv_url": "http://arxiv.org/abs/2508.08975v3",
      "published": "2025-08-12",
      "categories": [
        "stat.ME",
        "stat.AP"
      ]
    },
    {
      "title": "Position: Causal Machine Learning Requires Rigorous Synthetic Experiments for Broader Adoption",
      "authors": [
        "Audrey Poinsot",
        "Panayiotis Panayiotou",
        "Alessandro Leite",
        "Nicolas Chesneau",
        "Özgür Şimşek",
        "Marc Schoenauer"
      ],
      "abstract": "Causal machine learning has the potential to revolutionize decision-making by\ncombining the predictive power of machine learning algorithms with the theory\nof causal inference. However, these methods remain underutilized by the broader\nmachine learning community, in part because current empirical evaluations do\nnot permit assessment of their reliability and robustness, undermining their\npractical utility. Specifically, one of the principal criticisms made by the\ncommunity is the extensive use of synthetic experiments. We argue, on the\ncontrary, that synthetic experiments are essential and necessary to precisely\nassess and understand the capabilities of causal machine learning methods. To\nsubstantiate our position, we critically review the current evaluation\npractices, spotlight their shortcomings, and propose a set of principles for\nconducting rigorous empirical analyses with synthetic data. Adopting the\nproposed principles will enable comprehensive evaluations that build trust in\ncausal machine learning methods, driving their broader adoption and impactful\nreal-world use.",
      "pdf_url": "http://arxiv.org/pdf/2508.08883v1",
      "arxiv_url": "http://arxiv.org/abs/2508.08883v1",
      "published": "2025-08-12",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME",
        "stat.ML"
      ]
    },
    {
      "title": "TiMoE: Time-Aware Mixture of Language Experts",
      "authors": [
        "Robin Faro",
        "Dongyang Fan",
        "Tamar Alphaidze",
        "Martin Jaggi"
      ],
      "abstract": "Large language models (LLMs) are typically trained on fixed snapshots of the\nweb, which means that their knowledge becomes stale and their predictions risk\ntemporal leakage: relying on information that lies in the future relative to a\nquery. We tackle this problem by pre-training from scratch a set of GPT-style\nexperts on disjoint two-year slices of a 2013-2024 corpus and combining them\nthrough TiMoE, a Time-aware Mixture of Language Experts. At inference time,\nTiMoE masks all experts whose training window ends after the query timestamp\nand merges the remaining log-probabilities in a shared space, guaranteeing\nstrict causal validity while retaining the breadth of multi-period knowledge.\nWe also release TSQA, a 10k-question benchmark whose alternatives are\nexplicitly labelled as past, future or irrelevant, allowing fine-grained\nmeasurement of temporal hallucinations. Experiments on eight standard NLP tasks\nplus TSQA show that a co-adapted TiMoE variant matches or exceeds the best\nsingle-period expert and cuts future-knowledge errors by up to 15%. Our results\ndemonstrate that modular, time-segmented pre-training paired with causal\nrouting is a simple yet effective path toward LLMs that stay chronologically\ngrounded without sacrificing general performance much. We open source our code\nat TiMoE (Github): https://github.com/epfml/TiMoE",
      "pdf_url": "http://arxiv.org/pdf/2508.08827v1",
      "arxiv_url": "http://arxiv.org/abs/2508.08827v1",
      "published": "2025-08-12",
      "categories": [
        "cs.CL"
      ]
    }
  ]
}