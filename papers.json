{
  "last_updated": "2026-01-30T01:08:14.191413",
  "papers": [
    {
      "title": "Causal Inference in Biomedical Imaging via Functional Linear Structural Equation Models",
      "authors": [
        "Ting Li",
        "Ethan Fan",
        "Tengfei Li",
        "Hongtu Zhu"
      ],
      "abstract": "Understanding the causal effects of organ-specific features from medical imaging on clinical outcomes is essential for biomedical research and patient care. We propose a novel Functional Linear Structural Equation Model (FLSEM) to capture the relationships among clinical outcomes, functional imaging exposures, and scalar covariates like genetics, sex, and age. Traditional methods struggle with the infinite-dimensional nature of exposures and complex covariates. Our FLSEM overcomes these challenges by establishing identifiable conditions using scalar instrumental variables. We develop the Functional Group Support Detection and Root Finding (FGS-DAR) algorithm for efficient variable selection, supported by rigorous theoretical guarantees, including selection consistency and accurate parameter estimation. We further propose a test statistic to test the nullity of the functional coefficient, establishing its null limit distribution. Our approach is validated through extensive simulations and applied to UK Biobank data, demonstrating robust performance in detecting causal relationships from medical imaging.",
      "pdf_url": "https://arxiv.org/pdf/2601.20610v1",
      "arxiv_url": "http://arxiv.org/abs/2601.20610v1",
      "published": "2026-01-28",
      "categories": [
        "stat.ME",
        "math.ST"
      ]
    },
    {
      "title": "Exact Graph Learning via Integer Programming",
      "authors": [
        "Lucas Kook",
        "Søren Wengel Mogensen"
      ],
      "abstract": "Learning the dependence structure among variables in complex systems is a central problem across medical, natural, and social sciences. These structures can be naturally represented by graphs, and the task of inferring such graphs from data is known as graph learning or as causal discovery if the graphs are given a causal interpretation. Existing approaches typically rely on restrictive assumptions about the data-generating process, employ greedy oracle algorithms, or solve approximate formulations of the graph learning problem. As a result, they are either sensitive to violations of central assumptions or fail to guarantee globally optimal solutions. We address these limitations by introducing a nonparametric graph learning framework based on nonparametric conditional independence testing and integer programming. We reformulate the graph learning problem as an integer-programming problem and prove that solving the integer-programming problem provides a globally optimal solution to the original graph learning problem. Our method leverages efficient encodings of graphical separation criteria, enabling the exact recovery of larger graphs than was previously feasible. We provide an implementation in the openly available R package 'glip' which supports learning (acyclic) directed (mixed) graphs and chain graphs. From the resulting output one can compute representations of the corresponding Markov equivalence classes or weak equivalence classes. Empirically, we demonstrate that our approach is faster than other existing exact graph learning procedures for a large fraction of instances and graphs of various sizes. GLIP also achieves state-of-the-art performance on simulated data and benchmark datasets across all aforementioned classes of graphs.",
      "pdf_url": "https://arxiv.org/pdf/2601.20589v1",
      "arxiv_url": "http://arxiv.org/abs/2601.20589v1",
      "published": "2026-01-28",
      "categories": [
        "stat.ME",
        "cs.LG"
      ]
    },
    {
      "title": "MuVaC: AVariational Causal Framework for Multimodal Sarcasm Understanding in Dialogues",
      "authors": [
        "Diandian Guo",
        "Fangfang Yuan",
        "Cong Cao",
        "Xixun Lin",
        "Chuan Zhou",
        "Hao Peng",
        "Yanan Cao",
        "Yanbing Liu"
      ],
      "abstract": "The prevalence of sarcasm in multimodal dialogues on the social platforms presents a crucial yet challenging task for understanding the true intent behind online content. Comprehensive sarcasm analysis requires two key aspects: Multimodal Sarcasm Detection (MSD) and Multimodal Sarcasm Explanation (MuSE). Intuitively, the act of detection is the result of the reasoning process that explains the sarcasm. Current research predominantly focuses on addressing either MSD or MuSE as a single task. Even though some recent work has attempted to integrate these tasks, their inherent causal dependency is often overlooked. To bridge this gap, we propose MuVaC, a variational causal inference framework that mimics human cognitive mechanisms for understanding sarcasm, enabling robust multimodal feature learning to jointly optimize MSD and MuSE. Specifically, we first model MSD and MuSE from the perspective of structural causal models, establishing variational causal pathways to define the objectives for joint optimization. Next, we design an alignment-then-fusion approach to integrate multimodal features, providing robust fusion representations for sarcasm detection and explanation generation. Finally, we enhance the reasoning trustworthiness by ensuring consistency between detection results and explanations. Experimental results demonstrate the superiority of MuVaC in public datasets, offering a new perspective for understanding multimodal sarcasm.",
      "pdf_url": "https://arxiv.org/pdf/2601.20451v1",
      "arxiv_url": "http://arxiv.org/abs/2601.20451v1",
      "published": "2026-01-28",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "title": "United in Currency, Divided in Growth: Dynamic Effects of Euro Adoption",
      "authors": [
        "Harry Aytug"
      ],
      "abstract": "Does euro adoption affect long-run economic growth? Existing evidence is mixed, reflecting limited treated countries, long horizons that challenge inference, and heterogeneity across member states. We estimate causal dynamic and heterogeneous treatment effects using Causal Forests with Fixed Effects (CFFE), a machine-learning approach that combines causal forests with two-way fixed effects. Under a conditional parallel-trends assumption, we find that euro adoption reduced annual GDP growth by 0.3-0.4 percentage points on average. Effects emerge shortly after adoption and stabilize after roughly a decade.\n  Average effects mask substantial heterogeneity. Countries with lower initial GDP per capita experience larger and more persistent growth shortfalls than core economies. Weaker consumption and productivity growth contribute to the overall effect, while improvements in net exports partially offset these declines.\n  A two-country New Keynesian DSGE model with hysteresis generates qualitatively similar patterns: one-size-fits-all monetary policy and scarring mechanisms produce larger output losses under monetary union than under flexible exchange rates. By jointly estimating dynamic and heterogeneous treatment effects, the analysis highlights the importance of country characteristics in assessing the long-run consequences of monetary union.",
      "pdf_url": "https://arxiv.org/pdf/2601.20169v1",
      "arxiv_url": "http://arxiv.org/abs/2601.20169v1",
      "published": "2026-01-28",
      "categories": [
        "econ.EM"
      ]
    },
    {
      "title": "Decoupling and randomization for double-indexed permutation statistics",
      "authors": [
        "Mingxuan Zou",
        "Jingfan Xu",
        "Peng Ding",
        "Fang Han"
      ],
      "abstract": "This paper introduces a version of decoupling and randomization to establish concentration inequalities for double-indexed permutation statistics. The results yield, among other applications, a new combinatorial Hanson-Wright inequality and a new combinatorial Bennett inequality. Several illustrative examples from rank-based statistics, graph-based statistics, and causal inference are also provided.",
      "pdf_url": "https://arxiv.org/pdf/2601.20018v1",
      "arxiv_url": "http://arxiv.org/abs/2601.20018v1",
      "published": "2026-01-27",
      "categories": [
        "math.ST",
        "econ.EM",
        "math.PR"
      ]
    },
    {
      "title": "BabyReasoningBench: Generating Developmentally-Inspired Reasoning Tasks for Evaluating Baby Language Models",
      "authors": [
        "Kaustubh D. Dhole"
      ],
      "abstract": "Traditional evaluations of reasoning capabilities of language models are dominated by adult-centric benchmarks that presuppose broad world knowledge, complex instruction following, and mature pragmatic competence. These assumptions are mismatched to baby language models trained on developmentally plausible input such as child-directed speech and early-childhood narratives, and they obscure which reasoning abilities (if any) emerge under such constraints. We introduce BabyReasoningBench, a GPT-5.2 generated benchmark of 19 reasoning tasks grounded in classic paradigms from developmental psychology, spanning theory of mind, analogical and relational reasoning, causal inference and intervention selection, and core reasoning primitives that are known to be confounded by memory and pragmatics. We find that two GPT-2 based baby language models (pretrained on 10M and 100M of child-directed speech text) show overall low but uneven performance, with dissociations across task families: scaling improves several causal and physical reasoning tasks, while belief attribution and pragmatics-sensitive tasks remain challenging. BabyReasoningBench provides a developmentally grounded lens for analyzing what kinds of reasoning are supported by child-like training distributions, and for testing mechanistic hypotheses about how such abilities emerge.",
      "pdf_url": "https://arxiv.org/pdf/2601.18933v1",
      "arxiv_url": "http://arxiv.org/abs/2601.18933v1",
      "published": "2026-01-26",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "GraIP: A Benchmarking Framework For Neural Graph Inverse Problems",
      "authors": [
        "Semih Cantürk",
        "Andrei Manolache",
        "Arman Mielke",
        "Chendi Qian",
        "Antoine Siraudin",
        "Christopher Morris",
        "Mathias Niepert",
        "Guy Wolf"
      ],
      "abstract": "A wide range of graph learning tasks, such as structure discovery, temporal graph analysis, and combinatorial optimization, focus on inferring graph structures from data, rather than making predictions on given graphs. However, the respective methods to solve such problems are often developed in an isolated, task-specific manner and thus lack a unifying theoretical foundation. Here, we provide a stepping stone towards the formation of such a foundation and further development by introducing the Neural Graph Inverse Problem (GraIP) conceptual framework, which formalizes and reframes a broad class of graph learning tasks as inverse problems. Unlike discriminative approaches that directly predict target variables from given graph inputs, the GraIP paradigm addresses inverse problems, i.e., it relies on observational data and aims to recover the underlying graph structure by reversing the forward process, such as message passing or network dynamics, that produced the observed outputs. We demonstrate the versatility of GraIP across various graph learning tasks, including rewiring, causal discovery, and neural relational inference. We also propose benchmark datasets and metrics for each GraIP domain considered, and characterize and empirically evaluate existing baseline methods used to solve them. Overall, our unifying perspective bridges seemingly disparate applications and provides a principled approach to structural learning in constrained and combinatorial settings while encouraging cross-pollination of existing methods across graph inverse problems.",
      "pdf_url": "https://arxiv.org/pdf/2601.18917v1",
      "arxiv_url": "http://arxiv.org/abs/2601.18917v1",
      "published": "2026-01-26",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "From Fuzzy to Exact: The Halo Architecture for Infinite-Depth Reasoning via Rational Arithmetic",
      "authors": [
        "Hansheng Ren"
      ],
      "abstract": "Current paradigms in Deep Learning prioritize computational throughput over numerical precision, relying on the assumption that intelligence emerges from statistical correlation at scale. In this paper, we challenge this orthodoxy. We propose the Exactness Hypothesis: that General Intelligence (AGI), specifically high-order causal inference, requires a computational substrate capable of Arbitrary Precision Arithmetic. We argue that the \"hallucinations\" and logical incoherence seen in current Large Language Models (LLMs) are artifacts of IEEE 754 floating-point approximation errors accumulating over deep compositional functions. To mitigate this, we introduce the Halo Architecture, a paradigm shift to Rational Arithmetic ($\\mathbb{Q}$) supported by a novel Exact Inference Unit (EIU). Empirical validation on the Huginn-0125 prototype demonstrates that while 600B-parameter scale BF16 baselines collapse in chaotic systems, Halo maintains zero numerical divergence indefinitely. This work establishes exact arithmetic as a prerequisite for reducing logical uncertainty in System 2 AGI.",
      "pdf_url": "https://arxiv.org/pdf/2601.18702v1",
      "arxiv_url": "http://arxiv.org/abs/2601.18702v1",
      "published": "2026-01-26",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR"
      ]
    },
    {
      "title": "CASSANDRA: Programmatic and Probabilistic Learning and Inference for Stochastic World Modeling",
      "authors": [
        "Panagiotis Lymperopoulos",
        "Abhiramon Rajasekharan",
        "Ian Berlot-Attwell",
        "Stéphane Aroca-Ouellette",
        "Kaheer Suleman"
      ],
      "abstract": "Building world models is essential for planning in real-world domains such as businesses. Since such domains have rich semantics, we can leverage world knowledge to effectively model complex action effects and causal relationships from limited data. In this work, we propose CASSANDRA, a neurosymbolic world modeling approach that leverages an LLM as a knowledge prior to construct lightweight transition models for planning. CASSANDRA integrates two components: (1) LLM-synthesized code to model deterministic features, and (2) LLM-guided structure learning of a probabilistic graphical model to capture causal relationships among stochastic variables. We evaluate CASSANDRA in (i) a small-scale coffee-shop simulator and (ii) a complex theme park business simulator, where we demonstrate significant improvements in transition prediction and planning over baselines.",
      "pdf_url": "https://arxiv.org/pdf/2601.18620v1",
      "arxiv_url": "http://arxiv.org/abs/2601.18620v1",
      "published": "2026-01-26",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "Nearly Optimal Bayesian Inference for Structural Missingness",
      "authors": [
        "Chen Liang",
        "Donghua Yang",
        "Yutong Zhao",
        "Tianle Zhang",
        "Shenghang Zhou",
        "Zhiyu Liang",
        "Hengtong Zhang",
        "Hongzhi Wang",
        "Ziqi Li",
        "Xiyang Zhang",
        "Zheng Liang",
        "Yifei Li"
      ],
      "abstract": "Structural missingness breaks 'just impute and train': values can be undefined by causal or logical constraints, and the mask may depend on observed variables, unobserved variables (MNAR), and other missingness indicators. It simultaneously brings (i) a catch-22 situation with causal loop, prediction needs the missing features, yet inferring them depends on the missingness mechanism, (ii) under MNAR, the unseen are different, the missing part can come from a shifted distribution, and (iii) plug-in imputation, a single fill-in can lock in uncertainty and yield overconfident, biased decisions. In the Bayesian view, prediction via the posterior predictive distribution integrates over the full model posterior uncertainty, rather than relying on a single point estimate. This framework decouples (i) learning an in-model missing-value posterior from (ii) label prediction by optimizing the predictive posterior distribution, enabling posterior integration. This decoupling yields an in-model almost-free-lunch: once the posterior is learned, prediction is plug-and-play while preserving uncertainty propagation. It achieves SOTA on 43 classification and 15 imputation benchmarks, with finite-sample near Bayes-optimality guarantees under our SCM prior.",
      "pdf_url": "https://arxiv.org/pdf/2601.18500v2",
      "arxiv_url": "http://arxiv.org/abs/2601.18500v2",
      "published": "2026-01-26",
      "categories": [
        "cs.LG"
      ]
    }
  ]
}