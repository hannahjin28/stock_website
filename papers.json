{
  "last_updated": "2025-08-19T00:54:22.959268",
  "papers": [
    {
      "title": "Deconfounding via Profiled Transfer Learning",
      "authors": [
        "Ziyuan Chen",
        "Yifan Jiang",
        "Jingyuan Liu",
        "Fang Yao"
      ],
      "abstract": "Unmeasured confounders are a major source of bias in regression-based effect\nestimation and causal inference. In this paper, we advocate a new profiled\ntransfer learning framework, ProTrans, to address confounding effects in the\ntarget dataset, when additional source datasets that possess similar\nconfounding structures are available. We introduce the concept of profiled\nresiduals to characterize the shared confounding patterns between source and\ntarget datasets. By incorporating these profiled residuals into the target\ndebiasing step, we effectively mitigates the latent confounding effects. We\nalso propose a source selection strategy to enhance robustness of ProTrans\nagainst noninformative sources. As a byproduct, ProTrans can also be utilized\nto estimate treatment effects when potential confounders exist, without the use\nof auxiliary features such as instrumental or proxy variables, which are often\nchallenging to select in practice. Theoretically, we prove that the resulting\nestimated model shift from sources to target is confounding-free without any\nassumptions imposed on the true confounding structure, and that the target\nparameter estimation achieves the minimax optimal rate under mild conditions.\nSimulated and real-world experiments validate the effectiveness of ProTrans and\nsupport the theoretical findings.",
      "pdf_url": "http://arxiv.org/pdf/2508.11622v1",
      "arxiv_url": "http://arxiv.org/abs/2508.11622v1",
      "published": "2025-08-15",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "CrossTrace: Efficient Cross-Thread and Cross-Service Span Correlation in Distributed Tracing for Microservices",
      "authors": [
        "Linh-An Phan",
        "MingXue Wang",
        "Guangyu Wu",
        "Wang Dawei",
        "Chen Liqun",
        "Li Jin"
      ],
      "abstract": "Distributed tracing has become an essential technique for debugging and\ntroubleshooting modern microservice-based applications, enabling software\nengineers to detect performance bottlenecks, identify failures, and gain\ninsights into system behavior. However, implementing distributed tracing in\nlarge-scale applications remains challenging due to the need for extensive\ninstrumentation. To reduce this burden, zero-code instrumentation solutions,\nsuch as those based on eBPF, have emerged, allowing span data to be collected\nwithout modifying application code. Despite this promise, span correlation, the\nprocess of establishing causal relationships between spans, remains a critical\nchallenge in zero-code approaches. Existing solutions often rely on thread\naffinity, compromise system security by requiring the kernel integrity mode to\nbe disabled, or incur significant computational overhead due to complex\ninference algorithms. This paper presents CrossTrace, a practical and efficient\ndistributed tracing solution designed to support the debugging of microservice\napplications without requiring source code modifications. CrossTrace employs a\ngreedy algorithm to infer intra-service span relationships from delay patterns,\neliminating reliance on thread identifiers. For inter-service correlation,\nCrossTrace embeds span identifiers into TCP packet headers via eBPF, enabling\nsecure and efficient correlation compromising system security policies.\nEvaluation results show that CrossTrace can correlate thousands of spans within\nseconds with over 90% accuracy, making it suitable for production deployment\nand valuable for microservice observability and diagnosis.",
      "pdf_url": "http://arxiv.org/pdf/2508.11342v1",
      "arxiv_url": "http://arxiv.org/abs/2508.11342v1",
      "published": "2025-08-15",
      "categories": [
        "cs.NI"
      ]
    },
    {
      "title": "Estimating effects of longitudinal modified treatment policies (LMTPs) on rates of change in health outcomes",
      "authors": [
        "Anja Shahu",
        "Daniel Malinsky"
      ],
      "abstract": "Longitudinal data often contains time-varying outcomes measured at multiple\nvisits and scientific interest may lie in quantifying the effect of an\nintervention on an outcome's rate of change. For example, one may wish to study\nthe progression (or trajectory) of a disease over time under different\nhypothetical interventions. We extend the longitudinal modified treatment\npolicy (LMTP) methodology introduced in D\\'iaz et al. (2023) to estimate\neffects of complex interventions on rates of change in an outcome over time. We\nexploit the theoretical properties of a nonparametric efficient influence\nfunction (EIF)-based estimator to introduce a novel inference framework that\ncan be used to construct simultaneous confidence intervals for a variety of\ncausal effects of interest and to formally test relevant global and local\nhypotheses about rates of change. We illustrate the utility of our framework in\ninvestigating whether a longitudinal shift intervention affects an outcome's\ncounterfactual trajectory, as compared with no intervention. We present results\nfrom a simulation study to illustrate the performance of our inference\nframework in a longitudinal setting with time-varying confounding and a\ncontinuous exposure.",
      "pdf_url": "http://arxiv.org/pdf/2508.11131v1",
      "arxiv_url": "http://arxiv.org/abs/2508.11131v1",
      "published": "2025-08-15",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "The Knowledge-Reasoning Dissociation: Fundamental Limitations of LLMs in Clinical Natural Language Inference",
      "authors": [
        "Maël Jullien",
        "Marco Valentino",
        "André Freitas"
      ],
      "abstract": "Large language models are often assumed to acquire increasingly structured,\ngeneralizable internal representations simply by scaling data and parameters.\nWe interrogate this assumption by introducing a Clinical Trial Natural Language\nInference benchmark comprising four reasoning families, Causal Attribution,\nCompositional Grounding, Epistemic Verification, and Risk State Abstraction.\nEach item is paired with a targeted Ground Knowledge and Meta-Level Reasoning\nVerification (GKMRV) probe, allowing us to dissociate failures of factual\naccess from failures of inference. We evaluate six contemporary LLMs under both\ndirect and chain of thought prompting.\n  Models achieve near-ceiling GKMRV accuracy (mean accuracy 0.918) yet perform\npoorly on the main reasoning tasks (mean accuracy 0.25). Despite low accuracy,\noutput inferences are highly consistent across samples (mean 0.87), indicating\na systematic application of underlying heuristics and shortcuts.\n  These results reveal fundamental structural and representational limitations:\ncurrent LLMs often possess the relevant clinical knowledge but lack the\nstructured, composable internal representations needed to deploy it reliably\n(e.g., integrating constraints, weighing evidence, or simulating\ncounterfactuals). Decoupling knowledge from reasoning with GKMRV makes this\ndissociation explicit and measurable, providing an effective framework for\nprobing the reliability of LLMs in high-stakes domains.",
      "pdf_url": "http://arxiv.org/pdf/2508.10777v1",
      "arxiv_url": "http://arxiv.org/abs/2508.10777v1",
      "published": "2025-08-14",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Technical Report: Facilitating the Adoption of Causal Inference Methods Through LLM-Empowered Co-Pilot",
      "authors": [
        "Jeroen Berrevoets",
        "Julianna Piskorz",
        "Robert Davis",
        "Harry Amad",
        "Jim Weatherall",
        "Mihaela van der Schaar"
      ],
      "abstract": "Estimating treatment effects (TE) from observational data is a critical yet\ncomplex task in many fields, from healthcare and economics to public policy.\nWhile recent advances in machine learning and causal inference have produced\npowerful estimation techniques, their adoption remains limited due to the need\nfor deep expertise in causal assumptions, adjustment strategies, and model\nselection. In this paper, we introduce CATE-B, an open-source co-pilot system\nthat uses large language models (LLMs) within an agentic framework to guide\nusers through the end-to-end process of treatment effect estimation. CATE-B\nassists in (i) constructing a structural causal model via causal discovery and\nLLM-based edge orientation, (ii) identifying robust adjustment sets through a\nnovel Minimal Uncertainty Adjustment Set criterion, and (iii) selecting\nappropriate regression methods tailored to the causal structure and dataset\ncharacteristics. To encourage reproducibility and evaluation, we release a\nsuite of benchmark tasks spanning diverse domains and causal complexities. By\ncombining causal inference with intelligent, interactive assistance, CATE-B\nlowers the barrier to rigorous causal analysis and lays the foundation for a\nnew class of benchmarks in automated treatment effect estimation.",
      "pdf_url": "http://arxiv.org/pdf/2508.10581v1",
      "arxiv_url": "http://arxiv.org/abs/2508.10581v1",
      "published": "2025-08-14",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "eDIF: A European Deep Inference Fabric for Remote Interpretability of LLM",
      "authors": [
        "Irma Heithoff. Marc Guggenberger",
        "Sandra Kalogiannis",
        "Susanne Mayer",
        "Fabian Maag",
        "Sigurd Schacht",
        "Carsten Lanquillon"
      ],
      "abstract": "This paper presents a feasibility study on the deployment of a European Deep\nInference Fabric (eDIF), an NDIF-compatible infrastructure designed to support\nmechanistic interpretability research on large language models. The need for\nwidespread accessibility of LLM interpretability infrastructure in Europe\ndrives this initiative to democratize advanced model analysis capabilities for\nthe research community. The project introduces a GPU-based cluster hosted at\nAnsbach University of Applied Sciences and interconnected with partner\ninstitutions, enabling remote model inspection via the NNsight API. A\nstructured pilot study involving 16 researchers from across Europe evaluated\nthe platform's technical performance, usability, and scientific utility. Users\nconducted interventions such as activation patching, causal tracing, and\nrepresentation analysis on models including GPT-2 and DeepSeek-R1-70B. The\nstudy revealed a gradual increase in user engagement, stable platform\nperformance throughout, and a positive reception of the remote experimentation\ncapabilities. It also marked the starting point for building a user community\naround the platform. Identified limitations such as prolonged download\ndurations for activation data as well as intermittent execution interruptions\nare addressed in the roadmap for future development. This initiative marks a\nsignificant step towards widespread accessibility of LLM interpretability\ninfrastructure in Europe and lays the groundwork for broader deployment,\nexpanded tooling, and sustained community collaboration in mechanistic\ninterpretability research.",
      "pdf_url": "http://arxiv.org/pdf/2508.10553v1",
      "arxiv_url": "http://arxiv.org/abs/2508.10553v1",
      "published": "2025-08-14",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "title": "Identifying Unmeasured Confounders in Panel Causal Models: A Two-Stage LM-Wald Approach",
      "authors": [
        "Bang Quan Zheng"
      ],
      "abstract": "Panel data are widely used in political science to draw causal inferences.\nHowever, these models often rely on the strong and untested assumption of\nsequential ignorability--that no unmeasured variables influence both the\nindependent and outcome variables across time. Grounded in psychometric\nliterature on latent variable modeling, this paper introduces the Two-Stage\nLM-Wald (2SLW) approach, a diagnostic tool that extends the Lagrange Multiplier\n(LM) and Wald tests to detect violations of this assumption in panel causal\nmodels. Using Monte Carlo simulations within the Random Intercept Cross-Lagged\nPanel Model (RI-CLPM), which separates within and between person effects, I\ndemonstrate the 2SLW's ability to detect unmeasured confounding across three\nkey scenarios: biased corrections, distorted direct effects, and altered\nmediation pathways. I also illustrate the approach with an empirical\napplication to real-world panel data. By providing a practical and\ntheoretically grounded diagnostic, the 2SLW approach enhances the robustness of\ncausal inferences in the presence of potential time-varying confounders.\nMoreover, it can be readily implemented using the R package lavaan.",
      "pdf_url": "http://arxiv.org/pdf/2508.10342v1",
      "arxiv_url": "http://arxiv.org/abs/2508.10342v1",
      "published": "2025-08-14",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Synthesizing Evidence: Data-Pooling as a Tool for Treatment Selection in Online Experiments",
      "authors": [
        "Zhenkang Peng",
        "Chengzhang Li",
        "Ying Rong",
        "Renyu Zhang"
      ],
      "abstract": "Randomized experiments are the gold standard for causal inference but face\nsignificant challenges in business applications, including limited traffic\nallocation, the need for heterogeneous treatment effect estimation, and the\ncomplexity of managing overlapping experiments. These factors lead to high\nvariability in treatment effect estimates, making data-driven policy roll out\ndifficult. To address these issues, we introduce the data pooling treatment\nroll-out (DPTR) framework, which enhances policy roll-out by pooling data\nacross experiments rather than focusing narrowly on individual ones. DPTR can\neffectively accommodate both overlapping and non-overlapping traffic scenarios,\nregardless of linear or nonlinear model specifications. We demonstrate the\nframework's robustness through a three-pronged validation: (a) theoretical\nanalysis shows that DPTR surpasses the traditional difference-in-mean and\nordinary least squares methods under non-overlapping experiments, particularly\nwhen the number of experiments is large; (b) synthetic simulations confirm its\nadaptability in complex scenarios with overlapping traffic, rich covariates and\nnonlinear specifications; and (c) empirical applications to two experimental\ndatasets from real world platforms, demonstrating its effectiveness in guiding\ncustomized policy roll-outs for subgroups within a single experiment, as well\nas in coordinating policy deployments across multiple experiments with\noverlapping scenarios. By reducing estimation variability to improve\ndecision-making effectiveness, DPTR provides a scalable, practical solution for\nonline platforms to better leverage their experimental data in today's\nincreasingly complex business environments.",
      "pdf_url": "http://arxiv.org/pdf/2508.10331v2",
      "arxiv_url": "http://arxiv.org/abs/2508.10331v2",
      "published": "2025-08-14",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Statistical methods: Basic concepts, interpretations, and cautions",
      "authors": [
        "Sander Greenland"
      ],
      "abstract": "The study of associations and their causal explanations is a central research\nactivity whose methodology varies tremendously across fields. Even within\nspecialized subfields, comparisons across textbooks and journals reveals that\nthe basics are subject to considerable variation and controversy. This\nvariation is often obscured by the singular viewpoints presented within\ntextbooks and journal guidelines, which may be deceptively written as if the\nnorms they adopt are unchallenged. Furthermore, human limitations and the\nvastness within fields imply that no one can have expertise across all\nsubfields and that interpretations will be severely constrained by the\nlimitations of studies of human populations.\n  The present chapter outlines an approach to statistical methods that attempts\nto recognize these problems from the start, rather than assume they are absent\nas in the claims of 'statistical significance' and 'confidence' ordinarily\nattached to statistical tests and interval estimates. It does so by grounding\nmodels and statistics in data description, and treating inferences from them as\nspeculations based on assumptions that cannot be fully validated or checked\nusing the analysis data.",
      "pdf_url": "http://arxiv.org/pdf/2508.10168v1",
      "arxiv_url": "http://arxiv.org/abs/2508.10168v1",
      "published": "2025-08-13",
      "categories": [
        "stat.ME",
        "math.ST",
        "stat.TH"
      ]
    },
    {
      "title": "Linking GFAP Levels to Speech Anomalies in Acute Brain Injury: A Simulation Based Study",
      "authors": [
        "Shamaley Aravinthan",
        "Bin Hu"
      ],
      "abstract": "Background: Glial fibrillary acidic protein (GFAP) is a biomarker for\nintracerebral hemorrhage and traumatic brain injury, but its link to acute\nspeech disruption is untested. Speech anomalies often emerge early after\ninjury, enabling rapid triage.\n  Methods: We simulated a cohort of 200 virtual patients stratified by lesion\nlocation, onset time, and severity. GFAP kinetics followed published\ntrajectories; speech anomalies were generated from lesion-specific\nneurophysiological mappings. Ensemble machine-learning models used GFAP,\nspeech, and lesion features; robustness was tested under noise, delays, and\nlabel dropout. Causal inference (inverse probability of treatment weighting and\ntargeted maximum likelihood estimation) estimated directional associations\nbetween GFAP elevation and speech severity.\n  Findings: GFAP correlated with simulated speech anomaly severity (Spearman\nrho = 0.48), strongest for cortical lesions (rho = 0.55). Voice anomalies\npreceded detectable GFAP rise by a median of 42 minutes in cortical injury.\nClassifier area under the curve values were 0.74 (GFAP only), 0.78 (voice\nonly), and 0.86 for the fused multimodal model, which showed higher sensitivity\nin mild or ambiguous cases. Causal estimates indicated higher GFAP increased\nthe modeled probability of moderate-to-severe speech anomalies by 32 to 35\npercent, independent of lesion site and onset time.\n  Conclusion: These results support a link between GFAP elevation and speech\nanomalies in acute brain injury and suggest integrated biochemical-voice\ndiagnostics could improve early triage, especially for cortical injury.\nFindings are simulation-based and require validation in prospective clinical\nstudies with synchronized GFAP assays and speech recordings.",
      "pdf_url": "http://arxiv.org/pdf/2508.10130v1",
      "arxiv_url": "http://arxiv.org/abs/2508.10130v1",
      "published": "2025-08-13",
      "categories": [
        "q-bio.NC"
      ]
    }
  ]
}