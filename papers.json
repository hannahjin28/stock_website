{
  "last_updated": "2025-12-21T01:01:09.657385",
  "papers": [
    {
      "title": "Identification and efficient estimation of compliance and network causal effects in cluster-randomized trials",
      "authors": [
        "Chao Cheng",
        "Georgia Papadogeorgou",
        "Fan Li"
      ],
      "abstract": "Treatment noncompliance is pervasive in infectious disease cluster-randomized trials. Although all individuals within a cluster are assigned the same treatment condition, the treatment uptake status may vary across individuals due to noncompliance. We propose a semiparametric framework to evaluate the individual compliance effect and network assignment effect within principal stratum exhibiting different patterns of noncompliance. The individual compliance effect captures the portion of the treatment effect attributable to changes in treatment receipt, while the network assignment effect reflects the pure impact of treatment assignment and spillover among individuals within the same cluster. Unlike prior efforts which either empirically identify or interval identify these estimands, we characterize new structural assumptions for nonparametric point identification. We then develop semiparametrically efficient estimators that combine data-adaptive machine learning methods with efficient influence functions to enable more robust inference. Additionally, we introduce sensitivity analysis methods to study the impact under assumption violations, and apply the proposed methods to reanalyze a cluster-randomized trial in Kenya that evaluated the impact of school-based mass deworming on disease transmission.",
      "pdf_url": "https://arxiv.org/pdf/2512.16857v1",
      "arxiv_url": "http://arxiv.org/abs/2512.16857v1",
      "published": "2025-12-18",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Quantile-based causal inference for spatio-temporal processes: Assessing the impacts of wildfires on US air quality",
      "authors": [
        "Zipei Geng",
        "Jordan Richards",
        "Raphael Huser",
        "Marc G. Genton"
      ],
      "abstract": "Wildfires pose an increasingly severe threat to air quality, yet quantifying their causal impact remains challenging due to unmeasured meteorological and geographic confounders. Moreover, wildfire impacts on air quality may exhibit heterogeneous effects across pollution levels, which conventional mean-based causal methods fail to capture. To address these challenges, we develop a Quantile-based Latent Spatial Confounder Model (QLSCM) that substitutes conditional expectations with conditional quantiles, enabling causal analysis across the entire outcome distribution. We establish the causal interpretation of QLSCM theoretically, prove the identifiability of causal effects, and demonstrate estimator consistency under mild conditions. Simulations confirm the bias correction capability and the advantage of quantile-based inference over mean-based approaches. Applying our method to contiguous US wildfire and air quality data, we uncover important heterogeneous effects: fire radiative power exerts significant positive causal effects on aerosol optical depth at high quantiles in Western states like California and Oregon, while insignificant at lower quantiles. This indicates that wildfire impacts on air quality primarily manifest during extreme pollution events. Regional analyses reveal that Western and Northwestern regions experience the strongest causal effects during such extremes. These findings provide critical insights for environmental policy by identifying where and when mitigation efforts would be most effective.",
      "pdf_url": "https://arxiv.org/pdf/2512.16603v1",
      "arxiv_url": "http://arxiv.org/abs/2512.16603v1",
      "published": "2025-12-18",
      "categories": [
        "stat.AP"
      ]
    },
    {
      "title": "ARMFlow: AutoRegressive MeanFlow for Online 3D Human Reaction Generation",
      "authors": [
        "Zichen Geng",
        "Zeeshan Hayder",
        "Wei Liu",
        "Hesheng Wang",
        "Ajmal Mian"
      ],
      "abstract": "3D human reaction generation faces three main challenges:(1) high motion fidelity, (2) real-time inference, and (3) autoregressive adaptability for online scenarios. Existing methods fail to meet all three simultaneously. We propose ARMFlow, a MeanFlow-based autoregressive framework that models temporal dependencies between actor and reactor motions. It consists of a causal context encoder and an MLP-based velocity predictor. We introduce Bootstrap Contextual Encoding (BSCE) in training, encoding generated history instead of the ground-truth ones, to alleviate error accumulation in autoregressive generation. We further introduce the offline variant ReMFlow, achieving state-of-the-art performance with the fastest inference among offline methods. Our ARMFlow addresses key limitations of online settings by: (1) enhancing semantic alignment via a global contextual encoder; (2) achieving high accuracy and low latency in a single-step inference; and (3) reducing accumulated errors through BSCE. Our single-step online generation surpasses existing online methods on InterHuman and InterX by over 40% in FID, while matching offline state-of-the-art performance despite using only partial sequence conditions.",
      "pdf_url": "https://arxiv.org/pdf/2512.16234v1",
      "arxiv_url": "http://arxiv.org/abs/2512.16234v1",
      "published": "2025-12-18",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "BUILD with Precision: Bottom-Up Inference of Linear DAGs",
      "authors": [
        "Hamed Ajorlou",
        "Samuel Rey",
        "Gonzalo Mateos",
        "Geert Leus",
        "Antonio G. Marques"
      ],
      "abstract": "Learning the structure of directed acyclic graphs (DAGs) from observational data is a central problem in causal discovery, statistical signal processing, and machine learning. Under a linear Gaussian structural equation model (SEM) with equal noise variances, the problem is identifiable and we show that the ensemble precision matrix of the observations exhibits a distinctive structure that facilitates DAG recovery. Exploiting this property, we propose BUILD (Bottom-Up Inference of Linear DAGs), a deterministic stepwise algorithm that identifies leaf nodes and their parents, then prunes the leaves by removing incident edges to proceed to the next step, exactly reconstructing the DAG from the true precision matrix. In practice, precision matrices must be estimated from finite data, and ill-conditioning may lead to error accumulation across BUILD steps. As a mitigation strategy, we periodically re-estimate the precision matrix (with less variables as leaves are pruned), trading off runtime for enhanced robustness. Reproducible results on challenging synthetic benchmarks demonstrate that BUILD compares favorably to state-of-the-art DAG learning algorithms, while offering an explicit handle on complexity.",
      "pdf_url": "https://arxiv.org/pdf/2512.16111v1",
      "arxiv_url": "http://arxiv.org/abs/2512.16111v1",
      "published": "2025-12-18",
      "categories": [
        "cs.LG",
        "eess.SP"
      ]
    },
    {
      "title": "CauSTream: Causal Spatio-Temporal Representation Learning for Streamflow Forecasting",
      "authors": [
        "Shu Wan",
        "Reepal Shah",
        "John Sabo",
        "Huan Liu",
        "K. Sel√ßuk Candan"
      ],
      "abstract": "Streamflow forecasting is crucial for water resource management and risk mitigation. While deep learning models have achieved strong predictive performance, they often overlook underlying physical processes, limiting interpretability and generalization. Recent causal learning approaches address these issues by integrating domain knowledge, yet they typically rely on fixed causal graphs that fail to adapt to data. We propose CauStream, a unified framework for causal spatiotemporal streamflow forecasting. CauSTream jointly learns (i) a runoff causal graph among meteorological forcings and (ii) a routing graph capturing dynamic dependencies across stations. We further establish identifiability conditions for these causal structures under a nonparametric setting. We evaluate CauSTream on three major U.S. river basins across three forecasting horizons. The model consistently outperforms prior state-of-the-art methods, with performance gaps widening at longer forecast windows, indicating stronger generalization to unseen conditions. Beyond forecasting, CauSTream also learns causal graphs that capture relationships among hydrological factors and stations. The inferred structures align closely with established domain knowledge, offering interpretable insights into watershed dynamics. CauSTream offers a principled foundation for causal spatiotemporal modeling, with the potential to extend to a wide range of scientific and environmental applications.",
      "pdf_url": "https://arxiv.org/pdf/2512.16046v1",
      "arxiv_url": "http://arxiv.org/abs/2512.16046v1",
      "published": "2025-12-18",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "stat.ML"
      ]
    },
    {
      "title": "End-to-End Training for Autoregressive Video Diffusion via Self-Resampling",
      "authors": [
        "Yuwei Guo",
        "Ceyuan Yang",
        "Hao He",
        "Yang Zhao",
        "Meng Wei",
        "Zhenheng Yang",
        "Weilin Huang",
        "Dahua Lin"
      ],
      "abstract": "Autoregressive video diffusion models hold promise for world simulation but are vulnerable to exposure bias arising from the train-test mismatch. While recent works address this via post-training, they typically rely on a bidirectional teacher model or online discriminator. To achieve an end-to-end solution, we introduce Resampling Forcing, a teacher-free framework that enables training autoregressive video models from scratch and at scale. Central to our approach is a self-resampling scheme that simulates inference-time model errors on history frames during training. Conditioned on these degraded histories, a sparse causal mask enforces temporal causality while enabling parallel training with frame-level diffusion loss. To facilitate efficient long-horizon generation, we further introduce history routing, a parameter-free mechanism that dynamically retrieves the top-k most relevant history frames for each query. Experiments demonstrate that our approach achieves performance comparable to distillation-based baselines while exhibiting superior temporal consistency on longer videos owing to native-length training.",
      "pdf_url": "https://arxiv.org/pdf/2512.15702v1",
      "arxiv_url": "http://arxiv.org/abs/2512.15702v1",
      "published": "2025-12-17",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "mimic-video: Video-Action Models for Generalizable Robot Control Beyond VLAs",
      "authors": [
        "Jonas Pai",
        "Liam Achenbach",
        "Victoriano Montesinos",
        "Benedek Forrai",
        "Oier Mees",
        "Elvis Nava"
      ],
      "abstract": "Prevailing Vision-Language-Action Models (VLAs) for robotic manipulation are built upon vision-language backbones pretrained on large-scale, but disconnected static web data. As a result, despite improved semantic generalization, the policy must implicitly infer complex physical dynamics and temporal dependencies solely from robot trajectories. This reliance creates an unsustainable data burden, necessitating continuous, large-scale expert data collection to compensate for the lack of innate physical understanding. We contend that while vision-language pretraining effectively captures semantic priors, it remains blind to physical causality. A more effective paradigm leverages video to jointly capture semantics and visual dynamics during pretraining, thereby isolating the remaining task of low-level control. To this end, we introduce \\model, a novel Video-Action Model (VAM) that pairs a pretrained Internet-scale video model with a flow matching-based action decoder conditioned on its latent representations. The decoder serves as an Inverse Dynamics Model (IDM), generating low-level robot actions from the latent representation of video-space action plans. Our extensive evaluation shows that our approach achieves state-of-the-art performance on simulated and real-world robotic manipulation tasks, improving sample efficiency by 10x and convergence speed by 2x compared to traditional VLA architectures.",
      "pdf_url": "https://arxiv.org/pdf/2512.15692v1",
      "arxiv_url": "http://arxiv.org/abs/2512.15692v1",
      "published": "2025-12-17",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "title": "How Do Semantically Equivalent Code Transformations Impact Membership Inference on LLMs for Code?",
      "authors": [
        "Hua Yang",
        "Alejandro Velasco",
        "Thanh Le-Cong",
        "Md Nazmul Haque",
        "Bowen Xu",
        "Denys Poshyvanyk"
      ],
      "abstract": "The success of large language models for code relies on vast amounts of code data, including public open-source repositories, such as GitHub, and private, confidential code from companies. This raises concerns about intellectual property compliance and the potential unauthorized use of license-restricted code. While membership inference (MI) techniques have been proposed to detect such unauthorized usage, their effectiveness can be undermined by semantically equivalent code transformation techniques, which modify code syntax while preserving semantic.\n  In this work, we systematically investigate whether semantically equivalent code transformation rules might be leveraged to evade MI detection. The results reveal that model accuracy drops by only 1.5% in the worst case for each rule, demonstrating that transformed datasets can effectively serve as substitutes for fine-tuning. Additionally, we find that one of the rules (RenameVariable) reduces MI success by 10.19%, highlighting its potential to obscure the presence of restricted code. To validate these findings, we conduct a causal analysis confirming that variable renaming has the strongest causal effect in disrupting MI detection. Notably, we find that combining multiple transformations does not further reduce MI effectiveness. Our results expose a critical loophole in license compliance enforcement for training large language models for code, showing that MI detection can be substantially weakened by transformation-based obfuscation techniques.",
      "pdf_url": "https://arxiv.org/pdf/2512.15468v1",
      "arxiv_url": "http://arxiv.org/abs/2512.15468v1",
      "published": "2025-12-17",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CR"
      ]
    },
    {
      "title": "Non-parametric Causal Inference in Dynamic Thresholding Designs",
      "authors": [
        "Aditya Ghosh",
        "Stefan Wager"
      ],
      "abstract": "Consider a setting where we regularly monitor patients' fasting blood sugar, and declare them to have prediabetes (and encourage preventative care) if this number crosses a pre-specified threshold. The sharp, threshold-based treatment policy suggests that we should be able to estimate the long-term benefit of this preventative care by comparing the health trajectories of patients with blood sugar measurements right above and below the threshold. A naive regression-discontinuity analysis, however, is not applicable here, as it ignores the temporal dynamics of the problem where, e.g., a patient just below the threshold on one visit may become prediabetic (and receive treatment) following their next visit. Here, we study thresholding designs in general dynamic systems, and show that simple reduced-form characterizations remain available for a relevant causal target, namely a dynamic marginal policy effect at the treatment threshold. We develop a local-linear-regression approach for estimation and inference of this estimand, and demonstrate promise of our approach in numerical experiments.",
      "pdf_url": "https://arxiv.org/pdf/2512.15244v1",
      "arxiv_url": "http://arxiv.org/abs/2512.15244v1",
      "published": "2025-12-17",
      "categories": [
        "stat.ME",
        "econ.EM"
      ]
    },
    {
      "title": "Foundation Models in Biomedical Imaging: Turning Hype into Reality",
      "authors": [
        "Amgad Muneer",
        "Kai Zhang",
        "Ibraheem Hamdi",
        "Rizwan Qureshi",
        "Muhammad Waqas",
        "Shereen Fouad",
        "Hazrat Ali",
        "Syed Muhammad Anwar",
        "Jia Wu"
      ],
      "abstract": "Foundation models (FMs) are driving a prominent shift in artificial intelligence across different domains, including biomedical imaging. These models are designed to move beyond narrow pattern recognition towards emulating sophisticated clinical reasoning, understanding complex spatial relationships, and integrating multimodal data with unprecedented flexibility. However, a critical gap exists between this potential and the current reality, where the clinical evaluation and deployment of FMs are hampered by significant challenges. Herein, we critically assess the current state-of-the-art, analyzing hype by examining the core capabilities and limitations of FMs in the biomedical domain. We also provide a taxonomy of reasoning, ranging from emulated sequential logic and spatial understanding to the integration of explicit symbolic knowledge, to evaluate whether these models exhibit genuine cognition or merely mimic surface-level patterns. We argue that a critical frontier lies beyond statistical correlation, in the pursuit of causal inference, which is essential for building robust models that understand cause and effect. Furthermore, we discuss the paramount issues in deployment stemming from trustworthiness, bias, and safety, dissecting the challenges of algorithmic bias, data bias and privacy, and model hallucinations. We also draw attention to the need for more inclusive, rigorous, and clinically relevant validation frameworks to ensure their safe and ethical application. We conclude that while the vision of autonomous AI-doctors remains distant, the immediate reality is the emergence of powerful technology and assistive tools that would benefit clinical practice. The future of FMs in biomedical imaging hinges not on scale alone, but on developing hybrid, causally aware, and verifiably safe systems that augment, rather than replace, human expertise.",
      "pdf_url": "https://arxiv.org/pdf/2512.15808v1",
      "arxiv_url": "http://arxiv.org/abs/2512.15808v1",
      "published": "2025-12-17",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    }
  ]
}