{
  "last_updated": "2026-01-27T01:03:02.148065",
  "papers": [
    {
      "title": "Auto-Regressive Masked Diffusion Models",
      "authors": [
        "Mahdi Karami",
        "Ali Ghodsi"
      ],
      "abstract": "Masked diffusion models (MDMs) have emerged as a promising approach for language modeling, yet they face a performance gap compared to autoregressive models (ARMs) and require more training iterations. In this work, we present the Auto-Regressive Masked Diffusion (ARMD) model, an architecture designed to close this gap by unifying the training efficiency of autoregressive models with the parallel generation capabilities of diffusion-based models. Our key insight is to reframe the masked diffusion process as a block-wise causal model. This perspective allows us to design a strictly causal, permutation-equivariant architecture that computes all conditional probabilities across multiple denoising steps in a single, parallel forward pass. The resulting architecture supports efficient, autoregressive-style decoding and a progressive permutation training scheme, allowing the model to learn both canonical left-to-right and random token orderings. Leveraging this flexibility, we introduce a novel strided parallel generation strategy that accelerates inference by generating tokens in parallel streams while maintaining global coherence. Empirical results demonstrate that ARMD achieves state-of-the-art performance on standard language modeling benchmarks, outperforming established diffusion baselines while requiring significantly fewer training steps. Furthermore, it establishes a new benchmark for parallel text generation, effectively bridging the performance gap between parallel and sequential decoding.",
      "pdf_url": "https://arxiv.org/pdf/2601.16971v1",
      "arxiv_url": "http://arxiv.org/abs/2601.16971v1",
      "published": "2026-01-23",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "Finite Population Inference for Factorial Designs and Panel Experiments with Imperfect Compliance",
      "authors": [
        "Pedro Picchetti"
      ],
      "abstract": "This paper develops a finite population framework for analyzing causal effects in settings with imperfect compliance where multiple treatments affect the outcome of interest. Two prominent examples are factorial designs and panel experiments with imperfect compliance. I define finite population causal effects that capture the relative effectiveness of alternative treatment sequences. I provide nonparametric estimators for a rich class of factorial and dynamic causal effects and derive their finite population distributions as the sample size increases. Monte Carlo simulations illustrate the desirable properties of the estimators. Finally, I use the estimator for causal effects in factorial designs to revisit a famous voter mobilization experiment that analyzes the effects of voting encouragement through phone calls on turnout.",
      "pdf_url": "https://arxiv.org/pdf/2601.16749v1",
      "arxiv_url": "http://arxiv.org/abs/2601.16749v1",
      "published": "2026-01-23",
      "categories": [
        "stat.ME",
        "econ.EM"
      ]
    },
    {
      "title": "Investigating Twin Star Equation of States in Light of Recent Astrophysical Observations",
      "authors": [
        "Shamim Haque",
        "Atharva Shinde",
        "Asim Kumar Saha",
        "Tuhin Malik",
        "Ritam Mallick"
      ],
      "abstract": "Twin stars are predicted to exist in nature if the hadron-to-quark phase transition is strong enough to form a new branch of hybrid stars, separated from the branch of neutron stars. We adopt an agnostic approach, using transition energy density, transition pressure, the discontinuity strength, and a constant speed of sound for quark matter as our parameter space to construct a large possibility of hybrid equations of state, and thereby encapsulating a comprehensive picture of the twin star scenario. First, we report the complete conditions on our parameter space imposed by the general relativistic hydrostatic equilibrium solutions. For a fixed transition energy density and speed of sound for quark matter, we define distinct ranges of transition pressures based on the allowed strengths of discontinuity. Below a maximum transition pressure, a range of discontinuity exists that increases as the transition pressure decreases. Thereby, we identify the loci of the limits on discontinuities as the `witch-hat' curves. Based on the causality limit, the witch-hat curves can be punctured or incomplete. Strong constraints on this picture are drawn from the inferences from GW170817 and the NICER measurements. We computed the maximum mass for twin stars to be $2.05~M_\\odot$, the allowed strongest discontinuity in rest-mass density to be $7.76ρ_\\mathrm{sat}$, and the upper bound on transition rest-mass density to be $4.03ρ_\\mathrm{sat}$. Subsequently, we compute the implications of the stiffness of the quark matter equation of state on this picture. Different confidence levels for observational inferences are considered to assess the extent of inclusion (and rejection) of hybrid equations of state and, consequently, their effects on the limits of the maximum mass of twin stars and phase transition properties.",
      "pdf_url": "https://arxiv.org/pdf/2601.16674v1",
      "arxiv_url": "http://arxiv.org/abs/2601.16674v1",
      "published": "2026-01-23",
      "categories": [
        "astro-ph.HE"
      ]
    },
    {
      "title": "Bayesian Nonparametric Causal Inference for High-Dimensional Nutritional Data via Factor-Based Exposure Mapping",
      "authors": [
        "Dafne Zorzetto",
        "Zizhao Xie",
        "Julian Stamp",
        "Arman Oganisian",
        "Roberta De Vito"
      ],
      "abstract": "Diet plays a crucial role in health, and understanding the causal effects of dietary patterns is essential for informing public health policy and personalized nutrition strategies. However, causal inference in nutritional epidemiology faces several challenges: (i) high-dimensional and correlated food/nutrient intake data induce massive treatment levels; (ii) nutritional studies are interested in latent dietary patterns rather than single food items; and (iii) the goal is to estimate heterogeneous causal effects of these dietary patterns on health outcomes. We address these challenges by introducing a sophisticated exposure mapping framework that reduces the high-dimensional treatment space via factor analysis and enables the identification of dietary patterns. We also extend the Bayesian Causal Forest to accommodate three ordered levels of dietary exposure, better capturing the complex structure of nutritional data and enabling estimation of heterogeneous causal effects. We evaluate the proposed method through extensive simulations and apply it to a multi-center epidemiological study of Hispanic/Latino adults residing in the US. Using high-dimensional dietary data, we identify six dietary patterns and estimate their causal link with two key health risk factors: body mass index and fasting insulin levels. Our findings suggest that higher consumption of plant lipid-antioxidant, plant-based, animal protein, and dairy product patterns is associated with reduced risk.",
      "pdf_url": "https://arxiv.org/pdf/2601.16595v1",
      "arxiv_url": "http://arxiv.org/abs/2601.16595v1",
      "published": "2026-01-23",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Ordering-based Causal Discovery via Generalized Score Matching",
      "authors": [
        "Vy Vo",
        "He Zhao",
        "Trung Le",
        "Edwin V. Bonilla",
        "Dinh Phung"
      ],
      "abstract": "Learning DAG structures from purely observational data remains a long-standing challenge across scientific domains. An emerging line of research leverages the score of the data distribution to initially identify a topological order of the underlying DAG via leaf node detection and subsequently performs edge pruning for graph recovery. This paper extends the score matching framework for causal discovery, which is originally designated for continuous data, and introduces a novel leaf discriminant criterion based on the discrete score function. Through simulated and real-world experiments, we demonstrate that our theory enables accurate inference of true causal orders from observed discrete data and the identified ordering can significantly boost the accuracy of existing causal discovery baselines on nearly all of the settings.",
      "pdf_url": "https://arxiv.org/pdf/2601.16249v1",
      "arxiv_url": "http://arxiv.org/abs/2601.16249v1",
      "published": "2026-01-22",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Distributional Balancing for Causal Inference: A Unified Framework via Characteristic Function Distance",
      "authors": [
        "Diptanil Santra",
        "Guanhua Chen",
        "Chan Park"
      ],
      "abstract": "Weighting methods are essential tools for estimating causal effects in observational studies, with the goal of balancing pre-treatment covariates across treatment groups. Traditional approaches pursue this objective indirectly, for example, via inverse propensity score weighting or by matching a finite number of covariate moments, and therefore do not guarantee balance of the full joint covariate distributions. Recently, distributional balancing methods have emerged as robust, nonparametric alternatives that directly target alignment of entire covariate distributions, but they lack a unified framework, formal theoretical guarantees, and valid inferential procedures. We introduce a unified framework for nonparametric distributional balancing based on the characteristic function distance (CFD) and show that widely used discrepancy measures, including the maximum mean discrepancy and energy distance, arise as special cases. Our theoretical analysis establishes conditions under which the resulting CFD-based weighting estimator achieves $\\sqrt{n}$-consistency. Since the standard bootstrap may fail for this estimator, we propose subsampling as a valid alternative for inference. We further extend our approach to an instrumental variable setting to address potential unmeasured confounding. Finally, we evaluate the performance of our method through simulation studies and a real-world application, where the proposed estimator performs well and exhibits results consistent with our theoretical predictions.",
      "pdf_url": "https://arxiv.org/pdf/2601.15449v1",
      "arxiv_url": "http://arxiv.org/abs/2601.15449v1",
      "published": "2026-01-21",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Improving MoE Compute Efficiency by Composing Weight and Data Sparsity",
      "authors": [
        "Maciej Kilian",
        "Oleg Mkrtchyan",
        "Luke Zettlemoyer",
        "Akshat Shrivastava",
        "Armen Aghajanyan"
      ],
      "abstract": "Mixture-of-Experts layers achieve compute efficiency through weight sparsity: each token activates only a subset of experts. Data sparsity, where each expert processes only a subset of tokens, offers a complementary axis. Expert-choice routing implements data sparsity directly but violates causality in autoregressive models, creating train-inference mismatch. We recover data sparsity within causal token-choice MoE by leveraging zero-compute (null) experts within the routing pool. When a token routes to null experts, those slots consume no compute. The standard load balancing objective trains the model to uniformly use all experts (real and null) therefore creating data sparsity in expectation without the causality violations. We evaluate on vision-language model training, where data heterogeneity is pronounced: vision encoders produce many low-information tokens while text tokens are denser. At matched expected FLOPs, composing weight and data sparsity yields a more compute-efficient frontier than weight sparsity alone, with gains in training loss and downstream performance. The model learns implicit modality-aware allocation, routing vision tokens to null experts more aggressively than text, without explicit modality routing.",
      "pdf_url": "https://arxiv.org/pdf/2601.15370v1",
      "arxiv_url": "http://arxiv.org/abs/2601.15370v1",
      "published": "2026-01-21",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Many Experiments, Few Repetitions, Unpaired Data, and Sparse Effects: Is Causal Inference Possible?",
      "authors": [
        "Felix Schur",
        "Niklas Pfister",
        "Peng Ding",
        "Sach Mukherjee",
        "Jonas Peters"
      ],
      "abstract": "We study the problem of estimating causal effects under hidden confounding in the following unpaired data setting: we observe some covariates $X$ and an outcome $Y$ under different experimental conditions (environments) but do not observe them jointly; we either observe $X$ or $Y$. Under appropriate regularity conditions, the problem can be cast as an instrumental variable (IV) regression with the environment acting as a (possibly high-dimensional) instrument. When there are many environments but only a few observations per environment, standard two-sample IV estimators fail to be consistent. We propose a GMM-type estimator based on cross-fold sample splitting of the instrument-covariate sample and prove that it is consistent as the number of environments grows but the sample size per environment remains constant. We further extend the method to sparse causal effects via $\\ell_1$-regularized estimation and post-selection refitting.",
      "pdf_url": "https://arxiv.org/pdf/2601.15254v1",
      "arxiv_url": "http://arxiv.org/abs/2601.15254v1",
      "published": "2026-01-21",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "RadixMLP -- Intra-batch Deduplication for Causal Transformers",
      "authors": [
        "Michael Feil",
        "Julius Lipp"
      ],
      "abstract": "Batch inference workloads for causal transformer models frequently process sequences that share common prefixes, such as system prompts, few-shot examples, or shared queries. Standard inference engines treat each sequence independently, redundantly recomputing identical MLP activations for every copy of the shared prefix. We introduce RadixMLP, a technique that exploits the position-wise nature of MLPs, LayerNorms, linear projections, and embeddings to eliminate this redundancy. RadixMLP dynamically maps batches to a prefix trie, gathering shared segments into a compressed representation for position-wise computation and scattering results back only at attention boundaries. RadixMLP is stateless and operates within a single forward pass. In end-to-end serving benchmarks on MS~MARCO v1.1 with Qwen3 models (0.6B to 8B parameters), RadixMLP achieves 1.44-1.59$\\times$ speedups in realistic reranking workloads, with up to $5\\times$ speedups on synthetic benchmarks with longer shared prefixes. Our code is available at https://github.com/michaelfeil/radix-mlp.",
      "pdf_url": "https://arxiv.org/pdf/2601.15013v1",
      "arxiv_url": "http://arxiv.org/abs/2601.15013v1",
      "published": "2026-01-21",
      "categories": [
        "cs.LG",
        "cs.DC"
      ]
    },
    {
      "title": "Mirai: Autoregressive Visual Generation Needs Foresight",
      "authors": [
        "Yonghao Yu",
        "Lang Huang",
        "Zerun Wang",
        "Runyi Li",
        "Toshihiko Yamasaki"
      ],
      "abstract": "Autoregressive (AR) visual generators model images as sequences of discrete tokens and are trained with next token likelihood. This strict causality supervision optimizes each step only by its immediate next token, which diminishes global coherence and slows convergence. We ask whether foresight, training signals that originate from later tokens, can help AR visual generation. We conduct a series of controlled diagnostics along the injection level, foresight layout, and foresight source axes, unveiling a key insight: aligning foresight to AR models' internal representation on the 2D image grids improves causality modeling. We formulate this insight with Mirai (meaning \"future\" in Japanese), a general framework that injects future information into AR training with no architecture change and no extra inference overhead: Mirai-E uses explicit foresight from multiple future positions of unidirectional representations, whereas Mirai-I leverages implicit foresight from matched bidirectional representations. Extensive experiments show that Mirai significantly accelerates convergence and improves generation quality. For instance, Mirai can speed up LlamaGen-B's convergence by up to 10$\\times$ and reduce the generation FID from 5.34 to 4.34 on the ImageNet class-condition image generation benchmark. Our study highlights that visual autoregressive models need foresight.",
      "pdf_url": "https://arxiv.org/pdf/2601.14671v1",
      "arxiv_url": "http://arxiv.org/abs/2601.14671v1",
      "published": "2026-01-21",
      "categories": [
        "cs.CV"
      ]
    }
  ]
}