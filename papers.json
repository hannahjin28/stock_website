{
  "last_updated": "2026-01-15T00:57:06.533692",
  "papers": [
    {
      "title": "Automatic debiased machine learning and sensitivity analysis for sample selection models",
      "authors": [
        "Jakob Bjelac",
        "Victor Chernozhukov",
        "Phil-Adrian Klotz",
        "Jannis Kueck",
        "Theresa M. A. Schmitz"
      ],
      "abstract": "In this paper, we extend the Riesz representation framework to causal inference under sample selection, where both treatment assignment and outcome observability are non-random. Formulating the problem in terms of a Riesz representer enables stable estimation and a transparent decomposition of omitted variable bias into three interpretable components: a data-identified scale factor, outcome confounding strength, and selection confounding strength. For estimation, we employ the ForestRiesz estimator, which accounts for selective outcome observability while avoiding the instability associated with direct propensity score inversion. We assess finite-sample performance through a simulation study and show that conventional double machine learning approaches can be highly sensitive to tuning parameters due to their reliance on inverse probability weighting, whereas the ForestRiesz estimator delivers more stable performance by leveraging automatic debiased machine learning. In an empirical application to the gender wage gap in the U.S., we find that our ForestRiesz approach yields larger treatment effect estimates than a standard double machine learning approach, suggesting that ignoring sample selection leads to an underestimation of the gender wage gap. Sensitivity analysis indicates that implausibly strong unobserved confounding would be required to overturn our results. Overall, our approach provides a unified, robust, and computationally attractive framework for causal inference under sample selection.",
      "pdf_url": "https://arxiv.org/pdf/2601.08643v1",
      "arxiv_url": "http://arxiv.org/abs/2601.08643v1",
      "published": "2026-01-13",
      "categories": [
        "econ.EM",
        "stat.ML"
      ]
    },
    {
      "title": "Relational Knowledge Distillation Using Fine-tuned Function Vectors",
      "authors": [
        "Andrea Kang",
        "Yingnian Wu",
        "Hongjing Lu"
      ],
      "abstract": "Representing relations between concepts is a core prerequisite for intelligent systems to make sense of the world. Recent work using causal mediation analysis has shown that a small set of attention heads encodes task representation in in-context learning, captured in a compact representation known as the function vector. We show that fine-tuning function vectors with only a small set of examples (about 20 word pairs) yields better performance on relation-based word-completion tasks than using the original vectors derived from causal mediation analysis. These improvements hold for both small and large language models. Moreover, the fine-tuned function vectors yield improved decoding performance for relation words and show stronger alignment with human similarity judgments of semantic relations. Next, we introduce the composite function vector - a weighted combination of fine-tuned function vectors - to extract relational knowledge and support analogical reasoning. At inference time, inserting this composite vector into LLM activations markedly enhances performance on challenging analogy problems drawn from cognitive science and SAT benchmarks. Our results highlight the potential of activation patching as a controllable mechanism for encoding and manipulating relational knowledge, advancing both the interpretability and reasoning capabilities of large language models.",
      "pdf_url": "https://arxiv.org/pdf/2601.08169v1",
      "arxiv_url": "http://arxiv.org/abs/2601.08169v1",
      "published": "2026-01-13",
      "categories": [
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "Debiasing Large Language Models via Adaptive Causal Prompting with Sketch-of-Thought",
      "authors": [
        "Bowen Li",
        "Ziqi Xu",
        "Jing Ren",
        "Renqiang Luo",
        "Xikun Zhang",
        "Xiuzhen Zhang",
        "Yongli Ren",
        "Feng Xia"
      ],
      "abstract": "Despite notable advancements in prompting methods for Large Language Models (LLMs), such as Chain-of-Thought (CoT), existing strategies still suffer from excessive token usage and limited generalisability across diverse reasoning tasks. To address these limitations, we propose an Adaptive Causal Prompting with Sketch-of-Thought (ACPS) framework, which leverages structural causal models to infer the causal effect of a query on its answer and adaptively select an appropriate intervention (i.e., standard front-door and conditional front-door adjustments). This design enables generalisable causal reasoning across heterogeneous tasks without task-specific retraining. By replacing verbose CoT with concise Sketch-of-Thought, ACPS enables efficient reasoning that significantly reduces token usage and inference cost. Extensive experiments on multiple reasoning benchmarks and LLMs demonstrate that ACPS consistently outperforms existing prompting baselines in terms of accuracy, robustness, and computational efficiency.",
      "pdf_url": "https://arxiv.org/pdf/2601.08108v1",
      "arxiv_url": "http://arxiv.org/abs/2601.08108v1",
      "published": "2026-01-13",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "The Role of Confounders and Linearity in Ecological Inference: A Reassessment",
      "authors": [
        "Shiro Kuriwaki",
        "Cory McCartan"
      ],
      "abstract": "Estimating conditional means using only the marginal means available from aggregate data is commonly known as the ecological inference problem (EI). We provide a reassessment of EI, including a new formalization of identification conditions and a demonstration of how these conditions fail to hold in common cases. The identification conditions reveal that, similar to causal inference, credible ecological inference requires controlling for confounders. The aggregation process itself creates additional structure to assist in estimation by restricting the conditional expectation function to be linear in the predictor variable. A linear model perspective also clarifies the differences between the EI methods commonly used in the literature, and when they lead to ecological fallacies. We provide an overview of new methodology which builds on both the identification and linearity results to flexibly control for confounders and yield improved ecological inferences. Finally, using datasets for common EI problems in which the ground truth is fortuitously observed, we show that, while covariates can help, all methods are prone to overestimating both racial polarization and nationalized partisan voting.",
      "pdf_url": "https://arxiv.org/pdf/2601.07668v1",
      "arxiv_url": "http://arxiv.org/abs/2601.07668v1",
      "published": "2026-01-12",
      "categories": [
        "stat.AP"
      ]
    },
    {
      "title": "Functional Synthetic Control Methods for Metric Space-Valued Outcomes",
      "authors": [
        "Ryo Okano",
        "Daisuke Kurisu"
      ],
      "abstract": "The synthetic control method (SCM) is a widely used tool for evaluating causal effects of policy changes in panel data settings. Recent studies have extended its framework to accommodate complex outcomes that take values in metric spaces, such as distributions, functions, networks, covariance matrices, and compositional data. However, due to the lack of linear structure in general metric spaces, theoretical guarantees for estimation and inference within these extended frameworks remain underdeveloped. In this study, we propose the functional synthetic control (FSC) method as an extension of the SCM for metric space-valued outcomes. To address challenges arising from the nonlinearlity of metric spaces, we leverage isometric embeddings into Hilbert spaces. Building on this approach, we develop the FSC and augmented FSC estimators for counterfactual outcomes, with the latter being a bias-corrected version of the former. We then derive their finite-sample error bounds to establish theoretical guarantees for estimation, and construct prediction sets based on these estimators to conduct inference on causal effects. We demonstrate the usefulness of the proposed framework through simulation studies and three empirical applications.",
      "pdf_url": "https://arxiv.org/pdf/2601.07539v1",
      "arxiv_url": "http://arxiv.org/abs/2601.07539v1",
      "published": "2026-01-12",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Minimum Wasserstein distance estimator under covariate shift: closed-form, super-efficiency and irregularity",
      "authors": [
        "Junjun Lang",
        "Qiong Zhang",
        "Yukun Liu"
      ],
      "abstract": "Covariate shift arises when covariate distributions differ between source and target populations while the conditional distribution of the response remains invariant, and it underlies problems in missing data and causal inference. We propose a minimum Wasserstein distance estimation framework for inference under covariate shift that avoids explicit modeling of outcome regressions or importance weights. The resulting W-estimator admits a closed-form expression and is numerically equivalent to the classical 1-nearest neighbor estimator, yielding a new optimal transport interpretation of nearest neighbor methods. We establish root-$n$ asymptotic normality and show that the estimator is not asymptotically linear, leading to super-efficiency relative to the semiparametric efficient estimator under covariate shift in certain regimes, and uniformly in missing data problems. Numerical simulations, along with an analysis of a rainfall dataset, underscore the exceptional performance of our W-estimator.",
      "pdf_url": "https://arxiv.org/pdf/2601.07282v1",
      "arxiv_url": "http://arxiv.org/abs/2601.07282v1",
      "published": "2026-01-12",
      "categories": [
        "stat.ME",
        "stat.ML"
      ]
    },
    {
      "title": "Connections as treatment: causal inference with edge interventions in networks",
      "authors": [
        "Shuli Chen",
        "Jie Hu",
        "Zhichao Jiang"
      ],
      "abstract": "Causal inference has traditionally focused on interventions at the unit level. In many applications, however, the central question concerns the causal effects of connections between units, such as transportation links, social relationships, or collaborative ties. We develop a causal framework for edge interventions in networks, where treatments correspond to the presence or absence of edges. Our framework defines causal estimands under stochastic interventions on the network structure and introduces an inverse probability weighting estimator under an unconfoundedness assumption on edge assignment. We estimate edge probabilities using exponential random graph models, a widely used class of network models. We establish consistency and asymptotic normality of the proposed estimator. Finally, we apply our methodology to China's transportation network to estimate the causal impact of railroad connections on regional economic development.",
      "pdf_url": "https://arxiv.org/pdf/2601.07267v1",
      "arxiv_url": "http://arxiv.org/abs/2601.07267v1",
      "published": "2026-01-12",
      "categories": [
        "stat.ME",
        "stat.AP"
      ]
    },
    {
      "title": "MeepleLM: A Virtual Playtester Simulating Diverse Subjective Experiences",
      "authors": [
        "Zizhen Li",
        "Chuanhao Li",
        "Yibin Wang",
        "Yukang Feng",
        "Jianwen Sun",
        "Jiaxin Ai",
        "Fanrui Zhang",
        "Mingzhu Sun",
        "Yifei Huang",
        "Kaipeng Zhang"
      ],
      "abstract": "Recent advancements have expanded the role of Large Language Models in board games from playing agents to creative co-designers. However, a critical gap remains: current systems lack the capacity to offer constructive critique grounded in the emergent user experience. Bridging this gap is fundamental for harmonizing Human-AI collaboration, as it empowers designers to refine their creations via external perspectives while steering models away from biased or unpredictable outcomes. Automating critique for board games presents two challenges: inferring the latent dynamics connecting rules to gameplay without an explicit engine, and modeling the subjective heterogeneity of diverse player groups. To address these, we curate a dataset of 1,727 structurally corrected rulebooks and 150K reviews selected via quality scoring and facet-aware sampling. We augment this data with Mechanics-Dynamics-Aesthetics (MDA) reasoning to explicitly bridge the causal gap between written rules and player experience. We further distill player personas and introduce MeepleLM, a specialized model that internalizes persona-specific reasoning patterns to accurately simulate the subjective feedback of diverse player archetypes. Experiments demonstrate that MeepleLM significantly outperforms latest commercial models (e.g., GPT-5.1, Gemini3-Pro) in community alignment and critique quality, achieving a 70% preference rate in user studies assessing utility. MeepleLM serves as a reliable virtual playtester for general interactive systems, marking a pivotal step towards audience-aligned, experience-aware Human-AI collaboration.",
      "pdf_url": "https://arxiv.org/pdf/2601.07251v1",
      "arxiv_url": "http://arxiv.org/abs/2601.07251v1",
      "published": "2026-01-12",
      "categories": [
        "cs.HC"
      ]
    },
    {
      "title": "Benchmarking Egocentric Clinical Intent Understanding Capability for Medical Multimodal Large Language Models",
      "authors": [
        "Shaonan Liu",
        "Guo Yu",
        "Xiaoling Luo",
        "Shiyi Zheng",
        "Wenting Chen",
        "Jie Liu",
        "Linlin Shen"
      ],
      "abstract": "Medical Multimodal Large Language Models (Med-MLLMs) require egocentric clinical intent understanding for real-world deployment, yet existing benchmarks fail to evaluate this critical capability. To address these challenges, we introduce MedGaze-Bench, the first benchmark leveraging clinician gaze as a Cognitive Cursor to assess intent understanding across surgery, emergency simulation, and diagnostic interpretation. Our benchmark addresses three fundamental challenges: visual homogeneity of anatomical structures, strict temporal-causal dependencies in clinical workflows, and implicit adherence to safety protocols. We propose a Three-Dimensional Clinical Intent Framework evaluating: (1) Spatial Intent: discriminating precise targets amid visual noise, (2) Temporal Intent: inferring causal rationale through retrospective and prospective reasoning, and (3) Standard Intent: verifying protocol compliance through safety checks. Beyond accuracy metrics, we introduce Trap QA mechanisms to stress-test clinical reliability by penalizing hallucinations and cognitive sycophancy. Experiments reveal current MLLMs struggle with egocentric intent due to over-reliance on global features, leading to fabricated observations and uncritical acceptance of invalid instructions.",
      "pdf_url": "https://arxiv.org/pdf/2601.06750v1",
      "arxiv_url": "http://arxiv.org/abs/2601.06750v1",
      "published": "2026-01-11",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "MedEinst: Benchmarking the Einstellung Effect in Medical LLMs through Counterfactual Differential Diagnosis",
      "authors": [
        "Wenting Chen",
        "Zhongrui Zhu",
        "Guolin Huang",
        "Wenxuan Wang"
      ],
      "abstract": "Despite achieving high accuracy on medical benchmarks, LLMs exhibit the Einstellung Effect in clinical diagnosis--relying on statistical shortcuts rather than patient-specific evidence, causing misdiagnosis in atypical cases. Existing benchmarks fail to detect this critical failure mode. We introduce MedEinst, a counterfactual benchmark with 5,383 paired clinical cases across 49 diseases. Each pair contains a control case and a \"trap\" case with altered discriminative evidence that flips the diagnosis. We measure susceptibility via Bias Trap Rate--probability of misdiagnosing traps despite correctly diagnosing controls. Extensive Evaluation of 17 LLMs shows frontier models achieve high baseline accuracy but severe bias trap rates. Thus, we propose ECR-Agent, aligning LLM reasoning with Evidence-Based Medicine standard via two components: (1) Dynamic Causal Inference (DCI) performs structured reasoning through dual-pathway perception, dynamic causal graph reasoning across three levels (association, intervention, counterfactual), and evidence audit for final diagnosis; (2) Critic-Driven Graph and Memory Evolution (CGME) iteratively refines the system by storing validated reasoning paths in an exemplar base and consolidating disease-specific knowledge into evolving illness graphs. Source code is to be released.",
      "pdf_url": "https://arxiv.org/pdf/2601.06636v1",
      "arxiv_url": "http://arxiv.org/abs/2601.06636v1",
      "published": "2026-01-10",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    }
  ]
}