{
  "last_updated": "2025-10-22T00:53:30.115591",
  "papers": [
    {
      "title": "A Principle of Targeted Intervention for Multi-Agent Reinforcement Learning",
      "authors": [
        "Anjie Liu",
        "Jianhong Wang",
        "Samuel Kaski",
        "Jun Wang",
        "Mengyue Yang"
      ],
      "abstract": "Steering cooperative multi-agent reinforcement learning (MARL) towards\ndesired outcomes is challenging, particularly when the global guidance from a\nhuman on the whole multi-agent system is impractical in a large-scale MARL. On\nthe other hand, designing mechanisms to coordinate agents most relies on\nempirical studies, lacking a easy-to-use research tool. In this work, we employ\nmulti-agent influence diagrams (MAIDs) as a graphical framework to address the\nabove issues. First, we introduce interaction paradigms that leverage MAIDs to\nanalyze and visualize existing approaches in MARL. Then, we design a new\ninteraction paradigm based on MAIDs, referred to as targeted intervention that\nis applied to only a single targeted agent, so the problem of global guidance\ncan be mitigated. In our implementation, we introduce a causal inference\ntechnique-referred to as Pre-Strategy Intervention (PSI)-to realize the\ntargeted intervention paradigm. Since MAIDs can be regarded as a special class\nof causal diagrams, a composite desired outcome that integrates the primary\ntask goal and an additional desired outcome can be achieved by maximizing the\ncorresponding causal effect through the PSI. Moreover, the bundled relevance\ngraph analysis of MAIDs provides a tool to identify whether an MARL learning\nparadigm is workable under the design of an interaction paradigm. In\nexperiments, we demonstrate the effectiveness of our proposed targeted\nintervention, and verify the result of relevance graph analysis.",
      "pdf_url": "http://arxiv.org/pdf/2510.17697v1",
      "arxiv_url": "http://arxiv.org/abs/2510.17697v1",
      "published": "2025-10-20",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "I.2.11; I.2.6"
      ]
    },
    {
      "title": "CausalMamba: Scalable Conditional State Space Models for Neural Causal Inference",
      "authors": [
        "Sangyoon Bae",
        "Jiook Cha"
      ],
      "abstract": "We introduce CausalMamba, a scalable framework that addresses fundamental\nlimitations in fMRI-based causal inference: the ill-posed nature of inferring\nneural causality from hemodynamically distorted BOLD signals and the\ncomputational intractability of existing methods like Dynamic Causal Modeling\n(DCM). Our approach decomposes this complex inverse problem into two tractable\nstages: BOLD deconvolution to recover latent neural activity, followed by\ncausal graph inference using a novel Conditional Mamba architecture. On\nsimulated data, CausalMamba achieves 37% higher accuracy than DCM. Critically,\nwhen applied to real task fMRI data, our method recovers well-established\nneural pathways with 88% fidelity, whereas conventional approaches fail to\nidentify these canonical circuits in over 99% of subjects. Furthermore, our\nnetwork analysis of working memory data reveals that the brain strategically\nshifts its primary causal hub-recruiting executive or salience networks\ndepending on the stimulus-a sophisticated reconfiguration that remains\nundetected by traditional methods. This work provides neuroscientists with a\npractical tool for large-scale causal inference that captures both fundamental\ncircuit motifs and flexible network dynamics underlying cognitive function.",
      "pdf_url": "http://arxiv.org/pdf/2510.17318v1",
      "arxiv_url": "http://arxiv.org/abs/2510.17318v1",
      "published": "2025-10-20",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "LongInsightBench: A Comprehensive Benchmark for Evaluating Omni-Modal Models on Human-Centric Long-Video Understanding",
      "authors": [
        "ZhaoYang Han",
        "Qihan Lin",
        "Hao Liang",
        "Bowen Chen",
        "Zhou Liu",
        "Wentao Zhang"
      ],
      "abstract": "We introduce \\textbf{LongInsightBench}, the first benchmark designed to\nassess models' ability to understand long videos, with a focus on human\nlanguage, viewpoints, actions, and other contextual elements, while integrating\n\\textbf{visual, audio, and text} modalities. Our benchmark excels in three key\nareas: \\textbf{a) Long-Duration, Information-Dense Videos:} We carefully select\napproximately 1,000 videos from open-source datasets FineVideo based on\nduration limit and the information density of both visual and audio modalities,\nfocusing on content like lectures, interviews, and vlogs, which contain rich\nlanguage elements. \\textbf{b) Diverse and Challenging Task Scenarios:} We have\ndesigned six challenging task scenarios, including both Intra-Event and\nInter-Event Tasks. \\textbf{c) Rigorous and Comprehensive Quality Assurance\nPipelines:} We have developed a three-step, semi-automated data quality\nassurance pipeline to ensure the difficulty and validity of the synthesized\nquestions and answer options. Based on LongInsightBench, we designed a series\nof experiments. Experimental results shows that Omni-modal models(OLMs) still\nface challenge in tasks requiring precise temporal localization (T-Loc) and\nlong-range causal inference (CE-Caus). Extended experiments reveal the\ninformation loss and processing bias in multi-modal fusion of OLMs. Our dataset\nand code is available at\nhttps://anonymous.4open.science/r/LongInsightBench-910F/.",
      "pdf_url": "http://arxiv.org/pdf/2510.17305v2",
      "arxiv_url": "http://arxiv.org/abs/2510.17305v2",
      "published": "2025-10-20",
      "categories": [
        "cs.CV",
        "cs.MM"
      ]
    },
    {
      "title": "Discovering Causal Relationships using Proxy Variables under Unmeasured Confounding",
      "authors": [
        "Yong Wu",
        "Yanwei Fu",
        "Shouyan Wang",
        "Yizhou Wang",
        "Xinwei Sun"
      ],
      "abstract": "Inferring causal relationships between variable pairs in the observational\nstudy is crucial but challenging, due to the presence of unmeasured\nconfounding. While previous methods employed the negative controls to adjust\nfor the confounding bias, they were either restricted to the discrete setting\n(i.e., all variables are discrete) or relied on strong assumptions for\nidentification. To address these problems, we develop a general nonparametric\napproach that accommodates both discrete and continuous settings for testing\ncausal hypothesis under unmeasured confounders. By using only a single negative\ncontrol outcome (NCO), we establish a new identification result based on a\nnewly proposed integral equation that links the outcome and NCO, requiring only\nthe completeness and mild regularity conditions. We then propose a kernel-based\ntesting procedure that is more efficient than existing moment-restriction\nmethods. We derive the asymptotic level and power properties for our tests.\nFurthermore, we examine cases where our procedure using only NCO fails to\nachieve identification, and introduce a new procedure that incorporates a\nnegative control exposure (NCE) to restore identifiability. We demonstrate the\neffectiveness of our approach through extensive simulations and real-world data\nfrom the Intensive Care Data and World Values Survey.",
      "pdf_url": "http://arxiv.org/pdf/2510.17167v1",
      "arxiv_url": "http://arxiv.org/abs/2510.17167v1",
      "published": "2025-10-20",
      "categories": [
        "stat.ME",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ]
    },
    {
      "title": "Diverse Influence Component Analysis: A Geometric Approach to Nonlinear Mixture Identifiability",
      "authors": [
        "Hoang-Son Nguyen",
        "Xiao Fu"
      ],
      "abstract": "Latent component identification from unknown nonlinear mixtures is a\nfoundational challenge in machine learning, with applications in tasks such as\ndisentangled representation learning and causal inference. Prior work in\nnonlinear independent component analysis (nICA) has shown that auxiliary\nsignals -- such as weak supervision -- can support identifiability of\nconditionally independent latent components. More recent approaches explore\nstructural assumptions, e.g., sparsity in the Jacobian of the mixing function,\nto relax such requirements. In this work, we introduce Diverse Influence\nComponent Analysis (DICA), a framework that exploits the convex geometry of the\nmixing function's Jacobian. We propose a Jacobian Volume Maximization\n(J-VolMax) criterion, which enables latent component identification by\nencouraging diversity in their influence on the observed variables. Under\nreasonable conditions, this approach achieves identifiability without relying\non auxiliary information, latent component independence, or Jacobian sparsity\nassumptions. These results extend the scope of identifiability analysis and\noffer a complementary perspective to existing methods.",
      "pdf_url": "http://arxiv.org/pdf/2510.17040v2",
      "arxiv_url": "http://arxiv.org/abs/2510.17040v2",
      "published": "2025-10-19",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "Where, Not What: Compelling Video LLMs to Learn Geometric Causality for 3D-Grounding",
      "authors": [
        "Yutong Zhong"
      ],
      "abstract": "Multimodal 3D grounding has garnered considerable interest in Vision-Language\nModels (VLMs) \\cite{yin2025spatial} for advancing spatial reasoning in complex\nenvironments. However, these models suffer from a severe \"2D semantic bias\"\nthat arises from over-reliance on 2D image features for coarse localization,\nlargely disregarding 3D geometric inputs and resulting in suboptimal fusion\nperformance. In this paper, we propose a novel training framework called\nWhat-Where Representation Re-Forming (W2R2) to tackle this issue via\ndisentangled representation learning and targeted shortcut suppression. Our\napproach fundamentally reshapes the model's internal space by designating 2D\nfeatures as semantic beacons for \"What\" identification and 3D features as\nspatial anchors for \"Where\" localization, enabling precise 3D grounding without\nmodifying inference architecture. Key components include a dual-objective loss\nfunction with an Alignment Loss that supervises fused predictions using adapted\ncross-entropy for multimodal synergy, and a Pseudo-Label Loss that penalizes\noverly effective 2D-dominant pseudo-outputs via a margin-based mechanism.\nExperiments conducted on ScanRefer and ScanQA demonstrate the effectiveness of\nW2R2, with significant gains in localization accuracy and robustness,\nparticularly in cluttered outdoor scenes.",
      "pdf_url": "http://arxiv.org/pdf/2510.17034v1",
      "arxiv_url": "http://arxiv.org/abs/2510.17034v1",
      "published": "2025-10-19",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "Towards Real-Time Generative Speech Restoration with Flow-Matching",
      "authors": [
        "Tsun-An Hsieh",
        "Sebastian Braun"
      ],
      "abstract": "Generative models have shown robust performance on speech enhancement and\nrestoration tasks, but most prior approaches operate offline with high latency,\nmaking them unsuitable for streaming applications. In this work, we investigate\nthe feasibility of a low-latency, real-time generative speech restoration\nsystem based on flow-matching (FM). Our method tackles diverse real-world\ntasks, including denoising, dereverberation, and generative restoration. The\nproposed causal architecture without time-downsampling achieves introduces an\ntotal latency of only 20 ms, suitable for real-time communication. In addition,\nwe explore a broad set of architectural variations and sampling strategies to\nensure effective training and efficient inference. Notably, our flow-matching\nmodel maintains high enhancement quality with only 5 number of function\nevaluations (NFEs) during sampling, achieving similar performance as when using\n~20 NFEs under the same conditions. Experimental results indicate that causal\nFM-based models favor few-step reverse sampling, and smaller backbones degrade\nwith longer reverse trajectories. We further show a side-by-side comparison of\nFM to typical adversarial-loss-based training for the same model architecture.",
      "pdf_url": "http://arxiv.org/pdf/2510.16997v1",
      "arxiv_url": "http://arxiv.org/abs/2510.16997v1",
      "published": "2025-10-19",
      "categories": [
        "eess.AS"
      ]
    },
    {
      "title": "Causal Variance Decompositions for Measuring Health Inequalities",
      "authors": [
        "Lin Yu",
        "Zhihui Liu",
        "Kathy Han",
        "Olli Saarela"
      ],
      "abstract": "Recent causal inference literature has introduced causal effect\ndecompositions to quantify sources of observed inequalities or disparities in\noutcomes but usually limiting this to pairwise comparisons. In the context of\nhospital profiling, comparison of hospital performance may reveal inequalities\nin healthcare delivery between sociodemographic groups, which may be explained\nby access/selection or actual effect modification. We consider the case of\npolytomous exposures in hospital profiling where the comparison is often to the\nsystem wide average performance, and decompose the observed variance in care\ndelivery as the quantity of interest. For this, we formulate a new eight-way\ncausal variance decomposition where we attribute the observed variation to\ncomponents describing the main effects of hospital and group membership,\nmodification of the hospital effect by group membership, hospital\naccess/selection, effect of case-mix covariates and residual variance. We\ndiscuss the causal interpretation of the components, formulate parametric and\nnonparametric model based estimators and study the properties of these\nestimators through simulation. Finally, we illustrate our method by an example\nof cancer care delivery using data from the SEER database.",
      "pdf_url": "http://arxiv.org/pdf/2510.16975v1",
      "arxiv_url": "http://arxiv.org/abs/2510.16975v1",
      "published": "2025-10-19",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Causal inference for calibrated scaling interventions on time-to-event processes",
      "authors": [
        "Helene Charlotte Wiese Rytgaard",
        "Mark van der Laan"
      ],
      "abstract": "This work studies stochastic interventions in continuous-time event-history\nsettings formulated as multiplicative scalings of the observed intensity\ngoverning an intermediate event process. This gives rise to a family of causal\nestimands indexed by a scalar parameter {\\alpha}, which changes the event rate\nwhile preserving the temporal and covariate structure of the data-generating\nprocess. We introduce calibrated interventions, where \\(\\alpha\\) is chosen to\nachieve a pre-specified goal, such as a desired level of cumulative risk of the\nintermediate event, and define corresponding composite target parameters\ncapturing the resulting effects on the outcome process. Our proposal enables\npractical yet statistically principled intervention analysis in survival and\nlongitudinal settings, which offers a flexible alternative to deterministic or\nstatic interventions that are often ill-defined. The framework applies broadly\nto causal questions involving time-to-event treatments or mediators, and offers\na pragmatic analogue to indirect/direct effect decompositions. We present the\nefficient influence curves for various versions of target parameters under a\nnonparametric statistical model, discuss their double robustness properties,\nand propose an estimation procedure based on targeted maximum likelihood\nestimation (TMLE). The proposed estimands are illustrated through examples of\nevent-history scenarios addressing distinct causal questions.",
      "pdf_url": "http://arxiv.org/pdf/2510.16798v1",
      "arxiv_url": "http://arxiv.org/abs/2510.16798v1",
      "published": "2025-10-19",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Local Overidentification and Efficiency Gains in Modern Causal Inference and Data Combination",
      "authors": [
        "Xiaohong Chen",
        "Haitian Xie"
      ],
      "abstract": "This paper studies nonparametric local (over-)identification, in the sense of\nChen and Santos (2018), and the associated semiparametric efficiency in modern\ncausal frameworks. We develop a unified approach that begins by translating\nstructural models with latent variables into their induced statistical models\nof observables and then analyzes local overidentification through conditional\nmoment restrictions. We apply this approach to three leading models: (i) the\ngeneral treatment model under unconfoundedness, (ii) the negative control\nmodel, and (iii) the long-term causal inference model under unobserved\nconfounding. The first design yields a locally just-identified statistical\nmodel, implying that all regular asymptotically linear estimators of the\ntreatment effect share the same asymptotic variance, equal to the (trivial)\nsemiparametric efficiency bound. In contrast, the latter two models involve\nnonparametric endogeneity and are naturally locally overidentified;\nconsequently, some doubly robust orthogonal moment estimators of the average\ntreatment effect are inefficient. Whereas existing work typically imposes\nstrong conditions to restore just-identification before deriving the efficiency\nbound, we relax such assumptions and characterize the general efficiency bound,\nalong with efficient estimators, in the overidentified models (ii) and (iii).",
      "pdf_url": "http://arxiv.org/pdf/2510.16683v1",
      "arxiv_url": "http://arxiv.org/abs/2510.16683v1",
      "published": "2025-10-19",
      "categories": [
        "econ.EM"
      ]
    }
  ]
}