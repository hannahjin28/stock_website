{
  "last_updated": "2025-10-17T00:51:17.194216",
  "papers": [
    {
      "title": "Doing Things with Words: Rethinking Theory of Mind Simulation in Large Language Models",
      "authors": [
        "Agnese Lombardi",
        "Alessandro Lenci"
      ],
      "abstract": "Language is fundamental to human cooperation, facilitating not only the\nexchange of information but also the coordination of actions through shared\ninterpretations of situational contexts. This study explores whether the\nGenerative Agent-Based Model (GABM) Concordia can effectively model Theory of\nMind (ToM) within simulated real-world environments. Specifically, we assess\nwhether this framework successfully simulates ToM abilities and whether GPT-4\ncan perform tasks by making genuine inferences from social context, rather than\nrelying on linguistic memorization. Our findings reveal a critical limitation:\nGPT-4 frequently fails to select actions based on belief attribution,\nsuggesting that apparent ToM-like abilities observed in previous studies may\nstem from shallow statistical associations rather than true reasoning.\nAdditionally, the model struggles to generate coherent causal effects from\nagent actions, exposing difficulties in processing complex social interactions.\nThese results challenge current statements about emergent ToM-like capabilities\nin LLMs and highlight the need for more rigorous, action-based evaluation\nframeworks.",
      "pdf_url": "http://arxiv.org/pdf/2510.13395v1",
      "arxiv_url": "http://arxiv.org/abs/2510.13395v1",
      "published": "2025-10-15",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "title": "Novel Class Discovery for Point Cloud Segmentation via Joint Learning of Causal Representation and Reasoning",
      "authors": [
        "Yang Li",
        "Aming Wu",
        "Zihao Zhang",
        "Yahong Han"
      ],
      "abstract": "In this paper, we focus on Novel Class Discovery for Point Cloud Segmentation\n(3D-NCD), aiming to learn a model that can segment unlabeled (novel) 3D classes\nusing only the supervision from labeled (base) 3D classes. The key to this task\nis to setup the exact correlations between the point representations and their\nbase class labels, as well as the representation correlations between the\npoints from base and novel classes. A coarse or statistical correlation\nlearning may lead to the confusion in novel class inference. lf we impose a\ncausal relationship as a strong correlated constraint upon the learning\nprocess, the essential point cloud representations that accurately correspond\nto the classes should be uncovered. To this end, we introduce a structural\ncausal model (SCM) to re-formalize the 3D-NCD problem and propose a new method,\ni.e., Joint Learning of Causal Representation and Reasoning. Specifically, we\nfirst analyze hidden confounders in the base class representations and the\ncausal relationships between the base and novel classes through SCM. We devise\na causal representation prototype that eliminates confounders to capture the\ncausal representations of base classes. A graph structure is then used to model\nthe causal relationships between the base classes' causal representation\nprototypes and the novel class prototypes, enabling causal reasoning from base\nto novel classes. Extensive experiments and visualization results on 3D and 2D\nNCD semantic segmentation demonstrate the superiorities of our method.",
      "pdf_url": "http://arxiv.org/pdf/2510.13307v1",
      "arxiv_url": "http://arxiv.org/abs/2510.13307v1",
      "published": "2025-10-15",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "DeepCausalMMM: A Deep Learning Framework for Marketing Mix Modeling with Causal Inference",
      "authors": [
        "Aditya Puttaparthi Tirumala"
      ],
      "abstract": "Marketing Mix Modeling (MMM) is a statistical technique used to estimate the\nimpact of marketing activities on business outcomes such as sales, revenue, or\ncustomer visits. Traditional MMM approaches often rely on linear regression or\nBayesian hierarchical models that assume independence between marketing\nchannels and struggle to capture complex temporal dynamics and non-linear\nsaturation effects [@Hanssens2005; @Ng2021Bayesian].\n  DeepCausalMMM is a Python package that addresses these limitations by\ncombining deep learning, causal inference, and advanced marketing science. The\npackage uses Gated Recurrent Units (GRUs) to automatically learn temporal\npatterns such as adstock (carryover effects) and lag, while simultaneously\nlearning statistical dependencies and potential causal structures between\nmarketing channels through Directed Acyclic Graph (DAG) learning\n[@Zheng2018NOTEARS; @Gong2024CausalMMM]. Additionally, it implements Hill\nequation-based saturation curves to model diminishing returns and optimize\nbudget allocation.\n  Key innovations include: (1) a data-driven design where hyperparameters and\ntransformations (e.g., adstock decay, saturation curves) are learned or\nestimated from data with sensible defaults, rather than requiring fixed\nheuristics or manual specification, (2) multi-region modeling with both shared\nand region-specific parameters, (3) robust statistical methods including Huber\nloss and advanced regularization, (4) comprehensive response curve analysis for\nunderstanding channel saturation, and (5) an extensive visualization suite with\n14+ interactive dashboards for business insights.",
      "pdf_url": "http://arxiv.org/pdf/2510.13087v1",
      "arxiv_url": "http://arxiv.org/abs/2510.13087v1",
      "published": "2025-10-15",
      "categories": [
        "cs.LG",
        "stat.ME",
        "stat.ML",
        "62P20, 62M10, 68T05",
        "D.2.2; I.2.6; G.3"
      ]
    },
    {
      "title": "Towards xApp Conflict Evaluation with Explainable Machine Learning and Causal Inference in O-RAN",
      "authors": [
        "Pragya Sharma",
        "Shihua Sun",
        "Shachi Deshpande",
        "Angelos Stavrou",
        "Haining Wang"
      ],
      "abstract": "The Open Radio Access Network (O-RAN) architecture enables a flexible,\nvendor-neutral deployment of 5G networks by disaggregating base station\ncomponents and supporting third-party xApps for near real-time RAN control.\nHowever, the concurrent operation of multiple xApps can lead to conflicting\ncontrol actions, which may cause network performance degradation. In this work,\nwe propose a framework for xApp conflict management that combines explainable\nmachine learning and causal inference to evaluate the causal relationships\nbetween RAN Control Parameters (RCPs) and Key Performance Indicators (KPIs). We\nuse model explainability tools such as SHAP to identify RCPs that jointly\naffect the same KPI, signaling potential conflicts, and represent these\ninteractions as a causal Directed Acyclic Graph (DAG). We then estimate the\ncausal impact of each of these RCPs on their associated KPIs using metrics such\nas Average Treatment Effect (ATE) and Conditional Average Treatment Effect\n(CATE). This approach offers network operators guided insights into identifying\nconflicts and quantifying their impacts, enabling more informed and effective\nconflict resolution strategies across diverse xApp deployments.",
      "pdf_url": "http://arxiv.org/pdf/2510.13031v1",
      "arxiv_url": "http://arxiv.org/abs/2510.13031v1",
      "published": "2025-10-14",
      "categories": [
        "cs.NI",
        "cs.SY",
        "eess.SY"
      ]
    },
    {
      "title": "A Quantum Generative Framework for Modeling Single-Cell Transcriptomes with Gene-Gene and Cell-Cell Interactions",
      "authors": [
        "Selim Romero",
        "Vignesh Kumar",
        "Robert S. Chapkin",
        "James J. Cai"
      ],
      "abstract": "Single-cell RNA sequencing (scRNA-seq) data simulation is limited by\nclassical methods that rely on linear correlations, failing to capture the\nintrinsic, nonlinear dependencies and the simultaneous gene-gene and cell-cell\ninteractions. We introduce qSimCells, a novel hybrid quantum-classical\nsimulator that leverages quantum entanglement to model single-cell\ntranscriptomes. The core innovation is a quantum kernel that uses a\nparameterized quantum circuit with CNOT gates to encode complex, nonlinear gene\nregulatory network (GRN) and cell-cell communication topologies with explicit\ndirectionality (causality). The synthetic data exhibits non-classical\ndependencies that challenge standard analysis. We demonstrated that classical\ncorrelation methods (Pearson and Spearman) failed to reconstruct the complete\nprogrammed quantum causal paths, instead reporting spurious statistical\nartifacts driven by high base-gene expression probabilities. Applying\nCellChat2.0 to the simulated cell-cell communication validated the true\nmechanistic links by showing a robust, relative increase in communication\nprobability (up to 75-fold) only when the quantum entanglement was active. This\nwork confirms that the quantum kernel is essential for creating high-fidelity\nground truth data, highlighting the need for advanced inference techniques to\ncapture the complex, non-classical dependencies inherent in gene regulation.",
      "pdf_url": "http://arxiv.org/pdf/2510.12776v1",
      "arxiv_url": "http://arxiv.org/abs/2510.12776v1",
      "published": "2025-10-14",
      "categories": [
        "q-bio.QM",
        "cs.ET",
        "physics.bio-ph",
        "q-bio.GN"
      ]
    },
    {
      "title": "Causal inference of post-transcriptional regulation timelines from long-read sequencing in Arabidopsis thaliana",
      "authors": [
        "Rub√©n Martos",
        "Christophe Ambroise",
        "Guillem Rigaill"
      ],
      "abstract": "We propose a novel framework for reconstructing the chronology of genetic\nregulation using causal inference based on Pearl's theory. The approach\nproceeds in three main stages: causal discovery, causal inference, and\nchronology construction. We apply it to the ndhB and ndhD genes of the\nchloroplast in Arabidopsis thaliana, generating four alternative maturation\ntimeline models per gene, each derived from a different causal discovery\nalgorithm (HC, PC, LiNGAM, or NOTEARS). Two methodological challenges are\naddressed: the presence of missing data, handled via an EM algorithm that\njointly imputes missing values and estimates the Bayesian network, and the\nselection of the $\\ell_1$-regularization parameter in NOTEARS, for which we\nintroduce a stability selection strategy. The resulting causal models\nconsistently outperform reference chronologies in terms of both reliability and\nmodel fit. Moreover, by combining causal reasoning with domain expertise, the\nframework enables the formulation of testable hypotheses and the design of\ntargeted experimental interventions grounded in theoretical predictions.",
      "pdf_url": "http://arxiv.org/pdf/2510.12504v1",
      "arxiv_url": "http://arxiv.org/abs/2510.12504v1",
      "published": "2025-10-14",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "The Robustness of Differentiable Causal Discovery in Misspecified Scenarios",
      "authors": [
        "Huiyang Yi",
        "Yanyan He",
        "Duxin Chen",
        "Mingyu Kang",
        "He Wang",
        "Wenwu Yu"
      ],
      "abstract": "Causal discovery aims to learn causal relationships between variables from\ntargeted data, making it a fundamental task in machine learning. However,\ncausal discovery algorithms often rely on unverifiable causal assumptions,\nwhich are usually difficult to satisfy in real-world data, thereby limiting the\nbroad application of causal discovery in practical scenarios. Inspired by these\nconsiderations, this work extensively benchmarks the empirical performance of\nvarious mainstream causal discovery algorithms, which assume i.i.d. data, under\neight model assumption violations. Our experimental results show that\ndifferentiable causal discovery methods exhibit robustness under the metrics of\nStructural Hamming Distance and Structural Intervention Distance of the\ninferred graphs in commonly used challenging scenarios, except for scale\nvariation. We also provide the theoretical explanations for the performance of\ndifferentiable causal discovery methods. Finally, our work aims to\ncomprehensively benchmark the performance of recent differentiable causal\ndiscovery methods under model assumption violations, and provide the standard\nfor reasonable evaluation of causal discovery, as well as to further promote\nits application in real-world scenarios.",
      "pdf_url": "http://arxiv.org/pdf/2510.12503v1",
      "arxiv_url": "http://arxiv.org/abs/2510.12503v1",
      "published": "2025-10-14",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME",
        "stat.ML"
      ]
    },
    {
      "title": "On the permutation invariance principle for causal estimands",
      "authors": [
        "Jiaqi Tong",
        "Fan Li"
      ],
      "abstract": "In many causal inference problems, multiple action variables share the same\ncausal role, such as mediators, factors, network units, or genotypes, yet lack\na natural ordering. To avoid ambiguity in interpretation, causal estimands\nshould remain unchanged under relabeling, an implicit principle we refer to as\npermutation invariance. We formally characterize this principle, analyze its\nalgebraic and combinatorial structure for verification, and present a class of\nweighted estimands that are permutation-invariant while capturing interactions\nof all orders. We further provide guidance on selecting weights that yield\nresidual-free estimands, whose inclusion-exclusion sums capture the maximal\neffect, and extend our results to ratio effect measures.",
      "pdf_url": "http://arxiv.org/pdf/2510.11863v1",
      "arxiv_url": "http://arxiv.org/abs/2510.11863v1",
      "published": "2025-10-13",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "WaveletDiff: Multilevel Wavelet Diffusion For Time Series Generation",
      "authors": [
        "Yu-Hsiang Wang",
        "Olgica Milenkovic"
      ],
      "abstract": "Time series are ubiquitous in many applications that involve forecasting,\nclassification and causal inference tasks, such as healthcare, finance, audio\nsignal processing and climate sciences. Still, large, high-quality time series\ndatasets remain scarce. Synthetic generation can address this limitation;\nhowever, current models confined either to the time or frequency domains\nstruggle to reproduce the inherently multi-scaled structure of real-world time\nseries. We introduce WaveletDiff, a novel framework that trains diffusion\nmodels directly on wavelet coefficients to exploit the inherent\nmulti-resolution structure of time series data. The model combines dedicated\ntransformers for each decomposition level with cross-level attention mechanisms\nthat enable selective information exchange between temporal and frequency\nscales through adaptive gating. It also incorporates energy preservation\nconstraints for individual levels based on Parseval's theorem to preserve\nspectral fidelity throughout the diffusion process. Comprehensive tests across\nsix real-world datasets from energy, finance, and neuroscience domains\ndemonstrate that WaveletDiff consistently outperforms state-of-the-art\ntime-domain and frequency-domain generative methods on both short and long time\nseries across five diverse performance metrics. For example, WaveletDiff\nachieves discriminative scores and Context-FID scores that are $3\\times$\nsmaller on average than the second-best baseline across all datasets.",
      "pdf_url": "http://arxiv.org/pdf/2510.11839v1",
      "arxiv_url": "http://arxiv.org/abs/2510.11839v1",
      "published": "2025-10-13",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "The Role of Congeniality in Multiple Imputation for Doubly Robust Causal Estimation",
      "authors": [
        "Lucy D'Agostino McGowan"
      ],
      "abstract": "This paper provides clear and practical guidance on the specification of\nimputation models when multiple imputation is used in conjunction with doubly\nrobust estimation methods for causal inference. Through theoretical arguments\nand targeted simulations, we show that when a confounder has missing data the\ncorresponding imputation model must include all variables used in either the\npropensity score model or the outcome model, and that these variables must\nappear in the same functional form as in the final analysis. Violating these\nconditions can lead to biased treatment effect estimates, even when both\ncomponents of the doubly robust estimator are correctly specified. We present a\nmathematical framework for doubly robust estimation combined with multiple\nimputation, establish the theoretical requirements for proper imputation in\nthis setting, and demonstrate the consequences of misspecification through\nsimulation. Based on these findings, we offer concrete recommendations to\nensure valid inference when using multiple imputation with doubly robust\nmethods in applied causal analyses.",
      "pdf_url": "http://arxiv.org/pdf/2510.11633v1",
      "arxiv_url": "http://arxiv.org/abs/2510.11633v1",
      "published": "2025-10-13",
      "categories": [
        "stat.ME",
        "stat.AP"
      ]
    }
  ]
}