{
  "last_updated": "2025-04-06T00:53:56.745953",
  "papers": [
    {
      "title": "The Amenability Framework: Rethinking Causal Ordering Without Estimating Causal Effects",
      "authors": [
        "Carlos Fernández-Loría",
        "Jorge Loría"
      ],
      "abstract": "Who should we prioritize for intervention when we cannot estimate\nintervention effects? In many applied domains (e.g., advertising, customer\nretention, and behavioral nudging) prioritization is guided by predictive\nmodels that estimate outcome probabilities rather than causal effects. This\npaper investigates when these predictions (scores) can effectively rank\nindividuals by their intervention effects, particularly when direct effect\nestimation is infeasible or unreliable. We propose a conceptual framework based\non amenability: an individual's latent proclivity to be influenced by an\nintervention. We then formalize conditions under which predictive scores serve\nas effective proxies for amenability. These conditions justify using non-causal\nscores for intervention prioritization, even when the scores do not directly\nestimate effects. We further show that, under plausible assumptions, predictive\nmodels can outperform causal effect estimators in ranking individuals by\nintervention effects. Empirical evidence from an advertising context supports\nour theoretical findings, demonstrating that predictive modeling can offer a\nmore robust approach to targeting than effect estimation. Our framework\nsuggests a shift in focus, from estimating effects to inferring who is\namenable, as a practical and theoretically grounded strategy for prioritizing\ninterventions in resource-constrained environments.",
      "pdf_url": "http://arxiv.org/pdf/2504.02456v1",
      "arxiv_url": "http://arxiv.org/abs/2504.02456v1",
      "published": "2025-04-03",
      "categories": [
        "cs.LG",
        "stat.ME"
      ]
    },
    {
      "title": "Causal Self-supervised Pretrained Frontend with Predictive Code for Speech Separation",
      "authors": [
        "Wupeng Wang",
        "Zexu Pan",
        "Xinke Li",
        "Shuai Wang",
        "Haizhou Li"
      ],
      "abstract": "Speech separation (SS) seeks to disentangle a multi-talker speech mixture\ninto single-talker speech streams. Although SS can be generally achieved using\noffline methods, such a processing paradigm is not suitable for real-time\nstreaming applications. Causal separation models, which rely only on past and\npresent information, offer a promising solution for real-time streaming.\nHowever, these models typically suffer from notable performance degradation due\nto the absence of future context. In this paper, we introduce a novel frontend\nthat is designed to mitigate the mismatch between training and run-time\ninference by implicitly incorporating future information into causal models\nthrough predictive patterns. The pretrained frontend employs a transformer\ndecoder network with a causal convolutional encoder as the backbone and is\npretrained in a self-supervised manner with two innovative pretext tasks:\nautoregressive hybrid prediction and contextual knowledge distillation. These\ntasks enable the model to capture predictive patterns directly from mixtures in\na self-supervised manner. The pretrained frontend subsequently serves as a\nfeature extractor to generate high-quality predictive patterns. Comprehensive\nevaluations on synthetic and real-world datasets validated the effectiveness of\nthe proposed pretrained frontend.",
      "pdf_url": "http://arxiv.org/pdf/2504.02302v1",
      "arxiv_url": "http://arxiv.org/abs/2504.02302v1",
      "published": "2025-04-03",
      "categories": [
        "cs.SD",
        "cs.LG",
        "eess.AS"
      ]
    },
    {
      "title": "A Causal Inference Framework for Data Rich Environments",
      "authors": [
        "Alberto Abadie",
        "Anish Agarwal",
        "Devavrat Shah"
      ],
      "abstract": "We propose a formal model for counterfactual estimation with unobserved\nconfounding in \"data-rich\" settings, i.e., where there are a large number of\nunits and a large number of measurements per unit. Our model provides a bridge\nbetween the structural causal model view of causal inference common in the\ngraphical models literature with that of the latent factor model view common in\nthe potential outcomes literature. We show how classic models for potential\noutcomes and treatment assignments fit within our framework. We provide an\nidentification argument for the average treatment effect, the average treatment\neffect on the treated, and the average treatment effect on the untreated. For\nany estimator that has a fast enough estimation error rate for a certain\nnuisance parameter, we establish it is consistent for these various causal\nparameters. We then show principal component regression is one such estimator\nthat leads to consistent estimation, and we analyze the minimal smoothness\nrequired of the potential outcomes function for consistency.",
      "pdf_url": "http://arxiv.org/pdf/2504.01702v1",
      "arxiv_url": "http://arxiv.org/abs/2504.01702v1",
      "published": "2025-04-02",
      "categories": [
        "econ.EM",
        "cs.LG",
        "stat.ME"
      ]
    },
    {
      "title": "Identifying Macro Causal Effects in C-DMGs",
      "authors": [
        "Simon Ferreira",
        "Charles K. Assaad"
      ],
      "abstract": "Causal effect identification using causal graphs is a fundamental challenge\nin causal inference. While extensive research has been conducted in this area,\nmost existing methods assume the availability of fully specified causal graphs.\nHowever, in complex domains such as medicine and epidemiology, complete causal\nknowledge is often unavailable, and only partial information about the system\nis accessible. This paper focuses on causal effect identification within\npartially specified causal graphs, with particular emphasis on cluster-directed\nmixed graphs (C-DMGs). These graphs provide a higher-level representation of\ncausal relationships by grouping variables into clusters, offering a more\npractical approach for handling complex systems. Unlike fully specified causal\ngraphs, C-DMGs can contain cycles, which complicate their analysis and\ninterpretation. Furthermore, their cluster-based nature introduces new\nchallenges, as it gives rise to two distinct types of causal effects, macro\ncausal effects and micro causal effects, with different properties. In this\nwork, we focus on macro causal effects, which describe the effects of entire\nclusters on other clusters. We establish that the do-calculus is both sound and\ncomplete for identifying these effects in C-DMGs. Additionally, we provide a\ngraphical characterization of non-identifiability for macro causal effects in\nthese graphs.",
      "pdf_url": "http://arxiv.org/pdf/2504.01551v1",
      "arxiv_url": "http://arxiv.org/abs/2504.01551v1",
      "published": "2025-04-02",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "On the limitations for causal inference in Cox models with time-varying treatment",
      "authors": [
        "Mark B. Knudsen",
        "Erin E. Gabriel",
        "Torben Martinussen",
        "Helene C. W. Rytgaard",
        "Arvid Sjölander"
      ],
      "abstract": "When using the Cox model to analyze the effect of a time-varying treatment on\na survival outcome, treatment is commonly included, using only the current\nlevel as a time-dependent covariate. Such a model does not necessarily assume\nthat past treatment is not associated with the outcome (the Markov property),\nsince it is possible to model the hazard conditional on only the current\ntreatment value. However, modeling the hazard conditional on the full treatment\nhistory is required in order to interpret the results causally, and such a full\nmodel assumes the Markov property when only including current treatment. This\nis, for example, common in marginal structural Cox models. We demonstrate that\nrelying on the Markov property is problematic, since it only holds in\nunrealistic settings or if the treatment has no causal effect. This is the case\neven if there are no confounders and the true causal effect of treatment really\nonly depends on its current level. Further, we provide an example of a scenario\nwhere the Markov property is not fulfilled, but the Cox model that includes\nonly current treatment as a covariate is correctly specified. Transforming the\nresult to the survival scale does not give the true intervention-specific\nsurvival probabilities, showcasing that it is unclear how to make causal\nstatements from such models.",
      "pdf_url": "http://arxiv.org/pdf/2504.01524v1",
      "arxiv_url": "http://arxiv.org/abs/2504.01524v1",
      "published": "2025-04-02",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "PROPHET: An Inferable Future Forecasting Benchmark with Causal Intervened Likelihood Estimation",
      "authors": [
        "Zhengwei Tao",
        "Zhi Jin",
        "Bincheng Li",
        "Xiaoying Bai",
        "Haiyan Zhao",
        "Chengfeng Dou",
        "Xiancai Chen",
        "Jia Li",
        "Linyu Li",
        "Chongyang Tao"
      ],
      "abstract": "Predicting future events stands as one of the ultimate aspirations of\nartificial intelligence. Recent advances in large language model (LLM)-based\nsystems have shown remarkable potential in forecasting future events, thereby\ngarnering significant interest in the research community. Currently, several\nbenchmarks have been established to evaluate the forecasting capabilities by\nformalizing the event prediction as a retrieval-augmented generation (RAG) and\nreasoning task. In these benchmarks, each prediction question is answered with\nrelevant retrieved news articles. However, because there is no consideration on\nwhether the questions can be supported by valid or sufficient supporting\nrationales, some of the questions in these benchmarks may be inherently\nnoninferable. To address this issue, we introduce a new benchmark, PROPHET,\nwhich comprises inferable forecasting questions paired with relevant news for\nretrieval. To ensure the inferability of the benchmark, we propose Causal\nIntervened Likelihood (CIL), a statistical measure that assesses inferability\nthrough causal inference. In constructing this benchmark, we first collected\nrecent trend forecasting questions and then filtered the data using CIL,\nresulting in an inferable benchmark for event prediction. Through extensive\nexperiments, we first demonstrate the validity of CIL and in-depth\ninvestigations into event prediction with the aid of CIL. Subsequently, we\nevaluate several representative prediction systems on PROPHET, drawing valuable\ninsights for future directions.",
      "pdf_url": "http://arxiv.org/pdf/2504.01509v1",
      "arxiv_url": "http://arxiv.org/abs/2504.01509v1",
      "published": "2025-04-02",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "title": "Causal Models for Growing Networks",
      "authors": [
        "Gecia Bravo-Hermsdorff",
        "Lee M. Gunderson",
        "Kayvan Sadeghi"
      ],
      "abstract": "Real-world networks grow over time; statistical models based on node\nexchangeability are not appropriate. Instead of constraining the structure of\nthe \\textit{distribution} of edges, we propose that the relevant symmetries\nrefer to the \\textit{causal structure} between them. We first enumerate the 96\ncausal directed acyclic graph (DAG) models over pairs of nodes (dyad variables)\nin a growing network with finite ancestral sets that are invariant to node\ndeletion. We then partition them into 21 classes with ancestral sets that are\nclosed under node marginalization. Several of these classes are remarkably\namenable to distributed and asynchronous evaluation. As an example, we\nhighlight a simple model that exhibits flexible power-law degree distributions\nand emergent phase transitions in sparsity, which we characterize analytically.\nWith few parameters and much conditional independence, our proposed framework\nprovides natural baseline models for causal inference in relational data.",
      "pdf_url": "http://arxiv.org/pdf/2504.01012v1",
      "arxiv_url": "http://arxiv.org/abs/2504.01012v1",
      "published": "2025-04-01",
      "categories": [
        "cs.SI",
        "cs.DM",
        "math.CO",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ]
    },
    {
      "title": "Quantile Treatment Effects in High Dimensional Panel Data",
      "authors": [
        "Yihong Xu",
        "Li Zheng"
      ],
      "abstract": "We introduce a novel estimator for quantile causal effects with\nhigh-dimensional panel data (large $N$ and $T$), where only one or a few units\nare affected by the intervention or policy. Our method extends the generalized\nsynthetic control method (Xu 2017) from average treatment effect on the treated\nto quantile treatment effect on the treated, allowing the underlying factor\nstructure to change across the quantile of the interested outcome distribution.\nOur method involves estimating the quantile-dependent factors using the control\ngroup, followed by a quantile regression to estimate the quantile treatment\neffect using the treated units. We establish the asymptotic properties of our\nestimator and propose a bootstrap procedure for statistical inference,\nsupported by simulation studies. An empirical application of the 2008 China\nStimulus Program is provided.",
      "pdf_url": "http://arxiv.org/pdf/2504.00785v1",
      "arxiv_url": "http://arxiv.org/abs/2504.00785v1",
      "published": "2025-04-01",
      "categories": [
        "stat.ME",
        "econ.EM",
        "stat.AP",
        "62F12, 62P20"
      ]
    },
    {
      "title": "Contextualize-then-Aggregate: Circuits for In-Context Learning in Gemma-2 2B",
      "authors": [
        "Aleksandra Bakalova",
        "Yana Veitsman",
        "Xinting Huang",
        "Michael Hahn"
      ],
      "abstract": "In-Context Learning (ICL) is an intriguing ability of large language models\n(LLMs). Despite a substantial amount of work on its behavioral aspects and how\nit emerges in miniature setups, it remains unclear which mechanism assembles\ntask information from the individual examples in a fewshot prompt. We use\ncausal interventions to identify information flow in Gemma-2 2B for five\nnaturalistic ICL tasks. We find that the model infers task information using a\ntwo-step strategy we call contextualize-then-aggregate: In the lower layers,\nthe model builds up representations of individual fewshot examples, which are\ncontextualized by preceding examples through connections between fewshot input\nand output tokens across the sequence. In the higher layers, these\nrepresentations are aggregated to identify the task and prepare prediction of\nthe next output. The importance of the contextualization step differs between\ntasks, and it may become more important in the presence of ambiguous examples.\nOverall, by providing rigorous causal analysis, our results shed light on the\nmechanisms through which ICL happens in language models.",
      "pdf_url": "http://arxiv.org/pdf/2504.00132v1",
      "arxiv_url": "http://arxiv.org/abs/2504.00132v1",
      "published": "2025-03-31",
      "categories": [
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "Partial Transportability for Domain Generalization",
      "authors": [
        "Kasra Jalaldoust",
        "Alexis Bellot",
        "Elias Bareinboim"
      ],
      "abstract": "A fundamental task in AI is providing performance guarantees for predictions\nmade in unseen domains. In practice, there can be substantial uncertainty about\nthe distribution of new data, and corresponding variability in the performance\nof existing predictors. Building on the theory of partial identification and\ntransportability, this paper introduces new results for bounding the value of a\nfunctional of the target distribution, such as the generalization error of a\nclassifier, given data from source domains and assumptions about the data\ngenerating mechanisms, encoded in causal diagrams. Our contribution is to\nprovide the first general estimation technique for transportability problems,\nadapting existing parameterization schemes such Neural Causal Models to encode\nthe structural constraints necessary for cross-population inference. We\ndemonstrate the expressiveness and consistency of this procedure and further\npropose a gradient-based optimization scheme for making scalable inferences in\npractice. Our results are corroborated with experiments.",
      "pdf_url": "http://arxiv.org/pdf/2503.23605v1",
      "arxiv_url": "http://arxiv.org/abs/2503.23605v1",
      "published": "2025-03-30",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    }
  ]
}