{
  "last_updated": "2025-05-08T00:53:34.630630",
  "papers": [
    {
      "title": "Counterfactual Inference for Eliminating Sentiment Bias in Recommender Systems",
      "authors": [
        "Le Pan",
        "Yuanjiang Cao",
        "Chengkai Huang",
        "Wenjie Zhang",
        "Lina Yao"
      ],
      "abstract": "Recommender Systems (RSs) aim to provide personalized recommendations for\nusers. A newly discovered bias, known as sentiment bias, uncovers a common\nphenomenon within Review-based RSs (RRSs): the recommendation accuracy of users\nor items with negative reviews deteriorates compared with users or items with\npositive reviews. Critical users and niche items are disadvantaged by such\nunfair recommendations. We study this problem from the perspective of\ncounterfactual inference with two stages. At the model training stage, we build\na causal graph and model how sentiment influences the final rating score.\nDuring the inference stage, we decouple the direct and indirect effects to\nmitigate the impact of sentiment bias and remove the indirect effect using\ncounterfactual inference. We have conducted extensive experiments, and the\nresults validate that our model can achieve comparable performance on rating\nprediction for better recommendations and effective mitigation of sentiment\nbias. To the best of our knowledge, this is the first work to employ\ncounterfactual inference on sentiment bias mitigation in RSs.",
      "pdf_url": "http://arxiv.org/pdf/2505.03655v1",
      "arxiv_url": "http://arxiv.org/abs/2505.03655v1",
      "published": "2025-05-06",
      "categories": [
        "cs.IR",
        "cs.AI"
      ]
    },
    {
      "title": "Integrated Sensing, Computing, Communication, and Control for Time-Sequence-Based Semantic Communications",
      "authors": [
        "Qingliang Li",
        "Bo Chang",
        "Weidong Mei",
        "Zhi Chen"
      ],
      "abstract": "In the upcoming industrial internet of things (IIoT) era, a surge of\ntask-oriented applications will rely on real-time wireless control systems\n(WCSs). For these systems, ultra-reliable and low-latency wireless\ncommunication will be crucial to ensure the timely transmission of control\ninformation. To achieve this purpose, we propose a novel time-sequence-based\nsemantic communication paradigm, where an integrated sensing, computing,\ncommunication, and control (ISC3) architecture is developed to make sensible\nsemantic inference (SI) for the control information over time sequences,\nenabling adaptive control of the robot. However, due to the causal correlations\nin the time sequence, the control information does not present the Markov\nproperty. To address this challenge, we compute the mutual information of the\ncontrol information sensed at the transmitter (Tx) over different time and\nidentify their temporal semantic correlation via a semantic feature extractor\n(SFE) module. By this means, highly correlated information transmission can be\navoided, thus greatly reducing the communication overhead. Meanwhile, a\nsemantic feature reconstructor (SFR) module is employed at the receiver (Rx) to\nreconstruct the control information based on the previously received one if the\ninformation transmission is not activated at the Tx. Furthermore, a control\ngain policy is also employed at the Rx to adaptively adjust the control gain\nfor the controlled target based on several practical aspects such as the\nquality of the information transmission from the Tx to the Rx. We design the\nneural network structures of the above modules/policies and train their\nparameters by a novel hybrid reward multi-agent deep reinforcement learning\nframework. On-site experiments are conducted to evaluate the performance of our\nproposed method in practice, which shows significant gains over other baseline\nschemes.",
      "pdf_url": "http://arxiv.org/pdf/2505.03127v1",
      "arxiv_url": "http://arxiv.org/abs/2505.03127v1",
      "published": "2025-05-06",
      "categories": [
        "eess.SY",
        "cs.IT",
        "cs.SY",
        "math.IT"
      ]
    },
    {
      "title": "Multi-View Learning with Context-Guided Receptance for Image Denoising",
      "authors": [
        "Binghong Chen",
        "Tingting Chai",
        "Wei Jiang",
        "Yuanrong Xu",
        "Guanglu Zhou",
        "Xiangqian Wu"
      ],
      "abstract": "Image denoising is essential in low-level vision applications such as\nphotography and automated driving. Existing methods struggle with\ndistinguishing complex noise patterns in real-world scenes and consume\nsignificant computational resources due to reliance on Transformer-based\nmodels. In this work, the Context-guided Receptance Weighted Key-Value (\\M)\nmodel is proposed, combining enhanced multi-view feature integration with\nefficient sequence modeling. Our approach introduces the Context-guided Token\nShift (CTS) paradigm, which effectively captures local spatial dependencies and\nenhance the model's ability to model real-world noise distributions.\nAdditionally, the Frequency Mix (FMix) module extracting frequency-domain\nfeatures is designed to isolate noise in high-frequency spectra, and is\nintegrated with spatial representations through a multi-view learning process.\nTo improve computational efficiency, the Bidirectional WKV (BiWKV) mechanism is\nadopted, enabling full pixel-sequence interaction with linear complexity while\novercoming the causal selection constraints. The model is validated on multiple\nreal-world image denoising datasets, outperforming the existing\nstate-of-the-art methods quantitatively and reducing inference time up to 40\\%.\nQualitative results further demonstrate the ability of our model to restore\nfine details in various scenes.",
      "pdf_url": "http://arxiv.org/pdf/2505.02705v1",
      "arxiv_url": "http://arxiv.org/abs/2505.02705v1",
      "published": "2025-05-05",
      "categories": [
        "eess.IV",
        "cs.CV"
      ]
    },
    {
      "title": "Structure Causal Models and LLMs Integration in Medical Visual Question Answering",
      "authors": [
        "Zibo Xu",
        "Qiang Li",
        "Weizhi Nie",
        "Weijie Wang",
        "Anan Liu"
      ],
      "abstract": "Medical Visual Question Answering (MedVQA) aims to answer medical questions\naccording to medical images. However, the complexity of medical data leads to\nconfounders that are difficult to observe, so bias between images and questions\nis inevitable. Such cross-modal bias makes it challenging to infer medically\nmeaningful answers. In this work, we propose a causal inference framework for\nthe MedVQA task, which effectively eliminates the relative confounding effect\nbetween the image and the question to ensure the precision of the\nquestion-answering (QA) session. We are the first to introduce a novel causal\ngraph structure that represents the interaction between visual and textual\nelements, explicitly capturing how different questions influence visual\nfeatures. During optimization, we apply the mutual information to discover\nspurious correlations and propose a multi-variable resampling front-door\nadjustment method to eliminate the relative confounding effect, which aims to\nalign features based on their true causal relevance to the question-answering\ntask. In addition, we also introduce a prompt strategy that combines multiple\nprompt forms to improve the model's ability to understand complex medical data\nand answer accurately. Extensive experiments on three MedVQA datasets\ndemonstrate that 1) our method significantly improves the accuracy of MedVQA,\nand 2) our method achieves true causal correlations in the face of complex\nmedical data.",
      "pdf_url": "http://arxiv.org/pdf/2505.02703v1",
      "arxiv_url": "http://arxiv.org/abs/2505.02703v1",
      "published": "2025-05-05",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "Bayesian inference for cluster-randomized trials with multivariate outcomes subject to both truncation by death and missingness",
      "authors": [
        "Guangyu Tong",
        "Chenxi Li",
        "Eric Velazquez",
        "Michael O. Harhay",
        "Fan Li"
      ],
      "abstract": "Cluster-randomized trials (CRTs) on fragile populations frequently encounter\ncomplex attrition problems where the reasons for missing outcomes can be\nheterogeneous, with participants who are known alive, known to have died, or\nwith unknown survival status, and with complex and distinct missing data\nmechanisms for each group. Although existing methods have been developed to\naddress death truncation in CRTs, no existing methods can jointly accommodate\nparticipants who drop out for reasons unrelated to mortality or serious\nillnesses, or those with an unknown survival status. This paper proposes a\nBayesian framework for estimating survivor average causal effects in CRTs while\naccounting for different types of missingness. Our approach uses a multivariate\noutcome that jointly estimates the causal effects, and in the posterior\nestimates, we distinguish the individual-level and the cluster-level survivor\naverage causal effect. We perform simulation studies to evaluate the\nperformance of our model and found low bias and high coverage on key parameters\nacross several different scenarios. We use data from a geriatric CRT to\nillustrate the use of our model. Although our illustration focuses on the case\nof a bivariate continuous outcome, our model is straightforwardly extended to\naccommodate more than two endpoints as well as other types of endpoints (e.g.,\nbinary). Thus, this work provides a general modeling framework for handling\ncomplex missingness in CRTs and can be applied to a wide range of settings with\naging and palliative care populations.",
      "pdf_url": "http://arxiv.org/pdf/2505.02310v1",
      "arxiv_url": "http://arxiv.org/abs/2505.02310v1",
      "published": "2025-05-05",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Federated Causal Inference in Healthcare: Methods, Challenges, and Applications",
      "authors": [
        "Haoyang Li",
        "Jie Xu",
        "Kyra Gan",
        "Fei Wang",
        "Chengxi Zang"
      ],
      "abstract": "Federated causal inference enables multi-site treatment effect estimation\nwithout sharing individual-level data, offering a privacy-preserving solution\nfor real-world evidence generation. However, data heterogeneity across sites,\nmanifested in differences in covariate, treatment, and outcome, poses\nsignificant challenges for unbiased and efficient estimation. In this paper, we\npresent a comprehensive review and theoretical analysis of federated causal\neffect estimation across both binary/continuous and time-to-event outcomes. We\nclassify existing methods into weight-based strategies and optimization-based\nframeworks and further discuss extensions including personalized models,\npeer-to-peer communication, and model decomposition. For time-to-event\noutcomes, we examine federated Cox and Aalen-Johansen models, deriving\nasymptotic bias and variance under heterogeneity. Our analysis reveals that\nFedProx-style regularization achieves near-optimal bias-variance trade-offs\ncompared to naive averaging and meta-analysis. We review related software tools\nand conclude by outlining opportunities, challenges, and future directions for\nscalable, fair, and trustworthy federated causal inference in distributed\nhealthcare systems.",
      "pdf_url": "http://arxiv.org/pdf/2505.02238v1",
      "arxiv_url": "http://arxiv.org/abs/2505.02238v1",
      "published": "2025-05-04",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "TV-SurvCaus: Dynamic Representation Balancing for Causal Survival Analysis",
      "authors": [
        "Ayoub Abraich"
      ],
      "abstract": "Estimating the causal effect of time-varying treatments on survival outcomes\nis a challenging task in many domains, particularly in medicine where treatment\nprotocols adapt over time. While recent advances in representation learning\nhave improved causal inference for static treatments, extending these methods\nto dynamic treatment regimes with survival outcomes remains under-explored. In\nthis paper, we introduce TV-SurvCaus, a novel framework that extends\nrepresentation balancing techniques to the time-varying treatment setting for\nsurvival analysis. We provide theoretical guarantees through (1) a generalized\nbound for time-varying precision in estimation of heterogeneous effects, (2)\nvariance control via sequential balancing weights, (3) consistency results for\ndynamic treatment regimes, (4) convergence rates for representation learning\nwith temporal dependencies, and (5) a formal bound on the bias due to\ntreatment-confounder feedback. Our neural architecture incorporates sequence\nmodeling to handle temporal dependencies while balancing time-dependent\nrepresentations. Through extensive experiments on both synthetic and real-world\ndatasets, we demonstrate that TV-SurvCaus outperforms existing methods in\nestimating individualized treatment effects with time-varying covariates and\ntreatments. Our framework advances the field of causal inference by enabling\nmore accurate estimation of treatment effects in dynamic, longitudinal settings\nwith survival outcomes.",
      "pdf_url": "http://arxiv.org/pdf/2505.01785v1",
      "arxiv_url": "http://arxiv.org/abs/2505.01785v1",
      "published": "2025-05-03",
      "categories": [
        "stat.ML",
        "cs.LG"
      ]
    },
    {
      "title": "Causally Fair Node Classification on Non-IID Graph Data",
      "authors": [
        "Yucong Dai",
        "Lu Zhang",
        "Yaowei Hu",
        "Susan Gauch",
        "Yongkai Wu"
      ],
      "abstract": "Fair machine learning seeks to identify and mitigate biases in predictions\nagainst unfavorable populations characterized by demographic attributes, such\nas race and gender. Recently, a few works have extended fairness to graph data,\nsuch as social networks, but most of them neglect the causal relationships\namong data instances. This paper addresses the prevalent challenge in\nfairness-aware ML algorithms, which typically assume Independent and\nIdentically Distributed (IID) data. We tackle the overlooked domain of non-IID,\ngraph-based settings where data instances are interconnected, influencing the\noutcomes of fairness interventions. We base our research on the Network\nStructural Causal Model (NSCM) framework and posit two main assumptions:\nDecomposability and Graph Independence, which enable the computation of\ninterventional distributions in non-IID settings using the $do$-calculus. Based\non that, we develop the Message Passing Variational Autoencoder for Causal\nInference (MPVA) to compute interventional distributions and facilitate\ncausally fair node classification through estimated interventional\ndistributions. Empirical evaluations on semi-synthetic and real-world datasets\ndemonstrate that MPVA outperforms conventional methods by effectively\napproximating interventional distributions and mitigating bias. The\nimplications of our findings underscore the potential of causality-based\nfairness in complex ML applications, setting the stage for further research\ninto relaxing the initial assumptions to enhance model fairness.",
      "pdf_url": "http://arxiv.org/pdf/2505.01652v1",
      "arxiv_url": "http://arxiv.org/abs/2505.01652v1",
      "published": "2025-05-03",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Design-Based Inference under Random Potential Outcomes via Riesz Representation",
      "authors": [
        "Yukai Yang"
      ],
      "abstract": "We introduce a general framework for design-based causal inference that\naccommodates stochastic potential outcomes, thereby extending the classical\nNeyman-Rubin setup in which outcomes are treated as fixed. In our formulation,\neach unit's potential outcome is modelled as a function $\\tilde{y}_i(z,\n\\omega)$, where $\\omega$ denotes latent randomness external to the treatment\nassignment. Building on recent work that connects design-based estimation with\nthe Riesz representation theorem, we construct causal estimators by embedding\npotential outcomes in a Hilbert space and defining treatment effects as linear\nfunctionals. This allows us to derive unbiased and consistent estimators, even\nwhen potential outcomes exhibit random variation. The framework retains the key\nadvantage of design-based analysis, namely, the use of a known randomisation\nscheme for identification, while enabling inference in settings with inherent\nstochasticity. We establish large-sample properties under local dependence,\nprovide a variance estimator compatible with sparse dependency structures, and\nillustrate the method through a simulation. Our results unify design-based\nreasoning with random-outcome modelling, broadening the applicability of causal\ninference in complex experimental environments.",
      "pdf_url": "http://arxiv.org/pdf/2505.01324v2",
      "arxiv_url": "http://arxiv.org/abs/2505.01324v2",
      "published": "2025-05-02",
      "categories": [
        "stat.ME",
        "econ.EM",
        "math.ST",
        "stat.TH",
        "62G20, 62K99, 62D05"
      ]
    },
    {
      "title": "Robust Root Cause Diagnosis using In-Distribution Interventions",
      "authors": [
        "Lokesh Nagalapatti",
        "Ashutosh Srivastava",
        "Sunita Sarawagi",
        "Amit Sharma"
      ],
      "abstract": "Diagnosing the root cause of an anomaly in a complex interconnected system is\na pressing problem in today's cloud services and industrial operations. We\npropose In-Distribution Interventions (IDI), a novel algorithm that predicts\nroot cause as nodes that meet two criteria: 1) **Anomaly:** root cause nodes\nshould take on anomalous values; 2) **Fix:** had the root cause nodes assumed\nusual values, the target node would not have been anomalous. Prior methods of\nassessing the fix condition rely on counterfactuals inferred from a Structural\nCausal Model (SCM) trained on historical data. But since anomalies are rare and\nfall outside the training distribution, the fitted SCMs yield unreliable\ncounterfactual estimates. IDI overcomes this by relying on interventional\nestimates obtained by solely probing the fitted SCM at in-distribution inputs.\nWe present a theoretical analysis comparing and bounding the errors in\nassessing the fix condition using interventional and counterfactual estimates.\nWe then conduct experiments by systematically varying the SCM's complexity to\ndemonstrate the cases where IDI's interventional approach outperforms the\ncounterfactual approach and vice versa. Experiments on both synthetic and\nPetShop RCD benchmark datasets demonstrate that \\our\\ consistently identifies\ntrue root causes more accurately and robustly than nine existing\nstate-of-the-art RCD baselines. Code is released at\nhttps://github.com/nlokeshiisc/IDI_release.",
      "pdf_url": "http://arxiv.org/pdf/2505.00930v1",
      "arxiv_url": "http://arxiv.org/abs/2505.00930v1",
      "published": "2025-05-02",
      "categories": [
        "cs.LG"
      ]
    }
  ]
}