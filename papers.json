{
  "last_updated": "2025-09-12T00:47:38.802088",
  "papers": [
    {
      "title": "Teamwork as Linear Interpersonal Dynamics",
      "authors": [
        "Andrew Jun Lee",
        "Grace Qiyuan Miao",
        "Rick Dale",
        "Alexia Galati",
        "Hongjing Lu"
      ],
      "abstract": "Successful teamwork depends on interpersonal dynamics, the ways in which\nindividuals coordinate, influence, and adapt to one another over time. Existing\nmeasures of interpersonal dynamics, such as CRQA, correlation, Granger\ncausality, and transfer entropy, typically capture only a single dimension:\neither the synchrony/coordination or the direction of influence between\nindividuals. What is missing is a psychologically meaningful representation\nthat unifies these dimensions and varies systematically with behavior. We\npropose the context matrix as one such representation. The context matrix is\nthe transition matrix in a linear dynamical system, with entries specifying how\nmuch each individual's current behavior is attributable to their own versus\nevery other group member's past behaviors. Its values can be distilled into\npsychologically interpretable summary features of synchrony and directional\ninfluence. Evidence for the context matrix as psychologically meaningful is\nprovided in two steps. First, we develop a sequential Bayesian model that\ninfers context matrices from timeseries data and show that it accurately\nrecovers them in noisy simulations. Second, applying the model to human\neyetracking data, we show that summary features of the inferred context\nmatrices capture expected task-based differences in interpersonal dynamics (or\nlack thereof), predict task accuracy in psychologically reasonable ways, and\nshow some correspondence with existing measures (CRQA and Granger causality).\nWe conclude by situating the context matrix within a broader agenda for\nmodeling interpersonal dynamics.",
      "pdf_url": "http://arxiv.org/pdf/2509.08811v1",
      "arxiv_url": "http://arxiv.org/abs/2509.08811v1",
      "published": "2025-09-10",
      "categories": [
        "cs.MA"
      ]
    },
    {
      "title": "Doubly robust average treatment effect estimation for survival data",
      "authors": [
        "Byeonghee Lee",
        "Joonsung Kang"
      ],
      "abstract": "Considering censored outcomes in survival analysis can lead to quite complex\nresults in the model setting of causal inference. Causal inference has\nattracted a lot of attention over the past few years, but little research has\nbeen done on survival analysis. Even for the only research conducted, the\nmachine learning method was considered assuming a large sample, which is not\nsuitable in that the actual data are high dimensional low sample size (HDLSS)\nmethod. Therefore, penalty is considered for numerous covariates, and the\nrelationship between these covariates and treatment variables is reflected as a\ncovariate balancing property score (CBPS). It also considers censored results.\nTo this end, we will try to solve the above-mentioned problems by using\npenalized empirical likelihood, which considers both estimating equation and\npenalty. The proposed average treatment effect (ATE) estimator possesses the\noracle property, exhibiting key characteristics such as double robustness for\nunbiasedness, sparsity in model selection, and asymptotic normality.",
      "pdf_url": "http://arxiv.org/pdf/2509.08788v1",
      "arxiv_url": "http://arxiv.org/abs/2509.08788v1",
      "published": "2025-09-10",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Automatic Failure Attribution and Critical Step Prediction Method for Multi-Agent Systems Based on Causal Inference",
      "authors": [
        "Guoqing Ma",
        "Jia Zhu",
        "Hanghui Guo",
        "Weijie Shi",
        "Jiawei Shen",
        "Jingjiang Liu",
        "Yidan Liang"
      ],
      "abstract": "Multi-agent systems (MAS) are critical for automating complex tasks, yet\ntheir practical deployment is severely hampered by the challenge of failure\nattribution. Current diagnostic tools, which rely on statistical correlations,\nare fundamentally inadequate; on challenging benchmarks like Who\\&When,\nstate-of-the-art methods achieve less than 15\\% accuracy in locating the\nroot-cause step of a failure. To address this critical gap, we introduce the\nfirst failure attribution framework for MAS grounded in multi-granularity\ncausal inference. Our approach makes two key technical contributions: (1) a\nperformance causal inversion principle, which correctly models performance\ndependencies by reversing the data flow in execution logs, combined with\nShapley values to accurately assign agent-level blame; (2) a novel causal\ndiscovery algorithm, CDC-MAS, that robustly identifies critical failure steps\nby tackling the non-stationary nature of MAS interaction data. The framework's\nattribution results directly fuel an automated optimization loop, generating\ntargeted suggestions whose efficacy is validated via counterfactual\nsimulations. Evaluations on the Who\\&When and TRAIL benchmarks demonstrate a\nsignificant leap in performance. Our method achieves up to 36.2\\% step-level\naccuracy. Crucially, the generated optimizations boost overall task success\nrates by an average of 22.4\\%. This work provides a principled and effective\nsolution for debugging complex agent interactions, paving the way for more\nreliable and interpretable multi-agent systems.",
      "pdf_url": "http://arxiv.org/pdf/2509.08682v1",
      "arxiv_url": "http://arxiv.org/abs/2509.08682v1",
      "published": "2025-09-10",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "LD-ViCE: Latent Diffusion Model for Video Counterfactual Explanations",
      "authors": [
        "Payal Varshney",
        "Adriano Lucieri",
        "Christoph Balada",
        "Sheraz Ahmed",
        "Andreas Dengel"
      ],
      "abstract": "Video-based AI systems are increasingly adopted in safety-critical domains\nsuch as autonomous driving and healthcare. However, interpreting their\ndecisions remains challenging due to the inherent spatiotemporal complexity of\nvideo data and the opacity of deep learning models. Existing explanation\ntechniques often suffer from limited temporal coherence, insufficient\nrobustness, and a lack of actionable causal insights. Current counterfactual\nexplanation methods typically do not incorporate guidance from the target\nmodel, reducing semantic fidelity and practical utility. We introduce Latent\nDiffusion for Video Counterfactual Explanations (LD-ViCE), a novel framework\ndesigned to explain the behavior of video-based AI models. Compared to previous\napproaches, LD-ViCE reduces the computational costs of generating explanations\nby operating in latent space using a state-of-the-art diffusion model, while\nproducing realistic and interpretable counterfactuals through an additional\nrefinement step. Our experiments demonstrate the effectiveness of LD-ViCE\nacross three diverse video datasets, including EchoNet-Dynamic (cardiac\nultrasound), FERV39k (facial expression), and Something-Something V2 (action\nrecognition). LD-ViCE outperforms a recent state-of-the-art method, achieving\nan increase in R2 score of up to 68% while reducing inference time by half.\nQualitative analysis confirms that LD-ViCE generates semantically meaningful\nand temporally coherent explanations, offering valuable insights into the\ntarget model behavior. LD-ViCE represents a valuable step toward the\ntrustworthy deployment of AI in safety-critical domains.",
      "pdf_url": "http://arxiv.org/pdf/2509.08422v1",
      "arxiv_url": "http://arxiv.org/abs/2509.08422v1",
      "published": "2025-09-10",
      "categories": [
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "title": "On the Ambiguities of Incompatibility in Frequentist Inference",
      "authors": [
        "Alessandro Rovetta"
      ],
      "abstract": "The interpretation of the P-value and its monotone transform s=-log2(p), or\nS-value, remains debated despite decades of dedicated literature. Within the\nneo-Fisherian framework, these values are often described as indices of\n(in)compatibility between the observed data and a set of ideal assumptions\n(i.e., the statistical model). In this regard, this paper proposes the\ndistinction between two domains: the model domain, where assumptions are taken\nas perfectly true and every admissible outcome is, by construction, fully\ncompatible with the model; and the real domain, where assumptions may fail and\nface empirical scrutiny. I argue that, although interpreted through an\nobjective numerical index, any level of incompatibility can arise only in the\nlatter domain, where the epistemic status of the model under examination is\nuncertain and a genuine conflict between data and hypotheses can therefore\noccur. The extent to which P- and S-values are taken as indicating\nincompatibility is a matter of contextual judgment. Within this framework,\ndescriptive approaches serve to quantify the numerical values of P and S; these\ncan be interpreted as indicative of a certain degree (or amount) of\nincompatibility between data and hypotheses once causal knowledge of the\ndata-generating process and information about the costs and benefits of related\ndecisions become clearer. Although the distinction between the model domain and\nthe real domain may appear merely theoretical or even philosophical, I argue\nthat this perspective is useful for developing a clear mental representation of\nhow statistical estimates should be evaluated in practical settings and\napplications.",
      "pdf_url": "http://arxiv.org/pdf/2509.07147v1",
      "arxiv_url": "http://arxiv.org/abs/2509.07147v1",
      "published": "2025-09-08",
      "categories": [
        "stat.OT"
      ]
    },
    {
      "title": "MachineLearningLM: Scaling Many-shot In-context Learning via Continued Pretraining",
      "authors": [
        "Haoyu Dong",
        "Pengkun Zhang",
        "Mingzhe Lu",
        "Yanzhen Shen",
        "Guolin Ke"
      ],
      "abstract": "Large language models (LLMs) possess broad world knowledge and strong\ngeneral-purpose reasoning ability, yet they struggle to learn from many\nin-context examples on standard machine learning (ML) tasks, that is, to\nleverage many-shot demonstrations purely via in-context learning (ICL) without\ngradient descent. We introduce MachineLearningLM, a portable\ncontinued-pretraining framework that equips a general-purpose LLM with robust\nin-context ML capability while preserving its general knowledge and reasoning\nfor broader chat workflows.\n  Our pretraining procedure synthesizes ML tasks from millions of structural\ncausal models (SCMs), spanning shot counts up to 1,024. We begin with a\nrandom-forest teacher, distilling tree-based decision strategies into the LLM\nto strengthen robustness in numerical modeling. All tasks are serialized with a\ntoken-efficient prompt, enabling 3x to 6x more examples per context window and\ndelivering up to 50x amortized throughput via batch inference.\n  Despite a modest setup (Qwen-2.5-7B-Instruct with LoRA rank 8),\nMachineLearningLM outperforms strong LLM baselines (e.g., GPT-5-mini) by an\naverage of about 15% on out-of-distribution tabular classification across\nfinance, physics, biology, and healthcare domains. It exhibits a striking\nmany-shot scaling law: accuracy increases monotonically as in-context\ndemonstrations grow from 8 to 1,024. Without any task-specific training, it\nattains random-forest-level accuracy across hundreds of shots. General chat\ncapabilities, including knowledge and reasoning, are preserved: it achieves\n75.4% on MMLU.",
      "pdf_url": "http://arxiv.org/pdf/2509.06806v3",
      "arxiv_url": "http://arxiv.org/abs/2509.06806v3",
      "published": "2025-09-08",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "CausNVS: Autoregressive Multi-view Diffusion for Flexible 3D Novel View Synthesis",
      "authors": [
        "Xin Kong",
        "Daniel Watson",
        "Yannick Str√ºmpler",
        "Michael Niemeyer",
        "Federico Tombari"
      ],
      "abstract": "Multi-view diffusion models have shown promise in 3D novel view synthesis,\nbut most existing methods adopt a non-autoregressive formulation. This limits\ntheir applicability in world modeling, as they only support a fixed number of\nviews and suffer from slow inference due to denoising all frames\nsimultaneously. To address these limitations, we propose CausNVS, a multi-view\ndiffusion model in an autoregressive setting, which supports arbitrary\ninput-output view configurations and generates views sequentially. We train\nCausNVS with causal masking and per-frame noise, using pairwise-relative camera\npose encodings (CaPE) for precise camera control. At inference time, we combine\na spatially-aware sliding-window with key-value caching and noise conditioning\naugmentation to mitigate drift. Our experiments demonstrate that CausNVS\nsupports a broad range of camera trajectories, enables flexible autoregressive\nnovel view synthesis, and achieves consistently strong visual quality across\ndiverse settings. Project page: https://kxhit.github.io/CausNVS.html.",
      "pdf_url": "http://arxiv.org/pdf/2509.06579v1",
      "arxiv_url": "http://arxiv.org/abs/2509.06579v1",
      "published": "2025-09-08",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "Predicting Market Troughs: A Machine Learning Approach with Causal Interpretation",
      "authors": [
        "Peilin Rao",
        "Randall R. Rojas"
      ],
      "abstract": "This paper provides robust, new evidence on the causal drivers of market\ntroughs. We demonstrate that conclusions about these triggers are critically\nsensitive to model specification, moving beyond restrictive linear models with\na flexible DML average partial effect causal machine learning framework. Our\nrobust estimates identify the volatility of options-implied risk appetite and\nmarket liquidity as key causal drivers, relationships misrepresented or\nobscured by simpler models. These findings provide high-frequency empirical\nsupport for intermediary asset pricing theories. This causal analysis is\nenabled by a high-performance nowcasting model that accurately identifies\ncapitulation events in real-time.",
      "pdf_url": "http://arxiv.org/pdf/2509.05922v1",
      "arxiv_url": "http://arxiv.org/abs/2509.05922v1",
      "published": "2025-09-07",
      "categories": [
        "q-fin.ST",
        "econ.EM",
        "stat.ML",
        "91G80, 62P05",
        "J.4"
      ]
    },
    {
      "title": "From Eigenmodes to Proofs: Integrating Graph Spectral Operators with Symbolic Interpretable Reasoning",
      "authors": [
        "Andrew Kiruluta",
        "Priscilla Burity"
      ],
      "abstract": "We introduce Spectral NSR, a fully spectral neuro-symbolic reasoning\nframework that embeds logical rules as spectral templates and performs\ninference directly in the graph spectral domain. By leveraging graph signal\nprocessing (GSP) and frequency-selective filters grounded in the Laplacian\neigenstructure of knowledge graphs, the architecture unifies the\ninterpretability of symbolic reasoning with the scalability and adaptability of\nspectral learning. Beyond the core formulation, we incorporate a comprehensive\nset of extensions, including dynamic graph and basis learning, rational and\ndiffusion filters for sharper spectral selectivity, mixture-of-spectral-experts\nfor modular specialization, proof-guided training with spectral curricula, and\nuncertainty quantification for calibrated confidence. Additional enhancements\nsuch as large language model coupling, co-spectral transfer alignment,\nadversarial robustness, efficient GPU kernels, generalized Laplacians, and\ncausal interventions further expand the versatility of the framework.\n  Empirical evaluation on state-of-the-art reasoning benchmarks such as\nProofWriter and CLUTRR demonstrates that Spectral NSR achieves superior\naccuracy, faster inference, improved robustness to adversarial perturbations,\nand higher interpretability compared to leading baselines including\ntransformers, message-passing neural networks, and neuro-symbolic logic\nprogramming systems. Spectral attribution and proof-band agreement analyses\nconfirm that model decisions align closely with symbolic proof structures,\nwhile transfer experiments validate effective domain adaptation through\nco-spectral alignment. These results establish Spectral NSR as a scalable and\nprincipled foundation for the next generation of reasoning systems, offering\ntransparency, robustness, and generalization beyond conventional approaches.",
      "pdf_url": "http://arxiv.org/pdf/2509.07017v1",
      "arxiv_url": "http://arxiv.org/abs/2509.07017v1",
      "published": "2025-09-07",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "Causal Clustering for Conditional Average Treatment Effects Estimation and Subgroup Discovery",
      "authors": [
        "Zilong Wang",
        "Turgay Ayer",
        "Shihao Yang"
      ],
      "abstract": "Estimating heterogeneous treatment effects is critical in domains such as\npersonalized medicine, resource allocation, and policy evaluation. A central\nchallenge lies in identifying subpopulations that respond differently to\ninterventions, thereby enabling more targeted and effective decision-making.\nWhile clustering methods are well-studied in unsupervised learning, their\nintegration with causal inference remains limited. We propose a novel framework\nthat clusters individuals based on estimated treatment effects using a learned\nkernel derived from causal forests, revealing latent subgroup structures. Our\napproach consists of two main steps. First, we estimate debiased Conditional\nAverage Treatment Effects (CATEs) using orthogonalized learners via the\nRobinson decomposition, yielding a kernel matrix that encodes sample-level\nsimilarities in treatment responsiveness. Second, we apply kernelized\nclustering to this matrix to uncover distinct, treatment-sensitive\nsubpopulations and compute cluster-level average CATEs. We present this\nkernelized clustering step as a form of regularization within the\nresidual-on-residual regression framework. Through extensive experiments on\nsemi-synthetic and real-world datasets, supported by ablation studies and\nexploratory analyses, we demonstrate the effectiveness of our method in\ncapturing meaningful treatment effect heterogeneity.",
      "pdf_url": "http://arxiv.org/pdf/2509.05775v1",
      "arxiv_url": "http://arxiv.org/abs/2509.05775v1",
      "published": "2025-09-06",
      "categories": [
        "stat.ML",
        "cs.LG"
      ]
    }
  ]
}