{
  "last_updated": "2026-01-02T00:58:59.083849",
  "papers": [
    {
      "title": "CPR: Causal Physiological Representation Learning for Robust ECG Analysis under Distribution Shifts",
      "authors": [
        "Shunbo Jia",
        "Caizhi Liao"
      ],
      "abstract": "Deep learning models for Electrocardiogram (ECG) diagnosis have achieved remarkable accuracy but exhibit fragility against adversarial perturbations, particularly Smooth Adversarial Perturbations (SAP) that mimic biological morphology. Existing defenses face a critical dilemma: Adversarial Training (AT) provides robustness but incurs a prohibitive computational burden, while certified methods like Randomized Smoothing (RS) introduce significant inference latency, rendering them impractical for real-time clinical monitoring. We posit that this vulnerability stems from the models' reliance on non-robust spurious correlations rather than invariant pathological features. To address this, we propose Causal Physiological Representation Learning (CPR). Unlike standard denoising approaches that operate without semantic constraints, CPR incorporates a Physiological Structural Prior within a causal disentanglement framework. By modeling ECG generation via a Structural Causal Model (SCM), CPR enforces a structural intervention that strictly separates invariant pathological morphology (P-QRS-T complex) from non-causal artifacts. Empirical results on PTB-XL demonstrate that CPR significantly outperforms standard clinical preprocessing methods. Specifically, under SAP attacks, CPR achieves an F1 score of 0.632, surpassing Median Smoothing (0.541 F1) by 9.1%. Crucially, CPR matches the certified robustness of Randomized Smoothing while maintaining single-pass inference efficiency, offering a superior trade-off between robustness, efficiency, and clinical interpretability.",
      "pdf_url": "https://arxiv.org/pdf/2512.24564v1",
      "arxiv_url": "http://arxiv.org/abs/2512.24564v1",
      "published": "2025-12-31",
      "categories": [
        "cs.LG",
        "eess.SP"
      ]
    },
    {
      "title": "Demystifying Proximal Causal Inference",
      "authors": [
        "Grace V. Ringlein",
        "Trang Quynh Nguyen",
        "Peter P. Zandi",
        "Elizabeth A. Stuart",
        "Harsh Parikh"
      ],
      "abstract": "Proximal causal inference (PCI) has emerged as a promising framework for identifying and estimating causal effects in the presence of unobserved confounders. While many traditional causal inference methods rely on the assumption of no unobserved confounding, this assumption is likely often violated. PCI mitigates this challenge by relying on an alternative set of assumptions regarding the relationships between treatment, outcome, and auxiliary variables that serve as proxies for unmeasured confounders. We review existing identification results, discuss the assumptions necessary for valid causal effect estimation via PCI, and compare different PCI estimation methods. We offer practical guidance on operationalizing PCI, with a focus on selecting and evaluating proxy variables using domain knowledge, measurement error perspectives, and negative control analogies. Through conceptual examples, we demonstrate tensions in proxy selection and discuss the importance of clearly defining the unobserved confounding mechanism. By bridging formal results with applied considerations, this work aims to demystify PCI, encourage thoughtful use in practice, and identify open directions for methodological development and empirical research.",
      "pdf_url": "https://arxiv.org/pdf/2512.24413v1",
      "arxiv_url": "http://arxiv.org/abs/2512.24413v1",
      "published": "2025-12-30",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Stream-DiffVSR: Low-Latency Streamable Video Super-Resolution via Auto-Regressive Diffusion",
      "authors": [
        "Hau-Shiang Shiu",
        "Chin-Yang Lin",
        "Zhixiang Wang",
        "Chi-Wei Hsiao",
        "Po-Fan Yu",
        "Yu-Chih Chen",
        "Yu-Lun Liu"
      ],
      "abstract": "Diffusion-based video super-resolution (VSR) methods achieve strong perceptual quality but remain impractical for latency-sensitive settings due to reliance on future frames and expensive multi-step denoising. We propose Stream-DiffVSR, a causally conditioned diffusion framework for efficient online VSR. Operating strictly on past frames, it combines a four-step distilled denoiser for fast inference, an Auto-regressive Temporal Guidance (ARTG) module that injects motion-aligned cues during latent denoising, and a lightweight temporal-aware decoder with a Temporal Processor Module (TPM) that enhances detail and temporal coherence. Stream-DiffVSR processes 720p frames in 0.328 seconds on an RTX4090 GPU and significantly outperforms prior diffusion-based methods. Compared with the online SOTA TMP, it boosts perceptual quality (LPIPS +0.095) while reducing latency by over 130x. Stream-DiffVSR achieves the lowest latency reported for diffusion-based VSR, reducing initial delay from over 4600 seconds to 0.328 seconds, thereby making it the first diffusion VSR method suitable for low-latency online deployment. Project page: https://jamichss.github.io/stream-diffvsr-project-page/",
      "pdf_url": "https://arxiv.org/pdf/2512.23709v1",
      "arxiv_url": "http://arxiv.org/abs/2512.23709v1",
      "published": "2025-12-29",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "Propensity Patchwork Kriging for Scalable Inference on Heterogeneous Treatment Effects",
      "authors": [
        "Hajime Ogawa",
        "Shonosuke Sugasawa"
      ],
      "abstract": "Gaussian process-based models are attractive for estimating heterogeneous treatment effects (HTE), but their computational cost limits scalability in causal inference settings. In this work, we address this challenge by extending Patchwork Kriging into the causal inference framework. Our proposed method partitions the data according to the estimated propensity score and applies Patchwork Kriging to enforce continuity of HTE estimates across adjacent regions. By imposing continuity constraints only along the propensity score dimension, rather than the full covariate space, the proposed approach substantially reduces computational cost while avoiding discontinuities inherent in simple local approximations. The resulting method can be interpreted as a smoothing extension of stratification and provides an efficient approach to HTE estimation. The proposed method is demonstrated through simulation studies and a real data application.",
      "pdf_url": "https://arxiv.org/pdf/2512.23467v1",
      "arxiv_url": "http://arxiv.org/abs/2512.23467v1",
      "published": "2025-12-29",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Probabilistic Modelling is Sufficient for Causal Inference",
      "authors": [
        "Bruno Mlodozeniec",
        "David Krueger",
        "Richard E. Turner"
      ],
      "abstract": "Causal inference is a key research area in machine learning, yet confusion reigns over the tools needed to tackle it. There are prevalent claims in the machine learning literature that you need a bespoke causal framework or notation to answer causal questions. In this paper, we want to make it clear that you \\emph{can} answer any causal inference question within the realm of probabilistic modelling and inference, without causal-specific tools or notation. Through concrete examples, we demonstrate how causal questions can be tackled by writing down the probability of everything. Lastly, we reinterpret causal tools as emerging from standard probabilistic modelling and inference, elucidating their necessity and utility.",
      "pdf_url": "https://arxiv.org/pdf/2512.23408v1",
      "arxiv_url": "http://arxiv.org/abs/2512.23408v1",
      "published": "2025-12-29",
      "categories": [
        "stat.ML",
        "cs.LG",
        "stat.ME"
      ]
    },
    {
      "title": "Is Chain-of-Thought Really Not Explainability? Chain-of-Thought Can Be Faithful without Hint Verbalization",
      "authors": [
        "Kerem Zaman",
        "Shashank Srivastava"
      ],
      "abstract": "Recent work, using the Biasing Features metric, labels a CoT as unfaithful if it omits a prompt-injected hint that affected the prediction. We argue this metric confuses unfaithfulness with incompleteness, the lossy compression needed to turn distributed transformer computation into a linear natural language narrative. On multi-hop reasoning tasks with Llama-3 and Gemma-3, many CoTs flagged as unfaithful by Biasing Features are judged faithful by other metrics, exceeding 50% in some models. With a new faithful@k metric, we show that larger inference-time token budgets greatly increase hint verbalization (up to 90% in some settings), suggesting much apparent unfaithfulness is due to tight token limits. Using Causal Mediation Analysis, we further show that even non-verbalized hints can causally mediate prediction changes through the CoT. We therefore caution against relying solely on hint-based evaluations and advocate a broader interpretability toolkit, including causal mediation and corruption-based metrics.",
      "pdf_url": "https://arxiv.org/pdf/2512.23032v1",
      "arxiv_url": "http://arxiv.org/abs/2512.23032v1",
      "published": "2025-12-28",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Causal-Policy Forest for End-to-End Policy Learning",
      "authors": [
        "Masahiro Kato"
      ],
      "abstract": "This study proposes an end-to-end algorithm for policy learning in causal inference. We observe data consisting of covariates, treatment assignments, and outcomes, where only the outcome corresponding to the assigned treatment is observed. The goal of policy learning is to train a policy from the observed data, where a policy is a function that recommends an optimal treatment for each individual, to maximize the policy value. In this study, we first show that maximizing the policy value is equivalent to minimizing the mean squared error for the conditional average treatment effect (CATE) under $\\{-1, 1\\}$ restricted regression models. Based on this finding, we modify the causal forest, an end-to-end CATE estimation algorithm, for policy learning. We refer to our algorithm as the causal-policy forest. Our algorithm has three advantages. First, it is a simple modification of an existing, widely used CATE estimation method, therefore, it helps bridge the gap between policy learning and CATE estimation in practice. Second, while existing studies typically estimate nuisance parameters for policy learning as a separate task, our algorithm trains the policy in a more end-to-end manner. Third, as in standard decision trees and random forests, we train the models efficiently, avoiding computational intractability.",
      "pdf_url": "https://arxiv.org/pdf/2512.22846v1",
      "arxiv_url": "http://arxiv.org/abs/2512.22846v1",
      "published": "2025-12-28",
      "categories": [
        "econ.EM",
        "cs.LG",
        "math.ST",
        "stat.ME",
        "stat.ML"
      ]
    },
    {
      "title": "WeDLM: Reconciling Diffusion Language Models with Standard Causal Attention for Fast Inference",
      "authors": [
        "Aiwei Liu",
        "Minghua He",
        "Shaoxun Zeng",
        "Sijun Zhang",
        "Linhao Zhang",
        "Chuhan Wu",
        "Wei Jia",
        "Yuan Liu",
        "Xiao Zhou",
        "Jie Zhou"
      ],
      "abstract": "Autoregressive (AR) generation is the standard decoding paradigm for Large Language Models (LLMs), but its token-by-token nature limits parallelism at inference time. Diffusion Language Models (DLLMs) offer parallel decoding by recovering multiple masked tokens per step; however, in practice they often fail to translate this parallelism into deployment speed gains over optimized AR engines (e.g., vLLM). A key reason is that many DLLMs rely on bidirectional attention, which breaks standard prefix KV caching and forces repeated contextualization, undermining efficiency. We propose WeDLM, a diffusion decoding framework built entirely on standard causal attention to make parallel generation prefix-cache friendly. The core idea is to let each masked position condition on all currently observed tokens while keeping a strict causal mask, achieved by Topological Reordering that moves observed tokens to the physical prefix while preserving their logical positions. Building on this property, we introduce a streaming decoding procedure that continuously commits confident tokens into a growing left-to-right prefix and maintains a fixed parallel workload, avoiding the stop-and-wait behavior common in block diffusion methods. Experiments show that WeDLM preserves the quality of strong AR backbones while delivering substantial speedups, approaching 3x on challenging reasoning benchmarks and up to 10x in low-entropy generation regimes; critically, our comparisons are against AR baselines served by vLLM under matched deployment settings, demonstrating that diffusion-style decoding can outperform an optimized AR engine in practice.",
      "pdf_url": "https://arxiv.org/pdf/2512.22737v1",
      "arxiv_url": "http://arxiv.org/abs/2512.22737v1",
      "published": "2025-12-28",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "title": "Lightweight Inference-Time Personalization for Frozen Knowledge Graph Embeddings",
      "authors": [
        "Ozan Oguztuzun",
        "Cerag Oguztuzun"
      ],
      "abstract": "Foundation models for knowledge graphs (KGs) achieve strong cohort-level performance in link prediction, yet fail to capture individual user preferences; a key disconnect between general relational reasoning and personalized ranking. We propose GatedBias, a lightweight inference-time personalization framework that adapts frozen KG embeddings to individual user contexts without retraining or compromising global accuracy. Our approach introduces structure-gated adaptation: profile-specific features combine with graph-derived binary gates to produce interpretable, per-entity biases, requiring only ${\\sim}300$ trainable parameters. We evaluate GatedBias on two benchmark datasets (Amazon-Book and Last-FM), demonstrating statistically significant improvements in alignment metrics while preserving cohort performance. Counterfactual perturbation experiments validate causal responsiveness; entities benefiting from specific preference signals show 6--30$\\times$ greater rank improvements when those signals are boosted. These results show that personalized adaptation of foundation models can be both parameter-efficient and causally verifiable, bridging general knowledge representations with individual user needs.",
      "pdf_url": "https://arxiv.org/pdf/2512.22398v1",
      "arxiv_url": "http://arxiv.org/abs/2512.22398v1",
      "published": "2025-12-26",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Knot Forcing: Taming Autoregressive Video Diffusion Models for Real-time Infinite Interactive Portrait Animation",
      "authors": [
        "Steven Xiao",
        "Xindi Zhang",
        "Dechao Meng",
        "Qi Wang",
        "Peng Zhang",
        "Bang Zhang"
      ],
      "abstract": "Real-time portrait animation is essential for interactive applications such as virtual assistants and live avatars, requiring high visual fidelity, temporal coherence, ultra-low latency, and responsive control from dynamic inputs like reference images and driving signals. While diffusion-based models achieve strong quality, their non-causal nature hinders streaming deployment. Causal autoregressive video generation approaches enable efficient frame-by-frame generation but suffer from error accumulation, motion discontinuities at chunk boundaries, and degraded long-term consistency. In this work, we present a novel streaming framework named Knot Forcing for real-time portrait animation that addresses these challenges through three key designs: (1) a chunk-wise generation strategy with global identity preservation via cached KV states of the reference image and local temporal modeling using sliding window attention; (2) a temporal knot module that overlaps adjacent chunks and propagates spatio-temporal cues via image-to-video conditioning to smooth inter-chunk motion transitions; and (3) A \"running ahead\" mechanism that dynamically updates the reference frame's temporal coordinate during inference, keeping its semantic context ahead of the current rollout frame to support long-term coherence. Knot Forcing enables high-fidelity, temporally consistent, and interactive portrait animation over infinite sequences, achieving real-time performance with strong visual stability on consumer-grade GPUs.",
      "pdf_url": "https://arxiv.org/pdf/2512.21734v2",
      "arxiv_url": "http://arxiv.org/abs/2512.21734v2",
      "published": "2025-12-25",
      "categories": [
        "cs.CV"
      ]
    }
  ]
}