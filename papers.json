{
  "last_updated": "2025-04-15T00:52:02.499309",
  "papers": [
    {
      "title": "PlugSelect: Pruning Channels with Plug-and-Play Flexibility for Electroencephalography-based Brain Computer Interface",
      "authors": [
        "Xue Yuan",
        "Keren Shi",
        "Ning Jiang",
        "Jiayuan He"
      ],
      "abstract": "Automatic minimization and optimization of the number of the electrodes is\nessential for the practical application of electroencephalography (EEG)-based\nbrain computer interface (BCI). Previous methods typically require additional\ntraining costs or rely on prior knowledge assumptions. This study proposed a\nnovel channel pruning model, plug-and-select (PlugSelect), applicable across a\nbroad range of BCI paradigms with no additional training cost and plug-and-play\nfunctionality. It integrates gradients along the input path to globally infer\nthe causal relationships between input channels and outputs, and ranks the\ncontribution sequences to identify the most highly attributed channels. The\nresults showed that for three BCI paradigms, i.e., auditory attention decoding\n(AAD), motor imagery (MI), affective computation (AC), PlugSelect could reduce\nthe number of channels by at least half while effectively maintaining decoding\nperformance and improving efficiency. The outcome benefits the design of\nwearable EEG-based devices, facilitating the practical application of BCI\ntechnology.",
      "pdf_url": "http://arxiv.org/pdf/2504.08486v1",
      "arxiv_url": "http://arxiv.org/abs/2504.08486v1",
      "published": "2025-04-11",
      "categories": [
        "cs.HC"
      ]
    },
    {
      "title": "Enhanced Marginal Sensitivity Model and Bounds",
      "authors": [
        "Yi Zhang",
        "Wenfu Xu",
        "Zhiqiang Tan"
      ],
      "abstract": "Sensitivity analysis is important to assess the impact of unmeasured\nconfounding in causal inference from observational studies. The marginal\nsensitivity model (MSM) provides a useful approach in quantifying the influence\nof unmeasured confounders on treatment assignment and leading to tractable\nsharp bounds of common causal parameters. In this paper, to tighten MSM sharp\nbounds, we propose the enhanced MSM (eMSM) by incorporating another sensitivity\nconstraint that quantifies the influence of unmeasured confounders on outcomes.\nWe derive sharp population bounds of expected potential outcomes under eMSM,\nwhich are always narrower than the MSM sharp bounds in a simple and\ninterpretable way. We further discuss desirable specifications of sensitivity\nparameters related to the outcome sensitivity constraint, and obtain both\ndoubly robust point estimation and confidence intervals for the eMSM population\nbounds. The effectiveness of eMSM is also demonstrated numerically through two\nreal-data applications. Our development represents, for the first time, a\nsatisfactory extension of MSM to exploit both treatment and outcome sensitivity\nconstraints on unmeasured confounding.",
      "pdf_url": "http://arxiv.org/pdf/2504.08301v1",
      "arxiv_url": "http://arxiv.org/abs/2504.08301v1",
      "published": "2025-04-11",
      "categories": [
        "stat.ME",
        "math.ST",
        "stat.TH"
      ]
    },
    {
      "title": "Causal attribution with confidence",
      "authors": [
        "Ping Zhang",
        "Ruoyu Wang",
        "Wang Miao"
      ],
      "abstract": "To answer questions of \"causes of effects\", the probability of necessity is\nintroduced for assessing whether or not an observed outcome was caused by an\nearlier treatment. However, the statistical inference for probability of\nnecessity is understudied due to several difficulties, which hinders its\napplication in practice. The evaluation of the probability of necessity\ninvolves the joint distribution of potential outcomes, and thus it is in\ngeneral not point identified and one can at best obtain lower and upper bounds\neven in randomized experiments, unless certain monotonicity assumptions on\npotential outcomes are made. Moreover, these bounds are non-smooth functionals\nof the observed data distribution and standard estimation and inference methods\ncannot be directly applied. In this paper, we investigate the statistical\ninference for the probability of necessity in general situations where it may\nnot be point identified. We introduce a mild margin condition to tackle the\nnon-smoothness, under which the bounds become pathwise differentiable. We\nestablish the semiparametric efficiency theory and propose novel asymptotically\nefficient estimators of the bounds, and further construct confidence intervals\nfor the probability of necessity based on the proposed bounds estimators. The\nresultant confidence intervals are less conservative than existing methods and\ncan effectively make use of the observed covariates.",
      "pdf_url": "http://arxiv.org/pdf/2504.08294v1",
      "arxiv_url": "http://arxiv.org/abs/2504.08294v1",
      "published": "2025-04-11",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "A roadmap for systematic identification and analysis of multiple biases in causal inference",
      "authors": [
        "Rushani Wijesuriya",
        "Rachael A. Hughes",
        "John B. Carlin",
        "Rachel L. Peters",
        "Jennifer J. Koplin",
        "Margarita Moreno-Betancur"
      ],
      "abstract": "Observational studies examining causal effects rely on unverifiable causal\nassumptions, the violation of which can induce multiple biases. Quantitative\nbias analysis (QBA) methods examine the sensitivity of findings to such\nviolations, generally by producing bias-adjusted estimates under alternative\nassumptions. Common strategies for QBA address either a single source of bias\nor multiple sources one at a time, thus not informing the overall impact of the\npotential biases. We propose a systematic approach (roadmap) for identifying\nand analysing multiple biases together. Briefly, this consists of (i)\narticulating the assumptions underlying the primary analysis through\nspecification and emulation of the \"ideal trial\" that defines the causal\nestimand of interest and depicting these assumptions using casual diagrams;\n(ii) depicting alternative assumptions under which biases arise using causal\ndiagrams; (iii) obtaining a single estimate simultaneously adjusted for all\nbiases under the alternative assumptions. We illustrate the roadmap in an\ninvestigation of the effect of breastfeeding on risk of childhood asthma. We\nfurther use simulations to evaluate a recent simultaneous adjustment approach\nand illustrate the need for simultaneous rather than one-at-a-time adjustment\nto examine the overall impact of biases. The proposed roadmap should facilitate\nthe conduct of high-quality multiple bias analyses.",
      "pdf_url": "http://arxiv.org/pdf/2504.08263v1",
      "arxiv_url": "http://arxiv.org/abs/2504.08263v1",
      "published": "2025-04-11",
      "categories": [
        "stat.ME",
        "stat.OT"
      ]
    },
    {
      "title": "STEI-PCN: an efficient pure convolutional network for traffic prediction via spatial-temporal encoding and inferring",
      "authors": [
        "Kai Hu",
        "Zhidan Zhao",
        "Zhifeng Hao"
      ],
      "abstract": "Traffic data exhibits complex temporal, spatial, and spatial-temporal\ncorrelations. Most of models use either independent modules to separately\nextract temporal and spatial correlations or joint modules to synchronously\nextract them, without considering the spatial-temporal correlations. Moreover,\nmodels that consider joint spatial-temporal correlations (temporal, spatial,\nand spatial-temporal correlations) often encounter significant challenges in\naccuracy and computational efficiency which prevent such models from\ndemonstrating the expected advantages of a joint spatial-temporal correlations\narchitecture. To address these issues, this paper proposes an efficient pure\nconvolutional network for traffic prediction via spatial-temporal encoding and\ninferring (STEI-PCN). The model introduces and designs a dynamic adjacency\nmatrix inferring module based on absolute spatial and temporal coordinates, as\nwell as relative spatial and temporal distance encoding, using a graph\nconvolutional network combined with gating mechanism to capture local\nsynchronous joint spatial-temporal correlations. Additionally, three layers of\ntemporal dilated causal convolutional network are used to capture long-range\ntemporal correlations. Finally, through multi-view collaborative prediction\nmodule, the model integrates the gated-activated original, local synchronous\njoint spatial-temporal, and long-range temporal features to achieve\ncomprehensive prediction. This study conducts extensive experiments on flow\ndatasets (PeMS03/04/07/08) and speed dataset (PeMS-Bay), covering multiple\nprediction horizons. The results show that STEI-PCN demonstrates competitive\ncomputational efficiency in both training and inference speeds, and achieves\nsuperior or slightly inferior to state-of-the-art (SOTA) models on most\nevaluation metrics.",
      "pdf_url": "http://arxiv.org/pdf/2504.08061v1",
      "arxiv_url": "http://arxiv.org/abs/2504.08061v1",
      "published": "2025-04-10",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Relaxing the Markov Requirements on Reinforcement Learning Under Weak Partial Ignorability",
      "authors": [
        "MaryLena Bleile"
      ],
      "abstract": "Incomplete data, confounding effects, and violations of the Markov property\nare interrelated problems which are ubiquitous in Reinforcement Learning\napplications. We introduce the concept of ``partial ignorabilty\" and leverage\nit to establish a novel convergence theorem for adaptive Reinforcement\nLearning. This theoretical result relaxes the Markov assumption on the\nstochastic process underlying conventional $Q$-learning, deploying a\ngeneralized form of the Robbins-Monro stochastic approximation theorem to\nestablish optimality. This result has clear downstream implications for most\nactive subfields of Reinforcement Learning, with clear paths for extension to\nthe field of Causal Inference.",
      "pdf_url": "http://arxiv.org/pdf/2504.07722v1",
      "arxiv_url": "http://arxiv.org/abs/2504.07722v1",
      "published": "2025-04-10",
      "categories": [
        "cs.LG",
        "stat.ME",
        "60G"
      ]
    },
    {
      "title": "Better Decisions through the Right Causal World Model",
      "authors": [
        "Elisabeth Dillies",
        "Quentin Delfosse",
        "Jannis Blüml",
        "Raban Emunds",
        "Florian Peter Busch",
        "Kristian Kersting"
      ],
      "abstract": "Reinforcement learning (RL) agents have shown remarkable performances in\nvarious environments, where they can discover effective policies directly from\nsensory inputs. However, these agents often exploit spurious correlations in\nthe training data, resulting in brittle behaviours that fail to generalize to\nnew or slightly modified environments. To address this, we introduce the Causal\nObject-centric Model Extraction Tool (COMET), a novel algorithm designed to\nlearn the exact interpretable causal world models (CWMs). COMET first extracts\nobject-centric state descriptions from observations and identifies the\nenvironment's internal states related to the depicted objects' properties.\nUsing symbolic regression, it models object-centric transitions and derives\ncausal relationships governing object dynamics. COMET further incorporates\nlarge language models (LLMs) for semantic inference, annotating causal\nvariables to enhance interpretability.\n  By leveraging these capabilities, COMET constructs CWMs that align with the\ntrue causal structure of the environment, enabling agents to focus on\ntask-relevant features. The extracted CWMs mitigate the danger of shortcuts,\npermitting the development of RL systems capable of better planning and\ndecision-making across dynamic scenarios. Our results, validated in Atari\nenvironments such as Pong and Freeway, demonstrate the accuracy and robustness\nof COMET, highlighting its potential to bridge the gap between object-centric\nreasoning and causal inference in reinforcement learning.",
      "pdf_url": "http://arxiv.org/pdf/2504.07257v1",
      "arxiv_url": "http://arxiv.org/abs/2504.07257v1",
      "published": "2025-04-09",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Causal Inference under Interference through Designed Markets",
      "authors": [
        "Evan Munro"
      ],
      "abstract": "Equilibrium effects make it challenging to evaluate the impact of an\nindividual-level treatment on outcomes in a single market, even with data from\na randomized trial. In some markets, however, a centralized mechanism allocates\ngoods and imposes useful structure on spillovers. For a class of strategy-proof\n\"cutoff\" mechanisms, we propose an estimator for global treatment effects using\nindividual-level data from one market, where treatment assignment is\nunconfounded. Algorithmically, we re-run a weighted and perturbed version of\nthe mechanism. Under a continuum market approximation, the estimator is\nasymptotically normal and semi-parametrically efficient. We extend this\napproach to learn spillover-aware treatment rules with vanishing asymptotic\nregret. Empirically, adjusting for equilibrium effects notably diminishes the\nestimated effect of information on inequality in the Chilean school system.",
      "pdf_url": "http://arxiv.org/pdf/2504.07217v1",
      "arxiv_url": "http://arxiv.org/abs/2504.07217v1",
      "published": "2025-04-09",
      "categories": [
        "econ.EM"
      ]
    },
    {
      "title": "Efficient Timestamping for Sampling-based Race Detection",
      "authors": [
        "Minjian Zhang",
        "Daniel Wee Soong Lim",
        "Mosaad Al Thokair",
        "Umang Mathur",
        "Mahesh Viswanathan"
      ],
      "abstract": "Dynamic race detection based on the happens before (HB) partial order has now\nbecome the de facto approach to quickly identify data races in multi-threaded\nsoftware. Most practical implementations for detecting these races use\ntimestamps to infer causality between events and detect races based on these\ntimestamps. Such an algorithm updates timestamps (stored in vector clocks) at\nevery event in the execution, and is known to induce excessive overhead. Random\nsampling has emerged as a promising algorithmic paradigm to offset this\noverhead. It offers the promise of making sound race detection scalable. In\nthis work we consider the task of designing an efficient sampling based race\ndetector with low overhead for timestamping when the number of sampled events\nis much smaller than the total events in an execution. To solve this problem,\nwe propose (1) a new notion of freshness timestamp, (2) a new data structure to\nstore timestamps, and (3) an algorithm that uses a combination of them to\nreduce the cost of timestamping in sampling based race detection. Further, we\nprove that our algorithm is close to optimal -- the number of vector clock\ntraversals is bounded by the number of sampled events and number of threads,\nand further, on any given dynamic execution, the cost of timestamping due to\nour algorithm is close to the amount of work any timestamping-based algorithm\nmust perform on that execution, that is it is instance optimal. Our evaluation\non real world benchmarks demonstrates the effectiveness of our proposed\nalgorithm over prior timestamping algorithms that are agnostic to sampling.",
      "pdf_url": "http://arxiv.org/pdf/2504.06688v1",
      "arxiv_url": "http://arxiv.org/abs/2504.06688v1",
      "published": "2025-04-09",
      "categories": [
        "cs.PL"
      ]
    },
    {
      "title": "A Streamable Neural Audio Codec with Residual Scalar-Vector Quantization for Real-Time Communication",
      "authors": [
        "Xiao-Hang Jiang",
        "Yang Ai",
        "Rui-Chen Zheng",
        "Zhen-Hua Ling"
      ],
      "abstract": "This paper proposes StreamCodec, a streamable neural audio codec designed for\nreal-time communication. StreamCodec adopts a fully causal, symmetric\nencoder-decoder structure and operates in the modified discrete cosine\ntransform (MDCT) domain, aiming for low-latency inference and real-time\nefficient generation. To improve codebook utilization efficiency and compensate\nfor the audio quality loss caused by structural causality, StreamCodec\nintroduces a novel residual scalar-vector quantizer (RSVQ). The RSVQ\nsequentially connects scalar quantizers and improved vector quantizers in a\nresidual manner, constructing coarse audio contours and refining acoustic\ndetails, respectively. Experimental results confirm that the proposed\nStreamCodec achieves decoded audio quality comparable to advanced\nnon-streamable neural audio codecs. Specifically, on the 16 kHz LibriTTS\ndataset, StreamCodec attains a ViSQOL score of 4.30 at 1.5 kbps. It has a fixed\nlatency of only 20 ms and achieves a generation speed nearly 20 times real-time\non a CPU, with a lightweight model size of just 7M parameters, making it highly\nsuitable for real-time communication applications.",
      "pdf_url": "http://arxiv.org/pdf/2504.06561v1",
      "arxiv_url": "http://arxiv.org/abs/2504.06561v1",
      "published": "2025-04-09",
      "categories": [
        "cs.SD"
      ]
    }
  ]
}