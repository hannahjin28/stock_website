{
  "last_updated": "2025-03-11T00:48:31.074312",
  "papers": [
    {
      "title": "Integration of aggregated data in causally interpretable meta-analysis by inverse weighting",
      "authors": [
        "Tat-Thang Vo",
        "Tran Trong Khoi Le",
        "Sivem Afach",
        "Stijn Vansteelandt"
      ],
      "abstract": "Obtaining causally interpretable meta-analysis results is challenging when\nthere are differences in the distribution of effect modifiers between eligible\ntrials. To overcome this, recent work on transportability methods has\nconsidered standardizing results of individual studies over the case-mix of a\ntarget population, prior to pooling them as in a classical random-effect\nmeta-analysis. One practical challenge, however, is that case-mix\nstandardization often requires individual participant data (IPD) on outcome,\ntreatments and case-mix characteristics to be fully accessible in every\neligible study, along with IPD case-mix characteristics for a random sample\nfrom the target population. In this paper, we aim to develop novel strategies\nto integrate aggregated-level data from eligible trials with non-accessible IPD\ninto a causal meta-analysis, by extending moment-based methods frequently used\nfor population-adjusted indirect comparison in health technology assessment.\nSince valid inference for these moment-based methods by M-estimation theory\nrequires additional aggregated data that are often unavailable in practice,\ncomputational methods to address this concern are also developed. We assess the\nfinite-sample performance of the proposed approaches by simulated data, and\nthen apply these on real-world clinical data to investigate the effectiveness\nof risankizumab versus ustekinumab among patients with moderate to severe\npsoriasis.",
      "pdf_url": "http://arxiv.org/pdf/2503.05634v1",
      "arxiv_url": "http://arxiv.org/abs/2503.05634v1",
      "published": "2025-03-07",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Riemannian Metric Learning: Closer to You than You Imagine",
      "authors": [
        "Samuel Gruffaz",
        "Josua Sassen"
      ],
      "abstract": "Riemannian metric learning is an emerging field in machine learning,\nunlocking new ways to encode complex data structures beyond traditional\ndistance metric learning. While classical approaches rely on global distances\nin Euclidean space, they often fall short in capturing intrinsic data geometry.\nEnter Riemannian metric learning: a powerful generalization that leverages\ndifferential geometry to model the data according to their underlying\nRiemannian manifold. This approach has demonstrated remarkable success across\ndiverse domains, from causal inference and optimal transport to generative\nmodeling and representation learning. In this review, we bridge the gap between\nclassical metric learning and Riemannian geometry, providing a structured and\naccessible overview of key methods, applications, and recent advances. We argue\nthat Riemannian metric learning is not merely a technical refinement but a\nfundamental shift in how we think about data representations. Thus, this review\nshould serve as a valuable resource for researchers and practitioners\ninterested in exploring Riemannian metric learning and convince them that it is\ncloser to them than they might imagine-both in theory and in practice.",
      "pdf_url": "http://arxiv.org/pdf/2503.05321v1",
      "arxiv_url": "http://arxiv.org/abs/2503.05321v1",
      "published": "2025-03-07",
      "categories": [
        "stat.ML",
        "cs.LG",
        "math.DG",
        "68T05 (Primary), 58D17 (Secondary)",
        "I.2.6"
      ]
    },
    {
      "title": "Frequency Autoregressive Image Generation with Continuous Tokens",
      "authors": [
        "Hu Yu",
        "Hao Luo",
        "Hangjie Yuan",
        "Yu Rong",
        "Feng Zhao"
      ],
      "abstract": "Autoregressive (AR) models for image generation typically adopt a two-stage\nparadigm of vector quantization and raster-scan ``next-token prediction\",\ninspired by its great success in language modeling. However, due to the huge\nmodality gap, image autoregressive models may require a systematic reevaluation\nfrom two perspectives: tokenizer format and regression direction. In this\npaper, we introduce the frequency progressive autoregressive (\\textbf{FAR})\nparadigm and instantiate FAR with the continuous tokenizer. Specifically, we\nidentify spectral dependency as the desirable regression direction for FAR,\nwherein higher-frequency components build upon the lower one to progressively\nconstruct a complete image. This design seamlessly fits the causality\nrequirement for autoregressive models and preserves the unique spatial locality\nof image data. Besides, we delve into the integration of FAR and the continuous\ntokenizer, introducing a series of techniques to address optimization\nchallenges and improve the efficiency of training and inference processes. We\ndemonstrate the efficacy of FAR through comprehensive experiments on the\nImageNet dataset and verify its potential on text-to-image generation.",
      "pdf_url": "http://arxiv.org/pdf/2503.05305v1",
      "arxiv_url": "http://arxiv.org/abs/2503.05305v1",
      "published": "2025-03-07",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Kernel-based estimators for functional causal effects",
      "authors": [
        "Yordan P. Raykov",
        "Hengrui Luo",
        "Justin D. Strait",
        "Wasiur R. KhudaBukhsh"
      ],
      "abstract": "We propose causal effect estimators based on empirical Fr\\'{e}chet means and\noperator-valued kernels, tailored to functional data spaces. These methods\naddress the challenges of high-dimensionality, sequential ordering, and model\ncomplexity while preserving robustness to treatment misspecification. Using\nstructural assumptions, we obtain compact representations of potential\noutcomes, enabling scalable estimation of causal effects over time and across\ncovariates. We provide both theoretical, regarding the consistency of\nfunctional causal effects, as well as empirical comparison of a range of\nproposed causal effect estimators.\n  Applications to binary treatment settings with functional outcomes illustrate\nthe framework's utility in biomedical monitoring, where outcomes exhibit\ncomplex temporal dynamics. Our estimators accommodate scenarios with registered\ncovariates and outcomes, aligning them to the Fr\\'{e}chet means, as well as\ncases requiring higher-order representations to capture intricate\ncovariate-outcome interactions. These advancements extend causal inference to\ndynamic and non-linear domains, offering new tools for understanding complex\ntreatment effects in functional data settings.",
      "pdf_url": "http://arxiv.org/pdf/2503.05024v1",
      "arxiv_url": "http://arxiv.org/abs/2503.05024v1",
      "published": "2025-03-06",
      "categories": [
        "stat.ME",
        "cs.LG",
        "math.ST",
        "stat.TH",
        "62G05",
        "G.3"
      ]
    },
    {
      "title": "Compositional Causal Reasoning Evaluation in Language Models",
      "authors": [
        "Jacqueline R. M. A. Maasch",
        "Alihan Hüyük",
        "Xinnuo Xu",
        "Aditya V. Nori",
        "Javier Gonzalez"
      ],
      "abstract": "Causal reasoning and compositional reasoning are two core aspirations in\ngenerative AI. Measuring the extent of these behaviors requires principled\nevaluation methods. We explore a unified perspective that considers both\nbehaviors simultaneously, termed compositional causal reasoning (CCR): the\nability to infer how causal measures compose and, equivalently, how causal\nquantities propagate through graphs. We instantiate a framework for the\nsystematic evaluation of CCR for the average treatment effect and the\nprobability of necessity and sufficiency. As proof of concept, we demonstrate\nthe design of CCR tasks for language models in the LLama, Phi, and GPT\nfamilies. On a math word problem, our framework revealed a range of\ntaxonomically distinct error patterns. Additionally, CCR errors increased with\nthe complexity of causal paths for all models except o1.",
      "pdf_url": "http://arxiv.org/pdf/2503.04556v1",
      "arxiv_url": "http://arxiv.org/abs/2503.04556v1",
      "published": "2025-03-06",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "A Spatiotemporal, Quasi-experimental Causal Inference Approach to Characterize the Effects of Global Plastic Waste Export and Burning on Air Quality Using Remotely Sensed Data",
      "authors": [
        "Ellen M. Considine",
        "Rachel C. Nethery"
      ],
      "abstract": "Open burning of plastic waste may pose a significant threat to global health\nby degrading air quality, but quantitative research on this problem -- crucial\nfor policy making -- has previously been stunted by lack of data. Critically,\nmany low- and middle-income countries, where open burning is of greatest\nconcern, have little to no air quality monitoring. Here, we propose an\napproach, at the intersection of modern causal inference and environmental data\nscience, to leverage remotely sensed data products combined with spatiotemporal\ncausal analytic techniques to evaluate the impact of large-scale plastic waste\npolicies on air quality. Throughout, we use the case study of Indonesia before\nand after 2018, when China halted its import of plastic waste, resulting in\ndiversion of this massive waste stream to other countries in the East Asia &\nPacific region, including Indonesia. We tailor cutting-edge statistical methods\nto this setting, estimating effects of the increase in plastic waste imports on\nfine particulate matter near waste dump sites in Indonesia and allowing effects\nto vary as a function of the site's proximity to ports (from which\ninternational plastic waste enters the country), which serves as an induced\ncontinuous exposure or \"dose\" of treatment. We observe a statistically\nsignificant increase in monthly fine particulate matter concentrations near\ndump sites after China's ban took effect (2018-2019) compared to concentrations\nexpected under business-as-usual (2012-2017), with increases ranging from\n0.76--1.72$\\mu$g/m$^3$ (15--34\\% of the World Health Organization's recommended\nlimit for exposure on an annual basis) depending on the site's port proximity,\nat sites with port proximity above the 20th quantile. Sites with lower port\nproximity had smaller and not statistically significant effects.",
      "pdf_url": "http://arxiv.org/pdf/2503.04491v1",
      "arxiv_url": "http://arxiv.org/abs/2503.04491v1",
      "published": "2025-03-06",
      "categories": [
        "stat.AP",
        "stat.ME"
      ]
    },
    {
      "title": "Causally Reliable Concept Bottleneck Models",
      "authors": [
        "Giovanni De Felice",
        "Arianna Casanova Flores",
        "Francesco De Santis",
        "Silvia Santini",
        "Johannes Schneider",
        "Pietro Barbiero",
        "Alberto Termine"
      ],
      "abstract": "Concept-based models are an emerging paradigm in deep learning that\nconstrains the inference process to operate through human-interpretable\nconcepts, facilitating explainability and human interaction. However, these\narchitectures, on par with popular opaque neural models, fail to account for\nthe true causal mechanisms underlying the target phenomena represented in the\ndata. This hampers their ability to support causal reasoning tasks, limits\nout-of-distribution generalization, and hinders the implementation of fairness\nconstraints. To overcome these issues, we propose \\emph{Causally reliable\nConcept Bottleneck Models} (C$^2$BMs), a class of concept-based architectures\nthat enforce reasoning through a bottleneck of concepts structured according to\na model of the real-world causal mechanisms. We also introduce a pipeline to\nautomatically learn this structure from observational data and\n\\emph{unstructured} background knowledge (e.g., scientific literature).\nExperimental evidence suggest that C$^2$BM are more interpretable, causally\nreliable, and improve responsiveness to interventions w.r.t. standard opaque\nand concept-based models, while maintaining their accuracy.",
      "pdf_url": "http://arxiv.org/pdf/2503.04363v1",
      "arxiv_url": "http://arxiv.org/abs/2503.04363v1",
      "published": "2025-03-06",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Large Language Models for Zero-shot Inference of Causal Structures in Biology",
      "authors": [
        "Izzy Newsham",
        "Luka Kovačević",
        "Richard Moulange",
        "Nan Rosemary Ke",
        "Sach Mukherjee"
      ],
      "abstract": "Genes, proteins and other biological entities influence one another via\ncausal molecular networks. Causal relationships in such networks are mediated\nby complex and diverse mechanisms, through latent variables, and are often\nspecific to cellular context. It remains challenging to characterise such\nnetworks in practice. Here, we present a novel framework to evaluate large\nlanguage models (LLMs) for zero-shot inference of causal relationships in\nbiology. In particular, we systematically evaluate causal claims obtained from\nan LLM using real-world interventional data. This is done over one hundred\nvariables and thousands of causal hypotheses. Furthermore, we consider several\nprompting and retrieval-augmentation strategies, including large, and\npotentially conflicting, collections of scientific articles. Our results show\nthat with tailored augmentation and prompting, even relatively small LLMs can\ncapture meaningful aspects of causal structure in biological systems. This\nsupports the notion that LLMs could act as orchestration tools in biological\ndiscovery, by helping to distil current knowledge in ways amenable to\ndownstream analysis. Our approach to assessing LLMs with respect to\nexperimental data is relevant for a broad range of problems at the intersection\nof causal learning, LLMs and scientific discovery.",
      "pdf_url": "http://arxiv.org/pdf/2503.04347v1",
      "arxiv_url": "http://arxiv.org/abs/2503.04347v1",
      "published": "2025-03-06",
      "categories": [
        "cs.LG",
        "q-bio.GN"
      ]
    },
    {
      "title": "LEDiT: Your Length-Extrapolatable Diffusion Transformer without Positional Encoding",
      "authors": [
        "Shen Zhang",
        "Yaning Tan",
        "Siyuan Liang",
        "Zhaowei Chen",
        "Linze Li",
        "Ge Wu",
        "Yuhao Chen",
        "Shuheng Li",
        "Zhenyu Zhao",
        "Caihua Chen",
        "Jiajun Liang",
        "Yao Tang"
      ],
      "abstract": "Diffusion transformers(DiTs) struggle to generate images at resolutions\nhigher than their training resolutions. The primary obstacle is that the\nexplicit positional encodings(PE), such as RoPE, need extrapolation which\ndegrades performance when the inference resolution differs from training. In\nthis paper, we propose a Length-Extrapolatable Diffusion Transformer(LEDiT), a\nsimple yet powerful architecture to overcome this limitation. LEDiT needs no\nexplicit PEs, thereby avoiding extrapolation. The key innovations of LEDiT are\nintroducing causal attention to implicitly impart global positional information\nto tokens, while enhancing locality to precisely distinguish adjacent tokens.\nExperiments on 256x256 and 512x512 ImageNet show that LEDiT can scale the\ninference resolution to 512x512 and 1024x1024, respectively, while achieving\nbetter image quality compared to current state-of-the-art length extrapolation\nmethods(NTK-aware, YaRN). Moreover, LEDiT achieves strong extrapolation\nperformance with just 100K steps of fine-tuning on a pretrained DiT,\ndemonstrating its potential for integration into existing text-to-image DiTs.\nProject page: https://shenzhang2145.github.io/ledit/",
      "pdf_url": "http://arxiv.org/pdf/2503.04344v2",
      "arxiv_url": "http://arxiv.org/abs/2503.04344v2",
      "published": "2025-03-06",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "Spatial-Temporal Perception with Causal Inference for Naturalistic Driving Action Recognition",
      "authors": [
        "Qing Chang",
        "Wei Dai",
        "Zhihao Shuai",
        "Limin Yu",
        "Yutao Yue"
      ],
      "abstract": "Naturalistic driving action recognition is essential for vehicle cabin\nmonitoring systems. However, the complexity of real-world backgrounds presents\nsignificant challenges for this task, and previous approaches have struggled\nwith practical implementation due to their limited ability to observe subtle\nbehavioral differences and effectively learn inter-frame features from video.\nIn this paper, we propose a novel Spatial-Temporal Perception (STP)\narchitecture that emphasizes both temporal information and spatial\nrelationships between key objects, incorporating a causal decoder to perform\nbehavior recognition and temporal action localization. Without requiring\nmultimodal input, STP directly extracts temporal and spatial distance features\nfrom RGB video clips. Subsequently, these dual features are jointly encoded by\nmaximizing the expected likelihood across all possible permutations of the\nfactorization order. By integrating temporal and spatial features at different\nscales, STP can perceive subtle behavioral changes in challenging scenarios.\nAdditionally, we introduce a causal-aware module to explore relationships\nbetween video frame features, significantly enhancing detection efficiency and\nperformance. We validate the effectiveness of our approach using two publicly\navailable driver distraction detection benchmarks. The results demonstrate that\nour framework achieves state-of-the-art performance.",
      "pdf_url": "http://arxiv.org/pdf/2503.04078v1",
      "arxiv_url": "http://arxiv.org/abs/2503.04078v1",
      "published": "2025-03-06",
      "categories": [
        "cs.CV"
      ]
    }
  ]
}