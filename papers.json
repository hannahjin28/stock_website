{
  "last_updated": "2025-04-16T00:52:09.895065",
  "papers": [
    {
      "title": "A Two-Stage Interpretable Matching Framework for Causal Inference",
      "authors": [
        "Sahil Shikalgar",
        "Md. Noor-E-Alam"
      ],
      "abstract": "Matching in causal inference from observational data aims to construct\ntreatment and control groups with similar distributions of covariates, thereby\nreducing confounding and ensuring an unbiased estimation of treatment effects.\nThis matched sample closely mimics a randomized controlled trial (RCT), thus\nimproving the quality of causal estimates. We introduce a novel Two-stage\nInterpretable Matching (TIM) framework for transparent and interpretable\ncovariate matching. In the first stage, we perform exact matching across all\navailable covariates. For treatment and control units without an exact match in\nthe first stage, we proceed to the second stage. Here, we iteratively refine\nthe matching process by removing the least significant confounder in each\niteration and attempting exact matching on the remaining covariates. We learn a\ndistance metric for the dropped covariates to quantify closeness to the\ntreatment unit(s) within the corresponding strata. We used these high- quality\nmatches to estimate the conditional average treatment effects (CATEs). To\nvalidate TIM, we conducted experiments on synthetic datasets with varying\nassociation structures and correlations. We assessed its performance by\nmeasuring bias in CATE estimation and evaluating multivariate overlap between\ntreatment and control groups before and after matching. Additionally, we apply\nTIM to a real-world healthcare dataset from the Centers for Disease Control and\nPrevention (CDC) to estimate the causal effect of high cholesterol on diabetes.\nOur results demonstrate that TIM improves CATE estimates, increases\nmultivariate overlap, and scales effectively to high-dimensional data, making\nit a robust tool for causal inference in observational data.",
      "pdf_url": "http://arxiv.org/pdf/2504.09635v1",
      "arxiv_url": "http://arxiv.org/abs/2504.09635v1",
      "published": "2025-04-13",
      "categories": [
        "cs.AI",
        "stat.ME"
      ]
    },
    {
      "title": "PlugSelect: Pruning Channels with Plug-and-Play Flexibility for Electroencephalography-based Brain Computer Interface",
      "authors": [
        "Xue Yuan",
        "Keren Shi",
        "Ning Jiang",
        "Jiayuan He"
      ],
      "abstract": "Automatic minimization and optimization of the number of the electrodes is\nessential for the practical application of electroencephalography (EEG)-based\nbrain computer interface (BCI). Previous methods typically require additional\ntraining costs or rely on prior knowledge assumptions. This study proposed a\nnovel channel pruning model, plug-and-select (PlugSelect), applicable across a\nbroad range of BCI paradigms with no additional training cost and plug-and-play\nfunctionality. It integrates gradients along the input path to globally infer\nthe causal relationships between input channels and outputs, and ranks the\ncontribution sequences to identify the most highly attributed channels. The\nresults showed that for three BCI paradigms, i.e., auditory attention decoding\n(AAD), motor imagery (MI), affective computation (AC), PlugSelect could reduce\nthe number of channels by at least half while effectively maintaining decoding\nperformance and improving efficiency. The outcome benefits the design of\nwearable EEG-based devices, facilitating the practical application of BCI\ntechnology.",
      "pdf_url": "http://arxiv.org/pdf/2504.08486v1",
      "arxiv_url": "http://arxiv.org/abs/2504.08486v1",
      "published": "2025-04-11",
      "categories": [
        "cs.HC"
      ]
    },
    {
      "title": "Enhanced Marginal Sensitivity Model and Bounds",
      "authors": [
        "Yi Zhang",
        "Wenfu Xu",
        "Zhiqiang Tan"
      ],
      "abstract": "Sensitivity analysis is important to assess the impact of unmeasured\nconfounding in causal inference from observational studies. The marginal\nsensitivity model (MSM) provides a useful approach in quantifying the influence\nof unmeasured confounders on treatment assignment and leading to tractable\nsharp bounds of common causal parameters. In this paper, to tighten MSM sharp\nbounds, we propose the enhanced MSM (eMSM) by incorporating another sensitivity\nconstraint that quantifies the influence of unmeasured confounders on outcomes.\nWe derive sharp population bounds of expected potential outcomes under eMSM,\nwhich are always narrower than the MSM sharp bounds in a simple and\ninterpretable way. We further discuss desirable specifications of sensitivity\nparameters related to the outcome sensitivity constraint, and obtain both\ndoubly robust point estimation and confidence intervals for the eMSM population\nbounds. The effectiveness of eMSM is also demonstrated numerically through two\nreal-data applications. Our development represents, for the first time, a\nsatisfactory extension of MSM to exploit both treatment and outcome sensitivity\nconstraints on unmeasured confounding.",
      "pdf_url": "http://arxiv.org/pdf/2504.08301v1",
      "arxiv_url": "http://arxiv.org/abs/2504.08301v1",
      "published": "2025-04-11",
      "categories": [
        "stat.ME",
        "math.ST",
        "stat.TH"
      ]
    },
    {
      "title": "Causal attribution with confidence",
      "authors": [
        "Ping Zhang",
        "Ruoyu Wang",
        "Wang Miao"
      ],
      "abstract": "To answer questions of \"causes of effects\", the probability of necessity is\nintroduced for assessing whether or not an observed outcome was caused by an\nearlier treatment. However, the statistical inference for probability of\nnecessity is understudied due to several difficulties, which hinders its\napplication in practice. The evaluation of the probability of necessity\ninvolves the joint distribution of potential outcomes, and thus it is in\ngeneral not point identified and one can at best obtain lower and upper bounds\neven in randomized experiments, unless certain monotonicity assumptions on\npotential outcomes are made. Moreover, these bounds are non-smooth functionals\nof the observed data distribution and standard estimation and inference methods\ncannot be directly applied. In this paper, we investigate the statistical\ninference for the probability of necessity in general situations where it may\nnot be point identified. We introduce a mild margin condition to tackle the\nnon-smoothness, under which the bounds become pathwise differentiable. We\nestablish the semiparametric efficiency theory and propose novel asymptotically\nefficient estimators of the bounds, and further construct confidence intervals\nfor the probability of necessity based on the proposed bounds estimators. The\nresultant confidence intervals are less conservative than existing methods and\ncan effectively make use of the observed covariates.",
      "pdf_url": "http://arxiv.org/pdf/2504.08294v1",
      "arxiv_url": "http://arxiv.org/abs/2504.08294v1",
      "published": "2025-04-11",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "A roadmap for systematic identification and analysis of multiple biases in causal inference",
      "authors": [
        "Rushani Wijesuriya",
        "Rachael A. Hughes",
        "John B. Carlin",
        "Rachel L. Peters",
        "Jennifer J. Koplin",
        "Margarita Moreno-Betancur"
      ],
      "abstract": "Observational studies examining causal effects rely on unverifiable causal\nassumptions, the violation of which can induce multiple biases. Quantitative\nbias analysis (QBA) methods examine the sensitivity of findings to such\nviolations, generally by producing bias-adjusted estimates under alternative\nassumptions. Common strategies for QBA address either a single source of bias\nor multiple sources one at a time, thus not informing the overall impact of the\npotential biases. We propose a systematic approach (roadmap) for identifying\nand analysing multiple biases together. Briefly, this consists of (i)\narticulating the assumptions underlying the primary analysis through\nspecification and emulation of the \"ideal trial\" that defines the causal\nestimand of interest and depicting these assumptions using casual diagrams;\n(ii) depicting alternative assumptions under which biases arise using causal\ndiagrams; (iii) obtaining a single estimate simultaneously adjusted for all\nbiases under the alternative assumptions. We illustrate the roadmap in an\ninvestigation of the effect of breastfeeding on risk of childhood asthma. We\nfurther use simulations to evaluate a recent simultaneous adjustment approach\nand illustrate the need for simultaneous rather than one-at-a-time adjustment\nto examine the overall impact of biases. The proposed roadmap should facilitate\nthe conduct of high-quality multiple bias analyses.",
      "pdf_url": "http://arxiv.org/pdf/2504.08263v1",
      "arxiv_url": "http://arxiv.org/abs/2504.08263v1",
      "published": "2025-04-11",
      "categories": [
        "stat.ME",
        "stat.OT"
      ]
    },
    {
      "title": "STEI-PCN: an efficient pure convolutional network for traffic prediction via spatial-temporal encoding and inferring",
      "authors": [
        "Kai Hu",
        "Zhidan Zhao",
        "Zhifeng Hao"
      ],
      "abstract": "Traffic data exhibits complex temporal, spatial, and spatial-temporal\ncorrelations. Most of models use either independent modules to separately\nextract temporal and spatial correlations or joint modules to synchronously\nextract them, without considering the spatial-temporal correlations. Moreover,\nmodels that consider joint spatial-temporal correlations (temporal, spatial,\nand spatial-temporal correlations) often encounter significant challenges in\naccuracy and computational efficiency which prevent such models from\ndemonstrating the expected advantages of a joint spatial-temporal correlations\narchitecture. To address these issues, this paper proposes an efficient pure\nconvolutional network for traffic prediction via spatial-temporal encoding and\ninferring (STEI-PCN). The model introduces and designs a dynamic adjacency\nmatrix inferring module based on absolute spatial and temporal coordinates, as\nwell as relative spatial and temporal distance encoding, using a graph\nconvolutional network combined with gating mechanism to capture local\nsynchronous joint spatial-temporal correlations. Additionally, three layers of\ntemporal dilated causal convolutional network are used to capture long-range\ntemporal correlations. Finally, through multi-view collaborative prediction\nmodule, the model integrates the gated-activated original, local synchronous\njoint spatial-temporal, and long-range temporal features to achieve\ncomprehensive prediction. This study conducts extensive experiments on flow\ndatasets (PeMS03/04/07/08) and speed dataset (PeMS-Bay), covering multiple\nprediction horizons. The results show that STEI-PCN demonstrates competitive\ncomputational efficiency in both training and inference speeds, and achieves\nsuperior or slightly inferior to state-of-the-art (SOTA) models on most\nevaluation metrics.",
      "pdf_url": "http://arxiv.org/pdf/2504.08061v1",
      "arxiv_url": "http://arxiv.org/abs/2504.08061v1",
      "published": "2025-04-10",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Double Machine Learning for Causal Inference under Shared-State Interference",
      "authors": [
        "Chris Hays",
        "Manish Raghavan"
      ],
      "abstract": "Researchers and practitioners often wish to measure treatment effects in\nsettings where units interact via markets and recommendation systems. In these\nsettings, units are affected by certain shared states, like prices, algorithmic\nrecommendations or social signals. We formalize this structure, calling it\nshared-state interference, and argue that our formulation captures many\nrelevant applied settings. Our key modeling assumption is that individuals'\npotential outcomes are independent conditional on the shared state. We then\nprove an extension of a double machine learning (DML) theorem providing\nconditions for achieving efficient inference under shared-state interference.\nWe also instantiate our general theorem in several models of interest where it\nis possible to efficiently estimate the average direct effect (ADE) or global\naverage treatment effect (GATE).",
      "pdf_url": "http://arxiv.org/pdf/2504.08836v1",
      "arxiv_url": "http://arxiv.org/abs/2504.08836v1",
      "published": "2025-04-10",
      "categories": [
        "stat.ML",
        "cs.LG",
        "econ.EM"
      ]
    },
    {
      "title": "Relaxing the Markov Requirements on Reinforcement Learning Under Weak Partial Ignorability",
      "authors": [
        "MaryLena Bleile"
      ],
      "abstract": "Incomplete data, confounding effects, and violations of the Markov property\nare interrelated problems which are ubiquitous in Reinforcement Learning\napplications. We introduce the concept of ``partial ignorabilty\" and leverage\nit to establish a novel convergence theorem for adaptive Reinforcement\nLearning. This theoretical result relaxes the Markov assumption on the\nstochastic process underlying conventional $Q$-learning, deploying a\ngeneralized form of the Robbins-Monro stochastic approximation theorem to\nestablish optimality. This result has clear downstream implications for most\nactive subfields of Reinforcement Learning, with clear paths for extension to\nthe field of Causal Inference.",
      "pdf_url": "http://arxiv.org/pdf/2504.07722v1",
      "arxiv_url": "http://arxiv.org/abs/2504.07722v1",
      "published": "2025-04-10",
      "categories": [
        "cs.LG",
        "stat.ME",
        "60G"
      ]
    },
    {
      "title": "Better Decisions through the Right Causal World Model",
      "authors": [
        "Elisabeth Dillies",
        "Quentin Delfosse",
        "Jannis Blüml",
        "Raban Emunds",
        "Florian Peter Busch",
        "Kristian Kersting"
      ],
      "abstract": "Reinforcement learning (RL) agents have shown remarkable performances in\nvarious environments, where they can discover effective policies directly from\nsensory inputs. However, these agents often exploit spurious correlations in\nthe training data, resulting in brittle behaviours that fail to generalize to\nnew or slightly modified environments. To address this, we introduce the Causal\nObject-centric Model Extraction Tool (COMET), a novel algorithm designed to\nlearn the exact interpretable causal world models (CWMs). COMET first extracts\nobject-centric state descriptions from observations and identifies the\nenvironment's internal states related to the depicted objects' properties.\nUsing symbolic regression, it models object-centric transitions and derives\ncausal relationships governing object dynamics. COMET further incorporates\nlarge language models (LLMs) for semantic inference, annotating causal\nvariables to enhance interpretability.\n  By leveraging these capabilities, COMET constructs CWMs that align with the\ntrue causal structure of the environment, enabling agents to focus on\ntask-relevant features. The extracted CWMs mitigate the danger of shortcuts,\npermitting the development of RL systems capable of better planning and\ndecision-making across dynamic scenarios. Our results, validated in Atari\nenvironments such as Pong and Freeway, demonstrate the accuracy and robustness\nof COMET, highlighting its potential to bridge the gap between object-centric\nreasoning and causal inference in reinforcement learning.",
      "pdf_url": "http://arxiv.org/pdf/2504.07257v1",
      "arxiv_url": "http://arxiv.org/abs/2504.07257v1",
      "published": "2025-04-09",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Causal Inference under Interference through Designed Markets",
      "authors": [
        "Evan Munro"
      ],
      "abstract": "Equilibrium effects make it challenging to evaluate the impact of an\nindividual-level treatment on outcomes in a single market, even with data from\na randomized trial. In some markets, however, a centralized mechanism allocates\ngoods and imposes useful structure on spillovers. For a class of strategy-proof\n\"cutoff\" mechanisms, we propose an estimator for global treatment effects using\nindividual-level data from one market, where treatment assignment is\nunconfounded. Algorithmically, we re-run a weighted and perturbed version of\nthe mechanism. Under a continuum market approximation, the estimator is\nasymptotically normal and semi-parametrically efficient. We extend this\napproach to learn spillover-aware treatment rules with vanishing asymptotic\nregret. Empirically, adjusting for equilibrium effects notably diminishes the\nestimated effect of information on inequality in the Chilean school system.",
      "pdf_url": "http://arxiv.org/pdf/2504.07217v1",
      "arxiv_url": "http://arxiv.org/abs/2504.07217v1",
      "published": "2025-04-09",
      "categories": [
        "econ.EM"
      ]
    }
  ]
}