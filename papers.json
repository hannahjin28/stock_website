{
  "last_updated": "2025-07-10T00:56:38.761485",
  "papers": [
    {
      "title": "PromiseTune: Unveiling Causally Promising and Explainable Configuration Tuning",
      "authors": [
        "Pengzhou Chen",
        "Tao Chen"
      ],
      "abstract": "The high configurability of modern software systems has made configuration\ntuning a crucial step for assuring system performance, e.g., latency or\nthroughput. However, given the expensive measurements, large configuration\nspace, and rugged configuration landscape, existing tuners suffer\nineffectiveness due to the difficult balance of budget utilization between\nexploring uncertain regions (for escaping from local optima) and exploiting\nguidance of known good configurations (for fast convergence). The root cause is\nthat we lack knowledge of where the promising regions lay, which also causes\nchallenges in the explainability of the results.\n  In this paper, we propose PromiseTune that tunes configuration guided by\ncausally purified rules. PromiseTune is unique in the sense that we learn\nrules, which reflect certain regions in the configuration landscape, and purify\nthem with causal inference. The remaining rules serve as approximated\nreflections of the promising regions, bounding the tuning to emphasize these\nplaces in the landscape. This, as we demonstrate, can effectively mitigate the\nimpact of the exploration and exploitation trade-off. Those purified regions\ncan then be paired with the measured configurations to provide spatial\nexplainability at the landscape level. Comparing with 11 state-of-the-art\ntuners on 12 systems and varying budgets, we show that PromiseTune performs\nsignificantly better than the others with $42\\%$ superior rank to the overall\nsecond best while providing richer information to explain the hidden system\ncharacteristics.",
      "pdf_url": "http://arxiv.org/pdf/2507.05995v1",
      "arxiv_url": "http://arxiv.org/abs/2507.05995v1",
      "published": "2025-07-08",
      "categories": [
        "cs.SE",
        "68Nxx",
        "D.2.0; D.2.8"
      ]
    },
    {
      "title": "Estimating Interventional Distributions with Uncertain Causal Graphs through Meta-Learning",
      "authors": [
        "Anish Dhir",
        "Cristiana Diaconu",
        "Valentinian Mihai Lungu",
        "James Requeima",
        "Richard E. Turner",
        "Mark van der Wilk"
      ],
      "abstract": "In scientific domains -- from biology to the social sciences -- many\nquestions boil down to \\textit{What effect will we observe if we intervene on a\nparticular variable?} If the causal relationships (e.g.~a causal graph) are\nknown, it is possible to estimate the intervention distributions. In the\nabsence of this domain knowledge, the causal structure must be discovered from\nthe available observational data. However, observational data are often\ncompatible with multiple causal graphs, making methods that commit to a single\nstructure prone to overconfidence. A principled way to manage this structural\nuncertainty is via Bayesian inference, which averages over a posterior\ndistribution on possible causal structures and functional mechanisms.\nUnfortunately, the number of causal structures grows super-exponentially with\nthe number of nodes in the graph, making computations intractable. We propose\nto circumvent these challenges by using meta-learning to create an end-to-end\nmodel: the Model-Averaged Causal Estimation Transformer Neural Process\n(MACE-TNP). The model is trained to predict the Bayesian model-averaged\ninterventional posterior distribution, and its end-to-end nature bypasses the\nneed for expensive calculations. Empirically, we demonstrate that MACE-TNP\noutperforms strong Bayesian baselines. Our work establishes meta-learning as a\nflexible and scalable paradigm for approximating complex Bayesian causal\ninference, that can be scaled to increasingly challenging settings in the\nfuture.",
      "pdf_url": "http://arxiv.org/pdf/2507.05526v1",
      "arxiv_url": "http://arxiv.org/abs/2507.05526v1",
      "published": "2025-07-07",
      "categories": [
        "cs.LG",
        "stat.ME",
        "stat.ML"
      ]
    },
    {
      "title": "Identification of Causal Effects with a Bunching Design",
      "authors": [
        "Carolina Caetano",
        "Gregorio Caetano",
        "Leonard Goff",
        "Eric Nielsen"
      ],
      "abstract": "We show that causal effects can be identified when there is bunching in the\ndistribution of a continuous treatment variable, without imposing any\nparametric assumptions. This yields a new nonparametric method for overcoming\nselection bias in the absence of instrumental variables, panel data, or other\npopular research designs for causal inference. The method leverages the change\nof variables theorem from integration theory, relating the selection bias to\nthe ratio of the density of the treatment and the density of the part of the\noutcome that varies with confounders. At the bunching point, the treatment\nlevel is constant, so the variation in the outcomes is due entirely to\nunobservables, allowing us to identify the denominator. Our main result\nidentifies the average causal response to the treatment among individuals who\nmarginally select into the bunching point. We further show that under\nadditional smoothness assumptions on the selection bias, treatment effects away\nfrom the bunching point may also be identified. We propose estimators based on\nstandard software packages and apply the method to estimate the effect of\nmaternal smoking during pregnancy on birth weight.",
      "pdf_url": "http://arxiv.org/pdf/2507.05210v1",
      "arxiv_url": "http://arxiv.org/abs/2507.05210v1",
      "published": "2025-07-07",
      "categories": [
        "econ.EM"
      ]
    },
    {
      "title": "Practical considerations for Gaussian Process modeling for causal inference quasi-experimental studies with panel data",
      "authors": [
        "Sofia L. Vega",
        "Rachel C. Nethery"
      ],
      "abstract": "Estimating causal effects in quasi-experiments with spatio-temporal panel\ndata often requires adjusting for unmeasured confounding that varies across\nspace and time. Gaussian Processes (GPs) offer a flexible, nonparametric\nmodeling approach that can account for such complex dependencies through\ncarefully chosen covariance kernels. In this paper, we provide a practical and\ninterpretable framework for applying GPs to causal inference in panel data\nsettings. We demonstrate how GPs generalize popular methods such as synthetic\ncontrol and vertical regression, and we show that the GP posterior mean can be\nrepresented as a weighted average of observed outcomes, where the weights\nreflect spatial and temporal similarity. To support applied use, we explore how\ndifferent kernel choices impact both estimation performance and\ninterpretability, offering guidance for selecting between separable and\nnonseparable kernels. Through simulations and application to Hurricane Katrina\nmortality data, we illustrate how GP models can be used to estimate\ncounterfactual outcomes and quantify treatment effects. All code and materials\nare made publicly available to support reproducibility and encourage adoption.\nOur results suggest that GPs are a promising and interpretable tool for\naddressing unmeasured spatio-temporal confounding in quasi-experimental\nstudies.",
      "pdf_url": "http://arxiv.org/pdf/2507.05128v1",
      "arxiv_url": "http://arxiv.org/abs/2507.05128v1",
      "published": "2025-07-07",
      "categories": [
        "stat.ME",
        "stat.AP"
      ]
    },
    {
      "title": "Boosting Temporal Sentence Grounding via Causal Inference",
      "authors": [
        "Kefan Tang",
        "Lihuo He",
        "Jisheng Dang",
        "Xinbo Gao"
      ],
      "abstract": "Temporal Sentence Grounding (TSG) aims to identify relevant moments in an\nuntrimmed video that semantically correspond to a given textual query. Despite\nexisting studies having made substantial progress, they often overlook the\nissue of spurious correlations between video and textual queries. These\nspurious correlations arise from two primary factors: (1) inherent biases in\nthe textual data, such as frequent co-occurrences of specific verbs or phrases,\nand (2) the model's tendency to overfit to salient or repetitive patterns in\nvideo content. Such biases mislead the model into associating textual cues with\nincorrect visual moments, resulting in unreliable predictions and poor\ngeneralization to out-of-distribution examples. To overcome these limitations,\nwe propose a novel TSG framework, causal intervention and counterfactual\nreasoning that utilizes causal inference to eliminate spurious correlations and\nenhance the model's robustness. Specifically, we first formulate the TSG task\nfrom a causal perspective with a structural causal model. Then, to address\nunobserved confounders reflecting textual biases toward specific verbs or\nphrases, a textual causal intervention is proposed, utilizing do-calculus to\nestimate the causal effects. Furthermore, visual counterfactual reasoning is\nperformed by constructing a counterfactual scenario that focuses solely on\nvideo features, excluding the query and fused multi-modal features. This allows\nus to debias the model by isolating and removing the influence of the video\nfrom the overall effect. Experiments on public datasets demonstrate the\nsuperiority of the proposed method. The code is available at\nhttps://github.com/Tangkfan/CICR.",
      "pdf_url": "http://arxiv.org/pdf/2507.04958v1",
      "arxiv_url": "http://arxiv.org/abs/2507.04958v1",
      "published": "2025-07-07",
      "categories": [
        "cs.CV",
        "cs.MM"
      ]
    },
    {
      "title": "A validity-guided workflow for robust large language model research in psychology",
      "authors": [
        "Zhicheng Lin"
      ],
      "abstract": "Large language models (LLMs) are rapidly being integrated into psychological\nresearch as research tools, evaluation targets, human simulators, and cognitive\nmodels. However, recent evidence reveals severe measurement unreliability:\nPersonality assessments collapse under factor analysis, moral preferences\nreverse with punctuation changes, and theory-of-mind accuracy varies widely\nwith trivial rephrasing. These \"measurement phantoms\"--statistical artifacts\nmasquerading as psychological phenomena--threaten the validity of a growing\nbody of research. Guided by the dual-validity framework that integrates\npsychometrics with causal inference, we present a six-stage workflow that\nscales validity requirements to research ambition--using LLMs to code text\nrequires basic reliability and accuracy, while claims about psychological\nproperties demand comprehensive construct validation. Researchers must (1)\nexplicitly define their research goal and corresponding validity requirements,\n(2) develop and validate computational instruments through psychometric\ntesting, (3) design experiments that control for computational confounds, (4)\nexecute protocols with transparency, (5) analyze data using methods appropriate\nfor non-independent observations, and (6) report findings within demonstrated\nboundaries and use results to refine theory. We illustrate the workflow through\nan example of model evaluation--\"LLM selfhood\"--showing how systematic\nvalidation can distinguish genuine computational phenomena from measurement\nartifacts. By establishing validated computational instruments and transparent\npractices, this workflow provides a path toward building a robust empirical\nfoundation for AI psychology research.",
      "pdf_url": "http://arxiv.org/pdf/2507.04491v1",
      "arxiv_url": "http://arxiv.org/abs/2507.04491v1",
      "published": "2025-07-06",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ]
    },
    {
      "title": "Long-Context Modeling Networks for Monaural Speech Enhancement: A Comparative Study",
      "authors": [
        "Qiquan Zhang",
        "Moran Chen",
        "Zeyang Song",
        "Hexin Liu",
        "Xiangyu Zhang",
        "Haizhou Li"
      ],
      "abstract": "Advanced long-context modeling backbone networks, such as Transformer,\nConformer, and Mamba, have demonstrated state-of-the-art performance in speech\nenhancement. However, a systematic and comprehensive comparative study of these\nbackbones within a unified speech enhancement framework remains lacking. In\naddition, xLSTM, a more recent and efficient variant of LSTM, has shown\npromising results in language modeling and as a general-purpose vision\nbackbone. In this paper, we investigate the capability of xLSTM in speech\nenhancement, and conduct a comprehensive comparison and analysis of the\nTransformer, Conformer, Mamba, and xLSTM backbones within a unified framework,\nconsidering both causal and noncausal configurations. Overall, xLSTM and Mamba\nachieve better performance than Transformer and Conformer. Mamba demonstrates\nsignificantly superior training and inference efficiency, particularly for long\nspeech inputs, whereas xLSTM suffers from the slowest processing speed.",
      "pdf_url": "http://arxiv.org/pdf/2507.04368v1",
      "arxiv_url": "http://arxiv.org/abs/2507.04368v1",
      "published": "2025-07-06",
      "categories": [
        "eess.AS"
      ]
    },
    {
      "title": "Deconfounding Causal Inference through Two-Branch Framework with Early-Forking for Sensor-Based Cross-Domain Activity Recognition",
      "authors": [
        "Di Xiong",
        "Lei Zhang",
        "Shuoyuan Wang",
        "Dongzhou Cheng",
        "Wenbo Huang"
      ],
      "abstract": "Recently, domain generalization (DG) has emerged as a promising solution to\nmitigate distribution-shift issue in sensor-based human activity recognition\n(HAR) scenario. However, most existing DG-based works have merely focused on\nmodeling statistical dependence between sensor data and activity labels,\nneglecting the importance of intrinsic casual mechanism. Intuitively, every\nsensor input can be viewed as a mixture of causal (category-aware) and\nnon-causal factors (domain-specific), where only the former affects activity\nclassification judgment. In this paper, by casting such DG-based HAR as a\ncasual inference problem, we propose a causality-inspired representation\nlearning algorithm for cross-domain activity recognition. To this end, an\nearly-forking two-branch framework is designed, where two separate branches are\nrespectively responsible for learning casual and non-causal features, while an\nindependence-based Hilbert-Schmidt Information Criterion is employed to\nimplicitly disentangling them. Additionally, an inhomogeneous domain sampling\nstrategy is designed to enhance disentanglement, while a category-aware domain\nperturbation layer is performed to prevent representation collapse. Extensive\nexperiments on several public HAR benchmarks demonstrate that our\ncausality-inspired approach significantly outperforms eleven related\nstate-of-the-art baselines under cross-person, cross-dataset, and\ncross-position settings. Detailed ablation and visualizations analyses reveal\nunderlying casual mechanism, indicating its effectiveness, efficiency, and\nuniversality in cross-domain activity recognition scenario.",
      "pdf_url": "http://arxiv.org/pdf/2507.03898v1",
      "arxiv_url": "http://arxiv.org/abs/2507.03898v1",
      "published": "2025-07-05",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "GenAI-Powered Inference",
      "authors": [
        "Kosuke Imai",
        "Kentaro Nakamura"
      ],
      "abstract": "We introduce GenAI-Powered Inference (GPI), a statistical framework for both\ncausal and predictive inference using unstructured data, including text and\nimages. GPI leverages open-source Generative Artificial Intelligence (GenAI)\nmodels - such as large language models and diffusion models - not only to\ngenerate unstructured data at scale but also to extract low-dimensional\nrepresentations that capture their underlying structure. Applying machine\nlearning to these representations, GPI enables estimation of causal and\npredictive effects while quantifying associated estimation uncertainty. Unlike\nexisting approaches to representation learning, GPI does not require\nfine-tuning of generative models, making it computationally efficient and\nbroadly accessible. We illustrate the versatility of the GPI framework through\nthree applications: (1) analyzing Chinese social media censorship, (2)\nestimating predictive effects of candidates' facial appearance on electoral\noutcomes, and (3) assessing the persuasiveness of political rhetoric. An\nopen-source software package is available for implementing GPI.",
      "pdf_url": "http://arxiv.org/pdf/2507.03897v1",
      "arxiv_url": "http://arxiv.org/abs/2507.03897v1",
      "published": "2025-07-05",
      "categories": [
        "cs.LG",
        "stat.ME",
        "stat.ML"
      ]
    },
    {
      "title": "Enhancing Uncertainty Quantification for Runtime Safety Assurance Using Causal Risk Analysis and Operational Design Domain",
      "authors": [
        "Radouane Bouchekir",
        "Michell Guzman Cancimance"
      ],
      "abstract": "Ensuring the runtime safety of autonomous systems remains challenging due to\ndeep learning components' inherent uncertainty and their sensitivity to\nenvironmental changes. In this paper, we propose an enhancement of traditional\nuncertainty quantification by explicitly incorporating environmental conditions\nusing risk-based causal analysis. We leverage Hazard Analysis and Risk\nAssessment (HARA) and fault tree modeling to identify critical operational\nconditions affecting system functionality. These conditions, together with\nuncertainties from the data and model, are integrated into a unified Bayesian\nNetwork (BN). At runtime, this BN is instantiated using real-time environmental\nobservations to infer a probabilistic distribution over the safety estimation.\nThis distribution enables the computation of both expected performance and its\nassociated variance, providing a dynamic and context-aware measure of\nuncertainty. We demonstrate our approach through a case study of the Object\nDetection (OD) component in an Automated Valet Parking (AVP).",
      "pdf_url": "http://arxiv.org/pdf/2507.03515v1",
      "arxiv_url": "http://arxiv.org/abs/2507.03515v1",
      "published": "2025-07-04",
      "categories": [
        "cs.SE"
      ]
    }
  ]
}