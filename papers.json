{
  "last_updated": "2025-07-04T00:55:22.512397",
  "papers": [
    {
      "title": "Reasoning to Edit: Hypothetical Instruction-Based Image Editing with Visual Reasoning",
      "authors": [
        "Qingdong He",
        "Xueqin Chen",
        "Chaoyi Wang",
        "Yanjie Pan",
        "Xiaobin Hu",
        "Zhenye Gan",
        "Yabiao Wang",
        "Chengjie Wang",
        "Xiangtai Li",
        "Jiangning Zhang"
      ],
      "abstract": "Instruction-based image editing (IIE) has advanced rapidly with the success\nof diffusion models. However, existing efforts primarily focus on simple and\nexplicit instructions to execute editing operations such as adding, deleting,\nmoving, or swapping objects. They struggle to handle more complex implicit\nhypothetical instructions that require deeper reasoning to infer plausible\nvisual changes and user intent. Additionally, current datasets provide limited\nsupport for training and evaluating reasoning-aware editing capabilities.\nArchitecturally, these methods also lack mechanisms for fine-grained detail\nextraction that support such reasoning. To address these limitations, we\npropose Reason50K, a large-scale dataset specifically curated for training and\nevaluating hypothetical instruction reasoning image editing, along with\nReasonBrain, a novel framework designed to reason over and execute implicit\nhypothetical instructions across diverse scenarios. Reason50K includes over 50K\nsamples spanning four key reasoning scenarios: Physical, Temporal, Causal, and\nStory reasoning. ReasonBrain leverages Multimodal Large Language Models (MLLMs)\nfor editing guidance generation and a diffusion model for image synthesis,\nincorporating a Fine-grained Reasoning Cue Extraction (FRCE) module to capture\ndetailed visual and textual semantics essential for supporting instruction\nreasoning. To mitigate the semantic loss, we further introduce a Cross-Modal\nEnhancer (CME) that enables rich interactions between the fine-grained cues and\nMLLM-derived features. Extensive experiments demonstrate that ReasonBrain\nconsistently outperforms state-of-the-art baselines on reasoning scenarios\nwhile exhibiting strong zero-shot generalization to conventional IIE tasks. Our\ndataset and code will be released publicly.",
      "pdf_url": "http://arxiv.org/pdf/2507.01908v1",
      "arxiv_url": "http://arxiv.org/abs/2507.01908v1",
      "published": "2025-07-02",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "HOI-Dyn: Learning Interaction Dynamics for Human-Object Motion Diffusion",
      "authors": [
        "Lin Wu",
        "Zhixiang Chen",
        "Jianglin Lan"
      ],
      "abstract": "Generating realistic 3D human-object interactions (HOIs) remains a\nchallenging task due to the difficulty of modeling detailed interaction\ndynamics. Existing methods treat human and object motions independently,\nresulting in physically implausible and causally inconsistent behaviors. In\nthis work, we present HOI-Dyn, a novel framework that formulates HOI generation\nas a driver-responder system, where human actions drive object responses. At\nthe core of our method is a lightweight transformer-based interaction dynamics\nmodel that explicitly predicts how objects should react to human motion. To\nfurther enforce consistency, we introduce a residual-based dynamics loss that\nmitigates the impact of dynamics prediction errors and prevents misleading\noptimization signals. The dynamics model is used only during training,\npreserving inference efficiency. Through extensive qualitative and quantitative\nexperiments, we demonstrate that our approach not only enhances the quality of\nHOI generation but also establishes a feasible metric for evaluating the\nquality of generated interactions.",
      "pdf_url": "http://arxiv.org/pdf/2507.01737v2",
      "arxiv_url": "http://arxiv.org/abs/2507.01737v2",
      "published": "2025-07-02",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "Relational Causal Discovery with Latent Confounders",
      "authors": [
        "Andrea Piras",
        "Matteo Negro",
        "Ragib Ahsan",
        "David Arbour",
        "Elena Zheleva"
      ],
      "abstract": "Estimating causal effects from real-world relational data can be challenging\nwhen the underlying causal model and potential confounders are unknown. While\nseveral causal discovery algorithms exist for learning causal models with\nlatent confounders from data, they assume that the data is independent and\nidentically distributed (i.i.d.) and are not well-suited for learning from\nrelational data. Similarly, existing relational causal discovery algorithms\nassume causal sufficiency, which is unrealistic for many real-world datasets.\nTo address this gap, we propose RelFCI, a sound and complete causal discovery\nalgorithm for relational data with latent confounders. Our work builds upon the\nFast Causal Inference (FCI) and Relational Causal Discovery (RCD) algorithms\nand it defines new graphical models, necessary to support causal discovery in\nrelational domains. We also establish soundness and completeness guarantees for\nrelational d-separation with latent confounders. We present experimental\nresults demonstrating the effectiveness of RelFCI in identifying the correct\ncausal structure in relational causal models with latent confounders.",
      "pdf_url": "http://arxiv.org/pdf/2507.01700v1",
      "arxiv_url": "http://arxiv.org/abs/2507.01700v1",
      "published": "2025-07-02",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "rdhte: Conditional Average Treatment Effects in RD Designs",
      "authors": [
        "Sebastian Calonico",
        "Matias D. Cattaneo",
        "Max H. Farrell",
        "Filippo Palomba",
        "Rocio Titiunik"
      ],
      "abstract": "Understanding causal heterogeneous treatment effects based on pretreatment\ncovariates is a crucial aspect of empirical work. Building on Calonico,\nCattaneo, Farrell, Palomba, and Titiunik (2025), this article discusses the\nsoftware package rdhte for estimation and inference of heterogeneous treatment\neffects in sharp regression discontinuity (RD) designs. The package includes\nthree main commands: rdhte conducts estimation and robust bias-corrected\ninference for heterogeneous RD treatment effects, for a given choice of the\nbandwidth parameter; rdbwhte implements automatic bandwidth selection methods;\nand rdhte lincom computes point estimates and robust bias-corrected confidence\nintervals for linear combinations, a post-estimation command specifically\ntailored to rdhte. We also provide an overview of heterogeneous effects for\nsharp RD designs, give basic details on the methodology, and illustrate using\nan empirical application. Finally, we discuss how the package rdhte\ncomplements, and in specific cases recovers, the canonical RD package rdrobust\n(Calonico, Cattaneo, Farrell, and Titiunik 2017).",
      "pdf_url": "http://arxiv.org/pdf/2507.01128v1",
      "arxiv_url": "http://arxiv.org/abs/2507.01128v1",
      "published": "2025-07-01",
      "categories": [
        "econ.EM"
      ]
    },
    {
      "title": "Bayesian analysis of the causal reference-based model for missing data in clinical trials",
      "authors": [
        "Brendah Nansereko",
        "Marcel Wolbers",
        "James Carpenter",
        "Jonathan Bartlett"
      ],
      "abstract": "The statistical analysis of clinical trials is often complicated by missing\ndata. Patients sometimes experience intercurrent events (ICEs), which usually\n(although not always) lead to missing subsequent outcome measurements for such\nindividuals. The reference-based imputation methods were proposed by Carpenter\net al. (2013) and have been commonly adopted for handling missing data due to\nICEs when estimating treatment policy strategy estimands. Conventionally, the\nvariance for reference-based estimators was obtained using Rubin's rules.\nHowever, Rubin's rules variance estimator is biased compared to the repeated\nsampling variance of the point estimator, due to uncongeniality. Repeated\nsampling variance estimators were proposed as an alternative to variance\nestimation for reference-based estimators. However, these have the property\nthat they decrease as the proportion of ICEs increases. White et al. (2019)\nintroduced a causal model incorporating the concept of a 'maintained treatment\neffect' following the occurrence of ICEs and showed that this causal model\nincluded common reference-based estimators as special cases. Building on this\nframework, we propose introducing a prior distribution for the maintained\neffect parameter to account for uncertainty in this assumption. Our approach\nprovides inference for reference-based estimators that explicitly reflects our\nuncertainty about how much treatment effects are maintained after the\noccurrence of ICEs. In trials where no or little post-ICE data are observed,\nour proposed Bayesian reference-based causal model approach can be used to\nestimate the treatment policy treatment effect, incorporating uncertainty about\nthe reference-based assumption. We compare the frequentist properties of this\napproach with existing reference-based methods through simulations and by\napplication to an antidepressant trial.",
      "pdf_url": "http://arxiv.org/pdf/2507.00680v2",
      "arxiv_url": "http://arxiv.org/abs/2507.00680v2",
      "published": "2025-07-01",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Quantum Bayesian inference with Suport vector states for intrusion detection",
      "authors": [
        "Nayema Mridha",
        "Garrv Sipani",
        "Eva R Gaarder",
        "Shah Haque",
        "Radhika Kuttala",
        "Binay P Akhouri",
        "Mohamad M Al Zein",
        "Eric Howard"
      ],
      "abstract": "We present a quantum Bayesian inference method for intrusion detection, using\nexplicitly constructed quantum circuits and statevector simulation. Prior and\nconditional probabilities are encoded via unitary gates, and posterior\ndistributions are extracted through symbolic post-selection. Applied to a\nscenario with network spikes, system vulnerabilities, and false alarms, the\nmethod yields joint, marginal, and conditional probabilities aligned with\ncausal structure. Our results demonstrate the feasibility and interpretability\nof quantum-native inference for information security applications",
      "pdf_url": "http://arxiv.org/pdf/2507.00403v1",
      "arxiv_url": "http://arxiv.org/abs/2507.00403v1",
      "published": "2025-07-01",
      "categories": [
        "quant-ph"
      ]
    },
    {
      "title": "Causal Prompting for Implicit Sentiment Analysis with Large Language Models",
      "authors": [
        "Jing Ren",
        "Wenhao Zhou",
        "Bowen Li",
        "Mujie Liu",
        "Nguyen Linh Dan Le",
        "Jiade Cen",
        "Liping Chen",
        "Ziqi Xu",
        "Xiwei Xu",
        "Xiaodong Li"
      ],
      "abstract": "Implicit Sentiment Analysis (ISA) aims to infer sentiment that is implied\nrather than explicitly stated, requiring models to perform deeper reasoning\nover subtle contextual cues. While recent prompting-based methods using Large\nLanguage Models (LLMs) have shown promise in ISA, they often rely on majority\nvoting over chain-of-thought (CoT) reasoning paths without evaluating their\ncausal validity, making them susceptible to internal biases and spurious\ncorrelations. To address this challenge, we propose CAPITAL, a causal prompting\nframework that incorporates front-door adjustment into CoT reasoning. CAPITAL\ndecomposes the overall causal effect into two components: the influence of the\ninput prompt on the reasoning chains, and the impact of those chains on the\nfinal output. These components are estimated using encoder-based clustering and\nthe NWGM approximation, with a contrastive learning objective used to better\nalign the encoder's representation with the LLM's reasoning space. Experiments\non benchmark ISA datasets with three LLMs demonstrate that CAPITAL consistently\noutperforms strong prompting baselines in both accuracy and robustness,\nparticularly under adversarial conditions. This work offers a principled\napproach to integrating causal inference into LLM prompting and highlights its\nbenefits for bias-aware sentiment reasoning. The source code and case study are\navailable at: https://github.com/whZ62/CAPITAL.",
      "pdf_url": "http://arxiv.org/pdf/2507.00389v1",
      "arxiv_url": "http://arxiv.org/abs/2507.00389v1",
      "published": "2025-07-01",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "title": "Penalized FCI for Causal Structure Learning in a Sparse DAG for Biomarker Discovery in Parkinson's Disease",
      "authors": [
        "Samhita Pal",
        "Dhrubajyoti Ghosh",
        "Shu Yang"
      ],
      "abstract": "Parkinson's disease (PD) is a progressive neurodegenerative disorder that\nlacks reliable early-stage biomarkers for diagnosis, prognosis, and therapeutic\nmonitoring. While cerebrospinal fluid (CSF) biomarkers, such as alpha-synuclein\nseed amplification assays (alphaSyn-SAA), offer diagnostic potential, their\nclinical utility is limited by invasiveness and incomplete specificity. Plasma\nbiomarkers provide a minimally invasive alternative, but their mechanistic role\nin PD remains unclear. A major challenge is distinguishing whether plasma\nbiomarkers causally reflect primary neurodegenerative processes or are\ndownstream consequences of disease progression. To address this, we leverage\nthe Parkinson's Progression Markers Initiative (PPMI) Project 9000, containing\n2,924 plasma and CSF biomarkers, to systematically infer causal relationships\nwith disease status. However, only a sparse subset of these biomarkers and\ntheir interconnections are actually relevant for the disease. Existing causal\ndiscovery algorithms, such as Fast Causal Inference (FCI) and its variants,\nstruggle with the high dimensionality of biomarker datasets under sparsity,\nlimiting their scalability. We propose Penalized Fast Causal Inference (PFCI),\na novel approach that incorporates sparsity constraints to efficiently infer\ncausal structures in large-scale biological datasets. By applying PFCI to PPMI\ndata, we aim to identify biomarkers that are causally linked to PD pathology,\nenabling early diagnosis and patient stratification. Our findings will\nfacilitate biomarker-driven clinical trials and contribute to the development\nof neuroprotective therapies.",
      "pdf_url": "http://arxiv.org/pdf/2507.00173v1",
      "arxiv_url": "http://arxiv.org/abs/2507.00173v1",
      "published": "2025-06-30",
      "categories": [
        "stat.ME",
        "stat.AP"
      ]
    },
    {
      "title": "When Additive Noise Meets Unobserved Mediators: Bivariate Denoising Diffusion for Causal Discovery",
      "authors": [
        "Dominik Meier",
        "Sujai Hiremath",
        "Promit Ghosal",
        "Kyra Gan"
      ],
      "abstract": "Distinguishing cause and effect from bivariate observational data is a\nfoundational problem in many disciplines, but challenging without additional\nassumptions. Additive noise models (ANMs) are widely used to enable\nsample-efficient bivariate causal discovery. However, conventional ANM-based\nmethods fail when unobserved mediators corrupt the causal relationship between\nvariables. This paper makes three key contributions: first, we rigorously\ncharacterize why standard ANM approaches break down in the presence of\nunmeasured mediators. Second, we demonstrate that prior solutions for hidden\nmediation are brittle in finite sample settings, limiting their practical\nutility. To address these gaps, we propose Bivariate Denoising Diffusion (BiDD)\nfor causal discovery, a method designed to handle latent noise introduced by\nunmeasured mediators. Unlike prior methods that infer directionality through\nmean squared error loss comparisons, our approach introduces a novel\nindependence test statistic: during the noising and denoising processes for\neach variable, we condition on the other variable as input and evaluate the\nindependence of the predicted noise relative to this input. We prove asymptotic\nconsistency of BiDD under the ANM, and conjecture that it performs well under\nhidden mediation. Experiments on synthetic and real-world data demonstrate\nconsistent performance, outperforming existing methods in mediator-corrupted\nsettings while maintaining strong performance in mediator-free settings.",
      "pdf_url": "http://arxiv.org/pdf/2506.23374v1",
      "arxiv_url": "http://arxiv.org/abs/2506.23374v1",
      "published": "2025-06-29",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "CycleVAR: Repurposing Autoregressive Model for Unsupervised One-Step Image Translation",
      "authors": [
        "Yi Liu",
        "Shengqian Li",
        "Zuzeng Lin",
        "Feng Wang",
        "Si Liu"
      ],
      "abstract": "The current conditional autoregressive image generation methods have shown\npromising results, yet their potential remains largely unexplored in the\npractical unsupervised image translation domain, which operates without\nexplicit cross-domain correspondences. A critical limitation stems from the\ndiscrete quantization inherent in traditional Vector Quantization-based\nframeworks, which disrupts gradient flow between the Variational Autoencoder\ndecoder and causal Transformer, impeding end-to-end optimization during\nadversarial training in image space. To tackle this issue, we propose using\nSoftmax Relaxed Quantization, a novel approach that reformulates codebook\nselection as a continuous probability mixing process via Softmax, thereby\npreserving gradient propagation. Building upon this differentiable foundation,\nwe introduce CycleVAR, which reformulates image-to-image translation as\nimage-conditional visual autoregressive generation by injecting multi-scale\nsource image tokens as contextual prompts, analogous to prefix-based\nconditioning in language models. CycleVAR exploits two modes to generate the\ntarget image tokens, including (1) serial multi-step generation, enabling\niterative refinement across scales, and (2) parallel one-step generation\nsynthesizing all resolution outputs in a single forward pass. Experimental\nfindings indicate that the parallel one-step generation mode attains superior\ntranslation quality with quicker inference speed than the serial multi-step\nmode in unsupervised scenarios. Furthermore, both quantitative and qualitative\nresults indicate that CycleVAR surpasses previous state-of-the-art unsupervised\nimage translation models, \\textit{e}.\\textit{g}., CycleGAN-Turbo.",
      "pdf_url": "http://arxiv.org/pdf/2506.23347v1",
      "arxiv_url": "http://arxiv.org/abs/2506.23347v1",
      "published": "2025-06-29",
      "categories": [
        "cs.CV"
      ]
    }
  ]
}