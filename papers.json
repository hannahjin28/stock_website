{
  "last_updated": "2025-02-25T00:46:47.195743",
  "papers": [
    {
      "title": "Predicting gene essentiality and drug response from perturbation screens in preclinical cancer models with LEAP: Layered Ensemble of Autoencoders and Predictors",
      "authors": [
        "Barbara Bodinier",
        "Gaetan Dissez",
        "Linus Bleistein",
        "Antonin Dauvin"
      ],
      "abstract": "Preclinical perturbation screens, where the effects of genetic, chemical, or\nenvironmental perturbations are systematically tested on disease models, hold\nsignificant promise for machine learning-enhanced drug discovery due to their\nscale and causal nature. Predictive models can infer perturbation responses for\npreviously untested disease models based on molecular profiles. These in silico\nlabels can expand databases and guide experimental prioritization.\n  However, modelling perturbation-specific effects and generating robust\nprediction performances across diverse biological contexts remain elusive. We\nintroduce LEAP (Layered Ensemble of Autoencoders and Predictors), a novel\nensemble framework to improve robustness and generalization. LEAP leverages\nmultiple DAMAE (Data Augmented Masked Autoencoder) representations and LASSO\nregressors. By combining diverse gene expression representation models learned\nfrom different random initializations, LEAP consistently outperforms\nstate-of-the-art approaches in predicting gene essentiality or drug responses\nin unseen cell lines, tissues and disease models. Notably, our results show\nthat ensembling representation models, rather than prediction models alone,\nyields superior predictive performance.\n  Beyond its performance gains, LEAP is computationally efficient, requires\nminimal hyperparameter tuning and can therefore be readily incorporated into\ndrug discovery pipelines to prioritize promising targets and support\nbiomarker-driven stratification. The code and datasets used in this work are\nmade publicly available.",
      "pdf_url": "http://arxiv.org/pdf/2502.15646v1",
      "arxiv_url": "http://arxiv.org/abs/2502.15646v1",
      "published": "2025-02-21",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "EigenShield: Causal Subspace Filtering via Random Matrix Theory for Adversarially Robust Vision-Language Models",
      "authors": [
        "Nastaran Darabi",
        "Devashri Naik",
        "Sina Tayebati",
        "Dinithi Jayasuriya",
        "Ranganath Krishnan",
        "Amit Ranjan Trivedi"
      ],
      "abstract": "Vision-Language Models (VLMs) inherit adversarial vulnerabilities of Large\nLanguage Models (LLMs), which are further exacerbated by their multimodal\nnature. Existing defenses, including adversarial training, input\ntransformations, and heuristic detection, are computationally expensive,\narchitecture-dependent, and fragile against adaptive attacks. We introduce\nEigenShield, an inference-time defense leveraging Random Matrix Theory to\nquantify adversarial disruptions in high-dimensional VLM representations.\nUnlike prior methods that rely on empirical heuristics, EigenShield employs the\nspiked covariance model to detect structured spectral deviations. Using a\nRobustness-based Nonconformity Score (RbNS) and quantile-based thresholding, it\nseparates causal eigenvectors, which encode semantic information, from\ncorrelational eigenvectors that are susceptible to adversarial artifacts. By\nprojecting embeddings onto the causal subspace, EigenShield filters adversarial\nnoise without modifying model parameters or requiring adversarial training.\nThis architecture-independent, attack-agnostic approach significantly reduces\nthe attack success rate, establishing spectral analysis as a principled\nalternative to conventional defenses. Our results demonstrate that EigenShield\nconsistently outperforms all existing defenses, including adversarial training,\nUNIGUARD, and CIDER.",
      "pdf_url": "http://arxiv.org/pdf/2502.14976v1",
      "arxiv_url": "http://arxiv.org/abs/2502.14976v1",
      "published": "2025-02-20",
      "categories": [
        "cs.LG",
        "cs.CR",
        "cs.CV"
      ]
    },
    {
      "title": "Symmetric observations without symmetric causal explanations",
      "authors": [
        "Christian William",
        "Patrick Remy",
        "Jean-Daniel Bancal",
        "Yu Cai",
        "Nicolas Brunner",
        "Alejandro Pozas-Kerstjens"
      ],
      "abstract": "Inferring causal models from observed correlations is a challenging task,\ncrucial to many areas of science. In order to alleviate the effort, it is\nimportant to know whether symmetries in the observations correspond to\nsymmetries in the underlying realization. Via an explicit example, we answer\nthis question in the negative. We use a tripartite probability distribution\nover binary events that is realized by using three (different) independent\nsources of classical randomness. We prove that even removing the condition that\nthe sources distribute systems described by classical physics, the requirements\nthat i) the sources distribute the same physical systems, ii) these physical\nsystems respect relativistic causality, and iii) the correlations are the\nobserved ones, are incompatible.",
      "pdf_url": "http://arxiv.org/pdf/2502.14950v1",
      "arxiv_url": "http://arxiv.org/abs/2502.14950v1",
      "published": "2025-02-20",
      "categories": [
        "quant-ph",
        "cs.LG",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ]
    },
    {
      "title": "Internal Incoherency Scores for Constraint-based Causal Discovery Algorithms",
      "authors": [
        "Sofia Faltenbacher",
        "Jonas Wahl",
        "Rebecca Herman",
        "Jakob Runge"
      ],
      "abstract": "Causal discovery aims to infer causal graphs from observational or\nexperimental data. Methods such as the popular PC algorithm are based on\nconditional independence testing and utilize enabling assumptions, such as the\nfaithfulness assumption, for their inferences. In practice, these assumptions,\nas well as the functional assumptions inherited from the chosen conditional\nindependence test, are typically taken as a given and not further tested for\ntheir validity on the data. In this work, we propose internal coherency scores\nthat allow testing for assumption violations and finite sample errors, whenever\ndetectable without requiring ground truth or further statistical tests. We\nprovide a complete classification of erroneous results, including a distinction\nbetween detectable and undetectable errors, and prove that the detectable\nerroneous results can be measured by our scores. We illustrate our coherency\nscores on the PC algorithm with simulated and real-world datasets, and envision\nthat testing for internal coherency can become a standard tool in applying\nconstraint-based methods, much like a suite of tests is used to validate the\nassumptions of classical regression analysis.",
      "pdf_url": "http://arxiv.org/pdf/2502.14719v1",
      "arxiv_url": "http://arxiv.org/abs/2502.14719v1",
      "published": "2025-02-20",
      "categories": [
        "stat.ML",
        "cs.LG"
      ]
    },
    {
      "title": "Outlier Detection in Mendelian Randomisation",
      "authors": [
        "Maximilian M Mandl",
        "Anne-Laure Boulesteix",
        "Stephen Burgess",
        "Verena Zuber"
      ],
      "abstract": "Mendelian Randomisation (MR) uses genetic variants as instrumental variables\nto infer causal effects of exposures on an outcome. One key assumption of MR is\nthat the genetic variants used as instrumental variables are independent of the\noutcome conditional on the risk factor and unobserved confounders. Violations\nof this assumption, i.e. the effect of the instrumental variables on the\noutcome through a path other than the risk factor included in the model (which\ncan be caused by pleiotropy), are common phenomena in human genetics. Genetic\nvariants, which deviate from this assumption, appear as outliers to the MR\nmodel fit and can be detected by the general heterogeneity statistics proposed\nin the literature, which are known to suffer from overdispersion, i.e. too many\ngenetic variants are declared as false outliers. We propose a method that\ncorrects for overdispersion of the heterogeneity statistics in uni- and\nmultivariable MR analysis by making use of the estimated inflation factor to\ncorrectly remove outlying instruments and therefore account for pleiotropic\neffects. Our method is applicable to summary-level data.",
      "pdf_url": "http://arxiv.org/pdf/2502.14716v1",
      "arxiv_url": "http://arxiv.org/abs/2502.14716v1",
      "published": "2025-02-20",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Optimal word order for non-causal text generation with Large Language Models: the Spanish case",
      "authors": [
        "Andrea Busto-Castiñeira",
        "Silvia García-Méndez",
        "Francisco de Arriba-Pérez",
        "Francisco J. González-Castaño"
      ],
      "abstract": "Natural Language Generation (NLG) popularity has increased owing to the\nprogress in Large Language Models (LLMs), with zero-shot inference\ncapabilities. However, most neural systems utilize decoder-only causal\n(unidirectional) transformer models, which are effective for English but may\nreduce the richness of languages with less strict word order, subject omission,\nor different relative clause attachment preferences. This is the first work\nthat analytically addresses optimal text generation order for non-causal\nlanguage models. We present a novel Viterbi algorithm-based methodology for\nmaximum likelihood word order estimation. We analyze the non-causal\nmost-likelihood order probability for NLG in Spanish and, then, the probability\nof generating the same phrases with Spanish causal NLG. This comparative\nanalysis reveals that causal NLG prefers English-like SVO structures. We also\nanalyze the relationship between optimal generation order and causal\nleft-to-right generation order using Spearman's rank correlation. Our results\ndemonstrate that the ideal order predicted by the maximum likelihood estimator\nis not closely related to the causal order and may be influenced by the\nsyntactic structure of the target sentence.",
      "pdf_url": "http://arxiv.org/pdf/2502.14451v1",
      "arxiv_url": "http://arxiv.org/abs/2502.14451v1",
      "published": "2025-02-20",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "title": "Robust Counterfactual Inference in Markov Decision Processes",
      "authors": [
        "Jessica Lally",
        "Milad Kazemi",
        "Nicola Paoletti"
      ],
      "abstract": "This paper addresses a key limitation in existing counterfactual inference\nmethods for Markov Decision Processes (MDPs). Current approaches assume a\nspecific causal model to make counterfactuals identifiable. However, there are\nusually many causal models that align with the observational and interventional\ndistributions of an MDP, each yielding different counterfactual distributions,\nso fixing a particular causal model limits the validity (and usefulness) of\ncounterfactual inference. We propose a novel non-parametric approach that\ncomputes tight bounds on counterfactual transition probabilities across all\ncompatible causal models. Unlike previous methods that require solving\nprohibitively large optimisation problems (with variables that grow\nexponentially in the size of the MDP), our approach provides closed-form\nexpressions for these bounds, making computation highly efficient and scalable\nfor non-trivial MDPs. Once such an interval counterfactual MDP is constructed,\nour method identifies robust counterfactual policies that optimise the\nworst-case reward w.r.t. the uncertain interval MDP probabilities. We evaluate\nour method on various case studies, demonstrating improved robustness over\nexisting methods.",
      "pdf_url": "http://arxiv.org/pdf/2502.13731v1",
      "arxiv_url": "http://arxiv.org/abs/2502.13731v1",
      "published": "2025-02-19",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Distal Causal Excursion Effects: Modeling Long-Term Effects of Time-Varying Treatments in Micro-Randomized Trials",
      "authors": [
        "Tianchen Qian"
      ],
      "abstract": "Micro-randomized trials (MRTs) play a crucial role in optimizing digital\ninterventions. In an MRT, each participant is sequentially randomized among\ntreatment options hundreds of times. While the interventions tested in MRTs\ntarget short-term behavioral responses (proximal outcomes), their ultimate goal\nis to drive long-term behavior change (distal outcomes). However, existing\ncausal inference methods, such as the causal excursion effect, are limited to\nproximal outcomes, making it challenging to quantify the long-term impact of\ninterventions. To address this gap, we introduce the distal causal excursion\neffect (DCEE), a novel estimand that quantifies the long-term effect of\ntime-varying treatments. The DCEE contrasts distal outcomes under two excursion\npolicies while marginalizing over most treatment assignments, enabling a\nparsimonious and interpretable causal model even with a large number of\ndecision points. We propose two estimators for the DCEE -- one with\ncross-fitting and one without -- both robust to misspecification of the outcome\nmodel. We establish their asymptotic properties and validate their performance\nthrough simulations. We apply our method to the HeartSteps MRT to assess the\nimpact of activity prompts on long-term habit formation. Our findings suggest\nthat prompts delivered earlier in the study have a stronger long-term effect\nthan those delivered later, underscoring the importance of intervention timing\nin behavior change. This work provides the critically needed toolkit for\nscientists working on digital interventions to assess long-term causal effects\nusing MRT data.",
      "pdf_url": "http://arxiv.org/pdf/2502.13500v1",
      "arxiv_url": "http://arxiv.org/abs/2502.13500v1",
      "published": "2025-02-19",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Robust Inference for the Direct Average Treatment Effect with Treatment Assignment Interference",
      "authors": [
        "Matias D. Cattaneo",
        "Yihan He",
        "Ruiqi",
        "Yu"
      ],
      "abstract": "Uncertainty quantification in causal inference settings with random network\ninterference is a challenging open problem. We study the large sample\ndistributional properties of the classical difference-in-means Hajek treatment\neffect estimator, and propose a robust inference procedure for the\n(conditional) direct average treatment effect, allowing for cross-unit\ninterference in both the outcome and treatment equations. Leveraging ideas from\nstatistical physics, we introduce a novel Ising model capturing interference in\nthe treatment assignment, and then obtain three main results. First, we\nestablish a Berry-Esseen distributional approximation pointwise in the degree\nof interference generated by the Ising model. Our distributional approximation\nrecovers known results in the literature under no-interference in treatment\nassignment, and also highlights a fundamental fragility of inference procedures\ndeveloped using such a pointwise approximation. Second, we establish a uniform\ndistributional approximation for the Hajek estimator, and develop robust\ninference procedures that remain valid regardless of the unknown degree of\ninterference in the Ising model. Third, we propose a novel resampling method\nfor implementation of robust inference procedure. A key technical innovation\nunderlying our work is a new \\textit{De-Finetti Machine} that facilitates\nconditional i.i.d. Gaussianization, a technique that may be of independent\ninterest in other settings.",
      "pdf_url": "http://arxiv.org/pdf/2502.13238v1",
      "arxiv_url": "http://arxiv.org/abs/2502.13238v1",
      "published": "2025-02-18",
      "categories": [
        "stat.ME",
        "econ.EM"
      ]
    },
    {
      "title": "Robust Disentangled Counterfactual Learning for Physical Audiovisual Commonsense Reasoning",
      "authors": [
        "Mengshi Qi",
        "Changsheng Lv",
        "Huadong Ma"
      ],
      "abstract": "In this paper, we propose a new Robust Disentangled Counterfactual Learning\n(RDCL) approach for physical audiovisual commonsense reasoning. The task aims\nto infer objects' physics commonsense based on both video and audio input, with\nthe main challenge being how to imitate the reasoning ability of humans, even\nunder the scenario of missing modalities. Most of the current methods fail to\ntake full advantage of different characteristics in multi-modal data, and\nlacking causal reasoning ability in models impedes the progress of implicit\nphysical knowledge inferring. To address these issues, our proposed RDCL method\ndecouples videos into static (time-invariant) and dynamic (time-varying)\nfactors in the latent space by the disentangled sequential encoder, which\nadopts a variational autoencoder (VAE) to maximize the mutual information with\na contrastive loss function. Furthermore, we introduce a counterfactual\nlearning module to augment the model's reasoning ability by modeling physical\nknowledge relationships among different objects under counterfactual\nintervention. To alleviate the incomplete modality data issue, we introduce a\nrobust multimodal learning method to recover the missing data by decomposing\nthe shared features and model-specific features. Our proposed method is a\nplug-and-play module that can be incorporated into any baseline including VLMs.\nIn experiments, we show that our proposed method improves the reasoning\naccuracy and robustness of baseline methods and achieves the state-of-the-art\nperformance.",
      "pdf_url": "http://arxiv.org/pdf/2502.12425v1",
      "arxiv_url": "http://arxiv.org/abs/2502.12425v1",
      "published": "2025-02-18",
      "categories": [
        "cs.CV"
      ]
    }
  ]
}