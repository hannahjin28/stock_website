{
  "last_updated": "2025-06-15T01:01:00.552900",
  "papers": [
    {
      "title": "Foundation Models for Causal Inference via Prior-Data Fitted Networks",
      "authors": [
        "Yuchen Ma",
        "Dennis Frauen",
        "Emil Javurek",
        "Stefan Feuerriegel"
      ],
      "abstract": "Prior-data fitted networks (PFNs) have recently been proposed as a promising\nway to train tabular foundation models. PFNs are transformers that are\npre-trained on synthetic data generated from a prespecified prior distribution\nand that enable Bayesian inference through in-context learning. In this paper,\nwe introduce CausalFM, a comprehensive framework for training PFN-based\nfoundation models in various causal inference settings. First, we formalize the\nconstruction of Bayesian priors for causal inference based on structural causal\nmodels (SCMs) in a principled way and derive necessary criteria for the\nvalidity of such priors. Building on this, we propose a novel family of prior\ndistributions using causality-inspired Bayesian neural networks that enable\nCausalFM to perform Bayesian causal inference in various settings, including\nback-door, front-door, and instrumental variable adjustment. Finally, we\ninstantiate CausalFM and explicitly train a foundation model for estimating\nconditional average treatment effects (CATEs) using back-door adjustment. We\nshow that CausalFM performs competitively for CATE estimation using various\nsynthetic and semi-synthetic benchmarks. In sum, our framework can be used as a\ngeneral recipe to train foundation models for various causal inference\nsettings. In contrast to the current state-of-the-art in causal inference,\nCausalFM offers a novel paradigm with the potential to fundamentally change how\npractitioners perform causal inference in medicine, economics, and other\ndisciplines.",
      "pdf_url": "http://arxiv.org/pdf/2506.10914v1",
      "arxiv_url": "http://arxiv.org/abs/2506.10914v1",
      "published": "2025-06-12",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "From Images to Insights: Explainable Biodiversity Monitoring with Plain Language Habitat Explanations",
      "authors": [
        "Yutong Zhou",
        "Masahiro Ryo"
      ],
      "abstract": "Explaining why the species lives at a particular location is important for\nunderstanding ecological systems and conserving biodiversity. However, existing\necological workflows are fragmented and often inaccessible to non-specialists.\nWe propose an end-to-end visual-to-causal framework that transforms a species\nimage into interpretable causal insights about its habitat preference. The\nsystem integrates species recognition, global occurrence retrieval,\npseudo-absence sampling, and climate data extraction. We then discover causal\nstructures among environmental features and estimate their influence on species\noccurrence using modern causal inference methods. Finally, we generate\nstatistically grounded, human-readable causal explanations from structured\ntemplates and large language models. We demonstrate the framework on a bee and\na flower species and report early results as part of an ongoing project,\nshowing the potential of the multimodal AI assistant backed up by a recommended\necological modeling practice for describing species habitat in\nhuman-understandable language.",
      "pdf_url": "http://arxiv.org/pdf/2506.10559v1",
      "arxiv_url": "http://arxiv.org/abs/2506.10559v1",
      "published": "2025-06-12",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.ET"
      ]
    },
    {
      "title": "Towards Robust Multimodal Emotion Recognition under Missing Modalities and Distribution Shifts",
      "authors": [
        "Guowei Zhong",
        "Ruohong Huan",
        "Mingzhen Wu",
        "Ronghua Liang",
        "Peng Chen"
      ],
      "abstract": "Recent advancements in Multimodal Emotion Recognition (MER) face challenges\nin addressing both modality missing and Out-Of-Distribution (OOD) data\nsimultaneously. Existing methods often rely on specific models or introduce\nexcessive parameters, which limits their practicality. To address these issues,\nwe propose a novel robust MER framework, Causal Inference Distiller (CIDer),\nand introduce a new task, Random Modality Feature Missing (RMFM), to generalize\nthe definition of modality missing. CIDer integrates two key components: a\nModel-Specific Self-Distillation (MSSD) module and a Model-Agnostic Causal\nInference (MACI) module. MSSD enhances robustness under the RMFM task through a\nweight-sharing self-distillation approach applied across low-level features,\nattention maps, and high-level representations. Additionally, a Word-level\nSelf-aligned Attention Module (WSAM) reduces computational complexity, while a\nMultimodal Composite Transformer (MCT) facilitates efficient multimodal fusion.\nTo tackle OOD challenges, MACI employs a tailored causal graph to mitigate\nlabel and language biases using a Multimodal Causal Module (MCM) and\nfine-grained counterfactual texts. Notably, MACI can independently enhance OOD\ngeneralization with minimal additional parameters. Furthermore, we also\nintroduce the new repartitioned MER OOD datasets. Experimental results\ndemonstrate that CIDer achieves robust performance in both RMFM and OOD\nscenarios, with fewer parameters and faster training compared to\nstate-of-the-art methods. The implementation of this work is publicly\naccessible at https://github.com/gw-zhong/CIDer.",
      "pdf_url": "http://arxiv.org/pdf/2506.10452v1",
      "arxiv_url": "http://arxiv.org/abs/2506.10452v1",
      "published": "2025-06-12",
      "categories": [
        "cs.CV",
        "cs.CL",
        "cs.LG",
        "cs.MM"
      ]
    },
    {
      "title": "Correlation vs causation in Alzheimer's disease: an interpretability-driven study",
      "authors": [
        "Hamzah Dabool",
        "Raghad Mustafa"
      ],
      "abstract": "Understanding the distinction between causation and correlation is critical\nin Alzheimer's disease (AD) research, as it impacts diagnosis, treatment, and\nthe identification of true disease drivers. This experiment investigates the\nrelationships among clinical, cognitive, genetic, and biomarker features using\na combination of correlation analysis, machine learning classification, and\nmodel interpretability techniques. Employing the XGBoost algorithm, we\nidentified key features influencing AD classification, including cognitive\nscores and genetic risk factors. Correlation matrices revealed clusters of\ninterrelated variables, while SHAP (SHapley Additive exPlanations) values\nprovided detailed insights into feature contributions across disease stages.\nOur results highlight that strong correlations do not necessarily imply\ncausation, emphasizing the need for careful interpretation of associative data.\nBy integrating feature importance and interpretability with classical\nstatistical analysis, this work lays groundwork for future causal inference\nstudies aimed at uncovering true pathological mechanisms. Ultimately,\ndistinguishing causal factors from correlated markers can lead to improved\nearly diagnosis and targeted interventions for Alzheimer's disease.",
      "pdf_url": "http://arxiv.org/pdf/2506.10179v1",
      "arxiv_url": "http://arxiv.org/abs/2506.10179v1",
      "published": "2025-06-11",
      "categories": [
        "cs.AI",
        "q-bio.QM",
        "stat.AP"
      ]
    },
    {
      "title": "Multiverse: Your Language Models Secretly Decide How to Parallelize and Merge Generation",
      "authors": [
        "Xinyu Yang",
        "Yuwei An",
        "Hongyi Liu",
        "Tianqi Chen",
        "Beidi Chen"
      ],
      "abstract": "Autoregressive Large Language Models (AR-LLMs) frequently exhibit implicit\nparallelism in sequential generation. Inspired by this, we introduce\nMultiverse, a new generative model that enables natively parallel generation.\nMultiverse internalizes a MapReduce paradigm, generating automatically through\nthree stages: (i) a Map stage for adaptive task decomposition, (ii) a Process\nstage for parallel subtask execution, and (iii) a Reduce stage for lossless\nresult synthesis. Next, we build a real-world Multiverse reasoning model with\nco-design of data, algorithm, and system, enabling rapid and seamless transfer\nfrom frontier AR-LLMs. Starting from sequential reasoning chains, we create\nMultiverse 1K by converting them into structured training data using an\nautomated LLM-assisted pipeline, avoiding costly human annotations.\nAlgorithmically, we design Multiverse Attention to separate parallel reasoning\nsteps while keeping compatibility with causal attention for efficient training.\nSystematically, we implement Multiverse Engine to enable parallel inference. It\nfeatures a dedicated scheduler that dynamically switches between sequential and\nparallel generation, triggered directly by the model. After a 3-hour\nfine-tuning with 1K examples, our Multiverse-32B stands as the only\nopen-sourced non-AR model achieving performance on par with leading AR-LLMs of\nthe same scale, evidenced by AIME24 & 25 scores of 54% and 46%, respectively.\nMoreover, our budget control experiments show that Multiverse-32B exhibits\nsuperior scaling, outperforming AR-LLMs by 1.87% on average using the same\ncontext length. Such scaling further leads to practical efficiency gain,\nachieving up to 2x speedup across varying batch sizes. We have open-sourced the\nentire Multiverse ecosystem, including data, model weights, engine, supporting\ntools, as well as complete data curation prompts and detailed training and\nevaluation recipes.",
      "pdf_url": "http://arxiv.org/pdf/2506.09991v1",
      "arxiv_url": "http://arxiv.org/abs/2506.09991v1",
      "published": "2025-06-11",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "Causal Sufficiency and Necessity Improves Chain-of-Thought Reasoning",
      "authors": [
        "Xiangning Yu",
        "Zhuohan Wang",
        "Linyi Yang",
        "Haoxuan Li",
        "Anjie Liu",
        "Xiao Xue",
        "Jun Wang",
        "Mengyue Yang"
      ],
      "abstract": "Chain-of-Thought (CoT) prompting plays an indispensable role in endowing\nlarge language models (LLMs) with complex reasoning capabilities. However, CoT\ncurrently faces two fundamental challenges: (1) Sufficiency, which ensures that\nthe generated intermediate inference steps comprehensively cover and\nsubstantiate the final conclusion; and (2) Necessity, which identifies the\ninference steps that are truly indispensable for the soundness of the resulting\nanswer. We propose a causal framework that characterizes CoT reasoning through\nthe dual lenses of sufficiency and necessity. Incorporating causal Probability\nof Sufficiency and Necessity allows us not only to determine which steps are\nlogically sufficient or necessary to the prediction outcome, but also to\nquantify their actual influence on the final reasoning outcome under different\nintervention scenarios, thereby enabling the automated addition of missing\nsteps and the pruning of redundant ones. Extensive experimental results on\nvarious mathematical and commonsense reasoning benchmarks confirm substantial\nimprovements in reasoning efficiency and reduced token usage without\nsacrificing accuracy. Our work provides a promising direction for improving LLM\nreasoning performance and cost-effectiveness.",
      "pdf_url": "http://arxiv.org/pdf/2506.09853v1",
      "arxiv_url": "http://arxiv.org/abs/2506.09853v1",
      "published": "2025-06-11",
      "categories": [
        "cs.CL",
        "cs.AI",
        "math.ST",
        "stat.ME",
        "stat.TH"
      ]
    },
    {
      "title": "Benchmarking Debiasing Methods for LLM-based Parameter Estimates",
      "authors": [
        "Nicolas Audinet de Pieuchon",
        "Adel Daoud",
        "Connor T. Jerzak",
        "Moa Johansson",
        "Richard Johansson"
      ],
      "abstract": "Large language models (LLMs) offer an inexpensive yet powerful way to\nannotate text, but are often inconsistent when compared with experts. These\nerrors can bias downstream estimates of population parameters such as\nregression coefficients and causal effects. To mitigate this bias, researchers\nhave developed debiasing methods such as Design-based Supervised Learning (DSL)\nand Prediction-Powered Inference (PPI), which promise valid estimation by\ncombining LLM annotations with a limited number of expensive expert\nannotations. Although these methods produce consistent estimates under\ntheoretical assumptions, it is unknown how they compare in finite samples of\nsizes encountered in applied research. We make two contributions: First, we\nstudy how each method's performance scales with the number of expert\nannotations, highlighting regimes where LLM bias or limited expert labels\nsignificantly affect results. Second, we compare DSL and PPI across a range of\ntasks, finding that although both achieve low bias with large datasets, DSL\noften outperforms PPI on bias reduction and empirical efficiency, but its\nperformance is less consistent across datasets. Our findings indicate that\nthere is a bias-variance tradeoff at the level of debiasing methods, calling\nfor more research on developing metrics for quantifying their efficiency in\nfinite samples.",
      "pdf_url": "http://arxiv.org/pdf/2506.09627v1",
      "arxiv_url": "http://arxiv.org/abs/2506.09627v1",
      "published": "2025-06-11",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "title": "STOAT: Spatial-Temporal Probabilistic Causal Inference Network",
      "authors": [
        "Yang Yang",
        "Du Yin",
        "Hao Xue",
        "Flora Salim"
      ],
      "abstract": "Spatial-temporal causal time series (STC-TS) involve region-specific temporal\nobservations driven by causally relevant covariates and interconnected across\ngeographic or network-based spaces. Existing methods often model spatial and\ntemporal dynamics independently and overlook causality-driven probabilistic\nforecasting, limiting their predictive power. To address this, we propose STOAT\n(Spatial-Temporal Probabilistic Causal Inference Network), a novel framework\nfor probabilistic forecasting in STC-TS. The proposed method extends a causal\ninference approach by incorporating a spatial relation matrix that encodes\ninterregional dependencies (e.g. proximity or connectivity), enabling spatially\ninformed causal effect estimation. The resulting latent series are processed by\ndeep probabilistic models to estimate the parameters of the distributions,\nenabling calibrated uncertainty modeling. We further explore multiple output\ndistributions (e.g., Gaussian, Student's-$t$, Laplace) to capture\nregion-specific variability. Experiments on COVID-19 data across six countries\ndemonstrate that STOAT outperforms state-of-the-art probabilistic forecasting\nmodels (DeepAR, DeepVAR, Deep State Space Model, etc.) in key metrics,\nparticularly in regions with strong spatial dependencies. By bridging causal\ninference and geospatial probabilistic forecasting, STOAT offers a\ngeneralizable framework for complex spatial-temporal tasks, such as epidemic\nmanagement.",
      "pdf_url": "http://arxiv.org/pdf/2506.09544v2",
      "arxiv_url": "http://arxiv.org/abs/2506.09544v2",
      "published": "2025-06-11",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "Mitigating Spurious Correlations in LLMs via Causality-Aware Post-Training",
      "authors": [
        "Shurui Gui",
        "Shuiwang Ji"
      ],
      "abstract": "While large language models (LLMs) have demonstrated remarkable capabilities\nin language modeling, recent studies reveal that they often fail on\nout-of-distribution (OOD) samples due to spurious correlations acquired during\npre-training. Here, we aim to mitigate such spurious correlations through\ncausality-aware post-training (CAPT). By decomposing a biased prediction into\ntwo unbiased steps, known as \\textit{event estimation} and \\textit{event\nintervention}, we reduce LLMs' pre-training biases without incurring additional\nfine-tuning biases, thus enhancing the model's generalization ability.\nExperiments on the formal causal inference benchmark CLadder and the logical\nreasoning dataset PrOntoQA show that 3B-scale language models fine-tuned with\nCAPT can outperform both traditional SFT and larger LLMs on in-distribution\n(ID) and OOD tasks using only 100 ID fine-tuning samples, demonstrating the\neffectiveness and sample efficiency of CAPT.",
      "pdf_url": "http://arxiv.org/pdf/2506.09433v1",
      "arxiv_url": "http://arxiv.org/abs/2506.09433v1",
      "published": "2025-06-11",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "G-Sim: Generative Simulations with Large Language Models and Gradient-Free Calibration",
      "authors": [
        "Samuel Holt",
        "Max Ruiz Luyten",
        "Antonin Berthon",
        "Mihaela van der Schaar"
      ],
      "abstract": "Constructing robust simulators is essential for asking \"what if?\" questions\nand guiding policy in critical domains like healthcare and logistics. However,\nexisting methods often struggle, either failing to generalize beyond historical\ndata or, when using Large Language Models (LLMs), suffering from inaccuracies\nand poor empirical alignment. We introduce G-Sim, a hybrid framework that\nautomates simulator construction by synergizing LLM-driven structural design\nwith rigorous empirical calibration. G-Sim employs an LLM in an iterative loop\nto propose and refine a simulator's core components and causal relationships,\nguided by domain knowledge. This structure is then grounded in reality by\nestimating its parameters using flexible calibration techniques. Specifically,\nG-Sim can leverage methods that are both likelihood-free and gradient-free with\nrespect to the simulator, such as gradient-free optimization for direct\nparameter estimation or simulation-based inference for obtaining a posterior\ndistribution over parameters. This allows it to handle non-differentiable and\nstochastic simulators. By integrating domain priors with empirical evidence,\nG-Sim produces reliable, causally-informed simulators, mitigating\ndata-inefficiency and enabling robust system-level interventions for complex\ndecision-making.",
      "pdf_url": "http://arxiv.org/pdf/2506.09272v1",
      "arxiv_url": "http://arxiv.org/abs/2506.09272v1",
      "published": "2025-06-10",
      "categories": [
        "cs.LG",
        "stat.ML",
        "68T05, 68U20, 62F15",
        "I.2.6; I.6.5; G.3"
      ]
    }
  ]
}