{
  "last_updated": "2025-10-11T00:46:36.771203",
  "papers": [
    {
      "title": "ResAD: Normalized Residual Trajectory Modeling for End-to-End Autonomous Driving",
      "authors": [
        "Zhiyu Zheng",
        "Shaoyu Chen",
        "Haoran Yin",
        "Xinbang Zhang",
        "Jialv Zou",
        "Xinggang Wang",
        "Qian Zhang",
        "Lefei Zhang"
      ],
      "abstract": "End-to-end autonomous driving (E2EAD) systems, which learn to predict future\ntrajectories directly from sensor data, are fundamentally challenged by the\ninherent spatio-temporal imbalance of trajectory data. This imbalance creates a\nsignificant optimization burden, causing models to learn spurious correlations\ninstead of causal inference, while also prioritizing uncertain, distant\npredictions, thereby compromising immediate safety. To address these issues, we\npropose ResAD, a novel Normalized Residual Trajectory Modeling framework.\nInstead of predicting the future trajectory directly, our approach reframes the\nlearning task to predict the residual deviation from a deterministic inertial\nreference. The inertial reference serves as a counterfactual, forcing the model\nto move beyond simple pattern recognition and instead identify the underlying\ncausal factors (e.g., traffic rules, obstacles) that necessitate deviations\nfrom a default, inertially-guided path. To deal with the optimization imbalance\ncaused by uncertain, long-term horizons, ResAD further incorporates Point-wise\nNormalization of the predicted residual. It re-weights the optimization\nobjective, preventing large-magnitude errors associated with distant, uncertain\nwaypoints from dominating the learning signal. Extensive experiments validate\nthe effectiveness of our framework. On the NAVSIM benchmark, ResAD achieves a\nstate-of-the-art PDMS of 88.6 using a vanilla diffusion policy with only two\ndenoising steps, demonstrating that our approach significantly simplifies the\nlearning task and improves model performance. The code will be released to\nfacilitate further research.",
      "pdf_url": "http://arxiv.org/pdf/2510.08562v1",
      "arxiv_url": "http://arxiv.org/abs/2510.08562v1",
      "published": "2025-10-09",
      "categories": [
        "cs.CV",
        "cs.RO"
      ]
    },
    {
      "title": "Learning to Mitigate Post-Outage Load Surges: A Data-Driven Framework for Electrifying and Decarbonizing Grids",
      "authors": [
        "Wenlong Shi",
        "Dingwei Wang",
        "Liming Liu",
        "Zhaoyu Wang"
      ],
      "abstract": "Electrification and decarbonization are transforming power system demand and\nrecovery dynamics, yet their implications for post-outage load surges remain\npoorly understood. Here we analyze a metropolitan-scale heterogeneous dataset\nfor Indianapolis comprising 30,046 feeder-level outages between 2020 and 2024,\nlinked to smart meters and submetering, to quantify the causal impact of\nelectric vehicles (EVs), heat pumps (HPs) and distributed energy resources\n(DERs) on restoration surges. Statistical analysis and causal forest inference\ndemonstrate that rising penetrations of all three assets significantly increase\nsurge ratios, with effects strongly modulated by restoration timing, outage\nduration and weather conditions. We develop a component-aware multi-task\nTransformer estimator that disaggregates EV, HP and DER contributions, and\napply it to project historical outages under counterfactual 2035 adoption\npathways. In a policy-aligned pathway, evening restorations emerge as the\nbinding reliability constraint, with exceedance probabilities of 0.057 when\n30\\% of system load is restored within the first 15 minutes. Mitigation\nmeasures, probabilistic EV restarts, short thermostat offsets and accelerated\nDER reconnection, reduce exceedance to 0.019 and eliminate it entirely when\n20\\% or less of system load is restored. These results demonstrate that\ntransition-era surges are asset-driven and causally linked to electrification\nand decarbonization, but can be effectively managed through integrated\noperational strategies.",
      "pdf_url": "http://arxiv.org/pdf/2510.08357v1",
      "arxiv_url": "http://arxiv.org/abs/2510.08357v1",
      "published": "2025-10-09",
      "categories": [
        "eess.SY",
        "cs.SY"
      ]
    },
    {
      "title": "Counterfactual Identifiability via Dynamic Optimal Transport",
      "authors": [
        "Fabio De Sousa Ribeiro",
        "Ainkaran Santhirasekaram",
        "Ben Glocker"
      ],
      "abstract": "We address the open question of counterfactual identification for\nhigh-dimensional multivariate outcomes from observational data. Pearl (2000)\nargues that counterfactuals must be identifiable (i.e., recoverable from the\nobserved data distribution) to justify causal claims. A recent line of work on\ncounterfactual inference shows promising results but lacks identification,\nundermining the causal validity of its estimates. To address this, we establish\na foundation for multivariate counterfactual identification using\ncontinuous-time flows, including non-Markovian settings under standard\ncriteria. We characterise the conditions under which flow matching yields a\nunique, monotone and rank-preserving counterfactual transport map with tools\nfrom dynamic optimal transport, ensuring consistent inference. Building on\nthis, we validate the theory in controlled scenarios with counterfactual\nground-truth and demonstrate improvements in axiomatic counterfactual soundness\non real images.",
      "pdf_url": "http://arxiv.org/pdf/2510.08294v1",
      "arxiv_url": "http://arxiv.org/abs/2510.08294v1",
      "published": "2025-10-09",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "title": "DODO: Causal Structure Learning with Budgeted Interventions",
      "authors": [
        "Matteo Gregorini",
        "Chiara Boldrini",
        "Lorenzo Valerio"
      ],
      "abstract": "Artificial Intelligence has achieved remarkable advancements in recent years,\nyet much of its progress relies on identifying increasingly complex\ncorrelations. Enabling causality awareness in AI has the potential to enhance\nits performance by enabling a deeper understanding of the underlying mechanisms\nof the environment. In this paper, we introduce DODO, an algorithm defining how\nan Agent can autonomously learn the causal structure of its environment through\nrepeated interventions. We assume a scenario where an Agent interacts with a\nworld governed by a causal Directed Acyclic Graph (DAG), which dictates the\nsystem's dynamics but remains hidden from the Agent. The Agent's task is to\naccurately infer the causal DAG, even in the presence of noise. To achieve\nthis, the Agent performs interventions, leveraging causal inference techniques\nto analyze the statistical significance of observed changes. Results show\nbetter performance for DODO, compared to observational approaches, in all but\nthe most limited resource conditions. DODO is often able to reconstruct with as\nlow as zero errors the structure of the causal graph. In the most challenging\nconfiguration, DODO outperforms the best baseline by +0.25 F1 points.",
      "pdf_url": "http://arxiv.org/pdf/2510.08207v1",
      "arxiv_url": "http://arxiv.org/abs/2510.08207v1",
      "published": "2025-10-09",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Augur: Modeling Covariate Causal Associations in Time Series via Large Language Models",
      "authors": [
        "Zhiqing Cui",
        "Binwu Wang",
        "Qingxiang Liu",
        "Yeqiang Wang",
        "Zhengyang Zhou",
        "Yuxuan Liang",
        "Yang Wang"
      ],
      "abstract": "Large language models (LLM) have emerged as a promising avenue for time\nseries forecasting, offering the potential to integrate multimodal data.\nHowever, existing LLM-based approaches face notable limitations-such as\nmarginalized role in model architectures, reliance on coarse statistical text\nprompts, and lack of interpretability. In this work, we introduce Augur, a\nfully LLM driven time series forecasting framework that exploits LLM causal\nreasoning to discover and use directed causal associations among covariates.\nAugur uses a two stage teacher student architecture where a powerful teacher\nLLM infers a directed causal graph from time series using heuristic search\ntogether with pairwise causality testing. A lightweight student agent then\nrefines the graph and fine tune on high confidence causal associations that are\nencoded as rich textual prompts to perform forecasting. This design improves\npredictive accuracy while yielding transparent, traceable reasoning about\nvariable interactions. Extensive experiments on real-world datasets with 25\nbaselines demonstrate that Augur achieves competitive performance and robust\nzero-shot generalization.",
      "pdf_url": "http://arxiv.org/pdf/2510.07858v1",
      "arxiv_url": "http://arxiv.org/abs/2510.07858v1",
      "published": "2025-10-09",
      "categories": [
        "cs.AI",
        "cs.LG",
        "62M10",
        "I.2.7"
      ]
    },
    {
      "title": "Base Models Know How to Reason, Thinking Models Learn When",
      "authors": [
        "Constantin Venhoff",
        "Iv√°n Arcuschin",
        "Philip Torr",
        "Arthur Conmy",
        "Neel Nanda"
      ],
      "abstract": "Why do thinking language models like DeepSeek R1 outperform their base\ncounterparts? Despite consistent performance gains, it remains unclear to what\nextent thinking models learn entirely new reasoning capabilities or repurpose\npre-existing base model ones. In this work, we propose a hybrid model where we\nactivate reasoning mechanisms in base models at the right time to elicit\nthinking-model-level reasoning chains, implying that thinking models exploit\nalready existing capabilities. To ground our analysis, we introduce an\nunsupervised, bottom-up approach for uncovering human-interpretable reasoning\nbehaviors in thinking models. This approach provides an unbiased method to\ndiscover reasoning behaviors without imposing manual or LLM-derived\nassumptions. Across three base and four thinking models, using GSM8K and\nMATH500, our hybrid model recovers up to 91% of the performance gap to thinking\nmodels without any weight updates while steering only 12% of tokens.\nConcretely, our empirical setup provides a simple, causal way to test the\neffectiveness of existing reasoning mechanisms in base models by invoking them\ndirectly and measuring the resulting task performance. More broadly, these\nresults reframe our understanding of how thinking models are trained:\npre-training is when models acquire most of their reasoning mechanisms, and\npost-training teaches efficient deployment of these mechanisms at the right\ntime, enabling efficient use of their inference-time compute.",
      "pdf_url": "http://arxiv.org/pdf/2510.07364v1",
      "arxiv_url": "http://arxiv.org/abs/2510.07364v1",
      "published": "2025-10-08",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Incorporating Expert Knowledge into Bayesian Causal Discovery of Mixtures of Directed Acyclic Graphs",
      "authors": [
        "Zachris Bj√∂rkman",
        "Jorge Lor√≠a",
        "Sophie Wharrie",
        "Samuel Kaski"
      ],
      "abstract": "Bayesian causal discovery benefits from prior information elicited from\ndomain experts, and in heterogeneous domains any prior knowledge would be badly\nneeded. However, so far prior elicitation approaches have assumed a single\ncausal graph and hence are not suited to heterogeneous domains. We propose a\ncausal elicitation strategy for heterogeneous settings, based on Bayesian\nexperimental design (BED) principles, and a variational mixture structure\nlearning (VaMSL) method -- extending the earlier differentiable Bayesian\nstructure learning (DiBS) method -- to iteratively infer mixtures of causal\nBayesian networks (CBNs). We construct an informative graph prior incorporating\nelicited expert feedback in the inference of mixtures of CBNs. Our proposed\nmethod successfully produces a set of alternative causal models (mixture\ncomponents or clusters), and achieves an improved structure learning\nperformance on heterogeneous synthetic data when informed by a simulated\nexpert. Finally, we demonstrate that our approach is capable of capturing\ncomplex distributions in a breast cancer database.",
      "pdf_url": "http://arxiv.org/pdf/2510.06735v1",
      "arxiv_url": "http://arxiv.org/abs/2510.06735v1",
      "published": "2025-10-08",
      "categories": [
        "cs.LG",
        "stat.ME"
      ]
    },
    {
      "title": "Stable central limit theorems for discrete-time lag martingale difference arrays",
      "authors": [
        "Easton Huch",
        "Walter Dempsey"
      ],
      "abstract": "Recent work in dynamic causal inference introduced a class of discrete-time\nstochastic processes that generalize martingale difference sequences and arrays\nas follows: the random variates in each sequence have expectation zero given\ncertain lagged filtrations but not given the natural filtration. We formalize\nthis class of stochastic processes and prove a stable central limit theorem\n(CLT) via a Bernstein blocking scheme and an application of the classical\nmartingale CLT. We generalize our limit theorem to vector-valued processes via\nthe Cram\\'er-Wold device and develop a simple form for the limiting variance.\nWe demonstrate the application of these results to a problem in dynamic causal\ninference and present a simulation study supporting their validity.",
      "pdf_url": "http://arxiv.org/pdf/2510.06524v1",
      "arxiv_url": "http://arxiv.org/abs/2510.06524v1",
      "published": "2025-10-07",
      "categories": [
        "math.ST",
        "math.PR",
        "stat.TH",
        "60G48, 60F05 (Primary), 60G42, 60B12 (Secondary)"
      ]
    },
    {
      "title": "BlockGPT: Spatio-Temporal Modelling of Rainfall via Frame-Level Autoregression",
      "authors": [
        "Cristian Meo",
        "Varun Sarathchandran",
        "Avijit Majhi",
        "Shao Hung",
        "Carlo Saccardi",
        "Ruben Imhoff",
        "Roberto Deidda",
        "Remko Uijlenhoet",
        "Justin Dauwels"
      ],
      "abstract": "Predicting precipitation maps is a highly complex spatiotemporal modeling\ntask, critical for mitigating the impacts of extreme weather events. Short-term\nprecipitation forecasting, or nowcasting, requires models that are not only\naccurate but also computationally efficient for real-time applications. Current\nmethods, such as token-based autoregressive models, often suffer from flawed\ninductive biases and slow inference, while diffusion models can be\ncomputationally intensive. To address these limitations, we introduce BlockGPT,\na generative autoregressive transformer using batched tokenization (Block)\nmethod that predicts full two-dimensional fields (frames) at each time step.\nConceived as a model-agnostic paradigm for video prediction, BlockGPT\nfactorizes space-time by using self-attention within each frame and causal\nattention across frames; in this work, we instantiate it for precipitation\nnowcasting. We evaluate BlockGPT on two precipitation datasets, viz. KNMI\n(Netherlands) and SEVIR (U.S.), comparing it to state-of-the-art baselines\nincluding token-based (NowcastingGPT) and diffusion-based (DiffCast+Phydnet)\nmodels. The results show that BlockGPT achieves superior accuracy, event\nlocalization as measured by categorical metrics, and inference speeds up to 31x\nfaster than comparable baselines.",
      "pdf_url": "http://arxiv.org/pdf/2510.06293v1",
      "arxiv_url": "http://arxiv.org/abs/2510.06293v1",
      "published": "2025-10-07",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Can language models boost the power of randomized experiments without statistical bias?",
      "authors": [
        "Xinrui Ruan",
        "Xinwei Ma",
        "Yingfei Wang",
        "Waverly Wei",
        "Jingshen Wang"
      ],
      "abstract": "Randomized experiments or randomized controlled trials (RCTs) are gold\nstandards for causal inference, yet cost and sample-size constraints limit\npower. Meanwhile, modern RCTs routinely collect rich, unstructured data that\nare highly prognostic of outcomes but rarely used in causal analyses. We\nintroduce CALM (Causal Analysis leveraging Language Models), a statistical\nframework that integrates large language models (LLMs) predictions with\nestablished causal estimators to increase precision while preserving\nstatistical validity. CALM treats LLM outputs as auxiliary prognostic\ninformation and corrects their potential bias via a heterogeneous calibration\nstep that residualizes and optimally reweights predictions. We prove that CALM\nremains consistent even when LLM predictions are biased and achieves efficiency\ngains over augmented inverse probability weighting estimators for various\ncausal effects. In particular, CALM develops a few-shot variant that aggregates\npredictions across randomly sampled demonstration sets. The resulting\nU-statistic-like predictor restores i.i.d. structure and also mitigates\nprompt-selection variability. Empirically, in simulations calibrated to a\nmobile-app depression RCT, CALM delivers lower variance relative to other\nbenchmarking methods, is effective in zero- and few-shot settings, and remains\nstable across prompt designs. By principled use of LLMs to harness unstructured\ndata and external knowledge learned during pretraining, CALM provides a\npractical path to more precise causal analyses in RCTs.",
      "pdf_url": "http://arxiv.org/pdf/2510.05545v1",
      "arxiv_url": "http://arxiv.org/abs/2510.05545v1",
      "published": "2025-10-07",
      "categories": [
        "stat.ME",
        "econ.EM"
      ]
    }
  ]
}