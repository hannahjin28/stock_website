{
  "last_updated": "2025-12-05T00:56:03.887945",
  "papers": [
    {
      "title": "GaussDetect-LiNGAM:Causal Direction Identification without Gaussianity test",
      "authors": [
        "Ziyi Ding",
        "Xiao-Ping Zhang"
      ],
      "abstract": "We propose GaussDetect-LiNGAM, a novel approach for bivariate causal discovery that eliminates the need for explicit Gaussianity tests by leveraging a fundamental equivalence between noise Gaussianity and residual independence in the reverse regression. Under the standard LiNGAM assumptions of linearity, acyclicity, and exogeneity, we prove that the Gaussianity of the forward-model noise is equivalent to the independence between the regressor and residual in the reverse model. This theoretical insight allows us to replace fragile and sample-sensitive Gaussianity tests with robust kernel-based independence tests. Experimental results validate the equivalence and demonstrate that GaussDetect-LiNGAM maintains high consistency across diverse noise types and sample sizes, while reducing the number of tests per decision (TPD). Our method enhances both the efficiency and practical applicability of causal inference, making LiNGAM more accessible and reliable in real-world scenarios.",
      "pdf_url": "https://arxiv.org/pdf/2512.03428v1",
      "arxiv_url": "http://arxiv.org/abs/2512.03428v1",
      "published": "2025-12-03",
      "categories": [
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "title": "Assumption-Lean Differential Variance Inference for Heterogeneous Treatment Effect Detection",
      "authors": [
        "Philippe A. Boileau",
        "Hani Zaki",
        "Gabriele Lileikyte",
        "Niklas Nielsen",
        "Patrick R. Lawler",
        "Mireille E. Schnitzer"
      ],
      "abstract": "The conditional average treatment effect (CATE) is frequently estimated to refute the homogeneous treatment effect assumption. Under this assumption, all units making up the population under study experience identical benefit from a given treatment. Uncovering heterogeneous treatment effects through inference about the CATE, however, requires that covariates truly modifying the treatment effect be reliably collected at baseline. CATE-based techniques will necessarily fail to detect violations when effect modifiers are omitted from the data due to, for example, resource constraints. Severe measurement error has a similar impact. To address these limitations, we prove that the homogeneous treatment effect assumption can be gauged through inference about contrasts of the potential outcomes' variances. We derive causal machine learning estimators of these contrasts and study their asymptotic properties. We establish that these estimators are doubly robust and asymptotically linear under mild conditions, permitting formal hypothesis testing about the homogeneous treatment effect assumption even when effect modifiers are missing or mismeasured. Numerical experiments demonstrate that these estimators' asymptotic guarantees are approximately achieved in experimental and observational data alike. These inference procedures are then used to detect heterogeneous treatment effects in the re-analysis of randomized controlled trials investigating targeted temperature management in cardiac arrest patients.",
      "pdf_url": "https://arxiv.org/pdf/2512.03254v1",
      "arxiv_url": "http://arxiv.org/abs/2512.03254v1",
      "published": "2025-12-02",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "The BEAT-CF Causal Model: A model for guiding the design of trials and observational analyses of cystic fibrosis exacerbations",
      "authors": [
        "Steven Mascaro",
        "Owen Woodberry",
        "Charlie McLeod",
        "Mitch Messer",
        "Hiran Selvadurai",
        "Yue Wu",
        "Andre Schultz",
        "Thomas L Snelling"
      ],
      "abstract": "Loss of lung function in cystic fibrosis (CF) occurs progressively, punctuated by acute pulmonary exacerbations (PEx) in which abrupt declines in lung function are not fully recovered. A key component of CF management over the past half century has been the treatment of PEx to slow lung function decline. This has been credited with improvements in survival for people with CF (PwCF), but there is no consensus on the optimal approach to PEx management. BEAT-CF (Bayesian evidence-adaptive treatment of CF) was established to build an evidence-informed knowledge base for CF management. The BEAT-CF causal model is a directed acyclic graph (DAG) and Bayesian network (BN) for PEx that aims to inform the design and analysis of clinical trials comparing the effectiveness of alternative approaches to PEx management. The causal model describes relationships between background risk factors, treatments, and pathogen colonisation of the airways that affect the outcome of an individual PEx episode. The key factors, outcomes, and causal relationships were elicited from CF clinical experts and together represent current expert understanding of the pathophysiology of a PEx episode, guiding the design of data collection and studies and enabling causal inference. Here, we present the DAG that documents this understanding, along with the processes used in its development, providing transparency around our trial design and study processes, as well as a reusable framework for others.",
      "pdf_url": "https://arxiv.org/pdf/2512.03110v1",
      "arxiv_url": "http://arxiv.org/abs/2512.03110v1",
      "published": "2025-12-02",
      "categories": [
        "q-bio.QM",
        "cs.AI"
      ]
    },
    {
      "title": "SpriteHand: Real-Time Versatile Hand-Object Interaction with Autoregressive Video Generation",
      "authors": [
        "Zisu Li",
        "Hengye Lyu",
        "Jiaxin Shi",
        "Yufeng Zeng",
        "Mingming Fan",
        "Hanwang Zhang",
        "Chen Liang"
      ],
      "abstract": "Modeling and synthesizing complex hand-object interactions remains a significant challenge, even for state-of-the-art physics engines. Conventional simulation-based approaches rely on explicitly defined rigid object models and pre-scripted hand gestures, making them inadequate for capturing dynamic interactions with non-rigid or articulated entities such as deformable fabrics, elastic materials, hinge-based structures, furry surfaces, or even living creatures. In this paper, we present SpriteHand, an autoregressive video generation framework for real-time synthesis of versatile hand-object interaction videos across a wide range of object types and motion patterns. SpriteHand takes as input a static object image and a video stream in which the hands are imagined to interact with the virtual object embedded in a real-world scene, and generates corresponding hand-object interaction effects in real time. Our model employs a causal inference architecture for autoregressive generation and leverages a hybrid post-training approach to enhance visual realism and temporal coherence. Our 1.3B model supports real-time streaming generation at around 18 FPS and 640x368 resolution, with an approximate 150 ms latency on a single NVIDIA RTX 5090 GPU, and more than a minute of continuous output. Experiments demonstrate superior visual quality, physical plausibility, and interaction fidelity compared to both generative and engine-based baselines.",
      "pdf_url": "https://arxiv.org/pdf/2512.01960v1",
      "arxiv_url": "http://arxiv.org/abs/2512.01960v1",
      "published": "2025-12-01",
      "categories": [
        "cs.CV",
        "cs.HC"
      ]
    },
    {
      "title": "Mitigating Gender Bias in Depression Detection via Counterfactual Inference",
      "authors": [
        "Mingxuan Hu",
        "Hongbo Ma",
        "Xinlan Wu",
        "Ziqi Liu",
        "Jiaqi Liu",
        "Yangbin Chen"
      ],
      "abstract": "Audio-based depression detection models have demonstrated promising performance but often suffer from gender bias due to imbalanced training data. Epidemiological statistics show a higher prevalence of depression in females, leading models to learn spurious correlations between gender and depression. Consequently, models tend to over-diagnose female patients while underperforming on male patients, raising significant fairness concerns. To address this, we propose a novel Counterfactual Debiasing Framework grounded in causal inference. We construct a causal graph to model the decision-making process and identify gender bias as the direct causal effect of gender on the prediction. During inference, we employ counterfactual inference to estimate and subtract this direct effect, ensuring the model relies primarily on authentic acoustic pathological features. Extensive experiments on the DAIC-WOZ dataset using two advanced acoustic backbones demonstrate that our framework not only significantly reduces gender bias but also improves overall detection performance compared to existing debiasing strategies.",
      "pdf_url": "https://arxiv.org/pdf/2512.01834v1",
      "arxiv_url": "http://arxiv.org/abs/2512.01834v1",
      "published": "2025-12-01",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ]
    },
    {
      "title": "CauSight: Learning to Supersense for Visual Causal Discovery",
      "authors": [
        "Yize Zhang",
        "Meiqi Chen",
        "Sirui Chen",
        "Bo Peng",
        "Yanxi Zhang",
        "Tianyu Li",
        "Chaochao Lu"
      ],
      "abstract": "Causal thinking enables humans to understand not just what is seen, but why it happens. To replicate this capability in modern AI systems, we introduce the task of visual causal discovery. It requires models to infer cause-and-effect relations among visual entities across diverse scenarios instead of merely perceiving their presence. To this end, we first construct the Visual Causal Graph dataset (VCG-32K), a large-scale collection of over 32,000 images annotated with entity-level causal graphs, and further develop CauSight, a novel vision-language model to perform visual causal discovery through causally aware reasoning. Our training recipe integrates three components: (1) training data curation from VCG-32K, (2) Tree-of-Causal-Thought (ToCT) for synthesizing reasoning trajectories, and (3) reinforcement learning with a designed causal reward to refine the reasoning policy. Experiments show that CauSight outperforms GPT-4.1 on visual causal discovery, achieving over a threefold performance boost (21% absolute gain). Our code, model, and dataset are fully open-sourced at project page: https://github.com/OpenCausaLab/CauSight.",
      "pdf_url": "https://arxiv.org/pdf/2512.01827v1",
      "arxiv_url": "http://arxiv.org/abs/2512.01827v1",
      "published": "2025-12-01",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "Probabilistic Neuro-Symbolic Reasoning for Sparse Historical Data: A Framework Integrating Bayesian Inference, Causal Models, and Game-Theoretic Allocation",
      "authors": [
        "Saba Kublashvili"
      ],
      "abstract": "Modeling historical events poses fundamental challenges for machine learning: extreme data scarcity (N << 100), heterogeneous and noisy measurements, missing counterfactuals, and the requirement for human interpretable explanations. We present HistoricalML, a probabilistic neuro-symbolic framework that addresses these challenges through principled integration of (1) Bayesian uncertainty quantification to separate epistemic from aleatoric uncertainty, (2) structural causal models for counterfactual reasoning under confounding, (3) cooperative game theory (Shapley values) for fair allocation modeling, and (4) attention based neural architectures for context dependent factor weighting. We provide theoretical analysis showing that our approach achieves consistent estimation in the sparse data regime when strong priors from domain knowledge are available, and that Shapley based allocation satisfies axiomatic fairness guarantees that pure regression approaches cannot provide. We instantiate the framework on two historical case studies: the 19th century partition of Africa (N = 7 colonial powers) and the Second Punic War (N = 2 factions). Our model identifies Germany's +107.9 percent discrepancy as a quantifiable structural tension preceding World War I, with tension factor 36.43 and 0.79 naval arms race correlation. For the Punic Wars, Monte Carlo battle simulations achieve a 57.3 percent win probability for Carthage at Cannae and 57.8 percent for Rome at Zama, aligning with historical outcomes. Counterfactual analysis reveals that Carthaginian political support (support score 6.4 vs Napoleon's 7.1), rather than military capability, was the decisive factor.",
      "pdf_url": "https://arxiv.org/pdf/2512.01723v1",
      "arxiv_url": "http://arxiv.org/abs/2512.01723v1",
      "published": "2025-12-01",
      "categories": [
        "cs.AI",
        "cs.GT",
        "math.PR"
      ]
    },
    {
      "title": "Parallel Delayed Memory Units for Enhanced Temporal Modeling in Biomedical and Bioacoustic Signal Analysis",
      "authors": [
        "Pengfei Sun",
        "Wenyu Jiang",
        "Paul Devos",
        "Dick Botteldooren"
      ],
      "abstract": "Advanced deep learning architectures, particularly recurrent neural networks (RNNs), have been widely applied in audio, bioacoustic, and biomedical signal analysis, especially in data-scarce environments. While gated RNNs remain effective, they can be relatively over-parameterised and less training-efficient in some regimes, while linear RNNs tend to fall short in capturing the complexity inherent in bio-signals. To address these challenges, we propose the Parallel Delayed Memory Unit (PDMU), a {delay-gated state-space module for short-term temporal credit assignment} targeting audio and bioacoustic signals, which enhances short-term temporal state interactions and memory efficiency via a gated delay-line mechanism. Unlike previous Delayed Memory Units (DMU) that embed temporal dynamics into the delay-line architecture, the PDMU further compresses temporal information into vector representations using Legendre Memory Units (LMU). This design serves as a form of causal attention, allowing the model to dynamically adjust its reliance on past states and improve real-time learning performance. Notably, in low-information scenarios, the gating mechanism behaves similarly to skip connections by bypassing state decay and preserving early representations, thereby facilitating long-term memory retention. The PDMU is modular, supporting parallel training and sequential inference, and can be easily integrated into existing linear RNN frameworks. Furthermore, we introduce bidirectional, efficient, and spiking variants of the architecture, each offering additional gains in performance or energy efficiency. Experimental results on diverse audio and biomedical benchmarks demonstrate that the PDMU significantly enhances both memory capacity and overall model performance.",
      "pdf_url": "https://arxiv.org/pdf/2512.01626v1",
      "arxiv_url": "http://arxiv.org/abs/2512.01626v1",
      "published": "2025-12-01",
      "categories": [
        "cs.SD",
        "cs.NE"
      ]
    },
    {
      "title": "A Self-explainable Model of Long Time Series by Extracting Informative Structured Causal Patterns",
      "authors": [
        "Ziqian Wang",
        "Yuxiao Cheng",
        "Jinli Suo"
      ],
      "abstract": "Explainability is essential for neural networks that model long time series, yet most existing explainable AI methods only produce point-wise importance scores and fail to capture temporal structures such as trends, cycles, and regime changes. This limitation weakens human interpretability and trust in long-horizon models. To address these issues, we identify four key requirements for interpretable time-series modeling: temporal continuity, pattern-centric explanation, causal disentanglement, and faithfulness to the model's inference process. We propose EXCAP, a unified framework that satisfies all four requirements. EXCAP combines an attention-based segmenter that extracts coherent temporal patterns, a causally structured decoder guided by a pre-trained causal graph, and a latent aggregation mechanism that enforces representation stability. Our theoretical analysis shows that EXCAP provides smooth and stable explanations over time and is robust to perturbations in causal masks. Extensive experiments on classification and forecasting benchmarks demonstrate that EXCAP achieves strong predictive accuracy while generating coherent and causally grounded explanations. These results show that EXCAP offers a principled and scalable approach to interpretable modeling of long time series with relevance to high-stakes domains such as healthcare and finance.",
      "pdf_url": "https://arxiv.org/pdf/2512.01412v1",
      "arxiv_url": "http://arxiv.org/abs/2512.01412v1",
      "published": "2025-12-01",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "A Benchmark of Causal vs Correlation AI for Predictive Maintenance",
      "authors": [
        "Krishna Taduri",
        "Shaunak Dhande",
        "Giacinto Paolo",
        "Saggese",
        "Paul Smith"
      ],
      "abstract": "Predictive maintenance in manufacturing environments presents a challenging optimization problem characterized by extreme cost asymmetry, where missed failures incur costs roughly fifty times higher than false alarms. Conventional machine learning approaches typically optimize statistical accuracy metrics that do not reflect this operational reality and cannot reliably distinguish causal relationships from spurious correlations. This study evaluates eight predictive models, ranging from baseline statistical approaches to formal causal inference methods, on a dataset of 10,000 CNC machines with a 3.3% failure prevalence. The formal causal inference model (L5) achieved estimated annual cost savings of 1.16 million USD (a 70.2 percent reduction), outperforming the best correlation-based decision tree model (L3) by approximately 80,000 USD per year. The causal model matched the highest observed recall (87.9 percent) while reducing false alarms by 97 percent (from 165 to 5) and attained a precision of 92.1 percent, with a train-test performance gap of only 2.6 percentage points. These results indicate that causal AI methods, when combined with domain knowledge, can yield superior financial outcomes and more interpretable predictions compared to correlation-based approaches in predictive maintenance applications.",
      "pdf_url": "https://arxiv.org/pdf/2512.01149v1",
      "arxiv_url": "http://arxiv.org/abs/2512.01149v1",
      "published": "2025-11-30",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    }
  ]
}