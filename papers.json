{
  "last_updated": "2025-09-24T00:50:06.399961",
  "papers": [
    {
      "title": "The Narcissus Hypothesis:Descending to the Rung of Illusion",
      "authors": [
        "Riccardo Cadei",
        "Christian Intern√≤"
      ],
      "abstract": "Modern foundational models increasingly reflect not just world knowledge, but\npatterns of human preference embedded in their training data. We hypothesize\nthat recursive alignment-via human feedback and model-generated corpora-induces\na social desirability bias, nudging models to favor agreeable or flattering\nresponses over objective reasoning. We refer to it as the Narcissus Hypothesis\nand test it across 31 models using standardized personality assessments and a\nnovel Social Desirability Bias score. Results reveal a significant drift toward\nsocially conforming traits, with profound implications for corpus integrity and\nthe reliability of downstream inferences. We then offer a novel epistemological\ninterpretation, tracing how recursive bias may collapse higher-order reasoning\ndown Pearl's Ladder of Causality, culminating in what we refer to as the Rung\nof Illusion.",
      "pdf_url": "http://arxiv.org/pdf/2509.17999v1",
      "arxiv_url": "http://arxiv.org/abs/2509.17999v1",
      "published": "2025-09-22",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ]
    },
    {
      "title": "Everything all at once: On choosing an estimand for multi-component environmental exposures",
      "authors": [
        "Kara E. Rudolph",
        "Shodai Inose",
        "Nicholas Williams",
        "Ivan Diaz",
        "Lucia Calderon",
        "Jacqueline M. Torres",
        "Marianthi-Anna Kioumourtzoglou"
      ],
      "abstract": "Many research questions -- particularly those in environmental health -- do\nnot involve binary exposures. In environmental epidemiology, this includes\nmultivariate exposure mixtures with nondiscrete components. Causal inference\nestimands and estimators to quantify the relationship between an exposure\nmixture and an outcome are relatively few. We propose an approach to quantify a\nrelationship between a shift in the exposure mixture and the outcome -- either\nin the single timepoint or longitudinal setting. The shift in the exposure\nmixture can be defined flexibly in terms of shifting one or more components,\nincluding examining interaction between mixture components, and in terms of\nshifting the same or different amounts across components. The estimand we\ndiscuss has a similar interpretation as a main effect regression coefficient.\nFirst, we focus on choosing a shift in the exposure mixture supported by\nobserved data. We demonstrate how to assess extrapolation and modify the shift\nto minimize reliance on extrapolation. Second, we propose estimating the\nrelationship between the exposure mixture shift and outcome completely\nnonparametrically, using machine learning in model-fitting. This is in contrast\nto other current approaches, which employ parametric modeling for at least some\nrelationships, which we would like to avoid because parametric modeling\nassumptions in complex, nonrandomized settings are tenuous at best. We are\nmotivated by longitudinal data on pesticide exposures among participants in the\nCHAMACOS Maternal Cognition cohort. We examine the relationship between\nlongitudinal exposure to agricultural pesticides and risk of hypertension. We\nprovide step-by-step code to facilitate the easy replication and adaptation of\nthe approaches we use.",
      "pdf_url": "http://arxiv.org/pdf/2509.17960v1",
      "arxiv_url": "http://arxiv.org/abs/2509.17960v1",
      "published": "2025-09-22",
      "categories": [
        "stat.ME",
        "stat.AP"
      ]
    },
    {
      "title": "Revealing Multimodal Causality with Large Language Models",
      "authors": [
        "Jin Li",
        "Shoujin Wang",
        "Qi Zhang",
        "Feng Liu",
        "Tongliang Liu",
        "Longbing Cao",
        "Shui Yu",
        "Fang Chen"
      ],
      "abstract": "Uncovering cause-and-effect mechanisms from data is fundamental to scientific\nprogress. While large language models (LLMs) show promise for enhancing causal\ndiscovery (CD) from unstructured data, their application to the increasingly\nprevalent multimodal setting remains a critical challenge. Even with the advent\nof multimodal LLMs (MLLMs), their efficacy in multimodal CD is hindered by two\nprimary limitations: (1) difficulty in exploring intra- and inter-modal\ninteractions for comprehensive causal variable identification; and (2)\ninsufficiency to handle structural ambiguities with purely observational data.\nTo address these challenges, we propose MLLM-CD, a novel framework for\nmultimodal causal discovery from unstructured data. It consists of three key\ncomponents: (1) a novel contrastive factor discovery module to identify genuine\nmultimodal factors based on the interactions explored from contrastive sample\npairs; (2) a statistical causal structure discovery module to infer causal\nrelationships among discovered factors; and (3) an iterative multimodal\ncounterfactual reasoning module to refine the discovery outcomes iteratively by\nincorporating the world knowledge and reasoning capabilities of MLLMs.\nExtensive experiments on both synthetic and real-world datasets demonstrate the\neffectiveness of MLLM-CD in revealing genuine factors and causal relationships\namong them from multimodal unstructured data.",
      "pdf_url": "http://arxiv.org/pdf/2509.17784v1",
      "arxiv_url": "http://arxiv.org/abs/2509.17784v1",
      "published": "2025-09-22",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Regularizing Extrapolation in Causal Inference",
      "authors": [
        "David Arbour",
        "Harsh Parikh",
        "Bijan Niknam",
        "Elizabeth Stuart",
        "Kara Rudolph",
        "Avi Feller"
      ],
      "abstract": "Many common estimators in machine learning and causal inference are linear\nsmoothers, where the prediction is a weighted average of the training outcomes.\nSome estimators, such as ordinary least squares and kernel ridge regression,\nallow for arbitrarily negative weights, which improve feature imbalance but\noften at the cost of increased dependence on parametric modeling assumptions\nand higher variance. By contrast, estimators like importance weighting and\nrandom forests (sometimes implicitly) restrict weights to be non-negative,\nreducing dependence on parametric modeling and variance at the cost of worse\nimbalance. In this paper, we propose a unified framework that directly\npenalizes the level of extrapolation, replacing the current practice of a hard\nnon-negativity constraint with a soft constraint and corresponding\nhyperparameter. We derive a worst-case extrapolation error bound and introduce\na novel \"bias-bias-variance\" tradeoff, encompassing biases due to feature\nimbalance, model misspecification, and estimator variance; this tradeoff is\nespecially pronounced in high dimensions, particularly when positivity is poor.\nWe then develop an optimization procedure that regularizes this bound while\nminimizing imbalance and outline how to use this approach as a sensitivity\nanalysis for dependence on parametric modeling assumptions. We demonstrate the\neffectiveness of our approach through synthetic experiments and a real-world\napplication, involving the generalization of randomized controlled trial\nestimates to a target population of interest.",
      "pdf_url": "http://arxiv.org/pdf/2509.17180v1",
      "arxiv_url": "http://arxiv.org/abs/2509.17180v1",
      "published": "2025-09-21",
      "categories": [
        "cs.LG",
        "econ.EM",
        "stat.ME"
      ]
    },
    {
      "title": "Closing the Loop Inside Neural Networks: Causality-Guided Layer Adaptation for Fault Recovery Control",
      "authors": [
        "Mahdi Taheri",
        "Soon-Jo Chung",
        "Fred Y. Hadaegh"
      ],
      "abstract": "This paper studies the problem of real-time fault recovery control for\nnonlinear control-affine systems subject to actuator loss of effectiveness\nfaults and external disturbances. We derive a two-stage framework that combines\ncausal inference with selective online adaptation to achieve an effective\nlearning-based recovery control method. In the offline phase, we develop a\ncausal layer attribution technique based on the average causal effect (ACE) to\nevaluate the relative importance of each layer in a pretrained deep neural\nnetwork (DNN) controller compensating for faults. This methodology identifies a\nsubset of high-impact layers responsible for robust fault compensation. In the\nonline phase, we deploy a Lyapunov-based gradient update to adapt only the\nACE-selected layer to circumvent the need for full-network or last-layer only\nupdates. The proposed adaptive controller guarantees uniform ultimate\nboundedness (UUB) with exponential convergence of the closed-loop system in the\npresence of actuator faults and external disturbances. Compared to conventional\nadaptive DNN controllers with full-network adaptation, our methodology has a\nreduced computational overhead. To demonstrate the effectiveness of our\nproposed methodology, a case study is provided on a 3-axis attitude control\nsystem of a spacecraft with four reaction wheels.",
      "pdf_url": "http://arxiv.org/pdf/2509.16837v1",
      "arxiv_url": "http://arxiv.org/abs/2509.16837v1",
      "published": "2025-09-20",
      "categories": [
        "eess.SY",
        "cs.SY"
      ]
    },
    {
      "title": "Entropic Causal Inference: Graph Identifiability",
      "authors": [
        "Spencer Compton",
        "Kristjan Greenewald",
        "Dmitriy Katz",
        "Murat Kocaoglu"
      ],
      "abstract": "Entropic causal inference is a recent framework for learning the causal graph\nbetween two variables from observational data by finding the\ninformation-theoretically simplest structural explanation of the data, i.e.,\nthe model with smallest entropy. In our work, we first extend the causal graph\nidentifiability result in the two-variable setting under relaxed assumptions.\nWe then show the first identifiability result using the entropic approach for\nlearning causal graphs with more than two nodes. Our approach utilizes the\nproperty that ancestrality between a source node and its descendants can be\ndetermined using the bivariate entropic tests. We provide a sound sequential\npeeling algorithm for general graphs that relies on this property. We also\npropose a heuristic algorithm for small graphs that shows strong empirical\nperformance. We rigorously evaluate the performance of our algorithms on\nsynthetic data generated from a variety of models, observing improvement over\nprior work. Finally we test our algorithms on real-world datasets.",
      "pdf_url": "http://arxiv.org/pdf/2509.16463v1",
      "arxiv_url": "http://arxiv.org/abs/2509.16463v1",
      "published": "2025-09-19",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "What is a good matching of probability measures? A counterfactual lens on transport maps",
      "authors": [
        "Lucas De Lara",
        "Luca Ganassali"
      ],
      "abstract": "Coupling probability measures lies at the core of many problems in statistics\nand machine learning, from domain adaptation to transfer learning and causal\ninference. Yet, even when restricted to deterministic transports, such\ncouplings are not identifiable: two atomless marginals admit infinitely many\ntransport maps. The common recourse to optimal transport, motivated by cost\nminimization and cyclical monotonicity, obscures the fact that several distinct\nnotions of multivariate monotone matchings coexist. In this work, we first\ncarry a comparative analysis of three constructions of transport maps:\ncyclically monotone, quantile-preserving and triangular monotone maps. We\nestablish necessary and sufficient conditions for their equivalence, thereby\nclarifying their respective structural properties. In parallel, we formulate\ncounterfactual reasoning within the framework of structural causal models as a\nproblem of selecting transport maps between fixed marginals, which makes\nexplicit the role of untestable assumptions in counterfactual reasoning. Then,\nwe are able to connect these two perspectives by identifying conditions on\ncausal graphs and structural equations under which counterfactual maps coincide\nwith classical statistical transports. In this way, we delineate the\ncircumstances in which causal assumptions support the use of a specific\nstructure of transport map. Taken together, our results aim to enrich the\ntheoretical understanding of families of transport maps and to clarify their\npossible causal interpretations. We hope this work contributes to establishing\nnew bridges between statistical transport and causal inference.",
      "pdf_url": "http://arxiv.org/pdf/2509.16027v1",
      "arxiv_url": "http://arxiv.org/abs/2509.16027v1",
      "published": "2025-09-19",
      "categories": [
        "stat.ML",
        "cs.LG",
        "math.ST",
        "stat.ME",
        "stat.TH"
      ]
    },
    {
      "title": "Generalized Deep Multi-view Clustering via Causal Learning with Partially Aligned Cross-view Correspondence",
      "authors": [
        "Xihong Yang",
        "Siwei Wang",
        "Jiaqi Jin",
        "Fangdi Wang",
        "Tianrui Liu",
        "Yueming Jin",
        "Xinwang Liu",
        "En Zhu",
        "Kunlun He"
      ],
      "abstract": "Multi-view clustering (MVC) aims to explore the common clustering structure\nacross multiple views. Many existing MVC methods heavily rely on the assumption\nof view consistency, where alignments for corresponding samples across\ndifferent views are ordered in advance. However, real-world scenarios often\npresent a challenge as only partial data is consistently aligned across\ndifferent views, restricting the overall clustering performance. In this work,\nwe consider the model performance decreasing phenomenon caused by data order\nshift (i.e., from fully to partially aligned) as a generalized multi-view\nclustering problem. To tackle this problem, we design a causal multi-view\nclustering network, termed CauMVC. We adopt a causal modeling approach to\nunderstand multi-view clustering procedure. To be specific, we formulate the\npartially aligned data as an intervention and multi-view clustering with\npartially aligned data as an post-intervention inference. However, obtaining\ninvariant features directly can be challenging. Thus, we design a Variational\nAuto-Encoder for causal learning by incorporating an encoder from existing\ninformation to estimate the invariant features. Moreover, a decoder is designed\nto perform the post-intervention inference. Lastly, we design a contrastive\nregularizer to capture sample correlations. To the best of our knowledge, this\npaper is the first work to deal generalized multi-view clustering via causal\nlearning. Empirical experiments on both fully and partially aligned data\nillustrate the strong generalization and effectiveness of CauMVC.",
      "pdf_url": "http://arxiv.org/pdf/2509.16022v1",
      "arxiv_url": "http://arxiv.org/abs/2509.16022v1",
      "published": "2025-09-19",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "CIDER: A Causal Cure for Brand-Obsessed Text-to-Image Models",
      "authors": [
        "Fangjian Shen",
        "Zifeng Liang",
        "Chao Wang",
        "Wushao Wen"
      ],
      "abstract": "Text-to-image (T2I) models exhibit a significant yet under-explored \"brand\nbias\", a tendency to generate contents featuring dominant commercial brands\nfrom generic prompts, posing ethical and legal risks. We propose CIDER, a\nnovel, model-agnostic framework to mitigate bias at inference-time through\nprompt refinement to avoid costly retraining. CIDER uses a lightweight detector\nto identify branded content and a Vision-Language Model (VLM) to generate\nstylistically divergent alternatives. We introduce the Brand Neutrality Score\n(BNS) to quantify this issue and perform extensive experiments on leading T2I\nmodels. Results show CIDER significantly reduces both explicit and implicit\nbiases while maintaining image quality and aesthetic appeal. Our work offers a\npractical solution for more original and equitable content, contributing to the\ndevelopment of trustworthy generative AI.",
      "pdf_url": "http://arxiv.org/pdf/2509.15803v1",
      "arxiv_url": "http://arxiv.org/abs/2509.15803v1",
      "published": "2025-09-19",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Deep learning based doubly robust test for Granger causality",
      "authors": [
        "Yongchang Hui",
        "Chijin Liu",
        "Xiaojun Song"
      ],
      "abstract": "Granger causality is popular for analyzing time series data in many\napplications from natural science to social science including genomics,\nneuroscience, economics, and finance. Consequently, the Granger causality test\nhas become one of the main concerns of the econometrician for decades. Taking\nadvantage of the theoretical breakthroughs in deep learning in recent years, we\npropose a doubly robust Granger causality test (DRGCT). Our method offers\nseveral key advantages. The first and most direct benefit is for the users,\nDRGCT allows them to handle large lag orders while alleviating the curse of\ndimensionality that traditional nonlinear Granger causality tests usually face.\nSecond, introducing a doubly robust test statistic for time series based on\nneural networks that achieves a parametric convergence rate not only suggests a\nnew paradigm for nonparametric inference in econometrics, but also broadens the\napplication scope of deep learning. Third, a multiplier bootstrap method,\ncombined with the doubly robust approach, provides an efficient way to obtain\ncritical values, effectively reducing computational time and avoiding redundant\ncalculations. We prove that the test asymptotically controls the type I error,\nwhile achieving power approaches one, and validate the effectiveness of our\ntest through numerical simulations. In real data analysis, we apply DRGCT to\nrevisit the price-volume relationship problem in the stock markets of America,\nChina, and Japan.",
      "pdf_url": "http://arxiv.org/pdf/2509.15798v1",
      "arxiv_url": "http://arxiv.org/abs/2509.15798v1",
      "published": "2025-09-19",
      "categories": [
        "stat.ME"
      ]
    }
  ]
}