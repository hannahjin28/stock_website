{
  "last_updated": "2025-05-16T00:54:23.973811",
  "papers": [
    {
      "title": "Language Agents Mirror Human Causal Reasoning Biases. How Can We Help Them Think Like Scientists?",
      "authors": [
        "Anthony GX-Chen",
        "Dongyan Lin",
        "Mandana Samiei",
        "Doina Precup",
        "Blake A. Richards",
        "Rob Fergus",
        "Kenneth Marino"
      ],
      "abstract": "Language model (LM) agents are increasingly used as autonomous\ndecision-makers who need to actively gather information to guide their\ndecisions. A crucial cognitive skill for such agents is the efficient\nexploration and understanding of the causal structure of the world -- key to\nrobust, scientifically grounded reasoning. Yet, it remains unclear whether LMs\npossess this capability or exhibit systematic biases leading to erroneous\nconclusions. In this work, we examine LMs' ability to explore and infer causal\nrelationships, using the well-established \"Blicket Test\" paradigm from\ndevelopmental psychology. We find that LMs reliably infer the common, intuitive\ndisjunctive causal relationships but systematically struggle with the unusual,\nyet equally (or sometimes even more) evidenced conjunctive ones. This\n\"disjunctive bias\" persists across model families, sizes, and prompting\nstrategies, and performance further declines as task complexity increases.\nInterestingly, an analogous bias appears in human adults, suggesting that LMs\nmay have inherited deep-seated reasoning heuristics from their training data.\nTo this end, we quantify similarities between LMs and humans, finding that LMs\nexhibit adult-like inference profiles (but not children-like). Finally, we\npropose a test-time sampling method which explicitly samples and eliminates\nhypotheses about causal relationships from the LM. This scalable approach\nsignificantly reduces the disjunctive bias and moves LMs closer to the goal of\nscientific, causally rigorous reasoning.",
      "pdf_url": "http://arxiv.org/pdf/2505.09614v1",
      "arxiv_url": "http://arxiv.org/abs/2505.09614v1",
      "published": "2025-05-14",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Moving towards informative and actionable social media research",
      "authors": [
        "Joseph B. Bak-Coleman",
        "Stephan Lewandowsky",
        "Philipp Lorenz-Spreen",
        "Arvind Narayanan",
        "Amy Orben",
        "Lisa Oswald"
      ],
      "abstract": "Social media is nearly ubiquitous in modern life, and concerns have been\nraised about its putative societal impacts, ranging from undermining mental\nhealth and exacerbating polarization to fomenting violence and disrupting\ndemocracy. Despite extensive research, consensus on these effects remains\nelusive, with observational studies often highlighting concerns while\nrandomized controlled trials (RCTs) yield conflicting or null findings. This\nreview examines how the complexity inherent in social systems can account for\nsuch discrepancies, emphasizing that emergent societal and long-term outcomes\ncannot be readily inferred from individual-level effects. In complex systems,\nsuch as social networks, feedback loops, hysteresis, multi-scale dynamics, and\nnon-linearity limit the utility of approaches for assessing causality that are\notherwise robust in simpler contexts. Revisiting large-scale experiments, we\nexplore how null or conflicting findings may reflect these complexities rather\nthan a true absence of effects. Even in cases where the methods are\nappropriate, assessing the net impacts of social media provides little\nactionable insight given that eliminating social media is not a realistic\noption for whole populations. We argue that progress will require a\ncomplexity-minded approach focused on specific design choices of online\nplatforms that triangulates experimental, observational and theoretical\nmethods.",
      "pdf_url": "http://arxiv.org/pdf/2505.09254v1",
      "arxiv_url": "http://arxiv.org/abs/2505.09254v1",
      "published": "2025-05-14",
      "categories": [
        "cs.SI",
        "nlin.AO"
      ]
    },
    {
      "title": "Modeling Interdependent Cybersecurity Threats Using Bayesian Networks: A Case Study on In-Vehicle Infotainment Systems",
      "authors": [
        "Sangita Sridar"
      ],
      "abstract": "Cybersecurity threats are increasingly marked by interdependence,\nuncertainty, and evolving complexity challenges that traditional assessment\nmethods such as CVSS, STRIDE, and attack trees fail to adequately capture. This\npaper reviews the application of Bayesian Networks (BNs) in cybersecurity risk\nmodeling, highlighting their capacity to represent probabilistic dependencies,\nintegrate diverse threat indicators, and support reasoning under uncertainty. A\nstructured case study is presented in which a STRIDE-based attack tree for an\nautomotive In-Vehicle Infotainment (IVI) system is transformed into a Bayesian\nNetwork. Logical relationships are encoded using Conditional Probability Tables\n(CPTs), and threat likelihoods are derived from normalized DREAD scores. The\nmodel enables not only probabilistic inference of system compromise likelihood\nbut also supports causal analysis using do-calculus and local sensitivity\nanalysis to identify high-impact vulnerabilities. These analyses provide\ninsight into the most influential nodes within the threat propagation chain,\ninforming targeted mitigation strategies. While demonstrating the potential of\nBNs for dynamic and context-aware risk assessment, the study also outlines\nlimitations related to scalability, reliance on expert input, static structure\nassumptions, and limited temporal modeling. The paper concludes by advocating\nfor future enhancements through Dynamic Bayesian Networks, structure learning,\nand adaptive inference to better support real-time cybersecurity\ndecision-making in complex environments.",
      "pdf_url": "http://arxiv.org/pdf/2505.09048v1",
      "arxiv_url": "http://arxiv.org/abs/2505.09048v1",
      "published": "2025-05-14",
      "categories": [
        "cs.CR"
      ]
    },
    {
      "title": "Modern causal inference approaches to improve power for subgroup analysis in randomized controlled trials",
      "authors": [
        "Antonio D'Alessandro",
        "Jiyu Kim",
        "Samrachana Adhikari",
        "Donald Goff",
        "Falco Bargagli Stoffi",
        "Michele Santacatterina"
      ],
      "abstract": "In randomized controlled trials (RCTs), subgroup analyses are often planned\nto evaluate the heterogeneity of treatment effects within pre-specified\nsubgroups of interest. However, these analyses frequently have small sample\nsizes, reducing the power to detect heterogeneous effects. A way to increase\npower is by borrowing external data from similar RCTs or observational studies.\nIn this project, we target the conditional average treatment effect (CATE) as\nthe estimand of interest, provide identification assumptions, and propose a\ndoubly robust estimator that uses machine learning and Bayesian nonparametric\ntechniques. Borrowing data, however, may present the additional challenge of\npractical violations of the positivity assumption, the conditional probability\nof receiving treatment in the external data source may be small, leading to\nlarge inverse weights and erroneous inferences, thus negating the potential\npower gains from borrowing external data. To overcome this challenge, we also\npropose a covariate balancing approach, an automated debiased machine learning\n(DML) estimator, and a calibrated DML estimator. We show improved power in\nvarious simulations and offer practical recommendations for the application of\nthe proposed methods. Finally, we apply them to evaluate the effectiveness of\ncitalopram, a drug commonly used to treat depression, for negative symptoms in\nfirst-episode schizophrenia patients across subgroups defined by duration of\nuntreated psychosis, using data from two RCTs and an observational study.",
      "pdf_url": "http://arxiv.org/pdf/2505.08960v1",
      "arxiv_url": "http://arxiv.org/abs/2505.08960v1",
      "published": "2025-05-13",
      "categories": [
        "stat.ME",
        "62P10"
      ]
    },
    {
      "title": "AC-Reason: Towards Theory-Guided Actual Causality Reasoning with Large Language Models",
      "authors": [
        "Yanxi Zhang",
        "Xin Cong",
        "Zhong Zhang",
        "Xiao Liu",
        "Dongyan Zhao",
        "Yesai Wu"
      ],
      "abstract": "Actual causality (AC), a fundamental aspect of causal reasoning (CR), is\nresponsible for attribution and responsibility assignment in real-world\nscenarios. However, existing LLM-based methods lack grounding in formal AC\ntheory, resulting in limited interpretability. Therefore, we propose AC-Reason,\na semi-formal reasoning framework that identifies causally relevant events\nwithin an AC scenario, infers the values of their formal causal factors (e.g.,\nsufficiency, necessity, and normality), and answers AC queries via a\ntheory-guided algorithm with explanations. While AC-Reason does not explicitly\nconstruct a causal graph, it operates over variables in the underlying causal\nstructure to support principled reasoning. To enable comprehensive evaluation,\nwe introduce AC-Bench, a new benchmark built upon and substantially extending\nBig-Bench Hard Causal Judgment (BBH-CJ). AC-Bench comprises ~1K carefully\nannotated samples, each with detailed reasoning steps and focuses solely on\nactual causation. The case study shows that synthesized samples in AC-Bench\npresent greater challenges for LLMs. Extensive experiments on BBH-CJ and\nAC-Bench show that AC-Reason consistently improves LLM performance over\nbaselines. On BBH-CJ, all tested LLMs surpass the average human rater accuracy\nof 69.60%, with GPT-4 + AC-Reason achieving 75.04%. On AC-Bench, GPT-4 +\nAC-Reason again achieves the highest accuracy of 71.82%. AC-Bench further\nenables fine-grained analysis of reasoning faithfulness, revealing that only\nQwen-2.5-72B-Instruct, Claude-3.5-Sonnet, and GPT-4o exhibit faithful\nreasoning, whereas GPT-4 tends to exploit shortcuts. Finally, our ablation\nstudy proves that integrating AC theory into LLMs is highly effective, with the\nproposed algorithm contributing the most significant performance gains.",
      "pdf_url": "http://arxiv.org/pdf/2505.08750v1",
      "arxiv_url": "http://arxiv.org/abs/2505.08750v1",
      "published": "2025-05-13",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "title": "Assumption-robust Causal Inference",
      "authors": [
        "Aditya Ghosh",
        "Dominik Rothenhäusler"
      ],
      "abstract": "In observational causal inference, it is common to encounter multiple\nadjustment sets that appear equally plausible. It is often untestable which of\nthese adjustment sets are valid to adjust for (i.e., satisfies ignorability).\nThis discrepancy can pose practical challenges as it is typically unclear how\nto reconcile multiple, possibly conflicting estimates of the average treatment\neffect (ATE). A naive approach is to report the whole range (convex hull of the\nunion) of the resulting confidence intervals. However, the width of this\ninterval might not shrink to zero in large samples and can be unnecessarily\nwide in real applications. To address this issue, we propose a summary\nprocedure that generates a single estimate, one confidence interval, and\nidentifies a set of units for which the causal effect estimate remains valid,\nprovided at least one adjustment set is valid. The width of our proposed\nconfidence interval shrinks to zero with sample size at $n^{-1/2}$ rate, unlike\nthe original range which is of constant order. Thus, our assumption-robust\napproach enables reliable causal inference on the ATE even in scenarios where\nmost of the adjustment sets are invalid. Admittedly, this robustness comes at a\ncost: our inferential guarantees apply to a target population close to, but\ndifferent from, the one originally intended. We use synthetic and real-data\nexamples to demonstrate that our proposed procedure provides substantially\ntighter confidence intervals for the ATE as compared to the whole range. In\nparticular, for a real-world dataset on 401(k) retirement plans our method\nproduces a confidence interval 50\\% shorter than the whole range of confidence\nintervals based on multiple adjustment sets.",
      "pdf_url": "http://arxiv.org/pdf/2505.08729v1",
      "arxiv_url": "http://arxiv.org/abs/2505.08729v1",
      "published": "2025-05-13",
      "categories": [
        "stat.ME",
        "econ.EM"
      ]
    },
    {
      "title": "Bayesian Estimation of Causal Effects Using Proxies of a Latent Interference Network",
      "authors": [
        "Bar Weinstein",
        "Daniel Nevo"
      ],
      "abstract": "Network interference occurs when treatments assigned to some units affect the\noutcomes of others. Traditional approaches often assume that the observed\nnetwork correctly specifies the interference structure. However, in practice,\nresearchers frequently only have access to proxy measurements of the\ninterference network due to limitations in data collection or potential\nmismatches between measured networks and actual interference pathways. In this\npaper, we introduce a framework for estimating causal effects when only proxy\nnetworks are available. Our approach leverages a structural causal model that\naccommodates diverse proxy types, including noisy measurements, multiple data\nsources, and multilayer networks, and defines causal effects as interventions\non population-level treatments. Since the true interference network is latent,\nestimation poses significant challenges. To overcome them, we develop a\nBayesian inference framework. We propose a Block Gibbs sampler with Locally\nInformed Proposals to update the latent network, thereby efficiently exploring\nthe high-dimensional posterior space composed of both discrete and continuous\nparameters. We illustrate the performance of our method through numerical\nexperiments, demonstrating its accuracy in recovering causal effects even when\nonly proxies of the interference network are available.",
      "pdf_url": "http://arxiv.org/pdf/2505.08395v1",
      "arxiv_url": "http://arxiv.org/abs/2505.08395v1",
      "published": "2025-05-13",
      "categories": [
        "stat.ME",
        "stat.AP",
        "stat.CO",
        "stat.ML",
        "stat.OT"
      ]
    },
    {
      "title": "Empowering Vision Transformers with Multi-Scale Causal Intervention for Long-Tailed Image Classification",
      "authors": [
        "Xiaoshuo Yan",
        "Zhaochuan Li",
        "Lei Meng",
        "Zhuang Qi",
        "Wei Wu",
        "Zixuan Li",
        "Xiangxu Meng"
      ],
      "abstract": "Causal inference has emerged as a promising approach to mitigate long-tail\nclassification by handling the biases introduced by class imbalance. However,\nalong with the change of advanced backbone models from Convolutional Neural\nNetworks (CNNs) to Visual Transformers (ViT), existing causal models may not\nachieve an expected performance gain. This paper investigates the influence of\nexisting causal models on CNNs and ViT variants, highlighting that ViT's global\nfeature representation makes it hard for causal methods to model associations\nbetween fine-grained features and predictions, which leads to difficulties in\nclassifying tail classes with similar visual appearance. To address these\nissues, this paper proposes TSCNet, a two-stage causal modeling method to\ndiscover fine-grained causal associations through multi-scale causal\ninterventions. Specifically, in the hierarchical causal representation learning\nstage (HCRL), it decouples the background and objects, applying backdoor\ninterventions at both the patch and feature level to prevent model from using\nclass-irrelevant areas to infer labels which enhances fine-grained causal\nrepresentation. In the counterfactual logits bias calibration stage (CLBC), it\nrefines the optimization of model's decision boundary by adaptive constructing\ncounterfactual balanced data distribution to remove the spurious associations\nin the logits caused by data distribution. Extensive experiments conducted on\nvarious long-tail benchmarks demonstrate that the proposed TSCNet can eliminate\nmultiple biases introduced by data imbalance, which outperforms existing\nmethods.",
      "pdf_url": "http://arxiv.org/pdf/2505.08173v1",
      "arxiv_url": "http://arxiv.org/abs/2505.08173v1",
      "published": "2025-05-13",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "Asymptotically Efficient Data-adaptive Penalized Shrinkage Estimation with Application to Causal Inference",
      "authors": [
        "Herbert P. Susmann",
        "Yiting Li",
        "Mara A. McAdams-DeMarco",
        "Wenbo Wu",
        "Iván Díaz"
      ],
      "abstract": "A rich literature exists on constructing non-parametric estimators with\noptimal asymptotic properties. In addition to asymptotic guarantees, it is\noften of interest to design estimators with desirable finite-sample properties;\nsuch as reduced mean-squared error of a large set of parameters. We provide\nexamples drawn from causal inference where this may be the case, such as\nestimating a large number of group-specific treatment effects. We show how\nfinite-sample properties of non-parametric estimators, particularly their\nvariance, can be improved by careful application of penalization. Given a\ntarget parameter of interest we derive a novel penalized parameter defined as\nthe solution to an optimization problem that balances fidelity to the original\nparameter against a penalty term. By deriving the non-parametric efficiency\nbound for the penalized parameter, we are able to propose simple data-adaptive\nchoices for the L1 and L2 tuning parameters designed to minimize finite-sample\nmean-squared error while preserving optimal asymptotic properties. The L1 and\nL2 penalization amounts to an adjustment that can be performed as a\npost-processing step applied to any asymptotically normal and efficient\nestimator. We show in extensive simulations that this adjustment yields\nestimators with lower MSE than the unpenalized estimators. Finally, we apply\nour approach to estimate provider quality measures of kidney dialysis providers\nwithin a causal inference framework.",
      "pdf_url": "http://arxiv.org/pdf/2505.08065v1",
      "arxiv_url": "http://arxiv.org/abs/2505.08065v1",
      "published": "2025-05-12",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "rd2d: Causal Inference in Boundary Discontinuity Designs",
      "authors": [
        "Matias D. Cattaneo",
        "Rocio Titiunik",
        "Ruiqi Rae Yu"
      ],
      "abstract": "Boundary discontinuity designs -- also known as Multi-Score Regression\nDiscontinuity (RD) designs, with Geographic RD designs as a prominent example\n-- are often used in empirical research to learn about causal treatment effects\nalong a continuous assignment boundary defined by a bivariate score. This\narticle introduces the R package rd2d, which implements and extends the\nmethodological results developed in Cattaneo, Titiunik and Yu (2025) for\nboundary discontinuity designs. The package employs local polynomial estimation\nand inference using either the bivariate score or a univariate\ndistance-to-boundary metric. It features novel data-driven bandwidth selection\nprocedures, and offers both pointwise and uniform estimation and inference\nalong the assignment boundary. The numerical performance of the package is\ndemonstrated through a simulation study.",
      "pdf_url": "http://arxiv.org/pdf/2505.07989v1",
      "arxiv_url": "http://arxiv.org/abs/2505.07989v1",
      "published": "2025-05-12",
      "categories": [
        "stat.ME",
        "econ.EM",
        "stat.CO"
      ]
    }
  ]
}