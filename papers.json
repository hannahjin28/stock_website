{
  "last_updated": "2025-04-01T00:56:50.646206",
  "papers": [
    {
      "title": "A Unified Approach for Estimating Various Treatment Effects in Causal Inference",
      "authors": [
        "Kuan-Hsun Wu",
        "Li-Pang Chen"
      ],
      "abstract": "In this paper, we introduce a unified estimator to analyze various treatment\neffects in causal inference, including but not limited to the average treatment\neffect (ATE) and the quantile treatment effect (QTE). The proposed estimator is\ndeveloped under the statistical functional and cumulative distribution function\nstructure, which leads to a flexible and robust estimator and covers some\nfrequent treatment effects. In addition, our approach also takes variable\nselection into account, so that informative and network structure in\nconfounders can be identified and be implemented in our estimation procedure.\nThe theoretical properties, including variable selection consistency and\nasymptotic normality of the statistical functional estimator, are established.\nVarious treatment effects estimations are also conducted in numerical studies,\nand the results reveal that the proposed estimator generally outperforms the\nexisting methods and is more efficient than its competitors.",
      "pdf_url": "http://arxiv.org/pdf/2503.22616v1",
      "arxiv_url": "http://arxiv.org/abs/2503.22616v1",
      "published": "2025-03-28",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "EgoToM: Benchmarking Theory of Mind Reasoning from Egocentric Videos",
      "authors": [
        "Yuxuan Li",
        "Vijay Veerabadran",
        "Michael L. Iuzzolino",
        "Brett D. Roads",
        "Asli Celikyilmaz",
        "Karl Ridgeway"
      ],
      "abstract": "We introduce EgoToM, a new video question-answering benchmark that extends\nTheory-of-Mind (ToM) evaluation to egocentric domains. Using a causal ToM\nmodel, we generate multi-choice video QA instances for the Ego4D dataset to\nbenchmark the ability to predict a camera wearer's goals, beliefs, and next\nactions. We study the performance of both humans and state of the art\nmultimodal large language models (MLLMs) on these three interconnected\ninference problems. Our evaluation shows that MLLMs achieve close to\nhuman-level accuracy on inferring goals from egocentric videos. However, MLLMs\n(including the largest ones we tested with over 100B parameters) fall short of\nhuman performance when inferring the camera wearers' in-the-moment belief\nstates and future actions that are most consistent with the unseen video\nfuture. We believe that our results will shape the future design of an\nimportant class of egocentric digital assistants which are equipped with a\nreasonable model of the user's internal mental states.",
      "pdf_url": "http://arxiv.org/pdf/2503.22152v1",
      "arxiv_url": "http://arxiv.org/abs/2503.22152v1",
      "published": "2025-03-28",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "ClusterSC: Advancing Synthetic Control with Donor Selection",
      "authors": [
        "Saeyoung Rho",
        "Andrew Tang",
        "Noah Bergam",
        "Rachel Cummings",
        "Vishal Misra"
      ],
      "abstract": "In causal inference with observational studies, synthetic control (SC) has\nemerged as a prominent tool. SC has traditionally been applied to\naggregate-level datasets, but more recent work has extended its use to\nindividual-level data. As they contain a greater number of observed units, this\nshift introduces the curse of dimensionality to SC. To address this, we propose\nCluster Synthetic Control (ClusterSC), based on the idea that groups of\nindividuals may exist where behavior aligns internally but diverges between\ngroups. ClusterSC incorporates a clustering step to select only the relevant\ndonors for the target. We provide theoretical guarantees on the improvements\ninduced by ClusterSC, supported by empirical demonstrations on synthetic and\nreal-world datasets. The results indicate that ClusterSC consistently\noutperforms classical SC approaches.",
      "pdf_url": "http://arxiv.org/pdf/2503.21629v1",
      "arxiv_url": "http://arxiv.org/abs/2503.21629v1",
      "published": "2025-03-27",
      "categories": [
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "title": "Inferring Treatment Effects in Large Panels by Uncovering Latent Similarities",
      "authors": [
        "Ben Deaner",
        "Chen-Wei Hsiang",
        "Andrei Zeleneev"
      ],
      "abstract": "The presence of unobserved confounders is one of the main challenges in\nidentifying treatment effects. In this paper, we propose a new approach to\ncausal inference using panel data with large large $N$ and $T$. Our approach\nimputes the untreated potential outcomes for treated units using the outcomes\nfor untreated individuals with similar values of the latent confounders. In\norder to find units with similar latent characteristics, we utilize long\npre-treatment histories of the outcomes. Our analysis is based on a\nnonparametric, nonlinear, and nonseparable factor model for untreated potential\noutcomes and treatments. The model satisfies minimal smoothness requirements.\nWe impute both missing counterfactual outcomes and propensity scores using\nkernel smoothing based on the constructed measure of latent similarity between\nunits, and demonstrate that our estimates can achieve the optimal nonparametric\nrate of convergence up to log terms. Using these estimates, we construct a\ndoubly robust estimator of the period-specifc average treatment effect on the\ntreated (ATT), and provide conditions, under which this estimator is\n$\\sqrt{N}$-consistent, and asymptotically normal and unbiased. Our simulation\nstudy demonstrates that our method provides accurate inference for a wide range\nof data generating processes.",
      "pdf_url": "http://arxiv.org/pdf/2503.20769v2",
      "arxiv_url": "http://arxiv.org/abs/2503.20769v2",
      "published": "2025-03-26",
      "categories": [
        "econ.EM"
      ]
    },
    {
      "title": "Treatment Effects Inference with High-Dimensional Instruments and Control Variables",
      "authors": [
        "Xiduo Chen",
        "Xingdong Feng",
        "Antonio F. Galvao",
        "Yeheng Ge"
      ],
      "abstract": "Obtaining valid treatment effect inferences remains a challenging problem\nwhen dealing with numerous instruments and non-sparse control variables. In\nthis paper, we propose a novel ridge regularization-based instrumental\nvariables method for estimation and inference in the presence of both\nhigh-dimensional instrumental variables and high-dimensional control variables.\nThese methods are applicable both with and without sparsity assumptions. To\naddress the bias caused by high-dimensional instruments, we introduce a\ntwo-step procedure incorporating a data-splitting strategy. We establish\nstatistical properties of the estimator, including consistency and asymptotic\nnormality. Furthermore, we develop statistical inference procedures by\nproviding a consistent estimator for the asymptotic variance of the estimator.\nThe finite sample performance of the proposed method is evaluated through\nnumerical simulations. Results indicate that the new estimator consistently\noutperforms existing sparsity-based approaches across various settings,\noffering valuable insights for more complex scenarios. Finally, we provide an\nempirical application estimating the causal effect of schooling on earnings by\naddressing potential endogeneity through the use of high-dimensional\ninstrumental variables and high-dimensional covariates.",
      "pdf_url": "http://arxiv.org/pdf/2503.20149v1",
      "arxiv_url": "http://arxiv.org/abs/2503.20149v1",
      "published": "2025-03-26",
      "categories": [
        "econ.EM"
      ]
    },
    {
      "title": "Functional structural equation models with out-of-sample guarantees",
      "authors": [
        "Philip Kennerberg",
        "Ernst C. Wit"
      ],
      "abstract": "Statistical learning methods typically assume that the training and test data\noriginate from the same distribution, enabling effective risk minimization.\nHowever, real-world applications frequently involve distributional shifts,\nleading to poor model generalization. To address this, recent advances in\ncausal inference and robust learning have introduced strategies such as\ninvariant causal prediction and anchor regression. While these approaches have\nbeen explored for traditional structural equation models (SEMs), their\nextension to functional systems remains limited. This paper develops a risk\nminimization framework for functional SEMs using linear, potentially unbounded\noperators. We introduce a functional worst-risk minimization approach, ensuring\nrobust predictive performance across shifted environments. Our key contribution\nis a novel worst-risk decomposition theorem, which expresses the maximum\nout-of-sample risk in terms of observed environments. We establish conditions\nfor the existence and uniqueness of the worst-risk minimizer and provide\nconsistent estimation procedures. Empirical results on functional systems\nillustrate the advantages of our method in mitigating distributional shifts.\nThese findings contribute to the growing literature on robust functional\nregression and causal learning, offering practical guarantees for out-of-sample\ngeneralization in dynamic environments.",
      "pdf_url": "http://arxiv.org/pdf/2503.20072v1",
      "arxiv_url": "http://arxiv.org/abs/2503.20072v1",
      "published": "2025-03-25",
      "categories": [
        "math.ST",
        "stat.ME",
        "stat.TH",
        "62R10"
      ]
    },
    {
      "title": "Causal Bayesian Optimization with Unknown Graphs",
      "authors": [
        "Jean Durand",
        "Yashas Annadani",
        "Stefan Bauer",
        "Sonali Parbhoo"
      ],
      "abstract": "Causal Bayesian Optimization (CBO) is a methodology designed to optimize an\noutcome variable by leveraging known causal relationships through targeted\ninterventions. Traditional CBO methods require a fully and accurately specified\ncausal graph, which is a limitation in many real-world scenarios where such\ngraphs are unknown. To address this, we propose a new method for the CBO\nframework that operates without prior knowledge of the causal graph. Consistent\nwith causal bandit theory, we demonstrate through theoretical analysis and that\nfocusing on the direct causal parents of the target variable is sufficient for\noptimization, and provide empirical validation in the context of CBO.\nFurthermore we introduce a new method that learns a Bayesian posterior over the\ndirect parents of the target variable. This allows us to optimize the outcome\nvariable while simultaneously learning the causal structure. Our contributions\ninclude a derivation of the closed-form posterior distribution for the linear\ncase. In the nonlinear case where the posterior is not tractable, we present a\nGaussian Process (GP) approximation that still enables CBO by inferring the\nparents of the outcome variable. The proposed method performs competitively\nwith existing benchmarks and scales well to larger graphs, making it a\npractical tool for real-world applications where causal information is\nincomplete.",
      "pdf_url": "http://arxiv.org/pdf/2503.19554v1",
      "arxiv_url": "http://arxiv.org/abs/2503.19554v1",
      "published": "2025-03-25",
      "categories": [
        "stat.ML",
        "cs.LG"
      ]
    },
    {
      "title": "Body Discovery of Embodied AI",
      "authors": [
        "Zhe Sun",
        "Pengfei Tian",
        "Xiaozhu Hu",
        "Xiaoyu Zhao",
        "Huiying Li",
        "Zhenliang Zhang"
      ],
      "abstract": "In the pursuit of realizing artificial general intelligence (AGI), the\nimportance of embodied artificial intelligence (AI) becomes increasingly\napparent. Following this trend, research integrating robots with AGI has become\nprominent. As various kinds of embodiments have been designed, adaptability to\ndiverse embodiments will become important to AGI. We introduce a new challenge,\ntermed \"Body Discovery of Embodied AI\", focusing on tasks of recognizing\nembodiments and summarizing neural signal functionality. The challenge\nencompasses the precise definition of an AI body and the intricate task of\nidentifying embodiments in dynamic environments, where conventional approaches\noften prove inadequate. To address these challenges, we apply causal inference\nmethod and evaluate it by developing a simulator tailored for testing\nalgorithms with virtual environments. Finally, we validate the efficacy of our\nalgorithms through empirical testing, demonstrating their robust performance in\nvarious scenarios based on virtual environments.",
      "pdf_url": "http://arxiv.org/pdf/2503.19941v1",
      "arxiv_url": "http://arxiv.org/abs/2503.19941v1",
      "published": "2025-03-25",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.NE"
      ]
    },
    {
      "title": "Causal Links Between Anthropogenic Emissions and Air Pollution Dynamics in Delhi",
      "authors": [
        "Sourish Das",
        "Sudeep Shukla",
        "Alka Yadav",
        "Anirban Chakraborti"
      ],
      "abstract": "Air pollution poses significant health and environmental challenges,\nparticularly in rapidly urbanizing regions. Delhi-National Capital Region\nexperiences air pollution episodes due to complex interactions between\nanthropogenic emissions and meteorological conditions. Understanding the causal\ndrivers of key pollutants such as $PM_{2.5}$ and ground $O_3$ is crucial for\ndeveloping effective mitigation strategies. This study investigates the causal\nlinks of anthropogenic emissions on $PM_{2.5}$ and $O_3$ concentrations using\npredictive modeling and causal inference techniques. Integrating\nhigh-resolution air quality data from Jan 2018 to Aug 2023 across 32 monitoring\nstations, we develop predictive regression models that incorporate\nmeteorological variables (temperature and relative humidity), pollutant\nconcentrations ($NO_2, SO_2, CO$), and seasonal harmonic components to capture\nboth diurnal and annual cycles. Here, we show that reductions in anthropogenic\nemissions lead to significant decreases in $PM_{2.5}$ levels, whereas their\neffect on $O_3$ remains marginal and statistically insignificant. To address\nspatial heterogeneity, we employ Gaussian Process modeling. Further, we use\nGranger causality analysis and counterfactual simulation to establish direct\ncausal links. Validation using real-world data from the COVID-19 lockdown\nconfirms that reduced emissions led to a substantial drop in $PM_{2.5}$ but\nonly a slight, insignificant change in $O_3$. The findings highlight the\nnecessity of targeted emission reduction policies while emphasizing the need\nfor integrated strategies addressing both particulate and ozone pollution.\nThese insights are crucial for policymakers designing air pollution\ninterventions in other megacities, and offer a scalable methodology for\ntackling complex urban air pollution through data-driven decision-making.",
      "pdf_url": "http://arxiv.org/pdf/2503.18912v1",
      "arxiv_url": "http://arxiv.org/abs/2503.18912v1",
      "published": "2025-03-24",
      "categories": [
        "stat.AP",
        "physics.ao-ph",
        "physics.soc-ph",
        "stat.ML"
      ]
    },
    {
      "title": "Leveraging Large Language Models for Automated Causal Loop Diagram Generation: Enhancing System Dynamics Modeling through Curated Prompting Techniques",
      "authors": [
        "Ning-Yuan Georgia Liu",
        "David R. Keith"
      ],
      "abstract": "Transforming a dynamic hypothesis into a causal loop diagram (CLD) is crucial\nfor System Dynamics Modelling. Extracting key variables and causal\nrelationships from text to build a CLD is often challenging and time-consuming\nfor novice modelers, limiting SD tool adoption. This paper introduces and tests\na method for automating the translation of dynamic hypotheses into CLDs using\nlarge language models (LLMs) with curated prompting techniques. We first\ndescribe how LLMs work and how they can make the inferences needed to build\nCLDs using a standard digraph structure. Next, we develop a set of simple\ndynamic hypotheses and corresponding CLDs from leading SD textbooks. We then\ncompare the four different combinations of prompting techniques, evaluating\ntheir performance against CLDs labeled by expert modelers. Results show that\nfor simple model structures and using curated prompting techniques, LLMs can\ngenerate CLDs of a similar quality to expert-built ones, accelerating CLD\ncreation.",
      "pdf_url": "http://arxiv.org/pdf/2503.21798v1",
      "arxiv_url": "http://arxiv.org/abs/2503.21798v1",
      "published": "2025-03-23",
      "categories": [
        "cs.LG",
        "cs.CL"
      ]
    }
  ]
}