{
  "last_updated": "2025-09-21T00:54:36.127074",
  "papers": [
    {
      "title": "Randomization inference for stepped-wedge designs with noncompliance with application to a palliative care pragmatic trial",
      "authors": [
        "Jeffrey Zhang",
        "Zhe Chen",
        "Katherine R. Courtright",
        "Scott D. Halpern",
        "Michael O. Harhay",
        "Dylan S. Small",
        "Fan Li"
      ],
      "abstract": "While palliative care is increasingly commonly delivered to hospitalized\npatients with serious illnesses, few studies have estimated its causal effects.\nCourtright et al. (2016) adopted a cluster-randomized stepped-wedge design to\nassess the effect of palliative care on a patient-centered outcome. The\nrandomized intervention was a nudge to administer palliative care but did not\nguarantee receipt of palliative care, resulting in noncompliance (compliance\nrate ~30%). A subsequent analysis using methods suited for standard trial\ndesigns produced statistically anomalous results, as an intention-to-treat\nanalysis found no effect while an instrumental variable analysis did\n(Courtright et al., 2024). This highlights the need for a more principled\napproach to address noncompliance in stepped-wedge designs. We provide a formal\ncausal inference framework for the stepped-wedge design with noncompliance by\nintroducing a relevant causal estimand and corresponding estimators and\ninferential procedures. Through simulation, we compare an array of estimators\nacross a range of stepped-wedge designs and provide practical guidance in\nchoosing an analysis method. Finally, we apply our recommended methods to\nreanalyze the trial of Courtright et al. (2016), producing point estimates\nsuggesting a larger effect than the original analysis of (Courtright et al.,\n2024), but intervals that did not reach statistical significance.",
      "pdf_url": "http://arxiv.org/pdf/2509.14598v1",
      "arxiv_url": "http://arxiv.org/abs/2509.14598v1",
      "published": "2025-09-18",
      "categories": [
        "stat.ME",
        "stat.AP"
      ]
    },
    {
      "title": "Modeling User Redemption Behavior in Complex Incentive Digital Environment: An Empirical Study Using Large-Scale Transactional Data",
      "authors": [
        "Akira Matsui",
        "Takashi Teramoto",
        "Eiji Motohashi",
        "Hiroyuki Tsurumi"
      ],
      "abstract": "The digital economy implements complex incentive systems to retain users\nthrough point redemption. Understanding user behavior in such complex incentive\nstructures presents a fundamental challenge, especially in estimating the value\nof these digital assets against traditional money. This study tackles this\nquestion by analyzing large-scale, real-world transaction data from a popular\npersonal finance application that captures both monetary spending and\npoint-based transactions across Japan's deeply integrated loyalty networks. We\nfind that point usage is not random but is systematically linked to\ndemographics, with older users tending to convert points into financial assets.\nFurthermore, our analysis using a natural experiment and a causal inference\ntechnique reveals that a large point grant stimulated an increase in point\nspending without affecting cash expenditure. We also find that consumers'\nshopping styles are associated with their point redemption patterns. This\nstudy, conducted within a massive real-world economic ecosystem, examines how\nconsumers navigate multi-currency environments, with direct implications for\nmodeling economic behavior and designing digital platforms.",
      "pdf_url": "http://arxiv.org/pdf/2509.14508v1",
      "arxiv_url": "http://arxiv.org/abs/2509.14508v1",
      "published": "2025-09-18",
      "categories": [
        "cs.CY"
      ]
    },
    {
      "title": "Theoretical Note: The Relation Between Structure and Dynamics in Psychological Networks of Attitudes",
      "authors": [
        "Mark G. Orr",
        "Emily S. Teti",
        "Andrei Bura",
        "Henning Mortveit"
      ],
      "abstract": "Two claims of the Causal Attitude Network (CAN) model and the descendent\nAttitude Entropy framework (AE) are indicative of significant theoretical\nhurdles facing the psychological network modeling efforts of attitudes. The\nfirst claim is that the dynamics of change in an Ising like attitude network,\nunder perturbation of any one single node, can be inferred from the static\nnetwork attributes of said node. The second claim is that psychological network\nmodels of attitudes with Ising like dynamics will maximize both attitudinal\nconsistency and accuracy when within the small world topological regime. The\nfirst claim, one with significant application potentials, has not been\nsufficiently tested; the second claim, one with high theoretical novelty, has\nnever been addressed. Using a set of analytic results and simulations, we found\nlittle support for these claims; in short, the predictions are not logically\nconsistent with the theory. Our results have implications beyond attitude\nmodels to the larger field of psychological networks (e.g., in clinical\npsychology) in reference to how we should explain and understand their\ndynamics.",
      "pdf_url": "http://arxiv.org/pdf/2509.14418v1",
      "arxiv_url": "http://arxiv.org/abs/2509.14418v1",
      "published": "2025-09-17",
      "categories": [
        "q-bio.NC"
      ]
    },
    {
      "title": "CETUS: Causal Event-Driven Temporal Modeling With Unified Variable-Rate Scheduling",
      "authors": [
        "Hanfang Liang",
        "Bing Wang",
        "Shizhen Zhang",
        "Wen Jiang",
        "Yizhuo Yang",
        "Weixiang Guo",
        "Shenghai Yuan"
      ],
      "abstract": "Event cameras capture asynchronous pixel-level brightness changes with\nmicrosecond temporal resolution, offering unique advantages for high-speed\nvision tasks. Existing methods often convert event streams into intermediate\nrepresentations such as frames, voxel grids, or point clouds, which inevitably\nrequire predefined time windows and thus introduce window latency. Meanwhile,\npointwise detection methods face computational challenges that prevent\nreal-time efficiency due to their high computational cost. To overcome these\nlimitations, we propose the Variable-Rate Spatial Event Mamba, a novel\narchitecture that directly processes raw event streams without intermediate\nrepresentations. Our method introduces a lightweight causal spatial\nneighborhood encoder to efficiently capture local geometric relations, followed\nby Mamba-based state space models for scalable temporal modeling with linear\ncomplexity. During inference, a controller adaptively adjusts the processing\nspeed according to the event rate, achieving an optimal balance between window\nlatency and inference latency.",
      "pdf_url": "http://arxiv.org/pdf/2509.13784v1",
      "arxiv_url": "http://arxiv.org/abs/2509.13784v1",
      "published": "2025-09-17",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "Semiparametric Causal Inference for Right-Censored Outcomes with Many Weak Invalid Instruments",
      "authors": [
        "Qiushi Bu",
        "Wen Su",
        "Xingqiu Zhao",
        "Zhonghua Liu"
      ],
      "abstract": "We propose a semiparametric framework for causal inference with\nright-censored survival outcomes and many weak invalid instruments, motivated\nby Mendelian randomization in biobank studies where classical methods may fail.\nWe adopt an accelerated failure time model and construct a moment condition\nbased on augmented inverse probability of censoring weighting, incorporating\nboth uncensored and censored observations. Under a heteroscedasticity-based\ncondition on the treatment model, we establish point identification of the\ncausal effect despite censoring and invalid instruments. We propose GEL-NOW\n(Generalized Empirical Likelihood with Non-Orthogonal and Weak moments) for\nvalid inference under these conditions. A divergent number of Neyman orthogonal\nnuisance functions is estimated using deep neural networks. A key challenge is\nthat the conditional censoring distribution is a non-Neyman orthogonal\nnuisance, contributing to the first-order asymptotics of the estimator for the\ntarget causal effect parameter. We derive the asymptotic distribution and\nexplicitly incorporate this additional uncertainty into the asymptotic variance\nformula. We also introduce a censoring-adjusted over-identification test that\naccounts for this variance component. Simulation studies and UK Biobank\napplications demonstrate the method's robustness and practical utility.",
      "pdf_url": "http://arxiv.org/pdf/2509.13176v1",
      "arxiv_url": "http://arxiv.org/abs/2509.13176v1",
      "published": "2025-09-16",
      "categories": [
        "stat.ME",
        "math.ST",
        "stat.TH"
      ]
    },
    {
      "title": "Robust Sensitivity Analysis via Augmented Percentile Bootstrap under Simultaneous Violations of Unconfoundedness and Overlap",
      "authors": [
        "Han Cui",
        "Xinran Li"
      ],
      "abstract": "The identification of causal effects in observational studies typically\nrelies on two standard assumptions: unconfoundedness and overlap. However, both\nassumptions are often questionable in practice: unconfoundedness is inherently\nuntestable, and overlap may fail in the presence of extreme unmeasured\nconfounding. While various approaches have been developed to address unmeasured\nconfounding and extreme propensity scores separately, few methods accommodate\nsimultaneous violations of both assumptions. In this paper, we propose a\nsensitivity analysis framework that relaxes both unconfoundedness and overlap,\nbuilding upon the marginal sensitivity model. Specifically, we allow the bound\non unmeasured confounding to hold for only a subset of the population, thereby\naccommodating heterogeneity in confounding and allowing treatment probabilities\nto be zero or one. Moreover, unlike prior work, our approach does not require\nbounded outcomes and focuses on overlap-weighted average treatment effects,\nwhich are both practically meaningful and robust to non-overlap. We develop\ncomputationally efficient methods to obtain worst-case bounds via linear\nprogramming, and introduce a novel augmented percentile bootstrap procedure for\nstatistical inference. This bootstrap method handles parameters defined through\nover-identified estimating equations involving unobserved variables and may be\nof independent interest. Our work provides a unified and flexible framework for\nsensitivity analysis under violations of both unconfoundedness and overlap.",
      "pdf_url": "http://arxiv.org/pdf/2509.13169v1",
      "arxiv_url": "http://arxiv.org/abs/2509.13169v1",
      "published": "2025-09-16",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Inverse regression for causal inference with multiple outcomes",
      "authors": [
        "Wei Zhang",
        "Qizhai Li",
        "Peng Ding"
      ],
      "abstract": "With multiple outcomes in empirical research, a common strategy is to define\na composite outcome as a weighted average of the original outcomes. However,\nthe choices of weights are often subjective and can be controversial. We\npropose an inverse regression strategy for causal inference with multiple\noutcomes. The key idea is to regress the treatment on the outcomes, which is\nthe inverse of the standard regression of the outcomes on the treatment.\nAlthough this strategy is simple and even counterintuitive, it has several\nadvantages. First, testing for zero coefficients of the outcomes is equivalent\nto testing for the null hypothesis of zero effects, even though the inverse\nregression is deemed misspecified. Second, the coefficients of the outcomes\nprovide a data-driven choice of the weights for defining a composite outcome.\nWe also discuss the associated inference issues. Third, this strategy is\napplicable to general study designs. We illustrate the theory in both\nrandomized experiments and observational studies.",
      "pdf_url": "http://arxiv.org/pdf/2509.12587v1",
      "arxiv_url": "http://arxiv.org/abs/2509.12587v1",
      "published": "2025-09-16",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Prediction and Causality of functional MRI and synthetic signal using a Zero-Shot Time-Series Foundation Model",
      "authors": [
        "Alessandro Crimi",
        "Andrea Brovelli"
      ],
      "abstract": "Time-series forecasting and causal discovery are central in neuroscience, as\npredicting brain activity and identifying causal relationships between neural\npopulations and circuits can shed light on the mechanisms underlying cognition\nand disease. With the rise of foundation models, an open question is how they\ncompare to traditional methods for brain signal forecasting and causality\nanalysis, and whether they can be applied in a zero-shot setting. In this work,\nwe evaluate a foundation model against classical methods for inferring\ndirectional interactions from spontaneous brain activity measured with\nfunctional magnetic resonance imaging (fMRI) in humans. Traditional approaches\noften rely on Wiener-Granger causality. We tested the forecasting ability of\nthe foundation model in both zero-shot and fine-tuned settings, and assessed\ncausality by comparing Granger-like estimates from the model with standard\nGranger causality. We validated the approach using synthetic time series\ngenerated from ground-truth causal models, including logistic map coupling and\nOrnstein-Uhlenbeck processes. The foundation model achieved competitive\nzero-shot forecasting fMRI time series (mean absolute percentage error of 0.55\nin controls and 0.27 in patients). Although standard Granger causality did not\nshow clear quantitative differences between models, the foundation model\nprovided a more precise detection of causal interactions.\n  Overall, these findings suggest that foundation models offer versatility,\nstrong zero-shot performance, and potential utility for forecasting and causal\ndiscovery in time-series data.",
      "pdf_url": "http://arxiv.org/pdf/2509.12497v2",
      "arxiv_url": "http://arxiv.org/abs/2509.12497v2",
      "published": "2025-09-15",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "Causal-Symbolic Meta-Learning (CSML): Inducing Causal World Models for Few-Shot Generalization",
      "authors": [
        "Mohamed Zayaan S"
      ],
      "abstract": "Modern deep learning models excel at pattern recognition but remain\nfundamentally limited by their reliance on spurious correlations, leading to\npoor generalization and a demand for massive datasets. We argue that a key\ningredient for human-like intelligence-robust, sample-efficient learning-stems\nfrom an understanding of causal mechanisms. In this work, we introduce\nCausal-Symbolic Meta-Learning (CSML), a novel framework that learns to infer\nthe latent causal structure of a task distribution. CSML comprises three key\nmodules: a perception module that maps raw inputs to disentangled symbolic\nrepresentations; a differentiable causal induction module that discovers the\nunderlying causal graph governing these symbols and a graph-based reasoning\nmodule that leverages this graph to make predictions. By meta-learning a shared\ncausal world model across a distribution of tasks, CSML can rapidly adapt to\nnovel tasks, including those requiring reasoning about interventions and\ncounterfactuals, from only a handful of examples. We introduce CausalWorld, a\nnew physics-based benchmark designed to test these capabilities. Our\nexperiments show that CSML dramatically outperforms state-of-the-art\nmeta-learning and neuro-symbolic baselines, particularly on tasks demanding\ntrue causal inference.",
      "pdf_url": "http://arxiv.org/pdf/2509.12387v1",
      "arxiv_url": "http://arxiv.org/abs/2509.12387v1",
      "published": "2025-09-15",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "title": "AvatarSync: Rethinking Talking-Head Animation through Autoregressive Perspective",
      "authors": [
        "Yuchen Deng",
        "Xiuyang Wu",
        "Hai-Tao Zheng",
        "Suiyang Zhang",
        "Yi He",
        "Yuxing Han"
      ],
      "abstract": "Existing talking-head animation approaches based on Generative Adversarial\nNetworks (GANs) or diffusion models often suffer from inter-frame flicker,\nidentity drift, and slow inference. These limitations inherent to their video\ngeneration pipelines restrict their suitability for applications. To address\nthis, we introduce AvatarSync, an autoregressive framework on phoneme\nrepresentations that generates realistic and controllable talking-head\nanimations from a single reference image, driven directly text or audio input.\nIn addition, AvatarSync adopts a two-stage generation strategy, decoupling\nsemantic modeling from visual dynamics, which is a deliberate \"Divide and\nConquer\" design. The first stage, Facial Keyframe Generation (FKG), focuses on\nphoneme-level semantic representation by leveraging the many-to-one mapping\nfrom text or audio to phonemes. A Phoneme-to-Visual Mapping is constructed to\nanchor abstract phonemes to character-level units. Combined with a customized\nText-Frame Causal Attention Mask, the keyframes are generated. The second\nstage, inter-frame interpolation, emphasizes temporal coherence and visual\nsmoothness. We introduce a timestamp-aware adaptive strategy based on a\nselective state space model, enabling efficient bidirectional context\nreasoning. To support deployment, we optimize the inference pipeline to reduce\nlatency without compromising visual fidelity. Extensive experiments show that\nAvatarSync outperforms existing talking-head animation methods in visual\nfidelity, temporal consistency, and computational efficiency, providing a\nscalable and controllable solution.",
      "pdf_url": "http://arxiv.org/pdf/2509.12052v1",
      "arxiv_url": "http://arxiv.org/abs/2509.12052v1",
      "published": "2025-09-15",
      "categories": [
        "cs.CV"
      ]
    }
  ]
}