{
  "last_updated": "2025-03-03T00:49:39.172469",
  "papers": [
    {
      "title": "Transfer Learning in Latent Contextual Bandits with Covariate Shift Through Causal Transportability",
      "authors": [
        "Mingwei Deng",
        "Ville Kyrki",
        "Dominik Baumann"
      ],
      "abstract": "Transferring knowledge from one environment to another is an essential\nability of intelligent systems. Nevertheless, when two environments are\ndifferent, naively transferring all knowledge may deteriorate the performance,\na phenomenon known as negative transfer. In this paper, we address this issue\nwithin the framework of multi-armed bandits from the perspective of causal\ninference. Specifically, we consider transfer learning in latent contextual\nbandits, where the actual context is hidden, but a potentially high-dimensional\nproxy is observable. We further consider a covariate shift in the context\nacross environments. We show that naively transferring all knowledge for\nclassical bandit algorithms in this setting led to negative transfer. We then\nleverage transportability theory from causal inference to develop algorithms\nthat explicitly transfer effective knowledge for estimating the causal effects\nof interest in the target environment. Besides, we utilize variational\nautoencoders to approximate causal effects under the presence of a\nhigh-dimensional proxy. We test our algorithms on synthetic and semi-synthetic\ndatasets, empirically demonstrating consistently improved learning efficiency\nacross different proxies compared to baseline algorithms, showing the\neffectiveness of our causal framework in transferring knowledge.",
      "pdf_url": "http://arxiv.org/pdf/2502.20153v1",
      "arxiv_url": "http://arxiv.org/abs/2502.20153v1",
      "published": "2025-02-27",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "Economic Causal Inference Based on DML Framework: Python Implementation of Binary and Continuous Treatment Variables",
      "authors": [
        "Shunxin Yao"
      ],
      "abstract": "This study utilizes a simulated dataset to establish Python code for Double\nMachine Learning (DML) using Anaconda's Jupyter Notebook and the DML software\npackage from GitHub. The research focuses on causal inference experiments for\nboth binary and continuous treatment variables. The findings reveal that the\nDML model demonstrates relatively stable performance in calculating the Average\nTreatment Effect (ATE) and its robustness metrics. However, the study also\nhighlights that the computation of Conditional Average Treatment Effect (CATE)\nremains a significant challenge for future DML modeling, particularly in the\ncontext of continuous treatment variables. This underscores the need for\nfurther research and development in this area to enhance the model's\napplicability and accuracy.",
      "pdf_url": "http://arxiv.org/pdf/2502.19898v1",
      "arxiv_url": "http://arxiv.org/abs/2502.19898v1",
      "published": "2025-02-27",
      "categories": [
        "econ.EM",
        "62P20, 91B84",
        "C.1.3; G.3; I.2.6; J.4"
      ]
    },
    {
      "title": "Semiparametric Triple Difference Estimators",
      "authors": [
        "Sina Akbari",
        "Negar Kiyavash",
        "AmirEmad Ghassami"
      ],
      "abstract": "The triple difference causal inference framework is an extension of the\nwell-known difference-in-differences framework. It relaxes the parallel trends\nassumption of the difference-in-differences framework through leveraging data\nfrom an auxiliary domain. Despite being commonly applied in empirical research,\nthe triple difference framework has received relatively limited attention in\nthe statistics literature. Specifically, investigating the intricacies of\nidentification and the design of robust and efficient estimators for this\nframework has remained largely unexplored. This work aims to address these gaps\nin the literature. From the identification standpoint, we present outcome\nregression and weighting methods to identify the average treatment effect on\nthe treated in both panel data and repeated cross-section settings. For the\nlatter, we relax the commonly made assumption of time-invariant covariates.\nFrom the estimation perspective, we consider semiparametric estimators for the\ntriple difference framework in both panel data and repeated cross-sections\nsettings. We demonstrate that our proposed estimators are doubly robust.",
      "pdf_url": "http://arxiv.org/pdf/2502.19788v1",
      "arxiv_url": "http://arxiv.org/abs/2502.19788v1",
      "published": "2025-02-27",
      "categories": [
        "econ.EM",
        "stat.ME"
      ]
    },
    {
      "title": "Causal Effect Estimation under Networked Interference without Networked Unconfoundedness Assumption",
      "authors": [
        "Weilin Chen",
        "Ruichu Cai",
        "Jie Qiao",
        "Yuguang Yan",
        "José Miguel Hernández-Lobato"
      ],
      "abstract": "Estimating causal effects under networked interference is a crucial yet\nchallenging problem. Existing methods based on observational data mainly rely\non the networked unconfoundedness assumption, which guarantees the\nidentification of networked effects. However, the networked unconfoundedness\nassumption is usually violated due to the latent confounders in observational\ndata, hindering the identification of networked effects. Interestingly, in such\nnetworked settings, interactions between units provide valuable information for\nrecovering latent confounders. In this paper, we identify three types of latent\nconfounders in networked inference that hinder identification: those affecting\nonly the individual, those affecting only neighbors, and those influencing\nboth. Specifically, we devise a networked effect estimator based on\nidentifiable representation learning techniques. Theoretically, we establish\nthe identifiability of all latent confounders, and leveraging the identified\nlatent confounders, we provide the networked effect identification result.\nExtensive experiments validate our theoretical results and demonstrate the\neffectiveness of the proposed method.",
      "pdf_url": "http://arxiv.org/pdf/2502.19741v1",
      "arxiv_url": "http://arxiv.org/abs/2502.19741v1",
      "published": "2025-02-27",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "Training Robust Graph Neural Networks by Modeling Noise Dependencies",
      "authors": [
        "Yeonjun In",
        "Kanghoon Yoon",
        "Sukwon Yun",
        "Kibum Kim",
        "Sungchul Kim",
        "Chanyoung Park"
      ],
      "abstract": "In real-world applications, node features in graphs often contain noise from\nvarious sources, leading to significant performance degradation in GNNs.\nAlthough several methods have been developed to enhance robustness, they rely\non the unrealistic assumption that noise in node features is independent of the\ngraph structure and node labels, thereby limiting their applicability. To this\nend, we introduce a more realistic noise scenario, dependency-aware noise on\ngraphs (DANG), where noise in node features create a chain of noise\ndependencies that propagates to the graph structure and node labels. We propose\na novel robust GNN, DA-GNN, which captures the causal relationships among\nvariables in the data generating process (DGP) of DANG using variational\ninference. In addition, we present new benchmark datasets that simulate DANG in\nreal-world applications, enabling more practical research on robust GNNs.\nExtensive experiments demonstrate that DA-GNN consistently outperforms existing\nbaselines across various noise scenarios, including both DANG and conventional\nnoise models commonly considered in this field.",
      "pdf_url": "http://arxiv.org/pdf/2502.19670v1",
      "arxiv_url": "http://arxiv.org/abs/2502.19670v1",
      "published": "2025-02-27",
      "categories": [
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "title": "Treatment Non-Adherence Bias in Clinical Machine Learning: A Real-World Study on Hypertension Medication",
      "authors": [
        "Zhongyuan Liang",
        "Arvind Suresh",
        "Irene Y. Chen"
      ],
      "abstract": "Machine learning systems trained on electronic health records (EHRs)\nincreasingly guide treatment decisions, but their reliability depends on the\ncritical assumption that patients follow the prescribed treatments recorded in\nEHRs. Using EHR data from 3,623 hypertension patients, we investigate how\ntreatment non-adherence introduces implicit bias that can fundamentally distort\nboth causal inference and predictive modeling. By extracting patient adherence\ninformation from clinical notes using a large language model, we identify 786\npatients (21.7%) with medication non-adherence. We further uncover key\ndemographic and clinical factors associated with non-adherence, as well as\npatient-reported reasons including side effects and difficulties obtaining\nrefills. Our findings demonstrate that this implicit bias can not only reverse\nestimated treatment effects, but also degrade model performance by up to 5%\nwhile disproportionately affecting vulnerable populations by exacerbating\ndisparities in decision outcomes and model error rates. This highlights the\nimportance of accounting for treatment non-adherence in developing responsible\nand equitable clinical machine learning systems.",
      "pdf_url": "http://arxiv.org/pdf/2502.19625v1",
      "arxiv_url": "http://arxiv.org/abs/2502.19625v1",
      "published": "2025-02-26",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "Towards a robust approach to infer causality in molecular systems satisfying detailed balance",
      "authors": [
        "Vittorio Del Tatto",
        "Debarshi Banerjee",
        "Ali Hassanali",
        "Alessandro Laio"
      ],
      "abstract": "The ability to distinguish between correlation and causation of variables in\nmolecular systems remains an interesting and open area of investigation. In\nthis work, we probe causality in a molecular system using two independent\ncomputational methods that infer the causal direction through the language of\ninformation transfer. Specifically, we demonstrate that a molecular dynamics\nsimulation involving a single Tryptophan in liquid water displays asymmetric\ninformation transfer between specific collective variables, such as solute and\nsolvent coordinates. Analyzing a discrete Markov-state and Langevin dynamics on\na 2D free energy surface, we show that the same kind of asymmetries can emerge\neven in extremely simple systems, undergoing equilibrium and time-reversible\ndynamics. We use these model systems to rationalize the unidirectional\ninformation transfer in the molecular system in terms of asymmetries in the\nunderlying free energy landscape and/or relaxation dynamics of the relevant\ncoordinates. Finally, we propose a computational experiment that allows one to\ndecide if an asymmetric information transfer between two variables corresponds\nto a genuine causal link.",
      "pdf_url": "http://arxiv.org/pdf/2502.19384v1",
      "arxiv_url": "http://arxiv.org/abs/2502.19384v1",
      "published": "2025-02-26",
      "categories": [
        "physics.chem-ph",
        "cond-mat.stat-mech",
        "physics.bio-ph"
      ]
    },
    {
      "title": "Long-term Causal Inference via Modeling Sequential Latent Confounding",
      "authors": [
        "Weilin Chen",
        "Ruichu Cai",
        "Yuguang Yan",
        "Zhifeng Hao",
        "José Miguel Hernández-Lobato"
      ],
      "abstract": "Long-term causal inference is an important but challenging problem across\nvarious scientific domains. To solve the latent confounding problem in\nlong-term observational studies, existing methods leverage short-term\nexperimental data. Ghassami et al. propose an approach based on the Conditional\nAdditive Equi-Confounding Bias (CAECB) assumption, which asserts that the\nconfounding bias in the short-term outcome is equal to that in the long-term\noutcome, so that the long-term confounding bias and the causal effects can be\nidentified. While effective in certain cases, this assumption is limited to\nscenarios with a one-dimensional short-term outcome. In this paper, we\nintroduce a novel assumption that extends the CAECB assumption to accommodate\ntemporal short-term outcomes. Our proposed assumption states a functional\nrelationship between sequential confounding biases across temporal short-term\noutcomes, under which we theoretically establish the identification of\nlong-term causal effects. Based on the identification result, we develop an\nestimator and conduct a theoretical analysis of its asymptotic properties.\nExtensive experiments validate our theoretical results and demonstrate the\neffectiveness of the proposed method.",
      "pdf_url": "http://arxiv.org/pdf/2502.18994v1",
      "arxiv_url": "http://arxiv.org/abs/2502.18994v1",
      "published": "2025-02-26",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "Nonparametric Heterogeneous Long-term Causal Effect Estimation via Data Combination",
      "authors": [
        "Weilin Chen",
        "Ruichu Cai",
        "Junjie Wan",
        "Zeqin Yang",
        "José Miguel Hernández-Lobato"
      ],
      "abstract": "Long-term causal inference has drawn increasing attention in many scientific\ndomains. Existing methods mainly focus on estimating average long-term causal\neffects by combining long-term observational data and short-term experimental\ndata. However, it is still understudied how to robustly and effectively\nestimate heterogeneous long-term causal effects, significantly limiting\npractical applications. In this paper, we propose several two-stage style\nnonparametric estimators for heterogeneous long-term causal effect estimation,\nincluding propensity-based, regression-based, and multiple robust estimators.\nWe conduct a comprehensive theoretical analysis of their asymptotic properties\nunder mild assumptions, with the ultimate goal of building a better\nunderstanding of the conditions under which some estimators can be expected to\nperform better. Extensive experiments across several semi-synthetic and\nreal-world datasets validate the theoretical results and demonstrate the\neffectiveness of the proposed estimators.",
      "pdf_url": "http://arxiv.org/pdf/2502.18960v1",
      "arxiv_url": "http://arxiv.org/abs/2502.18960v1",
      "published": "2025-02-26",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "Enhancing DNA Foundation Models to Address Masking Inefficiencies",
      "authors": [
        "Monireh Safari",
        "Pablo Millan Arias",
        "Scott C. Lowe",
        "Lila Kari",
        "Angel X. Chang",
        "Graham W. Taylor"
      ],
      "abstract": "Masked language modelling (MLM) as a pretraining objective has been widely\nadopted in genomic sequence modelling. While pretrained models can successfully\nserve as encoders for various downstream tasks, the distribution shift between\npretraining and inference detrimentally impacts performance, as the pretraining\ntask is to map [MASK] tokens to predictions, yet the [MASK] is absent during\ndownstream applications. This means the encoder does not prioritize its\nencodings of non-[MASK] tokens, and expends parameters and compute on work only\nrelevant to the MLM task, despite this being irrelevant at deployment time. In\nthis work, we propose a modified encoder-decoder architecture based on the\nmasked autoencoder framework, designed to address this inefficiency within a\nBERT-based transformer. We empirically show that the resulting mismatch is\nparticularly detrimental in genomic pipelines where models are often used for\nfeature extraction without fine-tuning. We evaluate our approach on the\nBIOSCAN-5M dataset, comprising over 2 million unique DNA barcodes. We achieve\nsubstantial performance gains in both closed-world and open-world\nclassification tasks when compared against causal models and bidirectional\narchitectures pretrained with MLM tasks.",
      "pdf_url": "http://arxiv.org/pdf/2502.18405v1",
      "arxiv_url": "http://arxiv.org/abs/2502.18405v1",
      "published": "2025-02-25",
      "categories": [
        "cs.LG"
      ]
    }
  ]
}