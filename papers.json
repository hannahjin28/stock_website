{
  "last_updated": "2025-03-07T00:48:03.676999",
  "papers": [
    {
      "title": "Causal language jumps in clinical practice guidelines for diabetes management",
      "authors": [
        "Keling Wang",
        "Chang Wei",
        "Jeremy A. Labrecque"
      ],
      "abstract": "Clinical practice guidelines are designed to guide clinical practice and\ninvolve causal language. Sometimes guidelines make or require stronger causal\nclaims than those in the references they rely on, a phenomenon we refer to as\n'causal language jump'. We evaluated the strength of expressed causation in\ndiabetes guidelines and the evidence they reference to assess the pattern of\njumps. We randomly sampled 300 guideline statements from four diabetes\nguidelines. We rated the causation strength in the statements and the\ndependence on causation in recommendations supported by these statements using\nexisting scales. Among the causal statements, the cited original studies were\nsimilarly assessed. We also assessed how well they report target trial\nemulation (TTE) components as a proxy for reliability. Of the sampled\nstatements, 114 (38.0%) were causal, and 76 (66.7%) expressed strong causation.\n27.2% (31/114) of causal guideline statements demonstrated a \"causal language\njump\", and 34.9% (29/83) of guideline recommendations cannot be effectively\nsupported. Of the 53 eligible studies for TTE rating, most did not report\ntreatment assignment and causal contrast in detail. Our findings suggest causal\nlanguage jumps were common among diabetes guidelines. While these jumps are\nsometimes inevitable, they should always be supported by good causal inference\npractices.",
      "pdf_url": "http://arxiv.org/pdf/2503.03557v1",
      "arxiv_url": "http://arxiv.org/abs/2503.03557v1",
      "published": "2025-03-05",
      "categories": [
        "stat.AP",
        "stat.ME"
      ]
    },
    {
      "title": "The Ejection of Transient Jets in Swift J1727.8-1613 Revealed by Time-Dependent Visibility Modelling",
      "authors": [
        "Callan M. Wood",
        "James C. A. Miller-Jones",
        "Arash Bahramian",
        "Steven J. Tingay",
        "He-Xin Liu",
        "Diego Altamirano",
        "Rob Fender",
        "Elmar KÃ¶rding",
        "Dipankar Maitra",
        "Sera Markoff",
        "David M. Russell",
        "Thomas D. Russell",
        "Craig L. Sarazin",
        "Gregory R. Sivakoff",
        "Roberto Soria",
        "Alexandra J. Tetarenko",
        "Valeriu Tudose"
      ],
      "abstract": "High angular resolution radio observations of relativistic jets are necessary\nto understand the causal connection between accretion and jet ejection in low\nmass X-ray binaries. Images from these observations can be difficult to\nreconstruct due to the rapid intra-observational motion and variability of\ntransient jets. We have developed a time-dependent visibility model fitting and\nself-calibration procedure and applied it to a single four-hour VLBA\nobservation of the low-mass X-ray binary Swift J1727.8-1613 during the bright\nflaring period of its 2023 outburst. This allowed us to detect and model a\nslightly resolved self-absorbed compact core, as well as three downstream\ntransient jet knots. We were able to precisely measure the proper motion and\nflux density variability of these three jet knots, as well as (for the first\ntime) their intra-observational expansion. Using simultaneous multi-frequency\ndata, we were also able to measure the spectral index of the furthest\ndownstream jet knot, and the core, as well as the frequency-dependent core\nshift between 2.3 and 8.3 GHz. Using these measurements, we inferred the\nejection dates of the three jet knots, including one to within $\\pm40$ minutes,\nwhich is one of the most precise ever measured. The ejection of the transient\njet knots coincided with a bright X-ray flare and a drastic change in the X-ray\nspectral and timing properties as seen by HXMT, which is the clearest\nassociation ever seen between the launching of transient relativistic jets in\nan X-ray binary and a sudden change in the X-ray properties of the accretion\ninflow.",
      "pdf_url": "http://arxiv.org/pdf/2503.03073v1",
      "arxiv_url": "http://arxiv.org/abs/2503.03073v1",
      "published": "2025-03-05",
      "categories": [
        "astro-ph.HE"
      ]
    },
    {
      "title": "Out-of-Distribution Generalization on Graphs via Progressive Inference",
      "authors": [
        "Yiming Xu",
        "Bin Shi",
        "Zhen Peng",
        "Huixiang Liu",
        "Bo Dong",
        "Chen Chen"
      ],
      "abstract": "The development and evaluation of graph neural networks (GNNs) generally\nfollow the independent and identically distributed (i.i.d.) assumption. Yet\nthis assumption is often untenable in practice due to the uncontrollable data\ngeneration mechanism. In particular, when the data distribution shows a\nsignificant shift, most GNNs would fail to produce reliable predictions and may\neven make decisions randomly. One of the most promising solutions to improve\nthe model generalization is to pick out causal invariant parts in the input\ngraph. Nonetheless, we observe a significant distribution gap between the\ncausal parts learned by existing methods and the ground truth, leading to\nundesirable performance. In response to the above issues, this paper presents\nGPro, a model that learns graph causal invariance with progressive inference.\nSpecifically, the complicated graph causal invariant learning is decomposed\ninto multiple intermediate inference steps from easy to hard, and the\nperception of GPro is continuously strengthened through a progressive inference\nprocess to extract causal features that are stable to distribution shifts. We\nalso enlarge the training distribution by creating counterfactual samples to\nenhance the capability of the GPro in capturing the causal invariant parts.\nExtensive experiments demonstrate that our proposed GPro outperforms the\nstate-of-the-art methods by 4.91% on average. For datasets with more severe\ndistribution shifts, the performance improvement can be up to 6.86%.",
      "pdf_url": "http://arxiv.org/pdf/2503.02988v1",
      "arxiv_url": "http://arxiv.org/abs/2503.02988v1",
      "published": "2025-03-04",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "PanelMatch: Matching Methods for Causal Inference with Time-Series Cross-Section Data",
      "authors": [
        "Adam Rauh",
        "In Song Kim",
        "Kosuke Imai"
      ],
      "abstract": "Analyzing time-series cross-sectional (also known as longitudinal or panel)\ndata is an important process across a number of fields, including the social\nsciences, economics, finance, and medicine. PanelMatch is an R package that\nimplements a set of tools enabling researchers to apply matching methods for\ncausal inference with time-series cross-sectional data. Relative to other\ncommonly used methods for longitudinal analyses, like regression with fixed\neffects, the matching-based approach implemented in PanelMatch makes fewer\nparametric assumptions and offers more diagnostics. In this paper, we discuss\nthe PanelMatch package, showing users a recommended pipeline for doing causal\ninference analysis with it and highlighting useful diagnostic and visualization\ntools.",
      "pdf_url": "http://arxiv.org/pdf/2503.02073v1",
      "arxiv_url": "http://arxiv.org/abs/2503.02073v1",
      "published": "2025-03-03",
      "categories": [
        "stat.ME",
        "stat.AP"
      ]
    },
    {
      "title": "Learning Exposure Mapping Functions for Inferring Heterogeneous Peer Effects",
      "authors": [
        "Shishir Adhikari",
        "Sourav Medya",
        "Elena Zheleva"
      ],
      "abstract": "In causal inference, interference refers to the phenomenon in which the\nactions of peers in a network can influence an individual's outcome. Peer\neffect refers to the difference in counterfactual outcomes of an individual for\ndifferent levels of peer exposure, the extent to which an individual is exposed\nto the treatments, actions, or behaviors of peers. Estimating peer effects\nrequires deciding how to represent peer exposure. Typically, researchers define\nan exposure mapping function that aggregates peer treatments and outputs peer\nexposure. Most existing approaches for defining exposure mapping functions\nassume peer exposure based on the number or fraction of treated peers. Recent\nstudies have investigated more complex functions of peer exposure which capture\nthat different peers can exert different degrees of influence. However, none of\nthese works have explicitly considered the problem of automatically learning\nthe exposure mapping function. In this work, we focus on learning this function\nfor the purpose of estimating heterogeneous peer effects, where heterogeneity\nrefers to the variation in counterfactual outcomes for the same peer exposure\nbut different individual's contexts. We develop EgoNetGNN, a graph neural\nnetwork (GNN)-based method, to automatically learn the appropriate exposure\nmapping function allowing for complex peer influence mechanisms that, in\naddition to peer treatments, can involve the local neighborhood structure and\nedge attributes. We show that GNN models that use peer exposure based on the\nnumber or fraction of treated peers or learn peer exposure naively face\ndifficulty accounting for such influence mechanisms. Our comprehensive\nevaluation on synthetic and semi-synthetic network data shows that our method\nis more robust to different unknown underlying influence mechanisms when\nestimating heterogeneous peer effects when compared to state-of-the-art\nbaselines.",
      "pdf_url": "http://arxiv.org/pdf/2503.01722v1",
      "arxiv_url": "http://arxiv.org/abs/2503.01722v1",
      "published": "2025-03-03",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SI"
      ]
    },
    {
      "title": "ProRCA: A Causal Python Package for Actionable Root Cause Analysis in Real-world Business Scenarios",
      "authors": [
        "Ahmed Dawoud",
        "Shravan Talupula"
      ],
      "abstract": "Root Cause Analysis (RCA) is becoming ever more critical as modern systems\ngrow in complexity, volume of data, and interdependencies. While traditional\nRCA methods frequently rely on correlation-based or rule-based techniques,\nthese approaches can prove inadequate in highly dynamic, multi-layered\nenvironments. In this paper, we present a pathway-tracing package built on the\nDoWhy causal inference library. Our method integrates conditional anomaly\nscoring, noise-based attribution, and depth-first path exploration to reveal\nmulti-hop causal chains. By systematically tracing entire causal pathways from\nan observed anomaly back to the initial triggers, our approach provides a\ncomprehensive, end-to-end RCA solution. Experimental evaluations with synthetic\nanomaly injections demonstrate the package's ability to accurately isolate\ntriggers and rank root causes by their overall significance.",
      "pdf_url": "http://arxiv.org/pdf/2503.01475v1",
      "arxiv_url": "http://arxiv.org/abs/2503.01475v1",
      "published": "2025-03-03",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Causal Tree Extraction from Medical Case Reports: A Novel Task for Experts-like Text Comprehension",
      "authors": [
        "Sakiko Yahata",
        "Zhen Wan",
        "Fei Cheng",
        "Sadao Kurohashi",
        "Hisahiko Sato",
        "Ryozo Nagai"
      ],
      "abstract": "Extracting causal relationships from a medical case report is essential for\ncomprehending the case, particularly its diagnostic process. Since the\ndiagnostic process is regarded as a bottom-up inference, causal relationships\nin cases naturally form a multi-layered tree structure. The existing tasks,\nsuch as medical relation extraction, are insufficient for capturing the causal\nrelationships of an entire case, as they treat all relations equally without\nconsidering the hierarchical structure inherent in the diagnostic process.\nThus, we propose a novel task, Causal Tree Extraction (CTE), which receives a\ncase report and generates a causal tree with the primary disease as the root,\nproviding an intuitive understanding of a case's diagnostic process.\nSubsequently, we construct a Japanese case report CTE dataset, J-Casemap,\npropose a generation-based CTE method that outperforms the baseline by 20.2\npoints in the human evaluation, and introduce evaluation metrics that reflect\nclinician preferences. Further experiments also show that J-Casemap enhances\nthe performance of solving other medical tasks, such as question answering.",
      "pdf_url": "http://arxiv.org/pdf/2503.01302v1",
      "arxiv_url": "http://arxiv.org/abs/2503.01302v1",
      "published": "2025-03-03",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "title": "ACTIVA: Amortized Causal Effect Estimation without Graphs via Transformer-based Variational Autoencoder",
      "authors": [
        "Andreas Sauter",
        "Saber Salehkaleybar",
        "Aske Plaat",
        "Erman Acar"
      ],
      "abstract": "Predicting the distribution of outcomes under hypothetical interventions is\ncrucial in domains like healthcare, economics, and policy-making. Current\nmethods often rely on strong assumptions, such as known causal graphs or\nparametric models, and lack amortization across problem instances, limiting\ntheir practicality. We propose a novel transformer-based conditional\nvariational autoencoder architecture, named ACTIVA, that extends causal\ntransformer encoders to predict causal effects as mixtures of Gaussians. Our\nmethod requires no causal graph and predicts interventional distributions given\nonly observational data and a queried intervention. By amortizing over many\nsimulated instances, it enables zero-shot generalization to novel datasets\nwithout retraining. Experiments demonstrate accurate predictions for synthetic\nand semi-synthetic data, showcasing the effectiveness of our graph-free,\namortized causal inference approach.",
      "pdf_url": "http://arxiv.org/pdf/2503.01290v1",
      "arxiv_url": "http://arxiv.org/abs/2503.01290v1",
      "published": "2025-03-03",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Architectural and Inferential Inductive Biases For Exchangeable Sequence Modeling",
      "authors": [
        "Daksh Mittal",
        "Ang Li",
        "Tzu-Ching Yen",
        "Daniel Guetta",
        "Hongseok Namkoong"
      ],
      "abstract": "Autoregressive models have emerged as a powerful framework for modeling\nexchangeable sequences - i.i.d. observations when conditioned on some latent\nfactor - enabling direct modeling of uncertainty from missing data (rather than\na latent). Motivated by the critical role posterior inference plays as a\nsubroutine in decision-making (e.g., active learning, bandits), we study the\ninferential and architectural inductive biases that are most effective for\nexchangeable sequence modeling. For the inference stage, we highlight a\nfundamental limitation of the prevalent single-step generation approach:\ninability to distinguish between epistemic and aleatoric uncertainty. Instead,\na long line of works in Bayesian statistics advocates for multi-step\nautoregressive generation; we demonstrate this \"correct approach\" enables\nsuperior uncertainty quantification that translates into better performance on\ndownstream decision-making tasks. This naturally leads to the next question:\nwhich architectures are best suited for multi-step inference? We identify a\nsubtle yet important gap between recently proposed Transformer architectures\nfor exchangeable sequences (Muller et al., 2022; Nguyen & Grover, 2022; Ye &\nNamkoong, 2024), and prove that they in fact cannot guarantee exchangeability\ndespite introducing significant computational overhead. We illustrate our\nfindings using controlled synthetic settings, demonstrating how custom\narchitectures can significantly underperform standard causal masks,\nunderscoring the need for new architectural innovations.",
      "pdf_url": "http://arxiv.org/pdf/2503.01215v1",
      "arxiv_url": "http://arxiv.org/abs/2503.01215v1",
      "published": "2025-03-03",
      "categories": [
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "title": "Time-Varying Causal Survival Learning",
      "authors": [
        "Xiang Meng",
        "Iavor Bojinov"
      ],
      "abstract": "This work bridges the gap between staggered adoption designs and survival\nanalysis to estimate causal effects in settings with time-varying treatments,\naddressing a fundamental challenge in medical research exemplified by the\nStanford Heart Transplant study. In medical interventions, particularly organ\ntransplantation, the timing of treatment varies significantly across patients\ndue to factors such as donor availability and patient readiness, introducing\npotential bias in treatment effect estimation if not properly accounted for. We\nidentify conditions under which staggered adoption assumptions can justify the\nuse of survival analysis techniques for causal inference with time-varying\ntreatments. By establishing this connection, we enable the use of existing\nsurvival analysis methods while maintaining causal interpretability.\nFurthermore, we enhance estimation performance by incorporating double machine\nlearning methods, improving efficiency when handling complex relationships\nbetween patient characteristics and survival outcomes. Through both simulation\nstudies and application to heart transplant data, our approach demonstrates\nsuperior performance compared to traditional methods, reducing bias and\noffering theoretical guarantees for improved efficiency in survival analysis\nsettings.",
      "pdf_url": "http://arxiv.org/pdf/2503.00730v1",
      "arxiv_url": "http://arxiv.org/abs/2503.00730v1",
      "published": "2025-03-02",
      "categories": [
        "stat.ME"
      ]
    }
  ]
}