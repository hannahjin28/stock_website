{
  "last_updated": "2025-12-04T00:55:23.139350",
  "papers": [
    {
      "title": "SpriteHand: Real-Time Versatile Hand-Object Interaction with Autoregressive Video Generation",
      "authors": [
        "Zisu Li",
        "Hengye Lyu",
        "Jiaxin Shi",
        "Yufeng Zeng",
        "Mingming Fan",
        "Hanwang Zhang",
        "Chen Liang"
      ],
      "abstract": "Modeling and synthesizing complex hand-object interactions remains a significant challenge, even for state-of-the-art physics engines. Conventional simulation-based approaches rely on explicitly defined rigid object models and pre-scripted hand gestures, making them inadequate for capturing dynamic interactions with non-rigid or articulated entities such as deformable fabrics, elastic materials, hinge-based structures, furry surfaces, or even living creatures. In this paper, we present SpriteHand, an autoregressive video generation framework for real-time synthesis of versatile hand-object interaction videos across a wide range of object types and motion patterns. SpriteHand takes as input a static object image and a video stream in which the hands are imagined to interact with the virtual object embedded in a real-world scene, and generates corresponding hand-object interaction effects in real time. Our model employs a causal inference architecture for autoregressive generation and leverages a hybrid post-training approach to enhance visual realism and temporal coherence. Our 1.3B model supports real-time streaming generation at around 18 FPS and 640x368 resolution, with an approximate 150 ms latency on a single NVIDIA RTX 5090 GPU, and more than a minute of continuous output. Experiments demonstrate superior visual quality, physical plausibility, and interaction fidelity compared to both generative and engine-based baselines.",
      "pdf_url": "https://arxiv.org/pdf/2512.01960v1",
      "arxiv_url": "http://arxiv.org/abs/2512.01960v1",
      "published": "2025-12-01",
      "categories": [
        "cs.CV",
        "cs.HC"
      ]
    },
    {
      "title": "Mitigating Gender Bias in Depression Detection via Counterfactual Inference",
      "authors": [
        "Mingxuan Hu",
        "Hongbo Ma",
        "Xinlan Wu",
        "Ziqi Liu",
        "Jiaqi Liu",
        "Yangbin Chen"
      ],
      "abstract": "Audio-based depression detection models have demonstrated promising performance but often suffer from gender bias due to imbalanced training data. Epidemiological statistics show a higher prevalence of depression in females, leading models to learn spurious correlations between gender and depression. Consequently, models tend to over-diagnose female patients while underperforming on male patients, raising significant fairness concerns. To address this, we propose a novel Counterfactual Debiasing Framework grounded in causal inference. We construct a causal graph to model the decision-making process and identify gender bias as the direct causal effect of gender on the prediction. During inference, we employ counterfactual inference to estimate and subtract this direct effect, ensuring the model relies primarily on authentic acoustic pathological features. Extensive experiments on the DAIC-WOZ dataset using two advanced acoustic backbones demonstrate that our framework not only significantly reduces gender bias but also improves overall detection performance compared to existing debiasing strategies.",
      "pdf_url": "https://arxiv.org/pdf/2512.01834v1",
      "arxiv_url": "http://arxiv.org/abs/2512.01834v1",
      "published": "2025-12-01",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ]
    },
    {
      "title": "CauSight: Learning to Supersense for Visual Causal Discovery",
      "authors": [
        "Yize Zhang",
        "Meiqi Chen",
        "Sirui Chen",
        "Bo Peng",
        "Yanxi Zhang",
        "Tianyu Li",
        "Chaochao Lu"
      ],
      "abstract": "Causal thinking enables humans to understand not just what is seen, but why it happens. To replicate this capability in modern AI systems, we introduce the task of visual causal discovery. It requires models to infer cause-and-effect relations among visual entities across diverse scenarios instead of merely perceiving their presence. To this end, we first construct the Visual Causal Graph dataset (VCG-32K), a large-scale collection of over 32,000 images annotated with entity-level causal graphs, and further develop CauSight, a novel vision-language model to perform visual causal discovery through causally aware reasoning. Our training recipe integrates three components: (1) training data curation from VCG-32K, (2) Tree-of-Causal-Thought (ToCT) for synthesizing reasoning trajectories, and (3) reinforcement learning with a designed causal reward to refine the reasoning policy. Experiments show that CauSight outperforms GPT-4.1 on visual causal discovery, achieving over a threefold performance boost (21% absolute gain). Our code, model, and dataset are fully open-sourced at project page: https://github.com/OpenCausaLab/CauSight.",
      "pdf_url": "https://arxiv.org/pdf/2512.01827v1",
      "arxiv_url": "http://arxiv.org/abs/2512.01827v1",
      "published": "2025-12-01",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "Probabilistic Neuro-Symbolic Reasoning for Sparse Historical Data: A Framework Integrating Bayesian Inference, Causal Models, and Game-Theoretic Allocation",
      "authors": [
        "Saba Kublashvili"
      ],
      "abstract": "Modeling historical events poses fundamental challenges for machine learning: extreme data scarcity (N << 100), heterogeneous and noisy measurements, missing counterfactuals, and the requirement for human interpretable explanations. We present HistoricalML, a probabilistic neuro-symbolic framework that addresses these challenges through principled integration of (1) Bayesian uncertainty quantification to separate epistemic from aleatoric uncertainty, (2) structural causal models for counterfactual reasoning under confounding, (3) cooperative game theory (Shapley values) for fair allocation modeling, and (4) attention based neural architectures for context dependent factor weighting. We provide theoretical analysis showing that our approach achieves consistent estimation in the sparse data regime when strong priors from domain knowledge are available, and that Shapley based allocation satisfies axiomatic fairness guarantees that pure regression approaches cannot provide. We instantiate the framework on two historical case studies: the 19th century partition of Africa (N = 7 colonial powers) and the Second Punic War (N = 2 factions). Our model identifies Germany's +107.9 percent discrepancy as a quantifiable structural tension preceding World War I, with tension factor 36.43 and 0.79 naval arms race correlation. For the Punic Wars, Monte Carlo battle simulations achieve a 57.3 percent win probability for Carthage at Cannae and 57.8 percent for Rome at Zama, aligning with historical outcomes. Counterfactual analysis reveals that Carthaginian political support (support score 6.4 vs Napoleon's 7.1), rather than military capability, was the decisive factor.",
      "pdf_url": "https://arxiv.org/pdf/2512.01723v1",
      "arxiv_url": "http://arxiv.org/abs/2512.01723v1",
      "published": "2025-12-01",
      "categories": [
        "cs.AI",
        "cs.GT",
        "math.PR"
      ]
    },
    {
      "title": "Parallel Delayed Memory Units for Enhanced Temporal Modeling in Biomedical and Bioacoustic Signal Analysis",
      "authors": [
        "Pengfei Sun",
        "Wenyu Jiang",
        "Paul Devos",
        "Dick Botteldooren"
      ],
      "abstract": "Advanced deep learning architectures, particularly recurrent neural networks (RNNs), have been widely applied in audio, bioacoustic, and biomedical signal analysis, especially in data-scarce environments. While gated RNNs remain effective, they can be relatively over-parameterised and less training-efficient in some regimes, while linear RNNs tend to fall short in capturing the complexity inherent in bio-signals. To address these challenges, we propose the Parallel Delayed Memory Unit (PDMU), a {delay-gated state-space module for short-term temporal credit assignment} targeting audio and bioacoustic signals, which enhances short-term temporal state interactions and memory efficiency via a gated delay-line mechanism. Unlike previous Delayed Memory Units (DMU) that embed temporal dynamics into the delay-line architecture, the PDMU further compresses temporal information into vector representations using Legendre Memory Units (LMU). This design serves as a form of causal attention, allowing the model to dynamically adjust its reliance on past states and improve real-time learning performance. Notably, in low-information scenarios, the gating mechanism behaves similarly to skip connections by bypassing state decay and preserving early representations, thereby facilitating long-term memory retention. The PDMU is modular, supporting parallel training and sequential inference, and can be easily integrated into existing linear RNN frameworks. Furthermore, we introduce bidirectional, efficient, and spiking variants of the architecture, each offering additional gains in performance or energy efficiency. Experimental results on diverse audio and biomedical benchmarks demonstrate that the PDMU significantly enhances both memory capacity and overall model performance.",
      "pdf_url": "https://arxiv.org/pdf/2512.01626v1",
      "arxiv_url": "http://arxiv.org/abs/2512.01626v1",
      "published": "2025-12-01",
      "categories": [
        "cs.SD",
        "cs.NE"
      ]
    },
    {
      "title": "A Self-explainable Model of Long Time Series by Extracting Informative Structured Causal Patterns",
      "authors": [
        "Ziqian Wang",
        "Yuxiao Cheng",
        "Jinli Suo"
      ],
      "abstract": "Explainability is essential for neural networks that model long time series, yet most existing explainable AI methods only produce point-wise importance scores and fail to capture temporal structures such as trends, cycles, and regime changes. This limitation weakens human interpretability and trust in long-horizon models. To address these issues, we identify four key requirements for interpretable time-series modeling: temporal continuity, pattern-centric explanation, causal disentanglement, and faithfulness to the model's inference process. We propose EXCAP, a unified framework that satisfies all four requirements. EXCAP combines an attention-based segmenter that extracts coherent temporal patterns, a causally structured decoder guided by a pre-trained causal graph, and a latent aggregation mechanism that enforces representation stability. Our theoretical analysis shows that EXCAP provides smooth and stable explanations over time and is robust to perturbations in causal masks. Extensive experiments on classification and forecasting benchmarks demonstrate that EXCAP achieves strong predictive accuracy while generating coherent and causally grounded explanations. These results show that EXCAP offers a principled and scalable approach to interpretable modeling of long time series with relevance to high-stakes domains such as healthcare and finance.",
      "pdf_url": "https://arxiv.org/pdf/2512.01412v1",
      "arxiv_url": "http://arxiv.org/abs/2512.01412v1",
      "published": "2025-12-01",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "A Benchmark of Causal vs Correlation AI for Predictive Maintenance",
      "authors": [
        "Krishna Taduri",
        "Shaunak Dhande",
        "Giacinto Paolo",
        "Saggese",
        "Paul Smith"
      ],
      "abstract": "Predictive maintenance in manufacturing environments presents a challenging optimization problem characterized by extreme cost asymmetry, where missed failures incur costs roughly fifty times higher than false alarms. Conventional machine learning approaches typically optimize statistical accuracy metrics that do not reflect this operational reality and cannot reliably distinguish causal relationships from spurious correlations. This study evaluates eight predictive models, ranging from baseline statistical approaches to formal causal inference methods, on a dataset of 10,000 CNC machines with a 3.3% failure prevalence. The formal causal inference model (L5) achieved estimated annual cost savings of 1.16 million USD (a 70.2 percent reduction), outperforming the best correlation-based decision tree model (L3) by approximately 80,000 USD per year. The causal model matched the highest observed recall (87.9 percent) while reducing false alarms by 97 percent (from 165 to 5) and attained a precision of 92.1 percent, with a train-test performance gap of only 2.6 percentage points. These results indicate that causal AI methods, when combined with domain knowledge, can yield superior financial outcomes and more interpretable predictions compared to correlation-based approaches in predictive maintenance applications.",
      "pdf_url": "https://arxiv.org/pdf/2512.01149v1",
      "arxiv_url": "http://arxiv.org/abs/2512.01149v1",
      "published": "2025-11-30",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "FC-ADL: Efficient Microservice Anomaly Detection and Localisation Through Functional Connectivity",
      "authors": [
        "Giles Winchester",
        "George Parisis",
        "Luc Berthouze"
      ],
      "abstract": "Microservices have transformed software architecture through the creation of modular and independent services. However, they introduce operational complexities in service integration and system management that makes swift and accurate anomaly detection and localisation challenging. Despite the complex, dynamic, and interconnected nature of microservice architectures, prior works that investigate metrics for anomaly detection rarely include explicit information about time-varying interdependencies. And whilst prior works on fault localisation typically do incorporate information about dependencies between microservices, they scale poorly to real world large-scale deployments due to their reliance on computationally expensive causal inference. To address these challenges we propose FC-ADL, an end-to-end scalable approach for detecting and localising anomalous changes from microservice metrics based on the neuroscientific concept of functional connectivity. We show that by efficiently characterising time-varying changes in dependencies between microservice metrics we can both detect anomalies and provide root cause candidates without incurring the significant overheads of causal and multivariate approaches. We demonstrate that our approach can achieve top detection and localisation performance across a wide degree of different fault scenarios when compared to state-of-the-art approaches. Furthermore, we illustrate the scalability of our approach by applying it to Alibaba's extremely large real-world microservice deployment.",
      "pdf_url": "https://arxiv.org/pdf/2512.00844v1",
      "arxiv_url": "http://arxiv.org/abs/2512.00844v1",
      "published": "2025-11-30",
      "categories": [
        "cs.SE",
        "cs.DC",
        "cs.LG"
      ]
    },
    {
      "title": "ARCADIA: Scalable Causal Discovery for Corporate Bankruptcy Analysis Using Agentic AI",
      "authors": [
        "Fabrizio Maturo",
        "Donato Riccio",
        "Andrea Mazzitelli",
        "Giuseppe Bifulco",
        "Francesco Paolone",
        "Iulia Brezeanu"
      ],
      "abstract": "This paper introduces ARCADIA, an agentic AI framework for causal discovery that integrates large-language-model reasoning with statistical diagnostics to construct valid, temporally coherent causal structures. Unlike traditional algorithms, ARCADIA iteratively refines candidate DAGs through constraint-guided prompting and causal-validity feedback, leading to stable and interpretable models for real-world high-stakes domains. Experiments on corporate bankruptcy data show that ARCADIA produces more reliable causal graphs than NOTEARS, GOLEM, and DirectLiNGAM while offering a fully explainable, intervention-ready pipeline. The framework advances AI by demonstrating how agentic LLMs can participate in autonomous scientific modeling and structured causal inference.",
      "pdf_url": "https://arxiv.org/pdf/2512.00839v1",
      "arxiv_url": "http://arxiv.org/abs/2512.00839v1",
      "published": "2025-11-30",
      "categories": [
        "cs.AI",
        "stat.CO",
        "stat.ME"
      ]
    },
    {
      "title": "Causal Invariance and Counterfactual Learning Driven Cooperative Game for Multi-Label Classification",
      "authors": [
        "Yijia Fan",
        "Jusheng Zhang",
        "Kaitong Cai",
        "Jing Yang",
        "Keze Wang"
      ],
      "abstract": "Multi-label classification (MLC) remains vulnerable to label imbalance, spurious correlations, and distribution shifts, challenges that are particularly detrimental to rare label prediction. To address these limitations, we introduce the Causal Cooperative Game (CCG) framework, which conceptualizes MLC as a cooperative multi-player interaction. CCG unifies explicit causal discovery via Neural Structural Equation Models with a counterfactual curiosity reward to drive robust feature learning. Furthermore, it incorporates a causal invariance loss to ensure generalization across diverse environments, complemented by a specialized enhancement strategy for rare labels. Extensive benchmarking demonstrates that CCG substantially outperforms strong baselines in both rare label prediction and overall robustness. Through rigorous ablation studies and qualitative analysis, we validate the efficacy and interpretability of our components, underscoring the potential of synergizing causal inference with cooperative game theory for advancing multi-label learning.",
      "pdf_url": "https://arxiv.org/pdf/2512.00812v1",
      "arxiv_url": "http://arxiv.org/abs/2512.00812v1",
      "published": "2025-11-30",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    }
  ]
}