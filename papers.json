{
  "last_updated": "2025-06-24T00:55:33.551087",
  "papers": [
    {
      "title": "CLEAR-3K: Assessing Causal Explanatory Capabilities in Language Models",
      "authors": [
        "Naiming Liu",
        "Richard Baraniuk",
        "Shashank Sonkar"
      ],
      "abstract": "We introduce CLEAR-3K, a dataset of 3,000 assertion-reasoning questions\ndesigned to evaluate whether language models can determine if one statement\ncausally explains another. Each question present an assertion-reason pair and\nchallenge language models to distinguish between semantic relatedness and\ngenuine causal explanatory relationships. Through comprehensive evaluation of\n21 state-of-the-art language models (ranging from 0.5B to 72B parameters), we\nidentify two fundamental findings. First, language models frequently confuse\nsemantic similarity with causality, relying on lexical and semantic overlap\ninstead of inferring actual causal explanatory relationships. Second, as\nparameter size increases, models tend to shift from being overly skeptical\nabout causal relationships to being excessively permissive in accepting them.\nDespite this shift, performance measured by the Matthews Correlation\nCoefficient plateaus at just 0.55, even for the best-performing models.Hence,\nCLEAR-3K provides a crucial benchmark for developing and evaluating genuine\ncausal reasoning in language models, which is an essential capability for\napplications that require accurate assessment of causal relationships.",
      "pdf_url": "http://arxiv.org/pdf/2506.17180v1",
      "arxiv_url": "http://arxiv.org/abs/2506.17180v1",
      "published": "2025-06-20",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "title": "Flow-Based Non-stationary Temporal Regime Causal Structure Learning",
      "authors": [
        "Abdellah Rahmani",
        "Pascal Frossard"
      ],
      "abstract": "Understanding causal relationships in multivariate time series is crucial in\nmany scenarios, such as those dealing with financial or neurological data. Many\nsuch time series exhibit multiple regimes, i.e., consecutive temporal segments\nwith a priori unknown boundaries, with each regime having its own causal\nstructure. Inferring causal dependencies and regime shifts is critical for\nanalyzing the underlying processes. However, causal structure learning in this\nsetting is challenging due to (1) non stationarity, i.e., each regime can have\nits own causal graph and mixing function, and (2) complex noise distributions,\nwhich may be non Gaussian or heteroscedastic. Existing causal discovery\napproaches cannot address these challenges, since generally assume stationarity\nor Gaussian noise with constant variance. Hence, we introduce FANTOM, a unified\nframework for causal discovery that handles non stationary processes along with\nnon Gaussian and heteroscedastic noises. FANTOM simultaneously infers the\nnumber of regimes and their corresponding indices and learns each regime's\nDirected Acyclic Graph. It uses a Bayesian Expectation Maximization algorithm\nthat maximizes the evidence lower bound of the data log likelihood. On the\ntheoretical side, we prove, under mild assumptions, that temporal\nheteroscedastic causal models, introduced in FANTOM's formulation, are\nidentifiable in both stationary and non stationary settings. In addition,\nextensive experiments on synthetic and real data show that FANTOM outperforms\nexisting methods.",
      "pdf_url": "http://arxiv.org/pdf/2506.17065v1",
      "arxiv_url": "http://arxiv.org/abs/2506.17065v1",
      "published": "2025-06-20",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Modeling and Visualization Reasoning for Stakeholders in Education and Industry Integration Systems: Research on Structured Synthetic Dialogue Data Generation Based on NIST Standards",
      "authors": [
        "Wei Meng"
      ],
      "abstract": "This study addresses the structural complexity and semantic ambiguity in\nstakeholder interactions within the Education-Industry Integration (EII)\nsystem. The scarcity of real interview data, absence of structured variable\nmodeling, and lack of interpretability in inference mechanisms have limited the\nanalytical accuracy and policy responsiveness of EII research. To resolve these\nchallenges, we propose a structural modeling paradigm based on the National\nInstitute of Standards and Technology (NIST) synthetic data quality framework,\nfocusing on consistency, authenticity, and traceability. We design a five-layer\narchitecture that includes prompt-driven synthetic dialogue generation, a\nstructured variable system covering skills, institutional, and emotional\ndimensions, dependency and causal path modeling, graph-based structure design,\nand an interactive inference engine. Empirical results demonstrate the\neffectiveness of the approach using a 15-segment synthetic corpus, with 41,597\ntokens, 127 annotated variables, and 820 semantic relationship triples. The\nmodel exhibits strong structural consistency (Krippendorff alpha = 0.83),\nconstruct validity (RMSEA = 0.048, CFI = 0.93), and semantic alignment (mean\ncosine similarity > 0.78 via BERT). A key causal loop is identified: system\nmismatch leads to emotional frustration, reduced participation, skill gaps, and\nrecurrence of mismatch, revealing a structural degradation cycle. This research\nintroduces the first NIST-compliant AI modeling framework for stakeholder\nsystems and provides a foundation for policy simulation, curriculum design, and\ncollaborative strategy modeling.",
      "pdf_url": "http://arxiv.org/pdf/2506.16952v1",
      "arxiv_url": "http://arxiv.org/abs/2506.16952v1",
      "published": "2025-06-20",
      "categories": [
        "cs.CY",
        "68T50, 68T30, 91B06, 05C82, 62H30",
        "I.2.6; I.2.7; H.2.8; K.3.1; K.4.1"
      ]
    },
    {
      "title": "From Prompts to Constructs: A Dual-Validity Framework for LLM Research in Psychology",
      "authors": [
        "Zhicheng Lin"
      ],
      "abstract": "Large language models (LLMs) are rapidly being adopted across psychology,\nserving as research tools, experimental subjects, human simulators, and\ncomputational models of cognition. However, the application of human\nmeasurement tools to these systems can produce contradictory results, raising\nconcerns that many findings are measurement phantoms--statistical artifacts\nrather than genuine psychological phenomena. In this Perspective, we argue that\nbuilding a robust science of AI psychology requires integrating two of our\nfield's foundational pillars: the principles of reliable measurement and the\nstandards for sound causal inference. We present a dual-validity framework to\nguide this integration, which clarifies how the evidence needed to support a\nclaim scales with its scientific ambition. Using an LLM to classify text may\nrequire only basic accuracy checks, whereas claiming it can simulate anxiety\ndemands a far more rigorous validation process. Current practice systematically\nfails to meet these requirements, often treating statistical pattern matching\nas evidence of psychological phenomena. The same model output--endorsing \"I am\nanxious\"--requires different validation strategies depending on whether\nresearchers claim to measure, characterize, simulate, or model psychological\nconstructs. Moving forward requires developing computational analogues of\npsychological constructs and establishing clear, scalable standards of evidence\nrather than the uncritical application of human measurement tools.",
      "pdf_url": "http://arxiv.org/pdf/2506.16697v1",
      "arxiv_url": "http://arxiv.org/abs/2506.16697v1",
      "published": "2025-06-20",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ]
    },
    {
      "title": "Learning Causally Predictable Outcomes from Psychiatric Longitudinal Data",
      "authors": [
        "Eric V. Strobl"
      ],
      "abstract": "Causal inference in longitudinal biomedical data remains a central challenge,\nespecially in psychiatry, where symptom heterogeneity and latent confounding\nfrequently undermine classical estimators. Most existing methods for treatment\neffect estimation presuppose a fixed outcome variable and address confounding\nthrough observed covariate adjustment. However, the assumption of\nunconfoundedness may not hold for a fixed outcome in practice. To address this\nfoundational limitation, we directly optimize the outcome definition to\nmaximize causal identifiability. Our DEBIAS (Durable Effects with\nBackdoor-Invariant Aggregated Symptoms) algorithm learns non-negative,\nclinically interpretable weights for outcome aggregation, maximizing durable\ntreatment effects and empirically minimizing both observed and latent\nconfounding by leveraging the time-limited direct effects of prior treatments\nin psychiatric longitudinal data. The algorithm also furnishes an empirically\nverifiable test for outcome unconfoundedness. DEBIAS consistently outperforms\nstate-of-the-art methods in recovering causal effects for clinically\ninterpretable composite outcomes across comprehensive experiments in depression\nand schizophrenia.",
      "pdf_url": "http://arxiv.org/pdf/2506.16629v1",
      "arxiv_url": "http://arxiv.org/abs/2506.16629v1",
      "published": "2025-06-19",
      "categories": [
        "cs.LG",
        "q-bio.QM",
        "stat.ML"
      ]
    },
    {
      "title": "Robust Reward Modeling via Causal Rubrics",
      "authors": [
        "Pragya Srivastava",
        "Harman Singh",
        "Rahul Madhavan",
        "Gandharv Patil",
        "Sravanti Addepalli",
        "Arun Suggala",
        "Rengarajan Aravamudhan",
        "Soumya Sharma",
        "Anirban Laha",
        "Aravindan Raghuveer",
        "Karthikeyan Shanmugam",
        "Doina Precup"
      ],
      "abstract": "Reward models (RMs) are fundamental to aligning Large Language Models (LLMs)\nvia human feedback, yet they often suffer from reward hacking. They tend to\nlatch on to superficial or spurious attributes, such as response length or\nformatting, mistaking these cues learned from correlations in training data for\nthe true causal drivers of quality (e.g., factuality, relevance). This occurs\nbecause standard training objectives struggle to disentangle these factors,\nleading to brittle RMs and misaligned policies. We introduce Crome (Causally\nRobust Reward Modeling), a novel framework grounded in an explicit causal model\ndesigned to mitigate reward hacking. Crome employs the following synthetic\ntargeted augmentations during training: (1) Causal Augmentations, which are\npairs that differ along specific causal attributes, to enforce sensitivity\nalong each causal attribute individually, and (2) Neutral Augmentations, which\nare tie-label pairs varying primarily in spurious attributes, to enforce\ninvariance along spurious attributes. Notably, our augmentations are produced\nwithout any knowledge of spurious factors, via answer interventions only along\ncausal rubrics, that are identified by querying an oracle LLM. Empirically,\nCrome significantly outperforms standard baselines on RewardBench, improving\naverage accuracy by up to 5.4% and achieving gains of up to 13.2% and 7.2% in\nspecific categories. The robustness of Crome is further testified by the\nconsistent gains obtained in a Best-of-N inference setting across increasing N,\nacross various benchmarks, including the popular RewardBench (covering chat,\nchat-hard, safety, and reasoning tasks), the safety-focused WildGuardTest, and\nthe reasoning-specific GSM8k.",
      "pdf_url": "http://arxiv.org/pdf/2506.16507v1",
      "arxiv_url": "http://arxiv.org/abs/2506.16507v1",
      "published": "2025-06-19",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "An introduction to Causal Modelling",
      "authors": [
        "Gauranga Kumar Baishya"
      ],
      "abstract": "This tutorial provides a concise introduction to modern causal modeling by\nintegrating potential outcomes and graphical methods. We motivate causal\nquestions such as counterfactual reasoning under interventions and define\nbinary treatments and potential outcomes. We discuss causal effect\nmeasures-including average treatment effects on the treated and on the\nuntreated-and choices of effect scales for binary outcomes. We derive\nidentification in randomized experiments under exchangeability and consistency,\nand extend to stratification and blocking designs. We present inverse\nprobability weighting with propensity score estimation and robust inference via\nsandwich estimators. Finally, we introduce causal graphs, d-separation, the\nbackdoor criterion, single-world intervention graphs, and structural equation\nmodels, showing how graphical and potential-outcome approaches complement each\nother. Emphasis is placed on clear notation, intuitive explanations, and\npractical examples for applied researchers.",
      "pdf_url": "http://arxiv.org/pdf/2506.16486v1",
      "arxiv_url": "http://arxiv.org/abs/2506.16486v1",
      "published": "2025-06-19",
      "categories": [
        "stat.ME",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ]
    },
    {
      "title": "Unveiling Political Influence Through Social Media: Network and Causal Dynamics in the 2022 French Presidential Election",
      "authors": [
        "Ixandra Achitouv",
        "David Chavalarias"
      ],
      "abstract": "During the 2022 French presidential election, we collected daily Twitter\nmessages on key topics posted by political candidates and their close networks.\nUsing a data-driven approach, we analyze interactions among political parties,\nidentifying central topics that shape the landscape of political debate. Moving\nbeyond traditional correlation analyses, we apply a causal inference technique:\nConvergent Cross Mapping, to uncover directional influences among political\ncommunities, revealing how some parties are more likely to initiate changes in\nactivity while others tend to respond. This approach allows us to distinguish\ntrue influence from mere correlation, highlighting asymmetric relationships and\nhidden dynamics within the social media political network. Our findings\ndemonstrate how specific issues, such as health and foreign policy, act as\ncatalysts for cross-party influence, particularly during critical election\nphases. These insights provide a novel framework for understanding political\ndiscourse dynamics and have practical implications for campaign strategists and\nmedia analysts seeking to monitor and respond to shifts in political influence\nin real time.",
      "pdf_url": "http://arxiv.org/pdf/2506.16449v1",
      "arxiv_url": "http://arxiv.org/abs/2506.16449v1",
      "published": "2025-06-19",
      "categories": [
        "cs.SI",
        "cs.CY",
        "physics.soc-ph"
      ]
    },
    {
      "title": "Causal inference amid missingness-specific independencies and mechanism shifts",
      "authors": [
        "Johan de Aguas",
        "Leonard Henckel",
        "Johan Pensar",
        "Guido Biele"
      ],
      "abstract": "The recovery of causal effects in structural models with missing data often\nrelies on $m$-graphs, which assume that missingness mechanisms do not directly\ninfluence substantive variables. Yet, in many real-world settings, missing data\ncan alter decision-making processes, as the absence of key information may\naffect downstream actions and states. To overcome this limitation, we introduce\n$lm$-SCMs and $lm$-graphs, which extend $m$-graphs by integrating a label set\nthat represents relevant context-specific independencies (CSI), accounting for\nmechanism shifts induced by missingness. We define two causal effects within\nthese systems: the Full Average Treatment Effect (FATE), which reflects the\neffect in a hypothetical scenario had no data been missing, and the Natural\nAverage Treatment Effect (NATE), which captures the effect under the unaltered\nCSIs in the system. We propose recovery criteria for these queries and present\ndoubly-robust estimators for a graphical model inspired by a real-world\napplication. Simulations highlight key differences between these estimands and\nestimation methods. Findings from the application case suggest a small effect\nof ADHD treatment upon test achievement among Norwegian children, with a slight\neffect shift due to missing pre-tests scores.",
      "pdf_url": "http://arxiv.org/pdf/2506.15441v1",
      "arxiv_url": "http://arxiv.org/abs/2506.15441v1",
      "published": "2025-06-18",
      "categories": [
        "stat.ME",
        "math.ST",
        "stat.TH",
        "62D20, 62H22"
      ]
    },
    {
      "title": "Linear-Time Primitives for Algorithm Development in Graphical Causal Inference",
      "authors": [
        "Marcel Wien√∂bst",
        "Sebastian Weichwald",
        "Leonard Henckel"
      ],
      "abstract": "We introduce CIfly, a framework for efficient algorithmic primitives in\ngraphical causal inference that isolates reachability as a reusable core\noperation. It builds on the insight that many causal reasoning tasks can be\nreduced to reachability in purpose-built state-space graphs that can be\nconstructed on the fly during traversal. We formalize a rule table schema for\nspecifying such algorithms and prove they run in linear time. We establish\nCIfly as a more efficient alternative to the common primitives moralization and\nlatent projection, which we show are computationally equivalent to Boolean\nmatrix multiplication. Our open-source Rust implementation parses rule table\ntext files and runs the specified CIfly algorithms providing high-performance\nexecution accessible from Python and R. We demonstrate CIfly's utility by\nre-implementing a range of established causal inference tasks within the\nframework and by developing new algorithms for instrumental variables. These\ncontributions position CIfly as a flexible and scalable backbone for graphical\ncausal inference, guiding algorithm development and enabling easy and efficient\ndeployment.",
      "pdf_url": "http://arxiv.org/pdf/2506.15758v1",
      "arxiv_url": "http://arxiv.org/abs/2506.15758v1",
      "published": "2025-06-18",
      "categories": [
        "cs.AI",
        "cs.DS",
        "cs.LG",
        "stat.ME",
        "stat.ML"
      ]
    }
  ]
}