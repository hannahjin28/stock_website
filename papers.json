{
  "last_updated": "2025-05-27T00:52:58.107860",
  "papers": [
    {
      "title": "Scalable Policy Maximization Under Network Interference",
      "authors": [
        "Aidan Gleich",
        "Eric Laber",
        "Alexander Volfovsky"
      ],
      "abstract": "Many interventions, such as vaccines in clinical trials or coupons in online\nmarketplaces, must be assigned sequentially without full knowledge of their\neffects. Multi-armed bandit algorithms have proven successful in such settings.\nHowever, standard independence assumptions fail when the treatment status of\none individual impacts the outcomes of others, a phenomenon known as\ninterference. We study optimal-policy learning under interference on a dynamic\nnetwork. Existing approaches to this problem require repeated observations of\nthe same fixed network and struggle to scale in sample size beyond as few as\nfifteen connected units -- both limit applications. We show that under common\nassumptions on the structure of interference, rewards become linear. This\nenables us to develop a scalable Thompson sampling algorithm that maximizes\npolicy impact when a new $n$-node network is observed each round. We prove a\nBayesian regret bound that is sublinear in $n$ and the number of rounds.\nSimulation experiments show that our algorithm learns quickly and outperforms\nexisting methods. The results close a key scalability gap between causal\ninference methods for interference and practical bandit algorithms, enabling\npolicy optimization in large-scale networked systems.",
      "pdf_url": "http://arxiv.org/pdf/2505.18118v1",
      "arxiv_url": "http://arxiv.org/abs/2505.18118v1",
      "published": "2025-05-23",
      "categories": [
        "stat.ML",
        "cs.LG"
      ]
    },
    {
      "title": "Structured Thinking Matters: Improving LLMs Generalization in Causal Inference Tasks",
      "authors": [
        "Wentao Sun",
        "Joao Paulo Nogueira",
        "Alonso Silva"
      ],
      "abstract": "Despite remarkable advances in the field, LLMs remain unreliable in\ndistinguishing causation from correlation. Recent results from the Corr2Cause\ndataset benchmark reveal that state-of-the-art LLMs -- such as GPT-4 (F1 score:\n29.08) -- only marginally outperform random baselines (Random Uniform, F1\nscore: 20.38), indicating limited capacity of generalization. To tackle this\nlimitation, we propose a novel structured approach: rather than directly\nanswering causal queries, we provide the model with the capability to structure\nits thinking by guiding the model to build a structured knowledge graph,\nsystematically encoding the provided correlational premises, to answer the\ncausal queries. This intermediate representation significantly enhances the\nmodel's causal capabilities. Experiments on the test subset of the Corr2Cause\ndataset benchmark with Qwen3-32B model (reasoning model) show substantial gains\nover standard direct prompting methods, improving F1 scores from 32.71 to 48.26\n(over 47.5% relative increase), along with notable improvements in precision\nand recall. These results underscore the effectiveness of providing the model\nwith the capability to structure its thinking and highlight its promising\npotential for broader generalization across diverse causal inference tasks.",
      "pdf_url": "http://arxiv.org/pdf/2505.18034v1",
      "arxiv_url": "http://arxiv.org/abs/2505.18034v1",
      "published": "2025-05-23",
      "categories": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Federated Causal Inference from Multi-Site Observational Data via Propensity Score Aggregation",
      "authors": [
        "Khellaf Rémi",
        "Bellet Aurélien",
        "Josse Julie"
      ],
      "abstract": "Causal inference typically assumes centralized access to individual-level\ndata. Yet, in practice, data are often decentralized across multiple sites,\nmaking centralization infeasible due to privacy, logistical, or legal\nconstraints. We address this by estimating the Average Treatment Effect (ATE)\nfrom decentralized observational data using federated learning, which enables\ninference through the exchange of aggregate statistics rather than\nindividual-level data. We propose a novel method to estimate propensity scores\nin a (non-)parametric manner by computing a federated weighted average of local\nscores, using two theoretically grounded weighting schemes -- Membership\nWeights (MW) and Density Ratio Weights (DW) -- that balance communication\nefficiency and model flexibility. These federated scores are then used to\nconstruct two ATE estimators: the Federated Inverse Propensity Weighting\nestimator (Fed-IPW) and its augmented variant (Fed-AIPW). Unlike meta-analysis\nmethods, which fail when any site violates positivity, our approach leverages\nheterogeneity in treatment assignment across sites to improve overlap. We show\nthat Fed-IPW and Fed-AIPW perform well under site-level heterogeneity in sample\nsizes, treatment mechanisms, and covariate distributions, with theoretical\nanalysis and experiments on simulated and real-world data highlighting their\nstrengths and limitations relative to meta-analysis and related methods.",
      "pdf_url": "http://arxiv.org/pdf/2505.17961v1",
      "arxiv_url": "http://arxiv.org/abs/2505.17961v1",
      "published": "2025-05-23",
      "categories": [
        "stat.ME",
        "cs.AI",
        "math.ST",
        "stat.AP",
        "stat.TH"
      ]
    },
    {
      "title": "A Distributionally-Robust Framework for Nuisance in Causal Effect Estimation",
      "authors": [
        "Akira Tanimoto"
      ],
      "abstract": "Causal inference requires evaluating models on balanced distributions between\ntreatment and control groups, while training data often exhibits imbalance due\nto historical decision-making policies. Most conventional statistical methods\naddress this distribution shift through inverse probability weighting (IPW),\nwhich requires estimating propensity scores as an intermediate step. These\nmethods face two key challenges: inaccurate propensity estimation and\ninstability from extreme weights. We decompose the generalization error to\nisolate these issues--propensity ambiguity and statistical instability--and\naddress them through an adversarial loss function. Our approach combines\ndistributionally robust optimization for handling propensity uncertainty with\nweight regularization based on weighted Rademacher complexity. Experiments on\nsynthetic and real-world datasets demonstrate consistent improvements over\nexisting methods.",
      "pdf_url": "http://arxiv.org/pdf/2505.17717v1",
      "arxiv_url": "http://arxiv.org/abs/2505.17717v1",
      "published": "2025-05-23",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "The Third Pillar of Causal Analysis? A Measurement Perspective on Causal Representations",
      "authors": [
        "Dingling Yao",
        "Shimeng Huang",
        "Riccardo Cadei",
        "Kun Zhang",
        "Francesco Locatello"
      ],
      "abstract": "Causal reasoning and discovery, two fundamental tasks of causal analysis,\noften face challenges in applications due to the complexity, noisiness, and\nhigh-dimensionality of real-world data. Despite recent progress in identifying\nlatent causal structures using causal representation learning (CRL), what makes\nlearned representations useful for causal downstream tasks and how to evaluate\nthem are still not well understood. In this paper, we reinterpret CRL using a\nmeasurement model framework, where the learned representations are viewed as\nproxy measurements of the latent causal variables. Our approach clarifies the\nconditions under which learned representations support downstream causal\nreasoning and provides a principled basis for quantitatively assessing the\nquality of representations using a new Test-based Measurement EXclusivity\n(T-MEX) score. We validate T-MEX across diverse causal inference scenarios,\nincluding numerical simulations and real-world ecological video analysis,\ndemonstrating that the proposed framework and corresponding score effectively\nassess the identification of learned representations and their usefulness for\ncausal downstream tasks.",
      "pdf_url": "http://arxiv.org/pdf/2505.17708v1",
      "arxiv_url": "http://arxiv.org/abs/2505.17708v1",
      "published": "2025-05-23",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "Causal Spatio-Temporal Prediction: An Effective and Efficient Multi-Modal Approach",
      "authors": [
        "Yuting Huang",
        "Ziquan Fang",
        "Zhihao Zeng",
        "Lu Chen",
        "Yunjun Gao"
      ],
      "abstract": "Spatio-temporal prediction plays a crucial role in intelligent\ntransportation, weather forecasting, and urban planning. While integrating\nmulti-modal data has shown potential for enhancing prediction accuracy, key\nchallenges persist: (i) inadequate fusion of multi-modal information, (ii)\nconfounding factors that obscure causal relations, and (iii) high computational\ncomplexity of prediction models. To address these challenges, we propose\nE^2-CSTP, an Effective and Efficient Causal multi-modal Spatio-Temporal\nPrediction framework. E^2-CSTP leverages cross-modal attention and gating\nmechanisms to effectively integrate multi-modal data. Building on this, we\ndesign a dual-branch causal inference approach: the primary branch focuses on\nspatio-temporal prediction, while the auxiliary branch mitigates bias by\nmodeling additional modalities and applying causal interventions to uncover\ntrue causal dependencies. To improve model efficiency, we integrate GCN with\nthe Mamba architecture for accelerated spatio-temporal encoding. Extensive\nexperiments on 4 real-world datasets show that E^2-CSTP significantly\noutperforms 9 state-of-the-art methods, achieving up to 9.66% improvements in\naccuracy as well as 17.37%-56.11% reductions in computational overhead.",
      "pdf_url": "http://arxiv.org/pdf/2505.17637v1",
      "arxiv_url": "http://arxiv.org/abs/2505.17637v1",
      "published": "2025-05-23",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "TI-DeepONet: Learnable Time Integration for Stable Long-Term Extrapolation",
      "authors": [
        "Dibyajyoti Nayak",
        "Somdatta Goswami"
      ],
      "abstract": "Accurate temporal extrapolation presents a fundamental challenge for neural\noperators in modeling dynamical systems, where reliable predictions must extend\nsignificantly beyond the training time horizon. Conventional Deep Operator\nNetwork (DeepONet) approaches employ two inherently limited training paradigms\n- fixed-horizon rollouts that predict complete spatiotemporal solutions while\ndisregarding temporal causality, and autoregressive formulations that\naccumulate errors through sequential predictions. We introduce TI-DeepONet, a\nframework that integrates neural operators with adaptive numerical\ntime-stepping techniques to preserve the Markovian structure of dynamical\nsystems while mitigating error propagation in extended temporal forecasting.\nOur approach reformulates the learning objective from direct state prediction\nto the approximation of instantaneous time-derivative fields, which are then\nintegrated using established numerical schemes. This architecture supports\ncontinuous-time prediction and enables deployment of higher-precision\nintegrators during inference than those used during training, balancing\ncomputational efficiency with predictive accuracy. We further develop\nTI(L)-DeepONet, which incorporates learnable coefficients for intermediate\nslopes in the integration process, adapting to solution-specific variations and\nenhancing fidelity. Evaluation across three canonical PDEs shows that\nTI(L)-DeepONet marginally outperforms TI-DeepONet, with both reducing relative\nL2 extrapolation errors: approximately 81% over autoregressive and 70% over\nfixed-horizon methods. Notably, both maintain prediction stability for temporal\ndomains extending to about twice the training interval. This research\nestablishes a physics-aware operator learning paradigm that bridges neural\napproximation with numerical analysis while preserving the causal structure of\ndynamical systems.",
      "pdf_url": "http://arxiv.org/pdf/2505.17341v1",
      "arxiv_url": "http://arxiv.org/abs/2505.17341v1",
      "published": "2025-05-22",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "Learning Adaptive and Temporally Causal Video Tokenization in a 1D Latent Space",
      "authors": [
        "Yan Li",
        "Changyao Tian",
        "Renqiu Xia",
        "Ning Liao",
        "Weiwei Guo",
        "Junchi Yan",
        "Hongsheng Li",
        "Jifeng Dai",
        "Hao Li",
        "Xue Yang"
      ],
      "abstract": "We propose AdapTok, an adaptive temporal causal video tokenizer that can\nflexibly allocate tokens for different frames based on video content. AdapTok\nis equipped with a block-wise masking strategy that randomly drops tail tokens\nof each block during training, and a block causal scorer to predict the\nreconstruction quality of video frames using different numbers of tokens.\nDuring inference, an adaptive token allocation strategy based on integer linear\nprogramming is further proposed to adjust token usage given predicted scores.\nSuch design allows for sample-wise, content-aware, and temporally dynamic token\nallocation under a controllable overall budget. Extensive experiments for video\nreconstruction and generation on UCF-101 and Kinetics-600 demonstrate the\neffectiveness of our approach. Without additional image data, AdapTok\nconsistently improves reconstruction quality and generation performance under\ndifferent token budgets, allowing for more scalable and token-efficient\ngenerative video modeling.",
      "pdf_url": "http://arxiv.org/pdf/2505.17011v1",
      "arxiv_url": "http://arxiv.org/abs/2505.17011v1",
      "published": "2025-05-22",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "Beyond Correlation: Towards Causal Large Language Model Agents in Biomedicine",
      "authors": [
        "Adib Bazgir",
        "Amir Habibdoust Lafmajani",
        "Yuwen Zhang"
      ],
      "abstract": "Large Language Models (LLMs) show promise in biomedicine but lack true causal\nunderstanding, relying instead on correlations. This paper envisions causal LLM\nagents that integrate multimodal data (text, images, genomics, etc.) and\nperform intervention-based reasoning to infer cause-and-effect. Addressing this\nrequires overcoming key challenges: designing safe, controllable agentic\nframeworks; developing rigorous benchmarks for causal evaluation; integrating\nheterogeneous data sources; and synergistically combining LLMs with structured\nknowledge (KGs) and formal causal inference tools. Such agents could unlock\ntransformative opportunities, including accelerating drug discovery through\nautomated hypothesis generation and simulation, enabling personalized medicine\nthrough patient-specific causal models. This research agenda aims to foster\ninterdisciplinary efforts, bridging causal concepts and foundation models to\ndevelop reliable AI partners for biomedical progress.",
      "pdf_url": "http://arxiv.org/pdf/2505.16982v1",
      "arxiv_url": "http://arxiv.org/abs/2505.16982v1",
      "published": "2025-05-22",
      "categories": [
        "cs.AI",
        "physics.med-ph"
      ]
    },
    {
      "title": "On the Out-of-Distribution Generalization of Self-Supervised Learning",
      "authors": [
        "Wenwen Qiang",
        "Jingyao Wang",
        "Zeen Song",
        "Jiangmeng Li",
        "Changwen Zheng"
      ],
      "abstract": "In this paper, we focus on the out-of-distribution (OOD) generalization of\nself-supervised learning (SSL). By analyzing the mini-batch construction during\nthe SSL training phase, we first give one plausible explanation for SSL having\nOOD generalization. Then, from the perspective of data generation and causal\ninference, we analyze and conclude that SSL learns spurious correlations during\nthe training process, which leads to a reduction in OOD generalization. To\naddress this issue, we propose a post-intervention distribution (PID) grounded\nin the Structural Causal Model. PID offers a scenario where the spurious\nvariable and label variable is mutually independent. Besides, we demonstrate\nthat if each mini-batch during SSL training satisfies PID, the resulting SSL\nmodel can achieve optimal worst-case OOD performance. This motivates us to\ndevelop a batch sampling strategy that enforces PID constraints through the\nlearning of a latent variable model. Through theoretical analysis, we\ndemonstrate the identifiability of the latent variable model and validate the\neffectiveness of the proposed sampling strategy. Experiments conducted on\nvarious downstream OOD tasks demonstrate the effectiveness of the proposed\nsampling strategy.",
      "pdf_url": "http://arxiv.org/pdf/2505.16675v1",
      "arxiv_url": "http://arxiv.org/abs/2505.16675v1",
      "published": "2025-05-22",
      "categories": [
        "cs.LG"
      ]
    }
  ]
}