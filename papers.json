{
  "last_updated": "2025-06-10T00:55:17.259055",
  "papers": [
    {
      "title": "Preference Learning for AI Alignment: a Causal Perspective",
      "authors": [
        "Katarzyna Kobalczyk",
        "Mihaela van der Schaar"
      ],
      "abstract": "Reward modelling from preference data is a crucial step in aligning large\nlanguage models (LLMs) with human values, requiring robust generalisation to\nnovel prompt-response pairs. In this work, we propose to frame this problem in\na causal paradigm, providing the rich toolbox of causality to identify the\npersistent challenges, such as causal misidentification, preference\nheterogeneity, and confounding due to user-specific factors. Inheriting from\nthe literature of causal inference, we identify key assumptions necessary for\nreliable generalisation and contrast them with common data collection\npractices. We illustrate failure modes of naive reward models and demonstrate\nhow causally-inspired approaches can improve model robustness. Finally, we\noutline desiderata for future research and practices, advocating targeted\ninterventions to address inherent limitations of observational data.",
      "pdf_url": "http://arxiv.org/pdf/2506.05967v1",
      "arxiv_url": "http://arxiv.org/abs/2506.05967v1",
      "published": "2025-06-06",
      "categories": [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "title": "MOGO: Residual Quantized Hierarchical Causal Transformer for High-Quality and Real-Time 3D Human Motion Generation",
      "authors": [
        "Dongjie Fu",
        "Tengjiao Sun",
        "Pengcheng Fang",
        "Xiaohao Cai",
        "Hansung Kim"
      ],
      "abstract": "Recent advances in transformer-based text-to-motion generation have led to\nimpressive progress in synthesizing high-quality human motion. Nevertheless,\njointly achieving high fidelity, streaming capability, real-time\nresponsiveness, and scalability remains a fundamental challenge. In this paper,\nwe propose MOGO (Motion Generation with One-pass), a novel autoregressive\nframework tailored for efficient and real-time 3D motion generation. MOGO\ncomprises two key components: (1) MoSA-VQ, a motion scale-adaptive residual\nvector quantization module that hierarchically discretizes motion sequences\nwith learnable scaling to produce compact yet expressive representations; and\n(2) RQHC-Transformer, a residual quantized hierarchical causal transformer that\ngenerates multi-layer motion tokens in a single forward pass, significantly\nreducing inference latency. To enhance semantic fidelity, we further introduce\na text condition alignment mechanism that improves motion decoding under\ntextual control. Extensive experiments on benchmark datasets including\nHumanML3D, KIT-ML, and CMP demonstrate that MOGO achieves competitive or\nsuperior generation quality compared to state-of-the-art transformer-based\nmethods, while offering substantial improvements in real-time performance,\nstreaming generation, and generalization under zero-shot settings.",
      "pdf_url": "http://arxiv.org/pdf/2506.05952v1",
      "arxiv_url": "http://arxiv.org/abs/2506.05952v1",
      "published": "2025-06-06",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Generalizable, real-time neural decoding with hybrid state-space models",
      "authors": [
        "Avery Hee-Woon Ryoo",
        "Nanda H. Krishna",
        "Ximeng Mao",
        "Mehdi Azabou",
        "Eva L. Dyer",
        "Matthew G. Perich",
        "Guillaume Lajoie"
      ],
      "abstract": "Real-time decoding of neural activity is central to neuroscience and\nneurotechnology applications, from closed-loop experiments to brain-computer\ninterfaces, where models are subject to strict latency constraints. Traditional\nmethods, including simple recurrent neural networks, are fast and lightweight\nbut often struggle to generalize to unseen data. In contrast, recent\nTransformer-based approaches leverage large-scale pretraining for strong\ngeneralization performance, but typically have much larger computational\nrequirements and are not always suitable for low-resource or real-time\nsettings. To address these shortcomings, we present POSSM, a novel hybrid\narchitecture that combines individual spike tokenization via a cross-attention\nmodule with a recurrent state-space model (SSM) backbone to enable (1) fast and\ncausal online prediction on neural activity and (2) efficient generalization to\nnew sessions, individuals, and tasks through multi-dataset pretraining. We\nevaluate POSSM's decoding performance and inference speed on intracortical\ndecoding of monkey motor tasks, and show that it extends to clinical\napplications, namely handwriting and speech decoding in human subjects.\nNotably, we demonstrate that pretraining on monkey motor-cortical recordings\nimproves decoding performance on the human handwriting task, highlighting the\nexciting potential for cross-species transfer. In all of these tasks, we find\nthat POSSM achieves decoding accuracy comparable to state-of-the-art\nTransformers, at a fraction of the inference cost (up to 9x faster on GPU).\nThese results suggest that hybrid SSMs are a promising approach to bridging the\ngap between accuracy, inference speed, and generalization when training neural\ndecoders for real-time, closed-loop applications.",
      "pdf_url": "http://arxiv.org/pdf/2506.05320v1",
      "arxiv_url": "http://arxiv.org/abs/2506.05320v1",
      "published": "2025-06-05",
      "categories": [
        "q-bio.NC",
        "cs.LG"
      ]
    },
    {
      "title": "MesaNet: Sequence Modeling by Locally Optimal Test-Time Training",
      "authors": [
        "Johannes von Oswald",
        "Nino Scherrer",
        "Seijin Kobayashi",
        "Luca Versari",
        "Songlin Yang",
        "Maximilian Schlegel",
        "Kaitlin Maile",
        "Yanick Schimpf",
        "Oliver Sieberling",
        "Alexander Meulemans",
        "Rif A. Saurous",
        "Guillaume Lajoie",
        "Charlotte Frenkel",
        "Razvan Pascanu",
        "Blaise Agüera y Arcas",
        "João Sacramento"
      ],
      "abstract": "Sequence modeling is currently dominated by causal transformer architectures\nthat use softmax self-attention. Although widely adopted, transformers require\nscaling memory and compute linearly during inference. A recent stream of work\nlinearized the softmax operation, resulting in powerful recurrent neural\nnetwork (RNN) models with constant memory and compute costs such as DeltaNet,\nMamba or xLSTM. These models can be unified by noting that their recurrent\nlayer dynamics can all be derived from an in-context regression objective,\napproximately optimized through an online learning rule. Here, we join this\nline of work and introduce a numerically stable, chunkwise parallelizable\nversion of the recently proposed Mesa layer (von Oswald et al., 2024), and\nstudy it in language modeling at the billion-parameter scale. This layer again\nstems from an in-context loss, but which is now minimized to optimality at\nevery time point using a fast conjugate gradient solver. Through an extensive\nsuite of experiments, we show that optimal test-time training enables reaching\nlower language modeling perplexity and higher downstream benchmark performance\nthan previous RNNs, especially on tasks requiring long context understanding.\nThis performance gain comes at the cost of additional flops spent during\ninference time. Our results are therefore intriguingly related to recent trends\nof increasing test-time compute to improve performance -- here by spending\ncompute to solve sequential optimization problems within the neural network\nitself.",
      "pdf_url": "http://arxiv.org/pdf/2506.05233v1",
      "arxiv_url": "http://arxiv.org/abs/2506.05233v1",
      "published": "2025-06-05",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Causal Effect Identification in lvLiNGAM from Higher-Order Cumulants",
      "authors": [
        "Daniele Tramontano",
        "Yaroslav Kivva",
        "Saber Salehkaleybar",
        "Mathias Drton",
        "Negar Kiyavash"
      ],
      "abstract": "This paper investigates causal effect identification in latent variable\nLinear Non-Gaussian Acyclic Models (lvLiNGAM) using higher-order cumulants,\naddressing two prominent setups that are challenging in the presence of latent\nconfounding: (1) a single proxy variable that may causally influence the\ntreatment and (2) underspecified instrumental variable cases where fewer\ninstruments exist than treatments. We prove that causal effects are\nidentifiable with a single proxy or instrument and provide corresponding\nestimation methods. Experimental results demonstrate the accuracy and\nrobustness of our approaches compared to existing methods, advancing the\ntheoretical and practical understanding of causal inference in linear systems\nwith latent confounders.",
      "pdf_url": "http://arxiv.org/pdf/2506.05202v2",
      "arxiv_url": "http://arxiv.org/abs/2506.05202v2",
      "published": "2025-06-05",
      "categories": [
        "stat.ML",
        "cs.LG",
        "stat.ME"
      ]
    },
    {
      "title": "Nonlinear Causal Discovery for Grouped Data",
      "authors": [
        "Konstantin Göbler",
        "Tobias Windisch",
        "Mathias Drton"
      ],
      "abstract": "Inferring cause-effect relationships from observational data has gained\nsignificant attention in recent years, but most methods are limited to scalar\nrandom variables. In many important domains, including neuroscience,\npsychology, social science, and industrial manufacturing, the causal units of\ninterest are groups of variables rather than individual scalar measurements.\nMotivated by these applications, we extend nonlinear additive noise models to\nhandle random vectors, establishing a two-step approach for causal graph\nlearning: First, infer the causal order among random vectors. Second, perform\nmodel selection to identify the best graph consistent with this order. We\nintroduce effective and novel solutions for both steps in the vector case,\ndemonstrating strong performance in simulations. Finally, we apply our method\nto real-world assembly line data with partial knowledge of causal ordering\namong variable groups.",
      "pdf_url": "http://arxiv.org/pdf/2506.05120v1",
      "arxiv_url": "http://arxiv.org/abs/2506.05120v1",
      "published": "2025-06-05",
      "categories": [
        "stat.ML",
        "cs.LG",
        "stat.ME"
      ]
    },
    {
      "title": "Causal Policy Learning in Reinforcement Learning: Backdoor-Adjusted Soft Actor-Critic",
      "authors": [
        "Thanh Vinh Vo",
        "Young Lee",
        "Haozhe Ma",
        "Chien Lu",
        "Tze-Yun Leong"
      ],
      "abstract": "Hidden confounders that influence both states and actions can bias policy\nlearning in reinforcement learning (RL), leading to suboptimal or\nnon-generalizable behavior. Most RL algorithms ignore this issue, learning\npolicies from observational trajectories based solely on statistical\nassociations rather than causal effects. We propose DoSAC (Do-Calculus Soft\nActor-Critic with Backdoor Adjustment), a principled extension of the SAC\nalgorithm that corrects for hidden confounding via causal intervention\nestimation. DoSAC estimates the interventional policy $\\pi(a | \\mathrm{do}(s))$\nusing the backdoor criterion, without requiring access to true confounders or\ncausal labels. To achieve this, we introduce a learnable Backdoor Reconstructor\nthat infers pseudo-past variables (previous state and action) from the current\nstate to enable backdoor adjustment from observational data. This module is\nintegrated into a soft actor-critic framework to compute both the\ninterventional policy and its entropy. Empirical results on continuous control\nbenchmarks show that DoSAC outperforms baselines under confounded settings,\nwith improved robustness, generalization, and policy reliability.",
      "pdf_url": "http://arxiv.org/pdf/2506.05445v1",
      "arxiv_url": "http://arxiv.org/abs/2506.05445v1",
      "published": "2025-06-05",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Learning Joint Interventional Effects from Single-Variable Interventions in Additive Models",
      "authors": [
        "Armin Kekić",
        "Sergio Hernan Garrido Mejia",
        "Bernhard Schölkopf"
      ],
      "abstract": "Estimating causal effects of joint interventions on multiple variables is\ncrucial in many domains, but obtaining data from such simultaneous\ninterventions can be challenging. Our study explores how to learn joint\ninterventional effects using only observational data and single-variable\ninterventions. We present an identifiability result for this problem, showing\nthat for a class of nonlinear additive outcome mechanisms, joint effects can be\ninferred without access to joint interventional data. We propose a practical\nestimator that decomposes the causal effect into confounded and unconfounded\ncontributions for each intervention variable. Experiments on synthetic data\ndemonstrate that our method achieves performance comparable to models trained\ndirectly on joint interventional data, outperforming a purely observational\nestimator.",
      "pdf_url": "http://arxiv.org/pdf/2506.04945v1",
      "arxiv_url": "http://arxiv.org/abs/2506.04945v1",
      "published": "2025-06-05",
      "categories": [
        "stat.ML",
        "cs.LG"
      ]
    },
    {
      "title": "Bayesian Doubly Robust Causal Inference via Posterior Coupling",
      "authors": [
        "Shunichiro Orihara",
        "Tomotaka Momozaki",
        "Shonosuke Sugasawa"
      ],
      "abstract": "In observational studies, propensity score methods are central for estimating\ncausal effects while adjusting for confounders. Among them, the doubly robust\n(DR) estimator has gained considerable attention because it provides consistent\nestimates when either the propensity score model or the outcome model is\ncorrectly specified. Like other propensity score approaches, the DR estimator\ntypically involves two-step estimation: first, estimating the propensity score\nand outcome models, and then estimating the causal effects using the estimated\nvalues. However, this sequential procedure does not naturally align with the\nBayesian framework, which centers on updating prior beliefs solely through the\nlikelihood. In this manuscript, we propose novel Bayesian DR estimation via\nposterior coupling, which incorporates propensity score information via moment\nconditions directly into the posterior distribution. This design avoids the\nfeedback problem and enables a fully Bayesian interpretation of DR estimation\nwithout requiring two-step estimation. We detail the theoretical properties of\nthe proposed method and demonstrate its advantages over existing Bayesian\napproaches through comprehensive simulation studies and real data applications.",
      "pdf_url": "http://arxiv.org/pdf/2506.04868v1",
      "arxiv_url": "http://arxiv.org/abs/2506.04868v1",
      "published": "2025-06-05",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "OpenAg: Democratizing Agricultural Intelligence",
      "authors": [
        "Srikanth Thudumu",
        "Jason Fisher"
      ],
      "abstract": "Agriculture is undergoing a major transformation driven by artificial\nintelligence (AI), machine learning, and knowledge representation technologies.\nHowever, current agricultural intelligence systems often lack contextual\nunderstanding, explainability, and adaptability, especially for smallholder\nfarmers with limited resources. General-purpose large language models (LLMs),\nwhile powerful, typically lack the domain-specific knowledge and contextual\nreasoning needed for practical decision support in farming. They tend to\nproduce recommendations that are too generic or unrealistic for real-world\napplications. To address these challenges, we present OpenAg, a comprehensive\nframework designed to advance agricultural artificial general intelligence\n(AGI). OpenAg combines domain-specific foundation models, neural knowledge\ngraphs, multi-agent reasoning, causal explainability, and adaptive transfer\nlearning to deliver context-aware, explainable, and actionable insights. The\nsystem includes: (i) a unified agricultural knowledge base that integrates\nscientific literature, sensor data, and farmer-generated knowledge; (ii) a\nneural agricultural knowledge graph for structured reasoning and inference;\n(iii) an adaptive multi-agent reasoning system where AI agents specialize and\ncollaborate across agricultural domains; and (iv) a causal transparency\nmechanism that ensures AI recommendations are interpretable, scientifically\ngrounded, and aligned with real-world constraints. OpenAg aims to bridge the\ngap between scientific knowledge and the tacit expertise of experienced farmers\nto support scalable and locally relevant agricultural decision-making.",
      "pdf_url": "http://arxiv.org/pdf/2506.04571v1",
      "arxiv_url": "http://arxiv.org/abs/2506.04571v1",
      "published": "2025-06-05",
      "categories": [
        "cs.AI"
      ]
    }
  ]
}