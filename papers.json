{
  "last_updated": "2025-07-22T00:58:26.540734",
  "papers": [
    {
      "title": "On the importance of tail assumptions in climate extreme event attribution",
      "authors": [
        "Mengran Li",
        "Daniela Castro-Camilo"
      ],
      "abstract": "Extreme weather events are becoming more frequent and intense, posing serious\nthreats to human life, biodiversity, and ecosystems. A key objective of extreme\nevent attribution (EEA) is to assess whether and to what extent anthropogenic\nclimate change influences such events. Central to EEA is the accurate\nstatistical characterization of atmospheric extremes, which are inherently\nmultivariate or spatial due to their measurement over high-dimensional grids.\nWithin the counterfactual causal inference framework of Pearl, we evaluate how\ntail assumptions affect attribution conclusions by comparing three multivariate\nmodeling approaches for estimating causation metrics. These include: (i) the\nmultivariate generalized Pareto distribution, which imposes an invariant tail\ndependence structure; (ii) the factor copula model of Castro-Camilo and Huser\n(2020), which offers flexible subasymptotic behavior; and (iii) the model of\nHuser and Wadsworth (2019), which smoothly transitions between different forms\nof extremal dependence. We assess the implications of these modeling choices in\nboth simulated scenarios (under varying forms of model misspecification) and\nreal data applications, using weekly winter maxima over Europe from the\nM\\'et\\'eo-France CNRM model and daily precipitation from the ACCESS-CM2 model\nover the U.S. Our findings highlight that tail assumptions critically shape\ncausality metrics in EEA. Misspecification of the extremal dependence structure\ncan lead to substantially different and potentially misleading attribution\nconclusions, underscoring the need for careful model selection and evaluation\nwhen quantifying the influence of climate change on extreme events.",
      "pdf_url": "http://arxiv.org/pdf/2507.14019v1",
      "arxiv_url": "http://arxiv.org/abs/2507.14019v1",
      "published": "2025-07-18",
      "categories": [
        "stat.AP",
        "62G32, 62H10, 62P12, 62H20",
        "G.3"
      ]
    },
    {
      "title": "A regression-based approach for bidirectional proximal causal inference in the presence of unmeasured confounding",
      "authors": [
        "Jiaqi Min",
        "Xueyue Zhang",
        "Shanshan Luo"
      ],
      "abstract": "Proxy variables are commonly used in causal inference when unmeasured\nconfounding exists. While most existing proximal methods assume a\nunidirectional causal relationship between two primary variables, many social\nand biological systems exhibit complex feedback mechanisms that imply\nbidirectional causality. In this paper, using regression-based models, we\nextend the proximal framework to identify bidirectional causal effects in the\npresence of unmeasured confounding. We establish the identification of\nbidirectional causal effects and develop a sensitivity analysis method for\nviolations of the proxy structural conditions. Building on this identification\nresult, we derive bidirectional two-stage least squares estimators that are\nconsistent and asymptotically normal under standard regularity conditions.\nSimulation studies demonstrate that our approach delivers unbiased causal\neffect estimates and outperforms some standard methods. The simulation results\nalso confirm the reliability of the sensitivity analysis procedure. Applying\nour methodology to a state-level panel dataset from 1985 to 2014 in the United\nStates, we examine the bidirectional causal effects between abortion rates and\nmurder rates. The analysis reveals a consistent negative effect of abortion\nrates on murder rates, while also detecting a potential reciprocal effect from\nmurder rates to abortion rates that conventional unidirectional analyses have\nnot considered.",
      "pdf_url": "http://arxiv.org/pdf/2507.13965v1",
      "arxiv_url": "http://arxiv.org/abs/2507.13965v1",
      "published": "2025-07-18",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Reframing attention as a reinforcement learning problem for causal discovery",
      "authors": [
        "Turan Orujlu",
        "Christian Gumbsch",
        "Martin V. Butz",
        "Charley M Wu"
      ],
      "abstract": "Formal frameworks of causality have operated largely parallel to modern\ntrends in deep reinforcement learning (RL). However, there has been a revival\nof interest in formally grounding the representations learned by neural\nnetworks in causal concepts. Yet, most attempts at neural models of causality\nassume static causal graphs and ignore the dynamic nature of causal\ninteractions. In this work, we introduce Causal Process framework as a novel\ntheory for representing dynamic hypotheses about causal structure. Furthermore,\nwe present Causal Process Model as an implementation of this framework. This\nallows us to reformulate the attention mechanism popularized by Transformer\nnetworks within an RL setting with the goal to infer interpretable causal\nprocesses from visual observations. Here, causal inference corresponds to\nconstructing a causal graph hypothesis which itself becomes an RL task nested\nwithin the original RL problem. To create an instance of such hypothesis, we\nemploy RL agents. These agents establish links between units similar to the\noriginal Transformer attention mechanism. We demonstrate the effectiveness of\nour approach in an RL environment where we outperform current alternatives in\ncausal representation learning and agent performance, and uniquely recover\ngraphs of dynamic causal processes.",
      "pdf_url": "http://arxiv.org/pdf/2507.13920v1",
      "arxiv_url": "http://arxiv.org/abs/2507.13920v1",
      "published": "2025-07-18",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "CoTasks: Chain-of-Thought based Video Instruction Tuning Tasks",
      "authors": [
        "Yanan Wang",
        "Julio Vizcarra",
        "Zhi Li",
        "Hao Niu",
        "Mori Kurokawa"
      ],
      "abstract": "Despite recent progress in video large language models (VideoLLMs), a key\nopen challenge remains: how to equip models with chain-of-thought (CoT)\nreasoning abilities grounded in fine-grained object-level video understanding.\nExisting instruction-tuned models, such as the Qwen and LLaVA series, are\ntrained on high-level video-text pairs, often lacking structured annotations\nnecessary for compositional, step-by-step reasoning. We propose CoTasks:\nChain-of-Thought based Video Instruction Tuning Tasks, a new framework that\ndecomposes complex video questions of existing datasets (e.g., NeXT-QA, STAR)\ninto four entity-level foundational tasks: frame localization, entity tracking,\nspatial and temporal relation extraction. By embedding these intermediate\nCoT-style reasoning steps into the input, CoTasks enables models to explicitly\nperform object-centric spatiotemporal reasoning. Experiments on the NeXT-QA\nbenchmark show that CoTasks significantly enhance inference performance:\nLLaVA-video-7B improves by +3.3 points in average GPT-4 evaluation score, and\nQwen2.5-VL-3B gains +17.4, with large boosts in causal (+14.6), temporal\n(+10.9), and descriptive (+48.1) subcategories. These results demonstrate the\neffectiveness of CoTasks as a structured CoT-style supervision framework for\nimproving compositional video reasoning.",
      "pdf_url": "http://arxiv.org/pdf/2507.13609v1",
      "arxiv_url": "http://arxiv.org/abs/2507.13609v1",
      "published": "2025-07-18",
      "categories": [
        "cs.CV",
        "cs.CL"
      ]
    },
    {
      "title": "Combining stated and revealed preferences",
      "authors": [
        "Romuald Meango",
        "Marc Henry",
        "Ismael Mourifie"
      ],
      "abstract": "Can stated preferences inform counterfactual analyses of actual choice? This\nresearch proposes a novel approach to researchers who have access to both\nstated choices in hypothetical scenarios and actual choices, matched or\nunmatched. The key idea is to use stated choices to identify the distribution\nof individual unobserved heterogeneity. If this unobserved heterogeneity is the\nsource of endogeneity, the researcher can correct for its influence in a demand\nfunction estimation using actual choices and recover causal effects. Bounds on\ncausal effects are derived in the case, where stated choice and actual choices\nare observed in unmatched data sets. These data combination bounds are of\nindependent interest. We derive a valid bootstrap inference for the bounds and\nshow its good performance in a simulation experiment.",
      "pdf_url": "http://arxiv.org/pdf/2507.13552v1",
      "arxiv_url": "http://arxiv.org/abs/2507.13552v1",
      "published": "2025-07-17",
      "categories": [
        "econ.EM"
      ]
    },
    {
      "title": "CaSTFormer: Causal Spatio-Temporal Transformer for Driving Intention Prediction",
      "authors": [
        "Sirui Wang",
        "Zhou Guan",
        "Bingxi Zhao",
        "Tongjia Gu"
      ],
      "abstract": "Accurate prediction of driving intention is key to enhancing the safety and\ninteractive efficiency of human-machine co-driving systems. It serves as a\ncornerstone for achieving high-level autonomous driving. However, current\napproaches remain inadequate for accurately modeling the complex\nspatio-temporal interdependencies and the unpredictable variability of human\ndriving behavior. To address these challenges, we propose CaSTFormer, a Causal\nSpatio-Temporal Transformer to explicitly model causal interactions between\ndriver behavior and environmental context for robust intention prediction.\nSpecifically, CaSTFormer introduces a novel Reciprocal Shift Fusion (RSF)\nmechanism for precise temporal alignment of internal and external feature\nstreams, a Causal Pattern Extraction (CPE) module that systematically\neliminates spurious correlations to reveal authentic causal dependencies, and\nan innovative Feature Synthesis Network (FSN) that adaptively synthesizes these\npurified representations into coherent spatio-temporal inferences. We evaluate\nthe proposed CaSTFormer on the public Brain4Cars dataset, and it achieves\nstate-of-the-art performance. It effectively captures complex causal\nspatio-temporal dependencies and enhances both the accuracy and transparency of\ndriving intention prediction.",
      "pdf_url": "http://arxiv.org/pdf/2507.13425v1",
      "arxiv_url": "http://arxiv.org/abs/2507.13425v1",
      "published": "2025-07-17",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Resurrect Mask AutoRegressive Modeling for Efficient and Scalable Image Generation",
      "authors": [
        "Yi Xin",
        "Le Zhuo",
        "Qi Qin",
        "Siqi Luo",
        "Yuewen Cao",
        "Bin Fu",
        "Yangfan He",
        "Hongsheng Li",
        "Guangtao Zhai",
        "Xiaohong Liu",
        "Peng Gao"
      ],
      "abstract": "AutoRegressive (AR) models have made notable progress in image generation,\nwith Masked AutoRegressive (MAR) models gaining attention for their efficient\nparallel decoding. However, MAR models have traditionally underperformed when\ncompared to standard AR models. This study refines the MAR architecture to\nimprove image generation quality. We begin by evaluating various image\ntokenizers to identify the most effective one. Subsequently, we introduce an\nimproved Bidirectional LLaMA architecture by replacing causal attention with\nbidirectional attention and incorporating 2D RoPE, which together form our\nadvanced model, MaskGIL. Scaled from 111M to 1.4B parameters, MaskGIL achieves\na FID score of 3.71, matching state-of-the-art AR models in the ImageNet\n256x256 benchmark, while requiring only 8 inference steps compared to the 256\nsteps of AR models. Furthermore, we develop a text-driven MaskGIL model with\n775M parameters for generating images from text at various resolutions. Beyond\nimage generation, MaskGIL extends to accelerate AR-based generation and enable\nreal-time speech-to-image conversion. Our codes and models are available at\nhttps://github.com/synbol/MaskGIL.",
      "pdf_url": "http://arxiv.org/pdf/2507.13032v1",
      "arxiv_url": "http://arxiv.org/abs/2507.13032v1",
      "published": "2025-07-17",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "Causal Language Control in Multilingual Transformers via Sparse Feature Steering",
      "authors": [
        "Cheng-Ting Chou",
        "George Liu",
        "Jessica Sun",
        "Cole Blondin",
        "Kevin Zhu",
        "Vasu Sharma",
        "Sean O'Brien"
      ],
      "abstract": "Deterministically controlling the target generation language of large\nmultilingual language models (LLMs) remains a fundamental challenge,\nparticularly in zero-shot settings where neither explicit language prompts nor\nfine-tuning are available. In this work, we investigate whether sparse\nautoencoder (SAE) features, previously shown to correlate with interpretable\nmodel behaviors, can be leveraged to steer the generated language of LLMs\nduring inference. Leveraging pretrained SAEs on the residual streams of\nGemma-2B and Gemma-9B, we identify features whose activations differ most\nsignificantly between English and four target languages: Chinese, Japanese,\nSpanish, and French. By modifying just a single SAE feature at one transformer\nlayer, we achieve controlled language shifts with up to 90\\% success, as\nmeasured by FastText language classification, while preserving semantic\nfidelity according to LaBSE (Language-Agnostic BERT Sentence Embedding)\nsimilarity. Our analysis reveals that language steering is most effective in\nmid-to-late transformer layers and is amplified by specific attention heads\ndisproportionately associated with language-sensitive SAE features. These\nresults demonstrate the promise of sparse feature steering as a lightweight and\ninterpretable mechanism for controllable multilingual generation.",
      "pdf_url": "http://arxiv.org/pdf/2507.13410v1",
      "arxiv_url": "http://arxiv.org/abs/2507.13410v1",
      "published": "2025-07-17",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Modeling Open-World Cognition as On-Demand Synthesis of Probabilistic Models",
      "authors": [
        "Lionel Wong",
        "Katherine M. Collins",
        "Lance Ying",
        "Cedegao E. Zhang",
        "Adrian Weller",
        "Tobias Gerstenberg",
        "Timothy O'Donnell",
        "Alexander K. Lew",
        "Jacob D. Andreas",
        "Joshua B. Tenenbaum",
        "Tyler Brooke-Wilson"
      ],
      "abstract": "When faced with novel situations, people are able to marshal relevant\nconsiderations from a wide range of background knowledge and put these to use\nin inferences and predictions. What permits us to draw in globally relevant\ninformation and reason over it coherently? Here, we explore the hypothesis that\npeople use a combination of distributed and symbolic representations to\nconstruct bespoke mental models tailored to novel situations. We propose a\ncomputational implementation of this idea -- a ``Model Synthesis Architecture''\n(MSA) -- using language models to implement global relevance-based retrieval\nand model synthesis and probabilistic programs to implement bespoke, coherent\nworld models. We evaluate our MSA as a model of human judgments on a novel\nreasoning dataset. The dataset -- built around a `Model Olympics` domain of\nsports vignettes -- tests models' capacity for human-like, open-ended reasoning\nby requiring (i) judgments about novel causal structures described in language;\n(ii) drawing on large bodies of background knowledge; and (iii) doing both in\nlight of observations that introduce arbitrary novel variables. Our MSA\napproach captures human judgments better than language model-only baselines,\nunder both direct and chain-of-thought generations from the LM that supports\nmodel synthesis. These results suggest that MSAs can be implemented in a way\nthat mirrors people's ability to deliver locally coherent reasoning over\nglobally relevant variables, offering a path to understanding and replicating\nhuman reasoning in open-ended domains.",
      "pdf_url": "http://arxiv.org/pdf/2507.12547v2",
      "arxiv_url": "http://arxiv.org/abs/2507.12547v2",
      "published": "2025-07-16",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.PL"
      ]
    },
    {
      "title": "Targeted Deep Architectures: A TMLE-Based Framework for Robust Causal Inference in Neural Networks",
      "authors": [
        "Yi Li",
        "David Mccoy",
        "Nolan Gunter",
        "Kaitlyn Lee",
        "Alejandro Schuler",
        "Mark van der Laan"
      ],
      "abstract": "Modern deep neural networks are powerful predictive tools yet often lack\nvalid inference for causal parameters, such as treatment effects or entire\nsurvival curves. While frameworks like Double Machine Learning (DML) and\nTargeted Maximum Likelihood Estimation (TMLE) can debias machine-learning fits,\nexisting neural implementations either rely on \"targeted losses\" that do not\nguarantee solving the efficient influence function equation or computationally\nexpensive post-hoc \"fluctuations\" for multi-parameter settings. We propose\nTargeted Deep Architectures (TDA), a new framework that embeds TMLE directly\ninto the network's parameter space with no restrictions on the backbone\narchitecture. Specifically, TDA partitions model parameters - freezing all but\na small \"targeting\" subset - and iteratively updates them along a targeting\ngradient, derived from projecting the influence functions onto the span of the\ngradients of the loss with respect to weights. This procedure yields plug-in\nestimates that remove first-order bias and produce asymptotically valid\nconfidence intervals. Crucially, TDA easily extends to multi-dimensional causal\nestimands (e.g., entire survival curves) by merging separate targeting\ngradients into a single universal targeting update. Theoretically, TDA inherits\nclassical TMLE properties, including double robustness and semiparametric\nefficiency. Empirically, on the benchmark IHDP dataset (average treatment\neffects) and simulated survival data with informative censoring, TDA reduces\nbias and improves coverage relative to both standard neural-network estimators\nand prior post-hoc approaches. In doing so, TDA establishes a direct, scalable\npathway toward rigorous causal inference within modern deep architectures for\ncomplex multi-parameter targets.",
      "pdf_url": "http://arxiv.org/pdf/2507.12435v1",
      "arxiv_url": "http://arxiv.org/abs/2507.12435v1",
      "published": "2025-07-16",
      "categories": [
        "cs.LG"
      ]
    }
  ]
}