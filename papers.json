{
  "last_updated": "2025-12-12T00:56:42.410652",
  "papers": [
    {
      "title": "A Conversation with Mike West",
      "authors": [
        "Hedibert F. Lopes",
        "Filippo Ascolani"
      ],
      "abstract": "Mike West is currently the Arts & Sciences Distinguished Professor Emeritus of Statistics and Decision Sciences at Duke University. Mike's research in Bayesian analysis spans multiple interlinked areas: theory and methods of dynamic models in time series analysis, foundations of inference and decision analysis, multivariate and latent structure analysis, stochastic computation and optimisation, among others. Inter-disciplinary R&D has ranged across applications in commercial forecasting, dynamic networks, finance, econometrics, signal processing, climatology, systems biology, genomics and neuroscience, among other areas. Among Mike's currently active research areas are forecasting, causal prediction and decision analysis in business, economic policy and finance, as well as in personal decision making. Mike led the development of academic statistics at Duke University from 1990-2002, and has been broadly engaged in professional leadership elsewhere. He is past president of the International Society for Bayesian Analysis (ISBA), and has served in founding roles and as board member for several professional societies, national and international centres and institutes. Recipient of numerous awards, Mike has been active in research with various companies, banks, government agencies and academic centres, co-founder of a successful biotechnology company, and board member for several financial and IT companies. He has published 4 books, several edited volumes and over 200 papers. Mike has worked with many undergraduate and Master's research students, and as of 2025 has mentored around 65 primary PhD students and postdoctoral associates who moved to academic, industrial or governmental positions involving advanced statistical and data science research.",
      "pdf_url": "https://arxiv.org/pdf/2512.09790v1",
      "arxiv_url": "http://arxiv.org/abs/2512.09790v1",
      "published": "2025-12-10",
      "categories": [
        "stat.OT"
      ]
    },
    {
      "title": "Temporal Windows of Integration for Multisensory Wireless Systems as Enablers of Physical AI",
      "authors": [
        "Anup Mishra",
        "Jo√£o Henrique Inacio de Souza",
        "Petar Popovski"
      ],
      "abstract": "Physical artificial intelligence (AI) refers to the AI that interacts with the physical world in real time. Similar to multisensory perception, Physical AI makes decisions based on multimodal updates from sensors and devices. Physical AI thus operates with a finite spatial footprint of its sensory tributaries. The multimodal updates traverse heterogeneous and unreliable paths, involving wireless links. Throughput or latency guarantees do not ensure correct decision-making, as misaligned, misordered, or stale inputs still yield wrong inferences. Preserving decision-time coherence hinges on three timing primitives at the network-application interface: (i) simultaneity, a short coincidence window that groups measurements as co-temporal, (ii) causality, path-wise delivery that never lets a consequence precede its precursor, and (iii) usefulness, a validity horizon that drops information too stale to influence the current action. In this work, we focus on usefulness and adopt temporal window of integration (TWI)-Causality: the TWI enforces decision-time usefulness by assuming path-wise causal consistency and cross-path simultaneity are handled upstream. We model end-to-end path delay as the sum of sensing/propagation, computation, and access/transmission latencies, and formulate network design as minimizing the validity horizon under a delivery reliability constraint. In effect, this calibrates delay-reliability budgets for a timing-aware system operating over sensors within a finite spatial footprint. The joint choice of horizon and per-path reliability is cast as a convex optimization problem, solved to global optimality to obtain the minimal horizon and per-path allocation of reliability. This is compared favourably to a benchmark based on uniform-after-threshold allocation. Overall, this study contributes to timing-aware Physical AI in next-generation networks.",
      "pdf_url": "https://arxiv.org/pdf/2512.09589v1",
      "arxiv_url": "http://arxiv.org/abs/2512.09589v1",
      "published": "2025-12-10",
      "categories": [
        "eess.SP"
      ]
    },
    {
      "title": "Multiply-robust Estimator of Cumulative Incidence Function Difference for Right-Censored Competing Risks Data",
      "authors": [
        "Yifei Tian",
        "Ying Wu"
      ],
      "abstract": "In causal inference, estimating the average treatment effect is a central objective, and in the context of competing risks data, this effect can be quantified by the cause-specific cumulative incidence function (CIF) difference. While doubly robust estimators give a more robust way to estimate the causal effect from the observational study, they remain inconsistent if both models are misspecified. To improve the robustness, we develop a multiply robust estimator for the difference in cause-specific CIFs using right-censored competing risks data. The proposed framework integrates the pseudo-value approach, which transforms the censored, time-dependent CIF into a complete-data outcome, with the multiply robust estimation framework. By specifying multiple candidate models for both the propensity score and the outcome regression, the resulting estimator is consistent and asymptotically unbiased, provided that at least one of the multiple propensity score or outcome regression models is correctly specified. Simulation studies show our multiply robust estimator remains virtually unbiased and maintains nominal coverage rates under various model misspecification scenarios and a wide range of choices for the censoring rate. Finally, the proposed multiply robust model is illustrated using the Right Heart Catheterization dataset.",
      "pdf_url": "https://arxiv.org/pdf/2512.09433v1",
      "arxiv_url": "http://arxiv.org/abs/2512.09433v1",
      "published": "2025-12-10",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Prenatal alcohol exposure and child cognition: semi-continuous exposures, causal inference and evidence synthesis",
      "authors": [
        "Xiaoya Wang",
        "Richard J. Cook",
        "Yeying Zhu",
        "Tugba Akkaya-Hocagil",
        "R. Colin Carter",
        "Sandra W. Jacobson",
        "Joseph L. Jacobson",
        "Louise M. Ryan"
      ],
      "abstract": "We address the challenge of causal inference status and the dose-response effects with a semi-continuous exposure. A two-stage approach is proposed using estimating equation for multiple outcomes with large sample properties derived for the resulting estimators. Homogeneity tests are developed to assess whether causal effects of exposure status and the dose-response effects are the same across multiple outcomes. A global homogeneity test is also developed to assess whether the effect of exposure status (exposed/not exposed) and the dose-response effect of the continuous exposure level are each equal across all outcomes. The methods of estimation and testing are rigorously evaluated in simulation studies and applied to a motivating study on the effects of prenatal alcohol exposure on childhood cognition defined by executive function (EF), academic achievement in math, and learning and memory (LM).",
      "pdf_url": "https://arxiv.org/pdf/2512.09237v1",
      "arxiv_url": "http://arxiv.org/abs/2512.09237v1",
      "published": "2025-12-10",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Complementary strengths of the Neyman-Rubin and graphical causal frameworks",
      "authors": [
        "Tetiana Gorbach",
        "Xavier de Luna",
        "Juha Karvanen",
        "Ingeborg Waernbaum"
      ],
      "abstract": "This article contributes to the discussion on the relationship between the Neyman-Rubin and the graphical frameworks for causal inference. We present specific examples of data-generating mechanisms - such as those involving undirected or deterministic relationships and cycles - where analyses using a directed acyclic graph are challenging, but where the tools from the Neyman-Rubin causal framework are readily applicable. We also provide examples of data-generating mechanisms with M-bias, trapdoor variables, and complex front-door structures, where the application of the Neyman-Rubin approach is complicated, but the graphical approach is directly usable. The examples offer insights into commonly used causal inference frameworks and aim to improve comprehension of the languages for causal reasoning among a broad audience.",
      "pdf_url": "https://arxiv.org/pdf/2512.09130v1",
      "arxiv_url": "http://arxiv.org/abs/2512.09130v1",
      "published": "2025-12-09",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Prediction Intervals for Individual Treatment Effects in a Multiple Decision Point Framework using Conformal Inference",
      "authors": [
        "Swaraj Bose",
        "Walter Dempsey"
      ],
      "abstract": "Accurately quantifying uncertainty of individual treatment effects (ITEs) across multiple decision points is crucial for personalized decision-making in fields such as healthcare, finance, education, and online marketplaces. Previous work has focused on predicting non-causal longitudinal estimands or constructing prediction bands for ITEs using cross-sectional data based on exchangeability assumptions. We propose a novel method for constructing prediction intervals using conformal inference techniques for time-varying ITEs with weaker assumptions than prior literature. We guarantee a lower bound for coverage, which is dependent on the degree of non-exchangeability in the data. Although our method is broadly applicable across decision-making contexts, we support our theoretical claims with simulations emulating micro-randomized trials (MRTs) -- a sequential experimental design for mobile health (mHealth) studies. We demonstrate the practical utility of our method by applying it to a real-world MRT - the Intern Health Study (IHS).",
      "pdf_url": "https://arxiv.org/pdf/2512.08828v1",
      "arxiv_url": "http://arxiv.org/abs/2512.08828v1",
      "published": "2025-12-09",
      "categories": [
        "stat.ME",
        "stat.ML"
      ]
    },
    {
      "title": "Inferring Causal Relationships to Improve Caching for Clients with Correlated Requests: Applications to VR",
      "authors": [
        "Agrim Bari",
        "Gustavo de Veciana",
        "Yuqi Zhou"
      ],
      "abstract": "Efficient edge caching reduces latency and alleviates backhaul congestion in modern networks. Traditional caching policies, such as Least Recently Used (LRU) and Least Frequently Used (LFU), perform well under specific request patterns. LRU excels in workloads with strong temporal locality, while LFU is effective when content popularity remains static. However, real-world client requests often exhibit correlations due to shared contexts and coordinated activities. This is particularly evident in Virtual Reality (VR) environments, where groups of clients navigate shared virtual spaces, leading to correlated content requests.\n  In this paper, we introduce the \\textit{grouped client request model}, a generalization of the Independent Reference Model that explicitly captures different types of request correlations. Our theoretical analysis of LRU under this model reveals that the optimal causal caching policy depends on cache size: LFU is optimal for small to moderate caches, while LRU outperforms it for larger caches. To address the limitations of existing policies, we propose Least Following and Recently Used (LFRU), a novel online caching policy that dynamically infers and adapts to causal relationships in client requests to optimize evictions. LFRU prioritizes objects likely to be requested based on inferred dependencies, achieving near-optimal performance compared to the offline optimal Belady policy in structured correlation settings.\n  We develop VR based datasets to evaluate caching policies under realistic correlated requests. Our results show that LFRU consistently performs at least as well as LRU and LFU, outperforming LRU by up to 2.9x and LFU by up to1.9x in certain settings.",
      "pdf_url": "https://arxiv.org/pdf/2512.08626v1",
      "arxiv_url": "http://arxiv.org/abs/2512.08626v1",
      "published": "2025-12-09",
      "categories": [
        "cs.NI",
        "cs.SE"
      ]
    },
    {
      "title": "From Accuracy to Impact: The Impact-Driven AI Framework (IDAIF) for Aligning Engineering Architecture with Theory of Change",
      "authors": [
        "Yong-Woon Kim"
      ],
      "abstract": "This paper introduces the Impact-Driven AI Framework (IDAIF), a novel architectural methodology that integrates Theory of Change (ToC) principles with modern artificial intelligence system design. As AI systems increasingly influence high-stakes domains including healthcare, finance, and public policy, the alignment problem--ensuring AI behavior corresponds with human values and intentions--has become critical. Current approaches predominantly optimize technical performance metrics while neglecting the sociotechnical dimensions of AI deployment. IDAIF addresses this gap by establishing a systematic mapping between ToC's five-stage model (Inputs-Activities-Outputs-Outcomes-Impact) and corresponding AI architectural layers (Data Layer-Pipeline Layer-Inference Layer-Agentic Layer-Normative Layer). Each layer incorporates rigorous theoretical foundations: multi-objective Pareto optimization for value alignment, hierarchical multi-agent orchestration for outcome achievement, causal directed acyclic graphs (DAGs) for hallucination mitigation, and adversarial debiasing with Reinforcement Learning from Human Feedback (RLHF) for fairness assurance. We provide formal mathematical formulations for each component and introduce an Assurance Layer that manages assumption failures through guardian architectures. Three case studies demonstrate IDAIF application across healthcare, cybersecurity, and software engineering domains. This framework represents a paradigm shift from model-centric to impact-centric AI development, providing engineers with concrete architectural patterns for building ethical, trustworthy, and socially beneficial AI systems.",
      "pdf_url": "https://arxiv.org/pdf/2512.08449v1",
      "arxiv_url": "http://arxiv.org/abs/2512.08449v1",
      "published": "2025-12-09",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Causal inference under interference: computational barriers and algorithmic solutions",
      "authors": [
        "Sohom Bhattacharya",
        "Subhabrata Sen"
      ],
      "abstract": "We study causal effect estimation under interference from network data. We work under the chain-graph formulation pioneered in Tchetgen Tchetgen et. al (2021). Our first result shows that polynomial time evaluation of treatment effects is computationally hard in this framework without additional assumptions on the underlying chain graph. Subsequently, we assume that the interactions among the study units are governed either by (i) a dense graph or (ii) an i.i.d. Gaussian matrix. In each case, we show that the treatment effects have well-defined limits as the population size diverges to infinity. Additionally, we develop polynomial time algorithms to consistently evaluate the treatment effects in each case. Finally, we estimate the unknown parameters from the observed data using maximum pseudo-likelihood estimates, and establish the stability of our causal effect estimators under this perturbation. Our algorithms provably approximate the causal effects in polynomial time even in low-temperature regimes where the canonical MCMC samplers are slow mixing. For dense graphs, our results use the notion of regularity partitions; for Gaussian interactions, our approach uses ideas from spin glass theory and Approximate Message Passing.",
      "pdf_url": "https://arxiv.org/pdf/2512.08252v1",
      "arxiv_url": "http://arxiv.org/abs/2512.08252v1",
      "published": "2025-12-09",
      "categories": [
        "math.ST",
        "math.PR",
        "stat.ME"
      ]
    },
    {
      "title": "Empowerment Gain and Causal Model Construction: Children and adults are sensitive to controllability and variability in their causal interventions",
      "authors": [
        "Eunice Yiu",
        "Kelsey Allen",
        "Shiry Ginosar",
        "Alison Gopnik"
      ],
      "abstract": "Learning about the causal structure of the world is a fundamental problem for human cognition. Causal models and especially causal learning have proved to be difficult for large pretrained models using standard techniques of deep learning. In contrast, cognitive scientists have applied advances in our formal understanding of causation in computer science, particularly within the Causal Bayes Net formalism, to understand human causal learning. In the very different tradition of reinforcement learning, researchers have described an intrinsic reward signal called \"empowerment\" which maximizes mutual information between actions and their outcomes. \"Empowerment\" may be an important bridge between classical Bayesian causal learning and reinforcement learning and may help to characterize causal learning in humans and enable it in machines. If an agent learns an accurate causal world model, they will necessarily increase their empowerment, and increasing empowerment will lead to a more accurate causal world model. Empowerment may also explain distinctive features of childrens causal learning, as well as providing a more tractable computational account of how that learning is possible. In an empirical study, we systematically test how children and adults use cues to empowerment to infer causal relations, and design effective causal interventions.",
      "pdf_url": "https://arxiv.org/pdf/2512.08230v1",
      "arxiv_url": "http://arxiv.org/abs/2512.08230v1",
      "published": "2025-12-09",
      "categories": [
        "cs.AI"
      ]
    }
  ]
}