{
  "last_updated": "2025-10-23T00:52:02.382394",
  "papers": [
    {
      "title": "A Hybrid Enumeration Framework for Optimal Counterfactual Generation in Post-Acute COVID-19 Heart Failure",
      "authors": [
        "Jingya Cheng",
        "Alaleh Azhir",
        "Jiazi Tian",
        "Hossein Estiri"
      ],
      "abstract": "Counterfactual inference provides a mathematical framework for reasoning\nabout hypothetical outcomes under alternative interventions, bridging causal\nreasoning and predictive modeling. We present a counterfactual inference\nframework for individualized risk estimation and intervention analysis,\nillustrated through a clinical application to post-acute sequelae of COVID-19\n(PASC) among patients with pre-existing heart failure (HF). Using longitudinal\ndiagnosis, laboratory, and medication data from a large health-system cohort,\nwe integrate regularized predictive modeling with counterfactual search to\nidentify actionable pathways to PASC-related HF hospital admissions. The\nframework combines exact enumeration with optimization-based methods, including\nthe Nearest Instance Counterfactual Explanations (NICE) and Multi-Objective\nCounterfactuals (MOC) algorithms, to efficiently explore high-dimensional\nintervention spaces. Applied to more than 2700 individuals with confirmed\nSARS-CoV-2 infection and prior HF, the model achieved strong discriminative\nperformance (AUROC: 0.88, 95% CI: 0.84-0.91) and generated interpretable,\npatient-specific counterfactuals that quantify how modifying comorbidity\npatterns or treatment factors could alter predicted outcomes. This work\ndemonstrates how counterfactual reasoning can be formalized as an optimization\nproblem over predictive functions, offering a rigorous, interpretable, and\ncomputationally efficient approach to personalized inference in complex\nbiomedical systems.",
      "pdf_url": "http://arxiv.org/pdf/2510.18841v1",
      "arxiv_url": "http://arxiv.org/abs/2510.18841v1",
      "published": "2025-10-21",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "Improving the Generation and Evaluation of Synthetic Data for Downstream Medical Causal Inference",
      "authors": [
        "Harry Amad",
        "Zhaozhi Qian",
        "Dennis Frauen",
        "Julianna Piskorz",
        "Stefan Feuerriegel",
        "Mihaela van der Schaar"
      ],
      "abstract": "Causal inference is essential for developing and evaluating medical\ninterventions, yet real-world medical datasets are often difficult to access\ndue to regulatory barriers. This makes synthetic data a potentially valuable\nasset that enables these medical analyses, along with the development of new\ninference methods themselves. Generative models can produce synthetic data that\nclosely approximate real data distributions, yet existing methods do not\nconsider the unique challenges that downstream causal inference tasks, and\nspecifically those focused on treatments, pose. We establish a set of\ndesiderata that synthetic data containing treatments should satisfy to maximise\ndownstream utility: preservation of (i) the covariate distribution, (ii) the\ntreatment assignment mechanism, and (iii) the outcome generation mechanism.\nBased on these desiderata, we propose a set of evaluation metrics to assess\nsuch synthetic data. Finally, we present STEAM: a novel method for generating\nSynthetic data for Treatment Effect Analysis in Medicine that mimics the\ndata-generating process of data containing treatments and optimises for our\ndesiderata. We empirically demonstrate that STEAM achieves state-of-the-art\nperformance across our metrics as compared to existing generative models,\nparticularly as the complexity of the true data-generating process increases.",
      "pdf_url": "http://arxiv.org/pdf/2510.18768v1",
      "arxiv_url": "http://arxiv.org/abs/2510.18768v1",
      "published": "2025-10-21",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "Causally Perturbed Fairness Testing",
      "authors": [
        "Chengwen Du",
        "Tao Chen"
      ],
      "abstract": "To mitigate unfair and unethical discrimination over sensitive features\n(e.g., gender, age, or race), fairness testing plays an integral role in\nengineering systems that leverage AI models to handle tabular data. A key\nchallenge therein is how to effectively reveal fairness bugs under an\nintractable sample size using perturbation. Much current work has been focusing\non designing the test sample generators, ignoring the valuable knowledge about\ndata characteristics that can help guide the perturbation and hence limiting\ntheir full potential. In this paper, we seek to bridge such a gap by proposing\na generic framework of causally perturbed fairness testing, dubbed CausalFT.\nThrough causal inference, the key idea of CausalFT is to extract the most\ndirectly and causally relevant non-sensitive feature to its sensitive\ncounterpart, which can jointly influence the prediction of the label. Such a\ncausal relationship is then seamlessly injected into the perturbation to guide\na test sample generator. Unlike existing generator-level work, CausalFT serves\nas a higher-level framework that can be paired with diverse base generators.\nExtensive experiments on 1296 cases confirm that CausalFT can considerably\nimprove arbitrary base generators in revealing fairness bugs over 93% of the\ncases with acceptable extra runtime overhead. Compared with a state-of-the-art\napproach that ranks the non-sensitive features solely based on correlation,\nCausalFT performs significantly better on 64% cases while being much more\nefficient. Further, CausalFT can better improve bias resilience in nearly all\ncases.",
      "pdf_url": "http://arxiv.org/pdf/2510.18719v1",
      "arxiv_url": "http://arxiv.org/abs/2510.18719v1",
      "published": "2025-10-21",
      "categories": [
        "cs.SE",
        "cs.AI"
      ]
    },
    {
      "title": "C-SWAP: Explainability-Aware Structured Pruning for Efficient Neural Networks Compression",
      "authors": [
        "Baptiste Bauvin",
        "Lo√Øc Baret",
        "Ola Ahmad"
      ],
      "abstract": "Neural network compression has gained increasing attention in recent years,\nparticularly in computer vision applications, where the need for model\nreduction is crucial for overcoming deployment constraints. Pruning is a widely\nused technique that prompts sparsity in model structures, e.g. weights,\nneurons, and layers, reducing size and inference costs. Structured pruning is\nespecially important as it allows for the removal of entire structures, which\nfurther accelerates inference time and reduces memory overhead. However, it can\nbe computationally expensive, requiring iterative retraining and optimization.\nTo overcome this problem, recent methods considered one-shot setting, which\napplies pruning directly at post-training. Unfortunately, they often lead to a\nconsiderable drop in performance. In this paper, we focus on this issue by\nproposing a novel one-shot pruning framework that relies on explainable deep\nlearning. First, we introduce a causal-aware pruning approach that leverages\ncause-effect relations between model predictions and structures in a\nprogressive pruning process. It allows us to efficiently reduce the size of the\nnetwork, ensuring that the removed structures do not deter the performance of\nthe model. Then, through experiments conducted on convolution neural network\nand vision transformer baselines, pre-trained on classification tasks, we\ndemonstrate that our method consistently achieves substantial reductions in\nmodel size, with minimal impact on performance, and without the need for\nfine-tuning. Overall, our approach outperforms its counterparts, offering the\nbest trade-off. Our code is available on GitHub.",
      "pdf_url": "http://arxiv.org/pdf/2510.18636v1",
      "arxiv_url": "http://arxiv.org/abs/2510.18636v1",
      "published": "2025-10-21",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ]
    },
    {
      "title": "A Multi-Evidence Framework Rescues Low-Power Prognostic Signals and Rejects Statistical Artifacts in Cancer Genomics",
      "authors": [
        "Gokturk Aytug Akarlar"
      ],
      "abstract": "Motivation: Standard genome-wide association studies in cancer genomics rely\non statistical significance with multiple testing correction, but\nsystematically fail in underpowered cohorts. In TCGA breast cancer (n=967, 133\ndeaths), low event rates (13.8%) create severe power limitations, producing\nfalse negatives for known drivers and false positives for large passenger\ngenes. Results: We developed a five-criteria computational framework\nintegrating causal inference (inverse probability weighting, doubly robust\nestimation) with orthogonal biological validation (expression, mutation\npatterns, literature evidence). Applied to TCGA-BRCA mortality analysis,\nstandard Cox+FDR detected zero genes at FDR<0.05, confirming complete failure\nin underpowered settings. Our framework correctly identified RYR2 -- a cardiac\ngene with no cancer function -- as a false positive despite nominal\nsignificance (p=0.024), while identifying KMT2C as a complex candidate\nrequiring validation despite marginal significance (p=0.047, q=0.954). Power\nanalysis revealed median power of 15.1% across genes, with KMT2C achieving only\n29.8% power (HR=1.55), explaining borderline statistical significance despite\nstrong biological evidence. The framework distinguished true signals from\nartifacts through mutation pattern analysis: RYR2 showed 29.8% silent mutations\n(passenger signature) with no hotspots, while KMT2C showed 6.7% silent\nmutations with 31.4% truncating variants (driver signature). This\nmulti-evidence approach provides a template for analyzing underpowered cohorts,\nprioritizing biological interpretability over purely statistical significance.\n  Availability: All code and analysis pipelines available at\ngithub.com/akarlaraytu/causal-inference-for-cancer-genomics",
      "pdf_url": "http://arxiv.org/pdf/2510.18571v1",
      "arxiv_url": "http://arxiv.org/abs/2510.18571v1",
      "published": "2025-10-21",
      "categories": [
        "q-bio.GN",
        "cs.LG",
        "92B15, 62P10, 62F10, 62H17",
        "J.3; I.2.6; G.3"
      ]
    },
    {
      "title": "Towards Identifiability of Hierarchical Temporal Causal Representation Learning",
      "authors": [
        "Zijian Li",
        "Minghao Fu",
        "Junxian Huang",
        "Yifan Shen",
        "Ruichu Cai",
        "Yuewen Sun",
        "Guangyi Chen",
        "Kun Zhang"
      ],
      "abstract": "Modeling hierarchical latent dynamics behind time series data is critical for\ncapturing temporal dependencies across multiple levels of abstraction in\nreal-world tasks. However, existing temporal causal representation learning\nmethods fail to capture such dynamics, as they fail to recover the joint\ndistribution of hierarchical latent variables from \\textit{single-timestep\nobserved variables}. Interestingly, we find that the joint distribution of\nhierarchical latent variables can be uniquely determined using three\nconditionally independent observations. Building on this insight, we propose a\nCausally Hierarchical Latent Dynamic (CHiLD) identification framework. Our\napproach first employs temporal contextual observed variables to identify the\njoint distribution of multi-layer latent variables. Sequentially, we exploit\nthe natural sparsity of the hierarchical structure among latent variables to\nidentify latent variables within each layer. Guided by the theoretical results,\nwe develop a time series generative model grounded in variational inference.\nThis model incorporates a contextual encoder to reconstruct multi-layer latent\nvariables and normalize flow-based hierarchical prior networks to impose the\nindependent noise condition of hierarchical latent dynamics. Empirical\nevaluations on both synthetic and real-world datasets validate our theoretical\nclaims and demonstrate the effectiveness of CHiLD in modeling hierarchical\nlatent dynamics.",
      "pdf_url": "http://arxiv.org/pdf/2510.18310v1",
      "arxiv_url": "http://arxiv.org/abs/2510.18310v1",
      "published": "2025-10-21",
      "categories": [
        "cs.LG",
        "stat.ME"
      ]
    },
    {
      "title": "Online Time Series Forecasting with Theoretical Guarantees",
      "authors": [
        "Zijian Li",
        "Changze Zhou",
        "Minghao Fu",
        "Sanjay Manjunath",
        "Fan Feng",
        "Guangyi Chen",
        "Yingyao Hu",
        "Ruichu Cai",
        "Kun Zhang"
      ],
      "abstract": "This paper is concerned with online time series forecasting, where unknown\ndistribution shifts occur over time, i.e., latent variables influence the\nmapping from historical to future observations. To develop an automated way of\nonline time series forecasting, we propose a Theoretical framework for Online\nTime-series forecasting (TOT in short) with theoretical guarantees.\nSpecifically, we prove that supplying a forecaster with latent variables\ntightens the Bayes risk, the benefit endures under estimation uncertainty of\nlatent variables and grows as the latent variables achieve a more precise\nidentifiability. To better introduce latent variables into online forecasting\nalgorithms, we further propose to identify latent variables with minimal\nadjacent observations. Based on these results, we devise a model-agnostic\nblueprint by employing a temporal decoder to match the distribution of observed\nvariables and two independent noise estimators to model the causal inference of\nlatent variables and mixing procedures of observed variables, respectively.\nExperiment results on synthetic data support our theoretical claims. Moreover,\nplug-in implementations built on several baselines yield general improvement\nacross multiple benchmarks, highlighting the effectiveness in real-world\napplications.",
      "pdf_url": "http://arxiv.org/pdf/2510.18281v1",
      "arxiv_url": "http://arxiv.org/abs/2510.18281v1",
      "published": "2025-10-21",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "Intuitionistic $j$-Do-Calculus in Topos Causal Models",
      "authors": [
        "Sridhar Mahadevan"
      ],
      "abstract": "In this paper, we generalize Pearl's do-calculus to an Intuitionistic setting\ncalled $j$-stable causal inference inside a topos of sheaves. Our framework is\nan elaboration of the recently proposed framework of Topos Causal Models\n(TCMs), where causal interventions are defined as subobjects. We generalize the\noriginal setting of TCM using the Lawvere-Tierney topology on a topos, defined\nby a modal operator $j$ on the subobject classifier $\\Omega$. We introduce\n$j$-do-calculus, where we replace global truth with local truth defined by\nKripke-Joyal semantics, and formalize causal reasoning as structure-preserving\nmorphisms that are stable along $j$-covers. $j$-do-calculus is a sound rule\nsystem whose premises and conclusions are formulas of the internal\nIntuitionistic logic of the causal topos. We define $j$-stability for\nconditional independences and interventional claims as local truth in the\ninternal logic of the causal topos. We give three inference rules that mirror\nPearl's insertion/deletion and action/observation exchange, and we prove\nsoundness in the Kripke-Joyal semantics. A companion paper in preparation will\ndescribe how to estimate the required entities from data and instantiate $j$-do\nwith standard discovery procedures (e.g., score-based and constraint-based\nmethods), and will include experimental results on how to (i) form data-driven\n$j$-covers (via regime/section constructions), (ii) compute chartwise\nconditional independences after graph surgeries, and (iii) glue them to certify\nthe premises of the $j$-do rules in practice",
      "pdf_url": "http://arxiv.org/pdf/2510.17944v1",
      "arxiv_url": "http://arxiv.org/abs/2510.17944v1",
      "published": "2025-10-20",
      "categories": [
        "cs.LO",
        "cs.AI"
      ]
    },
    {
      "title": "A Principle of Targeted Intervention for Multi-Agent Reinforcement Learning",
      "authors": [
        "Anjie Liu",
        "Jianhong Wang",
        "Samuel Kaski",
        "Jun Wang",
        "Mengyue Yang"
      ],
      "abstract": "Steering cooperative multi-agent reinforcement learning (MARL) towards\ndesired outcomes is challenging, particularly when the global guidance from a\nhuman on the whole multi-agent system is impractical in a large-scale MARL. On\nthe other hand, designing mechanisms to coordinate agents most relies on\nempirical studies, lacking a easy-to-use research tool. In this work, we employ\nmulti-agent influence diagrams (MAIDs) as a graphical framework to address the\nabove issues. First, we introduce interaction paradigms that leverage MAIDs to\nanalyze and visualize existing approaches in MARL. Then, we design a new\ninteraction paradigm based on MAIDs, referred to as targeted intervention that\nis applied to only a single targeted agent, so the problem of global guidance\ncan be mitigated. In our implementation, we introduce a causal inference\ntechnique-referred to as Pre-Strategy Intervention (PSI)-to realize the\ntargeted intervention paradigm. Since MAIDs can be regarded as a special class\nof causal diagrams, a composite desired outcome that integrates the primary\ntask goal and an additional desired outcome can be achieved by maximizing the\ncorresponding causal effect through the PSI. Moreover, the bundled relevance\ngraph analysis of MAIDs provides a tool to identify whether an MARL learning\nparadigm is workable under the design of an interaction paradigm. In\nexperiments, we demonstrate the effectiveness of our proposed targeted\nintervention, and verify the result of relevance graph analysis.",
      "pdf_url": "http://arxiv.org/pdf/2510.17697v1",
      "arxiv_url": "http://arxiv.org/abs/2510.17697v1",
      "published": "2025-10-20",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "I.2.11; I.2.6"
      ]
    },
    {
      "title": "CausalMamba: Scalable Conditional State Space Models for Neural Causal Inference",
      "authors": [
        "Sangyoon Bae",
        "Jiook Cha"
      ],
      "abstract": "We introduce CausalMamba, a scalable framework that addresses fundamental\nlimitations in fMRI-based causal inference: the ill-posed nature of inferring\nneural causality from hemodynamically distorted BOLD signals and the\ncomputational intractability of existing methods like Dynamic Causal Modeling\n(DCM). Our approach decomposes this complex inverse problem into two tractable\nstages: BOLD deconvolution to recover latent neural activity, followed by\ncausal graph inference using a novel Conditional Mamba architecture. On\nsimulated data, CausalMamba achieves 37% higher accuracy than DCM. Critically,\nwhen applied to real task fMRI data, our method recovers well-established\nneural pathways with 88% fidelity, whereas conventional approaches fail to\nidentify these canonical circuits in over 99% of subjects. Furthermore, our\nnetwork analysis of working memory data reveals that the brain strategically\nshifts its primary causal hub-recruiting executive or salience networks\ndepending on the stimulus-a sophisticated reconfiguration that remains\nundetected by traditional methods. This work provides neuroscientists with a\npractical tool for large-scale causal inference that captures both fundamental\ncircuit motifs and flexible network dynamics underlying cognitive function.",
      "pdf_url": "http://arxiv.org/pdf/2510.17318v1",
      "arxiv_url": "http://arxiv.org/abs/2510.17318v1",
      "published": "2025-10-20",
      "categories": [
        "cs.CV"
      ]
    }
  ]
}