{
  "last_updated": "2025-12-30T00:57:30.645665",
  "papers": [
    {
      "title": "Knot Forcing: Taming Autoregressive Video Diffusion Models for Real-time Infinite Interactive Portrait Animation",
      "authors": [
        "Steven Xiao",
        "XIndi Zhang",
        "Dechao Meng",
        "Qi Wang",
        "Peng Zhang",
        "Bang Zhang"
      ],
      "abstract": "Real-time portrait animation is essential for interactive applications such as virtual assistants and live avatars, requiring high visual fidelity, temporal coherence, ultra-low latency, and responsive control from dynamic inputs like reference images and driving signals. While diffusion-based models achieve strong quality, their non-causal nature hinders streaming deployment. Causal autoregressive video generation approaches enable efficient frame-by-frame generation but suffer from error accumulation, motion discontinuities at chunk boundaries, and degraded long-term consistency. In this work, we present a novel streaming framework named Knot Forcing for real-time portrait animation that addresses these challenges through three key designs: (1) a chunk-wise generation strategy with global identity preservation via cached KV states of the reference image and local temporal modeling using sliding window attention; (2) a temporal knot module that overlaps adjacent chunks and propagates spatio-temporal cues via image-to-video conditioning to smooth inter-chunk motion transitions; and (3) A \"running ahead\" mechanism that dynamically updates the reference frame's temporal coordinate during inference, keeping its semantic context ahead of the current rollout frame to support long-term coherence. Knot Forcing enables high-fidelity, temporally consistent, and interactive portrait animation over infinite sequences, achieving real-time performance with strong visual stability on consumer-grade GPUs.",
      "pdf_url": "https://arxiv.org/pdf/2512.21734v1",
      "arxiv_url": "http://arxiv.org/abs/2512.21734v1",
      "published": "2025-12-25",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "Enabling Conversational Behavior Reasoning Capabilities in Full-Duplex Speech",
      "authors": [
        "Shuchang Pan",
        "Siddharth Banerjee",
        "Dhruv Hebbar",
        "Siddhant Patel",
        "Akshaj Gupta",
        "Kan Jen Cheng",
        "Hanjo Kim",
        "Zeyi Austin Li",
        "Martin Q. Ma",
        "Tingle Li",
        "Gopala Anumanchipalli",
        "Jiachen Lian"
      ],
      "abstract": "Human conversation is organized by an implicit chain of thoughts that manifests as timed speech acts. Capturing this causal pathway is key to building natural full-duplex interactive systems. We introduce a framework that enables reasoning over conversational behaviors by modeling this process as causal inference within a Graph-of-Thoughts (GoT). Our approach formalizes the intent-to-action pathway with a hierarchical labeling scheme, predicting high-level communicative intents and low-level speech acts to learn their causal and temporal dependencies. To train this system, we develop a hybrid corpus that pairs controllable, event-rich simulations with human-annotated rationales and real conversational speech. The GoT framework structures streaming predictions as an evolving graph, enabling a multimodal transformer to forecast the next speech act, generate concise justifications for its decisions, and dynamically refine its reasoning. Experiments on both synthetic and real duplex dialogues show that the framework delivers robust behavior detection, produces interpretable reasoning chains, and establishes a foundation for benchmarking conversational reasoning in full duplex spoken dialogue systems.",
      "pdf_url": "https://arxiv.org/pdf/2512.21706v1",
      "arxiv_url": "http://arxiv.org/abs/2512.21706v1",
      "published": "2025-12-25",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "CausalFSFG: Rethinking Few-Shot Fine-Grained Visual Categorization from Causal Perspective",
      "authors": [
        "Zhiwen Yang",
        "Jinglin Xu",
        "Yuxin Pen"
      ],
      "abstract": "Few-shot fine-grained visual categorization (FS-FGVC) focuses on identifying various subcategories within a common superclass given just one or few support examples. Most existing methods aim to boost classification accuracy by enriching the extracted features with discriminative part-level details. However, they often overlook the fact that the set of support samples acts as a confounding variable, which hampers the FS-FGVC performance by introducing biased data distribution and misguiding the extraction of discriminative features. To address this issue, we propose a new causal FS-FGVC (CausalFSFG) approach inspired by causal inference for addressing biased data distributions through causal intervention. Specifically, based on the structural causal model (SCM), we argue that FS-FGVC infers the subcategories (i.e., effect) from the inputs (i.e., cause), whereas both the few-shot condition disturbance and the inherent fine-grained nature (i.e., large intra-class variance and small inter-class variance) lead to unobservable variables that bring spurious correlations, compromising the final classification performance. To further eliminate the spurious correlations, our CausalFSFG approach incorporates two key components: (1) Interventional multi-scale encoder (IMSE) conducts sample-level interventions, (2) Interventional masked feature reconstruction (IMFR) conducts feature-level interventions, which together reveal real causalities from inputs to subcategories. Extensive experiments and thorough analyses on the widely-used public datasets, including CUB-200-2011, Stanford Dogs, and Stanford Cars, demonstrate that our CausalFSFG achieves new state-of-the-art performance. The code is available at https://github.com/PKU-ICST-MIPL/CausalFSFG_TMM.",
      "pdf_url": "https://arxiv.org/pdf/2512.21617v1",
      "arxiv_url": "http://arxiv.org/abs/2512.21617v1",
      "published": "2025-12-25",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "SVBench: Evaluation of Video Generation Models on Social Reasoning",
      "authors": [
        "Wenshuo Peng",
        "Gongxuan Wang",
        "Tianmeng Yang",
        "Chuanhao Li",
        "Xiaojie Xu",
        "Hui He",
        "Kaipeng Zhang"
      ],
      "abstract": "Recent text-to-video generation models exhibit remarkable progress in visual realism, motion fidelity, and text-video alignment, yet they remain fundamentally limited in their ability to generate socially coherent behavior. Unlike humans, who effortlessly infer intentions, beliefs, emotions, and social norms from brief visual cues, current models tend to render literal scenes without capturing the underlying causal or psychological logic. To systematically evaluate this gap, we introduce the first benchmark for social reasoning in video generation. Grounded in findings from developmental and social psychology, our benchmark organizes thirty classic social cognition paradigms into seven core dimensions, including mental-state inference, goal-directed action, joint attention, social coordination, prosocial behavior, social norms, and multi-agent strategy. To operationalize these paradigms, we develop a fully training-free agent-based pipeline that (i) distills the reasoning mechanism of each experiment, (ii) synthesizes diverse video-ready scenarios, (iii) enforces conceptual neutrality and difficulty control through cue-based critique, and (iv) evaluates generated videos using a high-capacity VLM judge across five interpretable dimensions of social reasoning. Using this framework, we conduct the first large-scale study across seven state-of-the-art video generation systems. Our results reveal substantial performance gaps: while modern models excel in surface-level plausibility, they systematically fail in intention recognition, belief reasoning, joint attention, and prosocial inference.",
      "pdf_url": "https://arxiv.org/pdf/2512.21507v1",
      "arxiv_url": "http://arxiv.org/abs/2512.21507v1",
      "published": "2025-12-25",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "Sensitivity Analysis of the Consistency Assumption",
      "authors": [
        "Brian Knaeble",
        "Qinyun Lin",
        "Erich Kummerfeld",
        "Kenneth A. Frank"
      ],
      "abstract": "Sensitivity analysis informs causal inference by assessing the sensitivity of conclusions to departures from assumptions. The consistency assumption states that there are no hidden versions of treatment and that the outcome arising naturally equals the outcome arising from intervention. When reasoning about the possibility of consistency violations, it can be helpful to distinguish between covariates and versions of treatment. In the context of surgery, for example, genomic variables are covariates and the skill of a particular surgeon is a version of treatment. There may be hidden versions of treatment, and this paper addresses that concern with a new kind of sensitivity analysis. Whereas many methods for sensitivity analysis are focused on confounding by unmeasured covariates, the methodology of this paper is focused on confounding by hidden versions of treatment. In this paper, new mathematical notation is introduced to support the novel method, and example applications are described.",
      "pdf_url": "https://arxiv.org/pdf/2512.21379v1",
      "arxiv_url": "http://arxiv.org/abs/2512.21379v1",
      "published": "2025-12-24",
      "categories": [
        "stat.ME",
        "cs.LG",
        "math.OC"
      ]
    },
    {
      "title": "Causal-driven attribution (CDA): Estimating channel influence without user-level data",
      "authors": [
        "Georgios Filippou",
        "Boi Mai Quach",
        "Diana Lenghel",
        "Arthur White",
        "Ashish Kumar Jha"
      ],
      "abstract": "Attribution modelling lies at the heart of marketing effectiveness, yet most existing approaches depend on user-level path data, which are increasingly inaccessible due to privacy regulations and platform restrictions. This paper introduces a Causal-Driven Attribution (CDA) framework that infers channel influence using only aggregated impression-level data, avoiding any reliance on user identifiers or click-path tracking. CDA integrates temporal causal discovery (using PCMCI) with causal effect estimation via a Structural Causal Model to recover directional channel relationships and quantify their contributions to conversions. Using large-scale synthetic data designed to replicate real marketing dynamics, we show that CDA achieves an average relative RMSE of 9.50% when given the true causal graph, and 24.23% when using the predicted graph, demonstrating strong accuracy under correct structure and meaningful signal recovery even under structural uncertainty. CDA captures cross-channel interdependencies while providing interpretable, privacy-preserving attribution insights, offering a scalable and future-proof alternative to traditional path-based models.",
      "pdf_url": "https://arxiv.org/pdf/2512.21211v1",
      "arxiv_url": "http://arxiv.org/abs/2512.21211v1",
      "published": "2025-12-24",
      "categories": [
        "stat.ML",
        "cs.LG"
      ]
    },
    {
      "title": "Hierarchical Modeling Approach to Fast and Accurate Table Recognition",
      "authors": [
        "Takaya Kawakatsu"
      ],
      "abstract": "The extraction and use of diverse knowledge from numerous documents is a pressing challenge in intelligent information retrieval. Documents contain elements that require different recognition methods. Table recognition typically consists of three subtasks, namely table structure, cell position and cell content recognition. Recent models have achieved excellent recognition with a combination of multi-task learning, local attention, and mutual learning. However, their effectiveness has not been fully explained, and they require a long period of time for inference. This paper presents a novel multi-task model that utilizes non-causal attention to capture the entire table structure, and a parallel inference algorithm for faster cell content inference. The superiority is demonstrated both visually and statistically on two large public datasets.",
      "pdf_url": "https://arxiv.org/pdf/2512.21083v1",
      "arxiv_url": "http://arxiv.org/abs/2512.21083v1",
      "published": "2025-12-24",
      "categories": [
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "title": "Clever Hans in Chemistry: Chemist Style Signals Confound Activity Prediction on Public Benchmarks",
      "authors": [
        "Andrew D. Blevins",
        "Ian K. Quigley"
      ],
      "abstract": "Can machine learning models identify which chemist made a molecule from structure alone? If so, models trained on literature data may exploit chemist intent rather than learning causal structure-activity relationships. We test this by linking CHEMBL assays to publication authors and training a 1,815-class classifier to predict authors from molecular fingerprints, achieving 60% top-5 accuracy under scaffold-based splitting. We then train an activity model that receives only a protein identifier and an author-probability vector derived from structure, with no direct access to molecular descriptors. This author-only model achieves predictive power comparable to a simple baseline that has access to structure. This reveals a \"Clever Hans\" failure mode: models can predict bioactivity largely by inferring chemist goals and favorite targets without requiring a lab-independent understanding of chemistry. We analyze the sources of this leakage, propose author-disjoint splits, and recommend dataset practices to decouple chemist intent from biological outcomes.",
      "pdf_url": "https://arxiv.org/pdf/2512.20924v1",
      "arxiv_url": "http://arxiv.org/abs/2512.20924v1",
      "published": "2025-12-24",
      "categories": [
        "q-bio.BM",
        "cs.LG",
        "physics.chem-ph"
      ]
    },
    {
      "title": "Generalization of RLVR Using Causal Reasoning as a Testbed",
      "authors": [
        "Brian Lu",
        "Hongyu Zhao",
        "Shuo Sun",
        "Hao Peng",
        "Rui Ding",
        "Hongyuan Mei"
      ],
      "abstract": "Reinforcement learning with verifiable rewards (RLVR) has emerged as a promising paradigm for post-training large language models (LLMs) on complex reasoning tasks. Yet, the conditions under which RLVR yields robust generalization remain poorly understood. This paper provides an empirical study of RLVR generalization in the setting of probabilistic inference over causal graphical models. This setting offers two natural axes along which to examine generalization: (i) the level of the probabilistic query -- associational, interventional, or counterfactual -- and (ii) the structural complexity of the query, measured by the size of its relevant subgraph. We construct datasets of causal graphs and queries spanning these difficulty axes and fine-tune Qwen-2.5-Instruct models using RLVR or supervised fine-tuning (SFT). We vary both the model scale (3B-32B) and the query level included in training. We find that RLVR yields stronger within-level and across-level generalization than SFT, but only for specific combinations of model size and training query level. Further analysis shows that RLVR's effectiveness depends on the model's initial reasoning competence. With sufficient initial competence, RLVR improves an LLM's marginalization strategy and reduces errors in intermediate probability calculations, producing substantial accuracy gains, particularly on more complex queries. These findings show that RLVR can improve specific causal reasoning subskills, with its benefits emerging only when the model has sufficient initial competence.",
      "pdf_url": "https://arxiv.org/pdf/2512.20760v1",
      "arxiv_url": "http://arxiv.org/abs/2512.20760v1",
      "published": "2025-12-23",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Information-theoretic signatures of causality in Bayesian networks and hypergraphs",
      "authors": [
        "Sung En Chiang",
        "Zhaolu Liu",
        "Robert L. Peach",
        "Mauricio Barahona"
      ],
      "abstract": "Analyzing causality in multivariate systems involves establishing how information is generated, distributed and combined, and thus requires tools that capture interactions beyond pairwise relations. Higher-order information theory provides such tools. In particular, Partial Information Decomposition (PID) allows the decomposition of the information that a set of sources provides about a target into redundant, unique, and synergistic components. Yet the mathematical connection between such higher-order information-theoretic measures and causal structure remains undeveloped. Here we establish the first theoretical correspondence between PID components and causal structure in both Bayesian networks and hypergraphs. We first show that in Bayesian networks unique information precisely characterizes direct causal neighbors, while synergy identifies collider relationships. This establishes a localist causal discovery paradigm in which the structure surrounding each variable can be recovered from its immediate informational footprint, eliminating the need for global search over graph space. Extending these results to higher-order systems, we prove that PID signatures in Bayesian hypergraphs differentiate parents, children, co-heads, and co-tails, revealing a higher-order collider effect unique to multi-tail hyperedges. We also present procedures by which our results can be used to characterize systematically the causal structure of Bayesian networks and hypergraphs. Our results position PID as a rigorous, model-agnostic foundation for inferring both pairwise and higher-order causal structure, and introduce a fundamentally local information-theoretic viewpoint on causal discovery.",
      "pdf_url": "https://arxiv.org/pdf/2512.20552v1",
      "arxiv_url": "http://arxiv.org/abs/2512.20552v1",
      "published": "2025-12-23",
      "categories": [
        "cs.IT",
        "stat.ML"
      ]
    }
  ]
}