{
  "last_updated": "2026-02-17T01:12:28.230220",
  "papers": [
    {
      "title": "Barron-Wiener-Laguerre models",
      "authors": [
        "Rahul Manavalan",
        "Filip Tronarp"
      ],
      "abstract": "We propose a probabilistic extension of Wiener-Laguerre models for causal operator learning. Classical Wiener-Laguerre models parameterize stable linear dynamics using orthonormal Laguerre bases and apply a static nonlinear map to the resulting features. While structurally efficient and interpretable, they provide only deterministic point estimates. We reinterpret the nonlinear component through the lens of Barron function approximation, viewing two-layer networks, random Fourier features, and extreme learning machines as discretizations of integral representations over parameter measures. This perspective naturally admits Bayesian inference on the nonlinear map and yields posterior predictive uncertainty. By combining Laguerre-parameterized causal dynamics with probabilistic Barron-type nonlinear approximators, we obtain a structured yet expressive class of causal operators equipped with uncertainty quantification. The resulting framework bridges classical system identification and modern measure-based function approximation, providing a principled approach to time-series modeling and nonlinear systems identification.",
      "pdf_url": "https://arxiv.org/pdf/2602.13098v1",
      "arxiv_url": "http://arxiv.org/abs/2602.13098v1",
      "published": "2026-02-13",
      "categories": [
        "stat.ME",
        "cs.LG"
      ]
    },
    {
      "title": "Uncertainty in Federated Granger Causality: From Origins to Systemic Consequences",
      "authors": [
        "Ayush Mohanty",
        "Nazal Mohamed",
        "Nagi Gebraeel"
      ],
      "abstract": "Granger Causality (GC) provides a rigorous framework for learning causal structures from time-series data. Recent federated variants of GC have targeted distributed infrastructure applications (e.g., smart grids) with distributed clients that generate high-dimensional data bound by data-sovereignty constraints. However, Federated GC algorithms only yield deterministic point estimates of causality and neglect uncertainty. This paper establishes the first methodology for rigorously quantifying uncertainty and its propagation within federated GC frameworks. We systematically classify sources of uncertainty, explicitly differentiating aleatoric (data noise) from epistemic (model variability) effects. We derive closed-form recursions that model the evolution of uncertainty through client-server interactions and identify four novel cross-covariance components that couple data uncertainties with model parameter uncertainties across the federated architecture. We also define rigorous convergence conditions for these uncertainty recursions and obtain explicit steady-state variances for both server and client model parameters. Our convergence analysis demonstrates that steady-state variances depend exclusively on client data statistics, thus eliminating dependence on initial epistemic priors and enhancing robustness. Empirical evaluations on synthetic benchmarks and real-world industrial datasets demonstrate that explicitly characterizing uncertainty significantly improves the reliability and interpretability of federated causal inference.",
      "pdf_url": "https://arxiv.org/pdf/2602.13004v1",
      "arxiv_url": "http://arxiv.org/abs/2602.13004v1",
      "published": "2026-02-13",
      "categories": [
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "title": "Jointly Optimizing Debiased CTR and Uplift for Coupons Marketing: A Unified Causal Framework",
      "authors": [
        "Siyun Yang",
        "Shixiao Yang",
        "Jian Wang",
        "Di Fan",
        "Kehe Cai",
        "Haoyan Fu",
        "Jiaming Zhang",
        "Wenjin Wu",
        "Peng Jiang"
      ],
      "abstract": "In online advertising, marketing interventions such as coupons introduce significant confounding bias into Click-Through Rate (CTR) prediction. Observed clicks reflect a mixture of users' intrinsic preferences and the uplift induced by these interventions. This causes conventional models to miscalibrate base CTRs, which distorts downstream ranking and billing decisions. Furthermore, marketing interventions often operate as multi-valued treatments with varying magnitudes, introducing additional complexity to CTR prediction.\n  To address these issues, we propose the \\textbf{Uni}fied \\textbf{M}ulti-\\textbf{V}alued \\textbf{T}reatment Network (UniMVT). Specifically, UniMVT disentangles confounding factors from treatment-sensitive representations, enabling a full-space counterfactual inference module to jointly reconstruct the debiased base CTR and intensity-response curves. To handle the complexity of multi-valued treatments, UniMVT employs an auxiliary intensity estimation task to capture treatment propensities and devise a unit uplift objective that normalizes the intervention effect. This ensures comparable estimation across the continuous coupon-value spectrum. UniMVT simultaneously achieves debiased CTR prediction for accurate system calibration and precise uplift estimation for incentive allocation. Extensive experiments on synthetic and industrial datasets demonstrate UniMVT's superiority in both predictive accuracy and calibration. Furthermore, real-world A/B tests confirm that UniMVT significantly improves business metrics through more effective coupon distribution.",
      "pdf_url": "https://arxiv.org/pdf/2602.12972v1",
      "arxiv_url": "http://arxiv.org/abs/2602.12972v1",
      "published": "2026-02-13",
      "categories": [
        "cs.SI",
        "cs.LG"
      ]
    },
    {
      "title": "Differentially Private Two-Stage Empirical Risk Minimization and Applications to Individualized Treatment Rule",
      "authors": [
        "Joowon Lee",
        "Guanhua Chen"
      ],
      "abstract": "Differential Privacy (DP) provides a rigorous framework for deriving privacy-preserving estimators by injecting calibrated noise to mask individual contributions while preserving population-level insights. Its central challenge lies in the privacy-utility trade-off: calibrating noise levels to ensure robust protection without compromising statistical performance. Standard DP methods struggle with a particular class of two-stage problems prevalent in individualized treatment rules (ITRs) and causal inference. In these settings, data-dependent weights are first computed to satisfy distributional constraints, such as covariate balance, before the final parameter of interest is estimated. Current DP approaches often privatize stages independently, which either degrades weight efficacy-leading to biased and inconsistent estimates-or introduces excessive noise to account for worst-case scenarios.\n  To address these challenges, we propose the Differentially Private Two-Stage Empirical Risk Minimization (DP-2ERM), a framework that injects a carefully calibrated noise only into the second stage while maintaining privacy for the entire pipeline and preserving the integrity of the first stage weights. Our theoretical contributions include deterministic bounds on weight perturbations across various widely used weighting methods, and probabilistic bounds on sensitivity for the final estimator. Simulations and real-world applications in ITR demonstrate that DP-2ERM significantly enhances utility over existing methods while providing rigorous privacy guarantees.",
      "pdf_url": "https://arxiv.org/pdf/2602.12604v1",
      "arxiv_url": "http://arxiv.org/abs/2602.12604v1",
      "published": "2026-02-13",
      "categories": [
        "math.ST",
        "stat.ML"
      ]
    },
    {
      "title": "Not a Silver Bullet for Loneliness: How Attachment and Age Shape Intimacy with AI Companions",
      "authors": [
        "Raffaele Ciriello",
        "Uri Gal",
        "Ofir Turel"
      ],
      "abstract": "Artificial intelligence (AI) companions are increasingly promoted as solutions for loneliness, often overlooking how personal dispositions and life-stage conditions shape artificial intimacy. Because intimacy is a primary coping mechanism for loneliness that varies by attachment style and age, we examine how different types of users form intimate relationships with AI companions in response to loneliness. Drawing on a hermeneutic literature review and a survey of 277 active AI companion users, we develop and test a model in which loneliness predicts intimacy, moderated by attachment insecurity and conditioned by age. Although the cross-sectional data limits causal inference, the results reveal a differentiated pattern. Loneliness is paradoxically associated with reduced intimacy for securely attached users but with increased intimacy for avoidant and ambivalent users, while anxious users show mixed effects. Older adults report higher intimacy even at lower loneliness levels. These findings challenge portrayals of AI companions as universal remedies for loneliness. Instead, artificial intimacy emerges as a sociotechnical process shaped by psychological dispositions and demographic conditions. The study clarifies who is most likely to form intimate relationships with AI companions and highlights ethical risks in commercial models that may capitalise on user vulnerability.",
      "pdf_url": "https://arxiv.org/pdf/2602.12476v1",
      "arxiv_url": "http://arxiv.org/abs/2602.12476v1",
      "published": "2026-02-12",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ]
    },
    {
      "title": "Temporal Framework for Causality-Preserving Scheduling of Measurements in Quantum Networks",
      "authors": [
        "Jakob Kaltoft Søndergaard",
        "René Bødker Christensen",
        "Petar Popovski"
      ],
      "abstract": "Distributed quantum protocols rely on classical feedforward information to process measurement outcomes, but heterogeneous hardware and uncertain local timing can make the causal order of measurements ambiguous when inferred solely from arrival times. Even in simple line networks with only Pauli measurements, end nodes cannot distinguish whether a missing outcome is caused by slow measurement or by delayed classical propagation. To resolve this ambiguity, we propose a time-division architecture for quantum networks in which nodes perform measurements in pre-assigned slots, ensuring a unique causal interpretation of outcomes. We formalize this temporal framework and derive the feedforward and adjacency constraints required to preserve measurement causality. For simple network topologies, we present an algorithm that yields optimal measurement schedules. Overall, the proposed time-division model provides a practical coordination layer that bridges the classical network timing with quantum measurement processing, enabling reliable and scalable measurement-based quantum networking.",
      "pdf_url": "https://arxiv.org/pdf/2602.12459v1",
      "arxiv_url": "http://arxiv.org/abs/2602.12459v1",
      "published": "2026-02-12",
      "categories": [
        "quant-ph"
      ]
    },
    {
      "title": "What does RL improve for Visual Reasoning? A Frankenstein-Style Analysis",
      "authors": [
        "Xirui Li",
        "Ming Li",
        "Tianyi Zhou"
      ],
      "abstract": "Reinforcement learning (RL) with verifiable rewards has become a standard post-training stage for boosting visual reasoning in vision-language models, yet it remains unclear what capabilities RL actually improves compared with supervised fine-tuning as cold-start initialization (IN). End-to-end benchmark gains conflate multiple factors, making it difficult to attribute improvements to specific skills. To bridge the gap, we propose a Frankenstein-style analysis framework including: (i) functional localization via causal probing; (ii) update characterization via parameter comparison; and (iii) transferability test via model merging. Instead, RL induces a consistent inference-time shift primarily in mid-to-late layers, and these mid-to-late refinements are both transferable (via merging) and necessary (via freezing) for RL gains. Overall, our results suggest that RL's reliable contribution in visual reasoning is not a uniform enhancement of visual perception, but a systematic refinement of mid-to-late transformer computation that improves vision-to-reasoning alignment and reasoning performance, highlighting the limitations of benchmark-only evaluation for understanding multimodal reasoning improvements.",
      "pdf_url": "https://arxiv.org/pdf/2602.12395v1",
      "arxiv_url": "http://arxiv.org/abs/2602.12395v1",
      "published": "2026-02-12",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "GPT-4o Lacks Core Features of Theory of Mind",
      "authors": [
        "John Muchovej",
        "Amanda Royka",
        "Shane Lee",
        "Julian Jara-Ettinger"
      ],
      "abstract": "Do Large Language Models (LLMs) possess a Theory of Mind (ToM)? Research into this question has focused on evaluating LLMs against benchmarks and found success across a range of social tasks. However, these evaluations do not test for the actual representations posited by ToM: namely, a causal model of mental states and behavior. Here, we use a cognitively-grounded definition of ToM to develop and test a new evaluation framework. Specifically, our approach probes whether LLMs have a coherent, domain-general, and consistent model of how mental states cause behavior -- regardless of whether that model matches a human-like ToM. We find that even though LLMs succeed in approximating human judgments in a simple ToM paradigm, they fail at a logically equivalent task and exhibit low consistency between their action predictions and corresponding mental state inferences. As such, these findings suggest that the social proficiency exhibited by LLMs is not the result of an domain-general or consistent ToM.",
      "pdf_url": "https://arxiv.org/pdf/2602.12150v1",
      "arxiv_url": "http://arxiv.org/abs/2602.12150v1",
      "published": "2026-02-12",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "U-Former ODE: Fast Probabilistic Forecasting of Irregular Time Series",
      "authors": [
        "Ilya Kuleshov",
        "Alexander Marusov",
        "Alexey Zaytsev"
      ],
      "abstract": "Probabilistic forecasting of irregularly sampled time series is crucial in domains such as healthcare and finance, yet it remains a formidable challenge. Existing Neural Controlled Differential Equation (Neural CDE) approaches, while effective at modelling continuous dynamics, suffer from slow, inherently sequential computation, which restricts scalability and limits access to global context. We introduce UFO (U-Former ODE), a novel architecture that seamlessly integrates the parallelizable, multiscale feature extraction of U-Nets, the powerful global modelling of Transformers, and the continuous-time dynamics of Neural CDEs. By constructing a fully causal, parallelizable model, UFO achieves a global receptive field while retaining strong sensitivity to local temporal dynamics. Extensive experiments on five standard benchmarks -- covering both regularly and irregularly sampled time series -- demonstrate that UFO consistently outperforms ten state-of-the-art neural baselines in predictive accuracy. Moreover, UFO delivers up to 15$\\times$ faster inference compared to conventional Neural CDEs, with consistently strong performance on long and highly multivariate sequences.",
      "pdf_url": "https://arxiv.org/pdf/2602.11738v1",
      "arxiv_url": "http://arxiv.org/abs/2602.11738v1",
      "published": "2026-02-12",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "WebTestPilot: Agentic End-to-End Web Testing against Natural Language Specification by Inferring Oracles with Symbolized GUI Elements",
      "authors": [
        "Xiwen Teoh",
        "Yun Lin",
        "Duc-Minh Nguyen",
        "Ruofei Ren",
        "Wenjie Zhang",
        "Jin Song Dong"
      ],
      "abstract": "Visual language model (VLM) agents show great promise in automating end-to-end (E2E) web testing against requirements in natural language. However, the probabilistic nature of language models can have inherent hallucinations. Therefore, given a detected inconsistency between the requirement and the web application, it is hard to distinguish whether it stems from the hallucination or a real application bug. Addressing this issue presents two core technical challenges: the implicit oracle inference challenge, where the agent must act as its own oracle to implicitly decide if the application's behavior is correct without guidance, and the probabilistic inference challenge, where an LLM's inconsistent reasoning undermines its trustworthiness as an oracle. Existing LLM-based approaches fail to capture such implicit oracles, either by treating any page navigation that doesn't crash as a success, or by checking each state in isolation, thus missing bugs dependent on context from prior steps.\n  We introduce WebTestPilot, an LLM-based agent designed to address these challenges. WebTestPilot uses (1) a symbolization layer which detects and symbolizes critical GUI elements on the web application into symbols (i.e., variables) and (2) translates natural language specification into a sequence of steps, each of which is equipped with inferred pre- and post-conditions over the symbols as an oracle. This oracle captures data, temporal, and causal dependencies, enabling the validation of implicit requirements. To advance research in this area, we build a benchmark of bug-injected web apps for evaluating NL-to-E2E testing. The results show that WebTestPilot achieves a task completion rate of 99%, with 96% precision and 96% recall in bug detection, outperforming the best baseline (+70 precision, +27 recall). The agent generalizes across diverse natural language inputs and model scales.",
      "pdf_url": "https://arxiv.org/pdf/2602.11724v1",
      "arxiv_url": "http://arxiv.org/abs/2602.11724v1",
      "published": "2026-02-12",
      "categories": [
        "cs.SE"
      ]
    }
  ]
}