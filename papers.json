{
  "last_updated": "2026-01-29T01:08:08.858232",
  "papers": [
    {
      "title": "BabyReasoningBench: Generating Developmentally-Inspired Reasoning Tasks for Evaluating Baby Language Models",
      "authors": [
        "Kaustubh D. Dhole"
      ],
      "abstract": "Traditional evaluations of reasoning capabilities of language models are dominated by adult-centric benchmarks that presuppose broad world knowledge, complex instruction following, and mature pragmatic competence. These assumptions are mismatched to baby language models trained on developmentally plausible input such as child-directed speech and early-childhood narratives, and they obscure which reasoning abilities (if any) emerge under such constraints. We introduce BabyReasoningBench, a GPT-5.2 generated benchmark of 19 reasoning tasks grounded in classic paradigms from developmental psychology, spanning theory of mind, analogical and relational reasoning, causal inference and intervention selection, and core reasoning primitives that are known to be confounded by memory and pragmatics. We find that two GPT-2 based baby language models (pretrained on 10M and 100M of child-directed speech text) show overall low but uneven performance, with dissociations across task families: scaling improves several causal and physical reasoning tasks, while belief attribution and pragmatics-sensitive tasks remain challenging. BabyReasoningBench provides a developmentally grounded lens for analyzing what kinds of reasoning are supported by child-like training distributions, and for testing mechanistic hypotheses about how such abilities emerge.",
      "pdf_url": "https://arxiv.org/pdf/2601.18933v1",
      "arxiv_url": "http://arxiv.org/abs/2601.18933v1",
      "published": "2026-01-26",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "GraIP: A Benchmarking Framework For Neural Graph Inverse Problems",
      "authors": [
        "Semih Cantürk",
        "Andrei Manolache",
        "Arman Mielke",
        "Chendi Qian",
        "Antoine Siraudin",
        "Christopher Morris",
        "Mathias Niepert",
        "Guy Wolf"
      ],
      "abstract": "A wide range of graph learning tasks, such as structure discovery, temporal graph analysis, and combinatorial optimization, focus on inferring graph structures from data, rather than making predictions on given graphs. However, the respective methods to solve such problems are often developed in an isolated, task-specific manner and thus lack a unifying theoretical foundation. Here, we provide a stepping stone towards the formation of such a foundation and further development by introducing the Neural Graph Inverse Problem (GraIP) conceptual framework, which formalizes and reframes a broad class of graph learning tasks as inverse problems. Unlike discriminative approaches that directly predict target variables from given graph inputs, the GraIP paradigm addresses inverse problems, i.e., it relies on observational data and aims to recover the underlying graph structure by reversing the forward process, such as message passing or network dynamics, that produced the observed outputs. We demonstrate the versatility of GraIP across various graph learning tasks, including rewiring, causal discovery, and neural relational inference. We also propose benchmark datasets and metrics for each GraIP domain considered, and characterize and empirically evaluate existing baseline methods used to solve them. Overall, our unifying perspective bridges seemingly disparate applications and provides a principled approach to structural learning in constrained and combinatorial settings while encouraging cross-pollination of existing methods across graph inverse problems.",
      "pdf_url": "https://arxiv.org/pdf/2601.18917v1",
      "arxiv_url": "http://arxiv.org/abs/2601.18917v1",
      "published": "2026-01-26",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "From Fuzzy to Exact: The Halo Architecture for Infinite-Depth Reasoning via Rational Arithmetic",
      "authors": [
        "Hansheng Ren"
      ],
      "abstract": "Current paradigms in Deep Learning prioritize computational throughput over numerical precision, relying on the assumption that intelligence emerges from statistical correlation at scale. In this paper, we challenge this orthodoxy. We propose the Exactness Hypothesis: that General Intelligence (AGI), specifically high-order causal inference, requires a computational substrate capable of Arbitrary Precision Arithmetic. We argue that the \"hallucinations\" and logical incoherence seen in current Large Language Models (LLMs) are artifacts of IEEE 754 floating-point approximation errors accumulating over deep compositional functions. To mitigate this, we introduce the Halo Architecture, a paradigm shift to Rational Arithmetic ($\\mathbb{Q}$) supported by a novel Exact Inference Unit (EIU). Empirical validation on the Huginn-0125 prototype demonstrates that while 600B-parameter scale BF16 baselines collapse in chaotic systems, Halo maintains zero numerical divergence indefinitely. This work establishes exact arithmetic as a prerequisite for reducing logical uncertainty in System 2 AGI.",
      "pdf_url": "https://arxiv.org/pdf/2601.18702v1",
      "arxiv_url": "http://arxiv.org/abs/2601.18702v1",
      "published": "2026-01-26",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR"
      ]
    },
    {
      "title": "CASSANDRA: Programmatic and Probabilistic Learning and Inference for Stochastic World Modeling",
      "authors": [
        "Panagiotis Lymperopoulos",
        "Abhiramon Rajasekharan",
        "Ian Berlot-Attwell",
        "Stéphane Aroca-Ouellette",
        "Kaheer Suleman"
      ],
      "abstract": "Building world models is essential for planning in real-world domains such as businesses. Since such domains have rich semantics, we can leverage world knowledge to effectively model complex action effects and causal relationships from limited data. In this work, we propose CASSANDRA, a neurosymbolic world modeling approach that leverages an LLM as a knowledge prior to construct lightweight transition models for planning. CASSANDRA integrates two components: (1) LLM-synthesized code to model deterministic features, and (2) LLM-guided structure learning of a probabilistic graphical model to capture causal relationships among stochastic variables. We evaluate CASSANDRA in (i) a small-scale coffee-shop simulator and (ii) a complex theme park business simulator, where we demonstrate significant improvements in transition prediction and planning over baselines.",
      "pdf_url": "https://arxiv.org/pdf/2601.18620v1",
      "arxiv_url": "http://arxiv.org/abs/2601.18620v1",
      "published": "2026-01-26",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "Nearly Optimal Bayesian Inference for Structural Missingness",
      "authors": [
        "Chen Liang",
        "Donghua Yang",
        "Yutong Zhao",
        "Tianle Zhang",
        "Shenghang Zhou",
        "Zhiyu Liang",
        "Hengtong Zhang",
        "Hongzhi Wang",
        "Ziqi Li",
        "Xiyang Zhang",
        "Zheng Liang",
        "Yifei Li"
      ],
      "abstract": "Structural missingness breaks 'just impute and train': values can be undefined by causal or logical constraints, and the mask may depend on observed variables, unobserved variables (MNAR), and other missingness indicators. It simultaneously brings (i) a catch-22 situation with causal loop, prediction needs the missing features, yet inferring them depends on the missingness mechanism, (ii) under MNAR, the unseen are different, the missing part can come from a shifted distribution, and (iii) plug-in imputation, a single fill-in can lock in uncertainty and yield overconfident, biased decisions. In the Bayesian view, prediction via the posterior predictive distribution integrates over the full model posterior uncertainty, rather than relying on a single point estimate. This framework decouples (i) learning an in-model missing-value posterior from (ii) label prediction by optimizing the predictive posterior distribution, enabling posterior integration. This decoupling yields an in-model almost-free-lunch: once the posterior is learned, prediction is plug-and-play while preserving uncertainty propagation. It achieves SOTA on 43 classification and 15 imputation benchmarks, with finite-sample near Bayes-optimality guarantees under our SCM prior.",
      "pdf_url": "https://arxiv.org/pdf/2601.18500v2",
      "arxiv_url": "http://arxiv.org/abs/2601.18500v2",
      "published": "2026-01-26",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "Making medical vision-language models think causally across modalities with retrieval-augmented cross-modal reasoning",
      "authors": [
        "Weiqin Yang",
        "Haowen Xue",
        "Qingyi Peng",
        "Hexuan Hu",
        "Qian Huang",
        "Tingbo Zhang"
      ],
      "abstract": "Medical vision-language models (VLMs) achieve strong performance in diagnostic reporting and image-text alignment, yet their underlying reasoning mechanisms remain fundamentally correlational, exhibiting reliance on superficial statistical associations that fail to capture the causal pathophysiological mechanisms central to clinical decision-making. This limitation makes them fragile, prone to hallucinations, and sensitive to dataset biases. Retrieval-augmented generation (RAG) offers a partial remedy by grounding predictions in external knowledge. However, conventional RAG depends on semantic similarity, introducing new spurious correlations. We propose Multimodal Causal Retrieval-Augmented Generation, a framework that integrates causal inference principles with multimodal retrieval. It retrieves clinically relevant exemplars and causal graphs from external sources, conditioning model reasoning on counterfactual and interventional evidence rather than correlations alone. Applied to radiology report generation, diagnosis prediction, and visual question answering, it improves factual accuracy, robustness to distribution shifts, and interpretability. Our results highlight causal retrieval as a scalable path toward medical VLMs that think beyond pattern matching, enabling trustworthy multimodal reasoning in high-stakes clinical settings.",
      "pdf_url": "https://arxiv.org/pdf/2601.18356v1",
      "arxiv_url": "http://arxiv.org/abs/2601.18356v1",
      "published": "2026-01-26",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "LLM-ForcedAligner: A Non-Autoregressive and Accurate LLM-Based Forced Aligner for Multilingual and Long-Form Speech",
      "authors": [
        "Bingshen Mu",
        "Xian Shi",
        "Xiong Wang",
        "Hexin Liu",
        "Jin Xu",
        "Lei Xie"
      ],
      "abstract": "Forced alignment (FA) predicts start and end timestamps for words or characters in speech, but existing methods are language-specific and prone to cumulative temporal shifts. The multilingual speech understanding and long-sequence processing abilities of speech large language models (SLLMs) make them promising for FA in multilingual, crosslingual, and long-form speech settings. However, directly applying the next-token prediction paradigm of SLLMs to FA results in hallucinations and slow inference. To bridge the gap, we propose LLM-ForcedAligner, reformulating FA as a slot-filling paradigm: timestamps are treated as discrete indices, and special timestamp tokens are inserted as slots into the transcript. Conditioned on the speech embeddings and the transcript with slots, the SLLM directly predicts the time indices at slots. During training, causal attention masking with non-shifted input and label sequences allows each slot to predict its own timestamp index based on itself and preceding context, with loss computed only at slot positions. Dynamic slot insertion enables FA at arbitrary positions. Moreover, non-autoregressive inference is supported, avoiding hallucinations and improving speed. Experiments across multilingual, crosslingual, and long-form speech scenarios show that LLM-ForcedAligner achieves a 69%~78% relative reduction in accumulated averaging shift compared with prior methods. The checkpoint and inference code will be released later.",
      "pdf_url": "https://arxiv.org/pdf/2601.18220v1",
      "arxiv_url": "http://arxiv.org/abs/2601.18220v1",
      "published": "2026-01-26",
      "categories": [
        "cs.SD",
        "eess.AS"
      ]
    },
    {
      "title": "\\textsc{NaVIDA}: Vision-Language Navigation with Inverse Dynamics Augmentation",
      "authors": [
        "Weiye Zhu",
        "Zekai Zhang",
        "Xiangchen Wang",
        "Hewei Pan",
        "Teng Wang",
        "Tiantian Geng",
        "Rongtao Xu",
        "Feng Zheng"
      ],
      "abstract": "Vision-and-Language Navigation (VLN) requires agents to interpret natural language instructions and act coherently in visually rich environments. However, most existing methods rely on reactive state-action mappings without explicitly modeling how actions causally transform subsequent visual observations. Lacking such vision-action causality, agents cannot anticipate the visual changes induced by its own actions, leading to unstable behaviors, weak generalization, and cumulative error along trajectory. To address these issues, we introduce \\textsc{NaVIDA} (\\textbf{Nav}igation with \\textbf{I}nverse \\textbf{D}ynamics \\textbf{A}ugmentation), a unified VLN framework that couples policy learning with action-grounded visual dynamics and adaptive execution. \\textsc{NaVIDA} augments training with chunk-based inverse-dynamics supervision to learn causal relationship between visual changes and corresponding actions. To structure this supervision and extend the effective planning range, \\textsc{NaVIDA} employs hierarchical probabilistic action chunking (HPAC), which organizes trajectories into multi-step chunks and provides discriminative, longer-range visual-change cues. To further curb error accumulation and stabilize behavior at inference, an entropy-guided mechanism adaptively sets the execution horizon of action chunks. Extensive experiments show that \\textsc{NaVIDA} achieves superior navigation performance compared to state-of-the-art methods with fewer parameters (3B vs. 8B). Real-world robot evaluations further validate the practical feasibility and effectiveness of our approach. Code and data will be available upon acceptance.",
      "pdf_url": "https://arxiv.org/pdf/2601.18188v1",
      "arxiv_url": "http://arxiv.org/abs/2601.18188v1",
      "published": "2026-01-26",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "VidLaDA: Bidirectional Diffusion Large Language Models for Efficient Video Understanding",
      "authors": [
        "Zhihao He",
        "Tieyuan Chen",
        "Kangyu Wang",
        "Ziran Qin",
        "Yang Shao",
        "Chaofan Gan",
        "Shijie Li",
        "Zuxuan Wu",
        "Weiyao Lin"
      ],
      "abstract": "Standard Autoregressive Video LLMs inevitably suffer from causal masking biases that hinder global spatiotemporal modeling, leading to suboptimal understanding efficiency. We propose VidLaDA, a Video LLM based on Diffusion Language Model utilizing bidirectional attention to capture bidirectional dependencies. To further tackle the inference bottleneck of diffusion decoding on massive video tokens, we introduce MARS-Cache. This framework accelerates inference by combining asynchronous visual cache refreshing with frame-wise chunk attention, effectively pruning redundancy while preserving global connectivity via anchor tokens. Extensive experiments show VidLaDA outperforms diffusion baselines and rivals state-of-the-art autoregressive models (e.g., Qwen2.5-VL and LLaVA-Video), with MARS-Cache delivering over 12x speedup without compromising reasoning accuracy. Code and checkpoints are open-sourced at https://github.com/ziHoHe/VidLaDA.",
      "pdf_url": "https://arxiv.org/pdf/2601.17868v1",
      "arxiv_url": "http://arxiv.org/abs/2601.17868v1",
      "published": "2026-01-25",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "S$^3$-Attention:Attention-Aligned Endogenous Retrieval for Memory-Bounded Long-Context Inference",
      "authors": [
        "Qingsen Ma",
        "Dianyun Wang",
        "Yaoye Wang",
        "Lechen Ning",
        "Sujie Zhu",
        "Xiaohang Zhang",
        "Jiaming Lyu",
        "Linhao Ren",
        "Zhenbo Xu",
        "Zhaofeng He"
      ],
      "abstract": "Large language models are increasingly applied to multi-document and long-form inputs, yet long-context inference remains memory- and noise-inefficient. Key-value (KV) caching scales linearly with context length, while external retrieval methods often return lexically similar but causally irrelevant passages.\n  We present S3-Attention, a memory-first inference-time framework that treats long-context processing as attention-aligned endogenous retrieval. S3-Attention decodes transient key and query projections into top-k sparse feature identifiers using lightweight sparse autoencoders, and constructs a CPU-based inverted index mapping features to token positions or spans during a single streaming scan. This design allows the KV cache to be discarded entirely and bounds GPU memory usage by the scan chunk size.\n  At generation time, feature co-activation is used to retrieve compact evidence spans, optionally fused with BM25 for exact lexical matching. Under a unified LongBench evaluation protocol with fixed prompting, decoding, and matched token budgets, S3-Hybrid closely matches full-context inference across multiple model families and improves robustness in several information-dense settings. We also report an engineering limitation of the current prototype, which incurs higher wall-clock latency than optimized full-KV baselines, motivating future kernel-level optimization.",
      "pdf_url": "https://arxiv.org/pdf/2601.17702v1",
      "arxiv_url": "http://arxiv.org/abs/2601.17702v1",
      "published": "2026-01-25",
      "categories": [
        "cs.CL",
        "cs.LG"
      ]
    }
  ]
}