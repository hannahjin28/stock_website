{
  "last_updated": "2025-07-25T00:58:21.058287",
  "papers": [
    {
      "title": "Debiased maximum-likelihood estimators for hazard ratios under machine-learning adjustment",
      "authors": [
        "Takashi Hayakawa",
        "Satoshi Asai"
      ],
      "abstract": "Previous studies have shown that hazard ratios between treatment groups\nestimated with the Cox model are uninterpretable because the indefinite\nbaseline hazard of the model fails to identify temporal change in the risk set\ncomposition due to treatment assignment and unobserved factors among multiple,\ncontradictory scenarios. To alleviate this problem, especially in studies based\non observational data with uncontrolled dynamic treatment and real-time\nmeasurement of many covariates, we propose abandoning the baseline hazard and\nusing machine learning to explicitly model the change in the risk set with or\nwithout latent variables. For this framework, we clarify the context in which\nhazard ratios can be causally interpreted, and then develop a method based on\nNeyman orthogonality to compute debiased maximum-likelihood estimators of\nhazard ratios. Computing the constructed estimators is more efficient than\ncomputing those based on weighted regression with marginal structural Cox\nmodels. Numerical simulations confirm that the proposed method identifies the\nground truth with minimal bias. These results lay the foundation for developing\na useful, alternative method for causal inference with uncontrolled,\nobservational data in modern epidemiology.",
      "pdf_url": "http://arxiv.org/pdf/2507.17686v1",
      "arxiv_url": "http://arxiv.org/abs/2507.17686v1",
      "published": "2025-07-23",
      "categories": [
        "stat.ML",
        "cs.LG"
      ]
    },
    {
      "title": "See the Forest and the Trees: A Synergistic Reasoning Framework for Knowledge-Based Visual Question Answering",
      "authors": [
        "Junjie Wang",
        "Yunhan Tang",
        "Yijie Wang",
        "Zhihao Yuan",
        "Huan Wang",
        "Yangfan He",
        "Bin Li"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) have pushed the frontiers of\nKnowledge-Based Visual Question Answering (KBVQA), yet their reasoning is\nfundamentally bottlenecked by a reliance on uni-dimensional evidence. This\n\"seeing only the trees, but not the forest\" approach prevents robust,\nmulti-faceted understanding. Inspired by the principle of seeing both the\nforest and trees, we propose Synergos-VQA, a novel synergistic reasoning\nframework. At its core, Synergos-VQA concurrently generates and fuses three\ncomplementary evidence streams at inference time: (1) Holistic Evidence to\nperceive the entire scene (the \"forest\"), (2) Structural Evidence from a\nprototype-driven module to identify key objects (the \"trees\"), and (3) Causal\nEvidence from a counterfactual probe to ensure the reasoning is robustly\ngrounded. By synergistically fusing this multi-faceted evidence, our framework\nachieves a more comprehensive and reliable reasoning process. Extensive\nexperiments show that Synergos-VQA decisively establishes a new\nstate-of-the-art on three challenging benchmarks, including OK-VQA and A-OKVQA.\nFurthermore, our approach demonstrates strong plug-and-play capabilities,\nsignificantly boosting various open-source MLLMs and proving that superior\nmethodological design can outperform sheer model scale.",
      "pdf_url": "http://arxiv.org/pdf/2507.17659v1",
      "arxiv_url": "http://arxiv.org/abs/2507.17659v1",
      "published": "2025-07-23",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "Doubly robust outlier resistant inference on causal treatment effect",
      "authors": [
        "Joonsung Kang"
      ],
      "abstract": "Outliers can severely distort causal effect estimation in observational\nstudies, yet this issue has received limited attention in the literature. Their\ninfluence is especially pronounced in small sample sizes, where detecting and\nremoving outliers becomes increasingly difficult. Therefore, it is essential to\nestimate treatment effects robustly without excluding these influential data\npoints. To address this, we propose a doubly robust point estimator for the\naverage treatment effect under a contaminated model that includes outliers.\nRobustness in outcome regression is achieved through a robust estimating\nequation, while covariate balancing propensity scores (CBPS) ensure resilience\nin propensity score modeling.\n  To prevent model overfitting due to the inclusion of numerous parameters, we\nincorporate variable selection. All these components are unified under a\npenalized empirical likelihood framework. For confidence interval estimation,\nmost existing approaches rely on asymptotic properties, which may be unreliable\nin finite samples. We derive an optimal finite-sample confidence interval for\nthe average treatment effect using our proposed estimating equation, ensuring\nthat the interval bounds remain unaffected by outliers. Through simulations and\na real-world application involving hypertension data with outliers, we\ndemonstrate that our method consistently outperforms existing approaches in\nboth accuracy and robustness.",
      "pdf_url": "http://arxiv.org/pdf/2507.17439v1",
      "arxiv_url": "http://arxiv.org/abs/2507.17439v1",
      "published": "2025-07-23",
      "categories": [
        "stat.ME",
        "cs.LG"
      ]
    },
    {
      "title": "CAPRI-CT: Causal Analysis and Predictive Reasoning for Image Quality Optimization in Computed Tomography",
      "authors": [
        "Sneha George Gnanakalavathy",
        "Hairil Abdul Razak",
        "Robert Meertens",
        "Jonathan E. Fieldsend",
        "Xujiong Ye",
        "Mohammed M. Abdelsamea"
      ],
      "abstract": "In computed tomography (CT), achieving high image quality while minimizing\nradiation exposure remains a key clinical challenge. This paper presents\nCAPRI-CT, a novel causal-aware deep learning framework for Causal Analysis and\nPredictive Reasoning for Image Quality Optimization in CT imaging. CAPRI-CT\nintegrates image data with acquisition metadata (such as tube voltage, tube\ncurrent, and contrast agent types) to model the underlying causal relationships\nthat influence image quality. An ensemble of Variational Autoencoders (VAEs) is\nemployed to extract meaningful features and generate causal representations\nfrom observational data, including CT images and associated imaging parameters.\nThese input features are fused to predict the Signal-to-Noise Ratio (SNR) and\nsupport counterfactual inference, enabling what-if simulations, such as changes\nin contrast agents (types and concentrations) or scan parameters. CAPRI-CT is\ntrained and validated using an ensemble learning approach, achieving strong\npredictive performance. By facilitating both prediction and interpretability,\nCAPRI-CT provides actionable insights that could help radiologists and\ntechnicians design more efficient CT protocols without repeated physical scans.\nThe source code and dataset are publicly available at\nhttps://github.com/SnehaGeorge22/capri-ct.",
      "pdf_url": "http://arxiv.org/pdf/2507.17420v1",
      "arxiv_url": "http://arxiv.org/abs/2507.17420v1",
      "published": "2025-07-23",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "Ballot Design and Electoral Outcomes: The Role of Candidate Order and Party Affiliation",
      "authors": [
        "Alessandro Arlotto",
        "Alexandre Belloni",
        "Fei Fang",
        "Saša Pekeč"
      ],
      "abstract": "We use causal inference to study how designing ballots with and without party\ndesignations impacts electoral outcomes when partisan voters rely on\nparty-order cues to infer candidate affiliation in races without designations.\nIf the party orders of candidates in races with and without party designations\ndiffer, these voters might cast their votes incorrectly. We identify a\nquasi-randomized natural experiment with contest-level treatment assignment\npertaining to North Carolina judicial elections and use double machine learning\nto accurately capture the magnitude of such incorrectly cast votes. Using\nprecinct-level election and demographic data, we estimate that 11.8% (95%\nconfidence interval: [4.0%, 19.6%]) of democratic partisan voters and 15.4%\n(95% confidence interval: [7.8%, 23.1%]) of republican partisan voters cast\ntheir votes incorrectly due to the difference in party orders. Our results\nindicate that ballots mixing contests with and without party designations\nmislead many voters, leading to outcomes that do not reflect true voter\npreferences. To accurately capture voter intent, such ballot designs should be\navoided.",
      "pdf_url": "http://arxiv.org/pdf/2507.16722v1",
      "arxiv_url": "http://arxiv.org/abs/2507.16722v1",
      "published": "2025-07-22",
      "categories": [
        "stat.AP"
      ]
    },
    {
      "title": "On Causal Inference for the Survivor Function",
      "authors": [
        "Benjamin R. Baer",
        "Ashkan Ertefaie",
        "Robert L. Strawderman"
      ],
      "abstract": "In this expository paper, we consider the problem of causal inference and\nefficient estimation for the counterfactual survivor function. This problem has\npreviously been considered in the literature in several papers, each relying on\nthe imposition of conditions meant to identify the desired estimand from the\nobserved data. These conditions, generally referred to as either implying or\nsatisfying coarsening at random, are inconsistently imposed across this\nliterature and, in all cases, fail to imply coarsening at random. We establish\nthe first general characterization of coarsening at random, and also sequential\ncoarsening at random, for this estimation problem. Other contributions include\nthe first general characterization of the set of all influence functions for\nthe counterfactual survival probability under sequential coarsening at random,\nand the corresponding nonparametric efficient influence function. These\ncharacterizations are general in that neither impose continuity assumptions on\neither the underlying failure or censoring time distributions. We further show\nhow the latter compares to alternative forms recently derived in the\nliterature, including establishing the pointwise equivalence of the influence\nfunctions for our nonparametric efficient estimator and that recently given in\nWestling et al (2024, Journal of the American Statistical Association).",
      "pdf_url": "http://arxiv.org/pdf/2507.16691v1",
      "arxiv_url": "http://arxiv.org/abs/2507.16691v1",
      "published": "2025-07-22",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Estimating Treatment Effects with Independent Component Analysis",
      "authors": [
        "Patrik Reizinger",
        "Lester Mackey",
        "Wieland Brendel",
        "Rahul Krishnan"
      ],
      "abstract": "The field of causal inference has developed a variety of methods to\naccurately estimate treatment effects in the presence of nuisance. Meanwhile,\nthe field of identifiability theory has developed methods like Independent\nComponent Analysis (ICA) to identify latent sources and mixing weights from\ndata. While these two research communities have developed largely\nindependently, they aim to achieve similar goals: the accurate and\nsample-efficient estimation of model parameters. In the partially linear\nregression (PLR) setting, Mackey et al. (2018) recently found that estimation\nconsistency can be improved with non-Gaussian treatment noise. Non-Gaussianity\nis also a crucial assumption for identifying latent factors in ICA. We provide\nthe first theoretical and empirical insights into this connection, showing that\nICA can be used for causal effect estimation in the PLR model. Surprisingly, we\nfind that linear ICA can accurately estimate multiple treatment effects even in\nthe presence of Gaussian confounders or nonlinear nuisance.",
      "pdf_url": "http://arxiv.org/pdf/2507.16467v1",
      "arxiv_url": "http://arxiv.org/abs/2507.16467v1",
      "published": "2025-07-22",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Do Large Language Models Have a Planning Theory of Mind? Evidence from MindGames: a Multi-Step Persuasion Task",
      "authors": [
        "Jared Moore",
        "Ned Cooper",
        "Rasmus Overmark",
        "Beba Cibralic",
        "Nick Haber",
        "Cameron R. Jones"
      ],
      "abstract": "Recent evidence suggests Large Language Models (LLMs) display Theory of Mind\n(ToM) abilities. Most ToM experiments place participants in a spectatorial\nrole, wherein they predict and interpret other agents' behavior. However, human\nToM also contributes to dynamically planning action and strategically\nintervening on others' mental states. We present MindGames: a novel `planning\ntheory of mind' (PToM) task which requires agents to infer an interlocutor's\nbeliefs and desires to persuade them to alter their behavior. Unlike previous\nevaluations, we explicitly evaluate use cases of ToM. We find that humans\nsignificantly outperform o1-preview (an LLM) at our PToM task (11% higher;\n$p=0.006$). We hypothesize this is because humans have an implicit causal model\nof other agents (e.g., they know, as our task requires, to ask about people's\npreferences). In contrast, o1-preview outperforms humans in a baseline\ncondition which requires a similar amount of planning but minimal mental state\ninferences (e.g., o1-preview is better than humans at planning when already\ngiven someone's preferences). These results suggest a significant gap between\nhuman-like social reasoning and LLM abilities.",
      "pdf_url": "http://arxiv.org/pdf/2507.16196v1",
      "arxiv_url": "http://arxiv.org/abs/2507.16196v1",
      "published": "2025-07-22",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "title": "CoLD: Counterfactually-Guided Length Debiasing for Process Reward Models",
      "authors": [
        "Congmin Zheng",
        "Jiachen Zhu",
        "Jianghao Lin",
        "Xinyi Dai",
        "Yong Yu",
        "Weinan Zhang",
        "Mengyue Yang"
      ],
      "abstract": "Process Reward Models (PRMs) play a central role in evaluating and guiding\nmulti-step reasoning in large language models (LLMs), especially for\nmathematical problem solving. However, we identify a pervasive length bias in\nexisting PRMs: they tend to assign higher scores to longer reasoning steps,\neven when the semantic content and logical validity are unchanged. This bias\nundermines the reliability of reward predictions and leads to overly verbose\noutputs during inference. To address this issue, we propose\nCoLD(Counterfactually-Guided Length Debiasing), a unified framework that\nmitigates length bias through three components: an explicit length-penalty\nadjustment, a learned bias estimator trained to capture spurious length-related\nsignals, and a joint training strategy that enforces length-invariance in\nreward predictions. Our approach is grounded in counterfactual reasoning and\ninformed by causal graph analysis. Extensive experiments on MATH500 and\nGSM-Plus show that CoLD consistently reduces reward-length correlation,\nimproves accuracy in step selection, and encourages more concise, logically\nvalid reasoning. These results demonstrate the effectiveness and practicality\nof CoLD in improving the fidelity and robustness of PRMs.",
      "pdf_url": "http://arxiv.org/pdf/2507.15698v1",
      "arxiv_url": "http://arxiv.org/abs/2507.15698v1",
      "published": "2025-07-21",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Inference on Nonlinear Counterfactual Functionals under a Multiplicative IV Model",
      "authors": [
        "Yonghoon Lee",
        "Mengxin Yu",
        "Jiewen Liu",
        "Chan Park",
        "Yunshu Zhang",
        "James M. Robins",
        "Eric J. Tchetgen Tchetgen"
      ],
      "abstract": "Instrumental variable (IV) methods play a central role in causal inference,\nparticularly in settings where treatment assignment is confounded by unobserved\nvariables. IV methods have been extensively developed in recent years and\napplied across diverse domains, from economics to epidemiology. In this work,\nwe study the recently introduced multiplicative IV (MIV) model and demonstrate\nits utility for causal inference beyond the average treatment effect. In\nparticular, we show that it enables identification and inference for a broad\nclass of counterfactual functionals characterized by moment equations. This\nincludes, for example, inference on quantile treatment effects. We develop\nmethods for efficient and multiply robust estimation of such functionals, and\nprovide inference procedures with asymptotic validity. Experimental results\ndemonstrate that the proposed procedure performs well even with moderate sample\nsizes.",
      "pdf_url": "http://arxiv.org/pdf/2507.15612v1",
      "arxiv_url": "http://arxiv.org/abs/2507.15612v1",
      "published": "2025-07-21",
      "categories": [
        "stat.ME"
      ]
    }
  ]
}