{
  "last_updated": "2025-09-10T00:48:42.129768",
  "papers": [
    {
      "title": "MachineLearningLM: Continued Pretraining Language Models on Millions of Synthetic Tabular Prediction Tasks Scales In-Context ML",
      "authors": [
        "Haoyu Dong",
        "Pengkun Zhang",
        "Mingzhe Lu",
        "Yanzhen Shen",
        "Guolin Ke"
      ],
      "abstract": "Large language models (LLMs) possess broad world knowledge and strong\ngeneral-purpose reasoning ability, yet they struggle to learn from many\nin-context examples on standard machine learning (ML) tasks, that is, to\nleverage many-shot demonstrations purely via in-context learning (ICL) without\ngradient descent. We introduce MachineLearningLM, a portable\ncontinued-pretraining framework that equips a general-purpose LLM with robust\nin-context ML capability while preserving its general knowledge and reasoning\nfor broader chat workflows.\n  Our pretraining procedure synthesizes ML tasks from millions of structural\ncausal models (SCMs), spanning shot counts up to 1,024. We begin with a\nrandom-forest teacher, distilling tree-based decision strategies into the LLM\nto strengthen robustness in numerical modeling. All tasks are serialized with a\ntoken-efficient prompt, enabling 3x to 6x more examples per context window and\ndelivering up to 50x amortized throughput via batch inference.\n  Despite a modest setup (Qwen-2.5-7B-Instruct with LoRA rank 8),\nMachineLearningLM outperforms strong LLM baselines (e.g., GPT-5-mini) by an\naverage of about 15% on out-of-distribution tabular classification across\nfinance, physics, biology, and healthcare domains. It exhibits a striking\nmany-shot scaling law: accuracy increases monotonically as in-context\ndemonstrations grow from 8 to 1,024. Without any task-specific training, it\nattains random-forest-level accuracy across hundreds of shots. General chat\ncapabilities, including knowledge and reasoning, are preserved: it achieves\n75.4% on MMLU.",
      "pdf_url": "http://arxiv.org/pdf/2509.06806v1",
      "arxiv_url": "http://arxiv.org/abs/2509.06806v1",
      "published": "2025-09-08",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "CausNVS: Autoregressive Multi-view Diffusion for Flexible 3D Novel View Synthesis",
      "authors": [
        "Xin Kong",
        "Daniel Watson",
        "Yannick Str√ºmpler",
        "Michael Niemeyer",
        "Federico Tombari"
      ],
      "abstract": "Multi-view diffusion models have shown promise in 3D novel view synthesis,\nbut most existing methods adopt a non-autoregressive formulation. This limits\ntheir applicability in world modeling, as they only support a fixed number of\nviews and suffer from slow inference due to denoising all frames\nsimultaneously. To address these limitations, we propose CausNVS, a multi-view\ndiffusion model in an autoregressive setting, which supports arbitrary\ninput-output view configurations and generates views sequentially. We train\nCausNVS with causal masking and per-frame noise, using pairwise-relative camera\npose encodings (CaPE) for precise camera control. At inference time, we combine\na spatially-aware sliding-window with key-value caching and noise conditioning\naugmentation to mitigate drift. Our experiments demonstrate that CausNVS\nsupports a broad range of camera trajectories, enables flexible autoregressive\nnovel view synthesis, and achieves consistently strong visual quality across\ndiverse settings. Project page: https://kxhit.github.io/CausNVS.html.",
      "pdf_url": "http://arxiv.org/pdf/2509.06579v1",
      "arxiv_url": "http://arxiv.org/abs/2509.06579v1",
      "published": "2025-09-08",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "Predicting Market Troughs: A Machine Learning Approach with Causal Interpretation",
      "authors": [
        "Peilin Rao",
        "Randall R. Rojas"
      ],
      "abstract": "This paper provides robust, new evidence on the causal drivers of market\ntroughs. We demonstrate that conclusions about these triggers are critically\nsensitive to model specification, moving beyond restrictive linear models with\na flexible DML average partial effect causal machine learning framework. Our\nrobust estimates identify the volatility of options-implied risk appetite and\nmarket liquidity as key causal drivers, relationships misrepresented or\nobscured by simpler models. These findings provide high-frequency empirical\nsupport for intermediary asset pricing theories. This causal analysis is\nenabled by a high-performance nowcasting model that accurately identifies\ncapitulation events in real-time.",
      "pdf_url": "http://arxiv.org/pdf/2509.05922v1",
      "arxiv_url": "http://arxiv.org/abs/2509.05922v1",
      "published": "2025-09-07",
      "categories": [
        "q-fin.ST",
        "econ.EM",
        "stat.ML",
        "91G80, 62P05",
        "J.4"
      ]
    },
    {
      "title": "Causal Clustering for Conditional Average Treatment Effects Estimation and Subgroup Discovery",
      "authors": [
        "Zilong Wang",
        "Turgay Ayer",
        "Shihao Yang"
      ],
      "abstract": "Estimating heterogeneous treatment effects is critical in domains such as\npersonalized medicine, resource allocation, and policy evaluation. A central\nchallenge lies in identifying subpopulations that respond differently to\ninterventions, thereby enabling more targeted and effective decision-making.\nWhile clustering methods are well-studied in unsupervised learning, their\nintegration with causal inference remains limited. We propose a novel framework\nthat clusters individuals based on estimated treatment effects using a learned\nkernel derived from causal forests, revealing latent subgroup structures. Our\napproach consists of two main steps. First, we estimate debiased Conditional\nAverage Treatment Effects (CATEs) using orthogonalized learners via the\nRobinson decomposition, yielding a kernel matrix that encodes sample-level\nsimilarities in treatment responsiveness. Second, we apply kernelized\nclustering to this matrix to uncover distinct, treatment-sensitive\nsubpopulations and compute cluster-level average CATEs. We present this\nkernelized clustering step as a form of regularization within the\nresidual-on-residual regression framework. Through extensive experiments on\nsemi-synthetic and real-world datasets, supported by ablation studies and\nexploratory analyses, we demonstrate the effectiveness of our method in\ncapturing meaningful treatment effect heterogeneity.",
      "pdf_url": "http://arxiv.org/pdf/2509.05775v1",
      "arxiv_url": "http://arxiv.org/abs/2509.05775v1",
      "published": "2025-09-06",
      "categories": [
        "stat.ML",
        "cs.LG"
      ]
    },
    {
      "title": "Bayesian Inference for Confounding Variables and Limited Information",
      "authors": [
        "Ellis Scharfenaker",
        "Duncan K. Foley"
      ],
      "abstract": "A central challenge in statistical inference is the presence of confounding\nvariables that may distort observed associations between treatment and outcome.\nConventional \"causal\" methods, grounded in assumptions such as ignorability,\nexclude the possibility of unobserved confounders, leading to posterior\ninferences that overstate certainty. We develop a Bayesian framework that\nrelaxes these assumptions by introducing entropy-favoring priors over\nhypothesis spaces that explicitly allow for latent confounding variables and\npartial information. Using the case of Simpson's paradox, we demonstrate how\nthis approach produces logically consistent posterior distributions that widen\ncredibly intervals in the presence of potential confounding. Our method\nprovides a generalizable, information-theoretic foundation for more robust\npredictive inference in observational sciences.",
      "pdf_url": "http://arxiv.org/pdf/2509.05520v1",
      "arxiv_url": "http://arxiv.org/abs/2509.05520v1",
      "published": "2025-09-05",
      "categories": [
        "stat.ME",
        "econ.EM"
      ]
    },
    {
      "title": "Semi-supervised inference for treatment heterogeneity",
      "authors": [
        "Yilizhati Anniwaer",
        "Yuqian Zhang"
      ],
      "abstract": "In causal inference, measuring treatment heterogeneity is crucial as it\nprovides scientific insights into how treatments influence outcomes and guides\npersonalized decision-making. In this work, we study semi-supervised settings\nwhere a labeled dataset is accompanied by a large unlabeled dataset, and\ndevelop semi-supervised estimators for two measures of treatment heterogeneity:\nthe total treatment heterogeneity (TTH) and the explained treatment\nheterogeneity (ETH) of a simplified working model. We propose semi-supervised\nestimators for both quantities and demonstrate their improved robustness and\nefficiency compared with supervised methods. For ETH estimation, we show that\ndirect semi-supervised approaches may result in efficiency loss relative to\nsupervised counterparts. To address this, we introduce a re-weighting strategy\nthat assigns data-dependent weights to labeled and unlabeled samples to\noptimize efficiency. The proposed approach guarantees an asymptotic variance no\nlarger than that of the supervised method, ensuring its safe use. We evaluate\nthe performance of the proposed estimators through simulation studies and a\nreal-data application based on an AIDS clinical trial.",
      "pdf_url": "http://arxiv.org/pdf/2509.05048v1",
      "arxiv_url": "http://arxiv.org/abs/2509.05048v1",
      "published": "2025-09-05",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Detecting extreme event-driven causality",
      "authors": [
        "Siyang Yu",
        "Yu Huang",
        "Zuntao Fu"
      ],
      "abstract": "The occurrence of some extreme events (such as marine heatwaves or\nexceptional circulations) can cause other extreme events (such as heatwave,\ndrought and flood). These concurrent extreme events have a great impact on\nenvironment and human health. However, how to detect and quantify the causes\nand impacts of these extreme events by a data-driven way is still unsolved. In\nthis study, the dynamic system method is extended to develop a method for\ndetecting the causality between extreme events. Taking the coupled\nLorenz-Lorenz systems with extreme event-driven coupling as an example, it is\ndemonstrated that this proposed detecting method is able to capture the extreme\nevent-driven causality, with even better causality detecting performance\nbetween concurrent extreme events. Comparison among three kinds of measured\nseries, full measurements outperform partial ones in event-to-event causality\ndetecting. The successful applicability of our proposed approach in Walker\ncirculation phenomenon indicates that our method contributes a novel way to the\nstudy of causal inference in complex systems. This method offers valuable\ninsights into multi-scale, nonlinear dynamics, particularly in uncovering\nassociations among extreme events.",
      "pdf_url": "http://arxiv.org/pdf/2509.05043v1",
      "arxiv_url": "http://arxiv.org/abs/2509.05043v1",
      "published": "2025-09-05",
      "categories": [
        "physics.ao-ph",
        "math-ph",
        "math.DS",
        "math.MP"
      ]
    },
    {
      "title": "DarkStream: real-time speech anonymization with low latency",
      "authors": [
        "Waris Quamer",
        "Ricardo Gutierrez-Osuna"
      ],
      "abstract": "We propose DarkStream, a streaming speech synthesis model for real-time\nspeaker anonymization. To improve content encoding under strict latency\nconstraints, DarkStream combines a causal waveform encoder, a short lookahead\nbuffer, and transformer-based contextual layers. To further reduce inference\ntime, the model generates waveforms directly via a neural vocoder, thus\nremoving intermediate mel-spectrogram conversions. Finally, DarkStream\nanonymizes speaker identity by injecting a GAN-generated pseudo-speaker\nembedding into linguistic features from the content encoder. Evaluations show\nour model achieves strong anonymization, yielding close to 50% speaker\nverification EER (near-chance performance) on the lazy-informed attack\nscenario, while maintaining acceptable linguistic intelligibility (WER within\n9%). By balancing low-latency, robust privacy, and minimal intelligibility\ndegradation, DarkStream provides a practical solution for privacy-preserving\nreal-time speech communication.",
      "pdf_url": "http://arxiv.org/pdf/2509.04667v1",
      "arxiv_url": "http://arxiv.org/abs/2509.04667v1",
      "published": "2025-09-04",
      "categories": [
        "eess.AS",
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "Precision Mental Health: Predicting Heterogeneous Treatment Effects for Depression through Data Integration",
      "authors": [
        "Carly L. Brantner",
        "Trang Quynh Nguyen",
        "Harsh Parikh",
        "Congwen Zhao",
        "Hwanhee Hong",
        "Elizabeth A. Stuart"
      ],
      "abstract": "When treating depression, clinicians are interested in determining the\noptimal treatment for a given patient, which is challenging given the amount of\ntreatments available. To advance individualized treatment allocation,\nintegrating data across multiple randomized controlled trials (RCTs) can\nenhance our understanding of treatment effect heterogeneity by increasing\navailable information. However, extending these inferences to individuals\noutside of the original RCTs remains crucial for clinical decision-making. We\nintroduce a two-stage meta-analytic method that predicts conditional average\ntreatment effects (CATEs) in target patient populations by leveraging the\ndistribution of CATEs across RCTs. Our approach generates 95\\% prediction\nintervals for CATEs in target settings using first-stage models that can\nincorporate parametric regression or non-parametric methods such as causal\nforests or Bayesian additive regression trees (BART). We validate our method\nthrough simulation studies and operationalize it to integrate multiple RCTs\ncomparing depression treatments, duloxetine and vortioxetine, to generate\nprediction intervals for target patient profiles. Our analysis reveals no\nstrong evidence of effect heterogeneity across trials, with the exception of\npotential age-related variability. Importantly, we show that CATE prediction\nintervals capture broader uncertainty than study-specific confidence intervals\nwhen warranted, reflecting both within-study and between-study variability.",
      "pdf_url": "http://arxiv.org/pdf/2509.04604v1",
      "arxiv_url": "http://arxiv.org/abs/2509.04604v1",
      "published": "2025-09-04",
      "categories": [
        "stat.AP",
        "stat.ME"
      ]
    },
    {
      "title": "Interpretable Clustering with Adaptive Heterogeneous Causal Structure Learning in Mixed Observational Data",
      "authors": [
        "Wenrui Li",
        "Qinghao Zhang",
        "Xiaowo Wang"
      ],
      "abstract": "Understanding causal heterogeneity is essential for scientific discovery in\ndomains such as biology and medicine. However, existing methods lack causal\nawareness, with insufficient modeling of heterogeneity, confounding, and\nobservational constraints, leading to poor interpretability and difficulty\ndistinguishing true causal heterogeneity from spurious associations. We propose\nan unsupervised framework, HCL (Interpretable Causal Mechanism-Aware Clustering\nwith Adaptive Heterogeneous Causal Structure Learning), that jointly infers\nlatent clusters and their associated causal structures from mixed-type\nobservational data without requiring temporal ordering, environment labels,\ninterventions or other prior knowledge. HCL relaxes the homogeneity and\nsufficiency assumptions by introducing an equivalent representation that\nencodes both structural heterogeneity and confounding. It further develops a\nbi-directional iterative strategy to alternately refine causal clustering and\nstructure learning, along with a self-supervised regularization that balance\ncross-cluster universality and specificity. Together, these components enable\nconvergence toward interpretable, heterogeneous causal patterns. Theoretically,\nwe show identifiability of heterogeneous causal structures under mild\nconditions. Empirically, HCL achieves superior performance in both clustering\nand structure learning tasks, and recovers biologically meaningful mechanisms\nin real-world single-cell perturbation data, demonstrating its utility for\ndiscovering interpretable, mechanism-level causal heterogeneity.",
      "pdf_url": "http://arxiv.org/pdf/2509.04415v1",
      "arxiv_url": "http://arxiv.org/abs/2509.04415v1",
      "published": "2025-09-04",
      "categories": [
        "cs.LG"
      ]
    }
  ]
}