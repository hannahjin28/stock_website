{
  "last_updated": "2025-05-09T00:53:07.821833",
  "papers": [
    {
      "title": "R^3-VQA: \"Read the Room\" by Video Social Reasoning",
      "authors": [
        "Lixing Niu",
        "Jiapeng Li",
        "Xingping Yu",
        "Shu Wang",
        "Ruining Feng",
        "Bo Wu",
        "Ping Wei",
        "Yisen Wang",
        "Lifeng Fan"
      ],
      "abstract": "\"Read the room\" is a significant social reasoning capability in human daily\nlife. Humans can infer others' mental states from subtle social cues. Previous\nsocial reasoning tasks and datasets lack complexity (e.g., simple scenes, basic\ninteractions, incomplete mental state variables, single-step reasoning, etc.)\nand fall far short of the challenges present in real-life social interactions.\nIn this paper, we contribute a valuable, high-quality, and comprehensive video\ndataset named R^3-VQA with precise and fine-grained annotations of social\nevents and mental states (i.e., belief, intent, desire, and emotion) as well as\ncorresponding social causal chains in complex social scenarios. Moreover, we\ninclude human-annotated and model-generated QAs. Our task R^3-VQA includes\nthree aspects: Social Event Understanding, Mental State Estimation, and Social\nCausal Reasoning. As a benchmark, we comprehensively evaluate the social\nreasoning capabilities and consistencies of current state-of-the-art large\nvision-language models (LVLMs). Comprehensive experiments show that (i) LVLMs\nare still far from human-level consistent social reasoning in complex social\nscenarios; (ii) Theory of Mind (ToM) prompting can help LVLMs perform better on\nsocial reasoning tasks. We provide some of our dataset and codes in\nsupplementary material and will release our full dataset and codes upon\nacceptance.",
      "pdf_url": "http://arxiv.org/pdf/2505.04147v1",
      "arxiv_url": "http://arxiv.org/abs/2505.04147v1",
      "published": "2025-05-07",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Regularized Fingerprinting with Linearly Optimal Weight Matrix in Detection and Attribution of Climate Change",
      "authors": [
        "Haoran Li",
        "Yan Li"
      ],
      "abstract": "Climate change detection and attribution plays a central role in establishing\nthe causal influence of human activities on global warming. The most widely\nused framework, optimal fingerprinting, is a linear regression model with\nerrors-in-variables (EIV), in which each covariate is subject to measurement\nerror whose covariance matrix is the same as that of the regression error up to\na known scale. The reliability of such detection and attribution analyses\ncritically depends on accurate inference of the regression coefficients. The\noptimal weight matrix in estimating the regression coefficient is the precision\nmatrix of the regression error, which is typically unknown and has to be\nestimated from climate model simulations with appropriate regularization.\nHowever, the estimators from the prevailing method, regularized optimal\nfingerprinting, are not optimal as believed, owing to the unreliable estimation\nof the optimal weight matrix, and their uncertainties are underestimated,\nleading to too narrow confidence intervals to match the nominal confidence\nlevels. In this paper, we propose consistent estimates of the variances of\nregression coefficients for weight matrices within the class of linear\nshrinkage estimators. Building on this result, we derive a linearly optimal\nweight matrix that directly minimizes the asymptotic variances of the estimated\nscaling factors within the fingerprinting framework. Numerical studies confirm\nthat the proposed method yields confidence intervals with empirical coverage\nrates close to the nominal level, while also achieving shorter average interval\nlengths. In applications to the detection and attribution analyses of annual\nmean near-surface air temperature at the global, continental, and\nsubcontinental scales during 1951--2020, the proposed method produced shorter\nconfidence intervals than the existing approaches in most of the analyses.",
      "pdf_url": "http://arxiv.org/pdf/2505.04070v1",
      "arxiv_url": "http://arxiv.org/abs/2505.04070v1",
      "published": "2025-05-07",
      "categories": [
        "stat.ME",
        "physics.ao-ph",
        "physics.data-an"
      ]
    },
    {
      "title": "Causal Inference in Counterbalanced Within-Subjects Designs",
      "authors": [
        "Justin Ho",
        "Jonathan Min"
      ],
      "abstract": "Experimental designs are fundamental for estimating causal effects. In some\nfields, within-subjects designs, which expose participants to both control and\ntreatment at different time periods, are used to address practical and\nlogistical concerns. Counterbalancing, a common technique in within-subjects\ndesigns, aims to remove carryover effects by randomizing treatment sequences.\nDespite its appeal, counterbalancing relies on the assumption that carryover\neffects are symmetric and cancel out, which is often unverifiable a priori. In\nthis paper, we formalize the challenges of counterbalanced within-subjects\ndesigns using the potential outcomes framework. We introduce sequential\nexchangeability as an additional identification assumption necessary for valid\ncausal inference in these designs. To address identification concerns, we\npropose diagnostic checks, the use of washout periods, and covariate\nadjustments, and alternative experimental designs to counterbalanced\nwithin-subjects design. Our findings demonstrate the limitations of\ncounterbalancing and provide guidance on when and how within-subjects designs\ncan be appropriately used for causal inference.",
      "pdf_url": "http://arxiv.org/pdf/2505.03937v1",
      "arxiv_url": "http://arxiv.org/abs/2505.03937v1",
      "published": "2025-05-06",
      "categories": [
        "stat.ME",
        "econ.EM"
      ]
    },
    {
      "title": "Counterfactual Inference for Eliminating Sentiment Bias in Recommender Systems",
      "authors": [
        "Le Pan",
        "Yuanjiang Cao",
        "Chengkai Huang",
        "Wenjie Zhang",
        "Lina Yao"
      ],
      "abstract": "Recommender Systems (RSs) aim to provide personalized recommendations for\nusers. A newly discovered bias, known as sentiment bias, uncovers a common\nphenomenon within Review-based RSs (RRSs): the recommendation accuracy of users\nor items with negative reviews deteriorates compared with users or items with\npositive reviews. Critical users and niche items are disadvantaged by such\nunfair recommendations. We study this problem from the perspective of\ncounterfactual inference with two stages. At the model training stage, we build\na causal graph and model how sentiment influences the final rating score.\nDuring the inference stage, we decouple the direct and indirect effects to\nmitigate the impact of sentiment bias and remove the indirect effect using\ncounterfactual inference. We have conducted extensive experiments, and the\nresults validate that our model can achieve comparable performance on rating\nprediction for better recommendations and effective mitigation of sentiment\nbias. To the best of our knowledge, this is the first work to employ\ncounterfactual inference on sentiment bias mitigation in RSs.",
      "pdf_url": "http://arxiv.org/pdf/2505.03655v1",
      "arxiv_url": "http://arxiv.org/abs/2505.03655v1",
      "published": "2025-05-06",
      "categories": [
        "cs.IR",
        "cs.AI"
      ]
    },
    {
      "title": "Integrated Sensing, Computing, Communication, and Control for Time-Sequence-Based Semantic Communications",
      "authors": [
        "Qingliang Li",
        "Bo Chang",
        "Weidong Mei",
        "Zhi Chen"
      ],
      "abstract": "In the upcoming industrial internet of things (IIoT) era, a surge of\ntask-oriented applications will rely on real-time wireless control systems\n(WCSs). For these systems, ultra-reliable and low-latency wireless\ncommunication will be crucial to ensure the timely transmission of control\ninformation. To achieve this purpose, we propose a novel time-sequence-based\nsemantic communication paradigm, where an integrated sensing, computing,\ncommunication, and control (ISC3) architecture is developed to make sensible\nsemantic inference (SI) for the control information over time sequences,\nenabling adaptive control of the robot. However, due to the causal correlations\nin the time sequence, the control information does not present the Markov\nproperty. To address this challenge, we compute the mutual information of the\ncontrol information sensed at the transmitter (Tx) over different time and\nidentify their temporal semantic correlation via a semantic feature extractor\n(SFE) module. By this means, highly correlated information transmission can be\navoided, thus greatly reducing the communication overhead. Meanwhile, a\nsemantic feature reconstructor (SFR) module is employed at the receiver (Rx) to\nreconstruct the control information based on the previously received one if the\ninformation transmission is not activated at the Tx. Furthermore, a control\ngain policy is also employed at the Rx to adaptively adjust the control gain\nfor the controlled target based on several practical aspects such as the\nquality of the information transmission from the Tx to the Rx. We design the\nneural network structures of the above modules/policies and train their\nparameters by a novel hybrid reward multi-agent deep reinforcement learning\nframework. On-site experiments are conducted to evaluate the performance of our\nproposed method in practice, which shows significant gains over other baseline\nschemes.",
      "pdf_url": "http://arxiv.org/pdf/2505.03127v1",
      "arxiv_url": "http://arxiv.org/abs/2505.03127v1",
      "published": "2025-05-06",
      "categories": [
        "eess.SY",
        "cs.IT",
        "cs.SY",
        "math.IT"
      ]
    },
    {
      "title": "Multi-View Learning with Context-Guided Receptance for Image Denoising",
      "authors": [
        "Binghong Chen",
        "Tingting Chai",
        "Wei Jiang",
        "Yuanrong Xu",
        "Guanglu Zhou",
        "Xiangqian Wu"
      ],
      "abstract": "Image denoising is essential in low-level vision applications such as\nphotography and automated driving. Existing methods struggle with\ndistinguishing complex noise patterns in real-world scenes and consume\nsignificant computational resources due to reliance on Transformer-based\nmodels. In this work, the Context-guided Receptance Weighted Key-Value (\\M)\nmodel is proposed, combining enhanced multi-view feature integration with\nefficient sequence modeling. Our approach introduces the Context-guided Token\nShift (CTS) paradigm, which effectively captures local spatial dependencies and\nenhance the model's ability to model real-world noise distributions.\nAdditionally, the Frequency Mix (FMix) module extracting frequency-domain\nfeatures is designed to isolate noise in high-frequency spectra, and is\nintegrated with spatial representations through a multi-view learning process.\nTo improve computational efficiency, the Bidirectional WKV (BiWKV) mechanism is\nadopted, enabling full pixel-sequence interaction with linear complexity while\novercoming the causal selection constraints. The model is validated on multiple\nreal-world image denoising datasets, outperforming the existing\nstate-of-the-art methods quantitatively and reducing inference time up to 40\\%.\nQualitative results further demonstrate the ability of our model to restore\nfine details in various scenes.",
      "pdf_url": "http://arxiv.org/pdf/2505.02705v1",
      "arxiv_url": "http://arxiv.org/abs/2505.02705v1",
      "published": "2025-05-05",
      "categories": [
        "eess.IV",
        "cs.CV"
      ]
    },
    {
      "title": "Structure Causal Models and LLMs Integration in Medical Visual Question Answering",
      "authors": [
        "Zibo Xu",
        "Qiang Li",
        "Weizhi Nie",
        "Weijie Wang",
        "Anan Liu"
      ],
      "abstract": "Medical Visual Question Answering (MedVQA) aims to answer medical questions\naccording to medical images. However, the complexity of medical data leads to\nconfounders that are difficult to observe, so bias between images and questions\nis inevitable. Such cross-modal bias makes it challenging to infer medically\nmeaningful answers. In this work, we propose a causal inference framework for\nthe MedVQA task, which effectively eliminates the relative confounding effect\nbetween the image and the question to ensure the precision of the\nquestion-answering (QA) session. We are the first to introduce a novel causal\ngraph structure that represents the interaction between visual and textual\nelements, explicitly capturing how different questions influence visual\nfeatures. During optimization, we apply the mutual information to discover\nspurious correlations and propose a multi-variable resampling front-door\nadjustment method to eliminate the relative confounding effect, which aims to\nalign features based on their true causal relevance to the question-answering\ntask. In addition, we also introduce a prompt strategy that combines multiple\nprompt forms to improve the model's ability to understand complex medical data\nand answer accurately. Extensive experiments on three MedVQA datasets\ndemonstrate that 1) our method significantly improves the accuracy of MedVQA,\nand 2) our method achieves true causal correlations in the face of complex\nmedical data.",
      "pdf_url": "http://arxiv.org/pdf/2505.02703v1",
      "arxiv_url": "http://arxiv.org/abs/2505.02703v1",
      "published": "2025-05-05",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "Bayesian inference for cluster-randomized trials with multivariate outcomes subject to both truncation by death and missingness",
      "authors": [
        "Guangyu Tong",
        "Chenxi Li",
        "Eric Velazquez",
        "Michael O. Harhay",
        "Fan Li"
      ],
      "abstract": "Cluster-randomized trials (CRTs) on fragile populations frequently encounter\ncomplex attrition problems where the reasons for missing outcomes can be\nheterogeneous, with participants who are known alive, known to have died, or\nwith unknown survival status, and with complex and distinct missing data\nmechanisms for each group. Although existing methods have been developed to\naddress death truncation in CRTs, no existing methods can jointly accommodate\nparticipants who drop out for reasons unrelated to mortality or serious\nillnesses, or those with an unknown survival status. This paper proposes a\nBayesian framework for estimating survivor average causal effects in CRTs while\naccounting for different types of missingness. Our approach uses a multivariate\noutcome that jointly estimates the causal effects, and in the posterior\nestimates, we distinguish the individual-level and the cluster-level survivor\naverage causal effect. We perform simulation studies to evaluate the\nperformance of our model and found low bias and high coverage on key parameters\nacross several different scenarios. We use data from a geriatric CRT to\nillustrate the use of our model. Although our illustration focuses on the case\nof a bivariate continuous outcome, our model is straightforwardly extended to\naccommodate more than two endpoints as well as other types of endpoints (e.g.,\nbinary). Thus, this work provides a general modeling framework for handling\ncomplex missingness in CRTs and can be applied to a wide range of settings with\naging and palliative care populations.",
      "pdf_url": "http://arxiv.org/pdf/2505.02310v1",
      "arxiv_url": "http://arxiv.org/abs/2505.02310v1",
      "published": "2025-05-05",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Federated Causal Inference in Healthcare: Methods, Challenges, and Applications",
      "authors": [
        "Haoyang Li",
        "Jie Xu",
        "Kyra Gan",
        "Fei Wang",
        "Chengxi Zang"
      ],
      "abstract": "Federated causal inference enables multi-site treatment effect estimation\nwithout sharing individual-level data, offering a privacy-preserving solution\nfor real-world evidence generation. However, data heterogeneity across sites,\nmanifested in differences in covariate, treatment, and outcome, poses\nsignificant challenges for unbiased and efficient estimation. In this paper, we\npresent a comprehensive review and theoretical analysis of federated causal\neffect estimation across both binary/continuous and time-to-event outcomes. We\nclassify existing methods into weight-based strategies and optimization-based\nframeworks and further discuss extensions including personalized models,\npeer-to-peer communication, and model decomposition. For time-to-event\noutcomes, we examine federated Cox and Aalen-Johansen models, deriving\nasymptotic bias and variance under heterogeneity. Our analysis reveals that\nFedProx-style regularization achieves near-optimal bias-variance trade-offs\ncompared to naive averaging and meta-analysis. We review related software tools\nand conclude by outlining opportunities, challenges, and future directions for\nscalable, fair, and trustworthy federated causal inference in distributed\nhealthcare systems.",
      "pdf_url": "http://arxiv.org/pdf/2505.02238v1",
      "arxiv_url": "http://arxiv.org/abs/2505.02238v1",
      "published": "2025-05-04",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "TV-SurvCaus: Dynamic Representation Balancing for Causal Survival Analysis",
      "authors": [
        "Ayoub Abraich"
      ],
      "abstract": "Estimating the causal effect of time-varying treatments on survival outcomes\nis a challenging task in many domains, particularly in medicine where treatment\nprotocols adapt over time. While recent advances in representation learning\nhave improved causal inference for static treatments, extending these methods\nto dynamic treatment regimes with survival outcomes remains under-explored. In\nthis paper, we introduce TV-SurvCaus, a novel framework that extends\nrepresentation balancing techniques to the time-varying treatment setting for\nsurvival analysis. We provide theoretical guarantees through (1) a generalized\nbound for time-varying precision in estimation of heterogeneous effects, (2)\nvariance control via sequential balancing weights, (3) consistency results for\ndynamic treatment regimes, (4) convergence rates for representation learning\nwith temporal dependencies, and (5) a formal bound on the bias due to\ntreatment-confounder feedback. Our neural architecture incorporates sequence\nmodeling to handle temporal dependencies while balancing time-dependent\nrepresentations. Through extensive experiments on both synthetic and real-world\ndatasets, we demonstrate that TV-SurvCaus outperforms existing methods in\nestimating individualized treatment effects with time-varying covariates and\ntreatments. Our framework advances the field of causal inference by enabling\nmore accurate estimation of treatment effects in dynamic, longitudinal settings\nwith survival outcomes.",
      "pdf_url": "http://arxiv.org/pdf/2505.01785v1",
      "arxiv_url": "http://arxiv.org/abs/2505.01785v1",
      "published": "2025-05-03",
      "categories": [
        "stat.ML",
        "cs.LG"
      ]
    }
  ]
}