{
  "last_updated": "2025-07-16T00:58:03.928201",
  "papers": [
    {
      "title": "T-GRAB: A Synthetic Diagnostic Benchmark for Learning on Temporal Graphs",
      "authors": [
        "Alireza Dizaji",
        "Benedict Aaron Tjandra",
        "Mehrab Hamidi",
        "Shenyang Huang",
        "Guillaume Rabusseau"
      ],
      "abstract": "Dynamic graph learning methods have recently emerged as powerful tools for\nmodelling relational data evolving through time. However, despite extensive\nbenchmarking efforts, it remains unclear whether current Temporal Graph Neural\nNetworks (TGNNs) effectively capture core temporal patterns such as\nperiodicity, cause-and-effect, and long-range dependencies. In this work, we\nintroduce the Temporal Graph Reasoning Benchmark (T-GRAB), a comprehensive set\nof synthetic tasks designed to systematically probe the capabilities of TGNNs\nto reason across time. T-GRAB provides controlled, interpretable tasks that\nisolate key temporal skills: counting/memorizing periodic repetitions,\ninferring delayed causal effects, and capturing long-range dependencies over\nboth spatial and temporal dimensions. We evaluate 11 temporal graph learning\nmethods on these tasks, revealing fundamental shortcomings in their ability to\ngeneralize temporal patterns. Our findings offer actionable insights into the\nlimitations of current models, highlight challenges hidden by traditional\nreal-world benchmarks, and motivate the development of architectures with\nstronger temporal reasoning abilities. The code for T-GRAB can be found at:\nhttps://github.com/alirezadizaji/T-GRAB.",
      "pdf_url": "http://arxiv.org/pdf/2507.10183v1",
      "arxiv_url": "http://arxiv.org/abs/2507.10183v1",
      "published": "2025-07-14",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "Text-Driven Causal Representation Learning for Source-Free Domain Generalization",
      "authors": [
        "Lihua Zhou",
        "Mao Ye",
        "Nianxin Li",
        "Shuaifeng Li",
        "Jinlin Wu",
        "Xiatian Zhu",
        "Lei Deng",
        "Hongbin Liu",
        "Jiebo Luo",
        "Zhen Lei"
      ],
      "abstract": "Deep learning often struggles when training and test data distributions\ndiffer. Traditional domain generalization (DG) tackles this by including data\nfrom multiple source domains, which is impractical due to expensive data\ncollection and annotation. Recent vision-language models like CLIP enable\nsource-free domain generalization (SFDG) by using text prompts to simulate\nvisual representations, reducing data demands. However, existing SFDG methods\nstruggle with domain-specific confounders, limiting their generalization\ncapabilities. To address this issue, we propose TDCRL\n(\\textbf{T}ext-\\textbf{D}riven \\textbf{C}ausal \\textbf{R}epresentation\n\\textbf{L}earning), the first method to integrate causal inference into the\nSFDG setting. TDCRL operates in two steps: first, it employs data augmentation\nto generate style word vectors, combining them with class information to\ngenerate text embeddings to simulate visual representations; second, it trains\na causal intervention network with a confounder dictionary to extract\ndomain-invariant features. Grounded in causal learning, our approach offers a\nclear and effective mechanism to achieve robust, domain-invariant features,\nensuring robust generalization. Extensive experiments on PACS, VLCS,\nOfficeHome, and DomainNet show state-of-the-art performance, proving TDCRL\neffectiveness in SFDG.",
      "pdf_url": "http://arxiv.org/pdf/2507.09961v1",
      "arxiv_url": "http://arxiv.org/abs/2507.09961v1",
      "published": "2025-07-14",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "Exploring the effects of mechanical ventilator settings with modified vector-valued treatment policies",
      "authors": [
        "Ziren Jiang",
        "Philip S. Crooke",
        "John J. Marini",
        "Jared D. Huling"
      ],
      "abstract": "Mechanical ventilation is critical for managing respiratory failure, but\ninappropriate ventilator settings can lead to ventilator-induced lung injury\n(VILI), increasing patient morbidity and mortality. Evaluating the causal\nimpact of ventilator settings is challenging due to the complex interplay of\nmultiple treatment variables and strong confounding due to ventilator\nguidelines. In this paper, we propose a modified vector-valued treatment policy\n(MVTP) framework coupled with energy balancing weights to estimate causal\neffects involving multiple continuous ventilator parameters simultaneously in\naddition to sensitivity analysis to unmeasured confounding. Our approach\nmitigates common challenges in causal inference for vector-valued treatments,\nsuch as infeasible treatment combinations, stringent positivity assumptions,\nand interpretability concerns. Using the MIMIC-III database, our analyses\nsuggest that equal reductions in the total power of ventilation (i.e., the\nmechanical power) through different ventilator parameters result in different\nexpected patient outcomes. Specifically, lowering airway pressures may yield\ngreater reductions in patient mortality compared to proportional adjustments of\ntidal volume alone. Moreover, controlling for respiratory-system compliance and\nminute ventilation, we found a significant benefit of reducing driving pressure\nin patients with acute respiratory distress syndrome (ARDS). Our analyses help\nshed light on the contributors to VILI.",
      "pdf_url": "http://arxiv.org/pdf/2507.09809v1",
      "arxiv_url": "http://arxiv.org/abs/2507.09809v1",
      "published": "2025-07-13",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Bridging Structural Causal Inference and Machine Learning The S-DIDML Estimator for Heterogeneous Treatment Effects",
      "authors": [
        "Yile Yu",
        "Anzhi Xu"
      ],
      "abstract": "In response to the increasing complexity of policy environments and the\nproliferation of high-dimensional data, this paper introduces the S-DIDML\nestimator a framework grounded in structure and semiparametrically flexible for\ncausal inference. By embedding Difference-in-Differences (DID) logic within a\nDouble Machine Learning (DML) architecture, the S-DIDML approach combines the\nstrengths of temporal identification, machine learning-based nuisance\nadjustment, and orthogonalized estimation. We begin by identifying critical\nlimitations in existing methods, including the lack of structural\ninterpretability in ML models, instability of classical DID under\nhigh-dimensional confounding, and the temporal rigidity of standard DML\nframeworks. Building on recent advances in staggered adoption designs and\nNeyman orthogonalization, S-DIDML offers a five-step estimation pipeline that\nenables robust estimation of heterogeneous treatment effects (HTEs) while\nmaintaining interpretability and scalability. Demonstrative applications are\ndiscussed across labor economics, education, taxation, and environmental\npolicy. The proposed framework contributes to the methodological frontier by\noffering a blueprint for policy-relevant, structurally interpretable, and\nstatistically valid causal analysis in complex data settings.",
      "pdf_url": "http://arxiv.org/pdf/2507.09718v1",
      "arxiv_url": "http://arxiv.org/abs/2507.09718v1",
      "published": "2025-07-13",
      "categories": [
        "stat.ME",
        "91-01"
      ]
    },
    {
      "title": "Dynamic Sparse Causal-Attention Temporal Networks for Interpretable Causality Discovery in Multivariate Time Series",
      "authors": [
        "Meriem Zerkouk",
        "Miloud Mihoubi",
        "Belkacem Chikhaoui"
      ],
      "abstract": "Understanding causal relationships in multivariate time series (MTS) is\nessential for effective decision-making in fields such as finance and\nmarketing, where complex dependencies and lagged effects challenge conventional\nanalytical approaches. We introduce Dynamic Sparse Causal-Attention Temporal\nNetworks for Interpretable Causality Discovery in MTS (DyCAST-Net), a novel\narchitecture designed to enhance causal discovery by integrating dilated\ntemporal convolutions and dynamic sparse attention mechanisms. DyCAST-Net\neffectively captures multiscale temporal dependencies through dilated\nconvolutions while leveraging an adaptive thresholding strategy in its\nattention mechanism to eliminate spurious connections, ensuring both accuracy\nand interpretability. A statistical shuffle test validation further strengthens\nrobustness by filtering false positives and improving causal inference\nreliability. Extensive evaluations on financial and marketing datasets\ndemonstrate that DyCAST-Net consistently outperforms existing models such as\nTCDF, GCFormer, and CausalFormer. The model provides a more precise estimation\nof causal delays and significantly reduces false discoveries, particularly in\nnoisy environments. Moreover, attention heatmaps offer interpretable insights,\nuncovering hidden causal patterns such as the mediated effects of advertising\non consumer behavior and the influence of macroeconomic indicators on financial\nmarkets. Case studies illustrate DyCAST-Net's ability to detect latent\nmediators and lagged causal factors, making it particularly effective in\nhigh-dimensional, dynamic settings. The model's architecture enhanced by\nRMSNorm stabilization and causal masking ensures scalability and adaptability\nacross diverse application domains",
      "pdf_url": "http://arxiv.org/pdf/2507.09439v1",
      "arxiv_url": "http://arxiv.org/abs/2507.09439v1",
      "published": "2025-07-13",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR"
      ]
    },
    {
      "title": "A Framework for Predictive Directional Trading Based on Volatility and Causal Inference",
      "authors": [
        "Ivan Letteri"
      ],
      "abstract": "Purpose: This study introduces a novel framework for identifying and\nexploiting predictive lead-lag relationships in financial markets. We propose\nan integrated approach that combines advanced statistical methodologies with\nmachine learning models to enhance the identification and exploitation of\npredictive relationships between equities. Methods: We employed a Gaussian\nMixture Model (GMM) to cluster nine prominent stocks based on their mid-range\nhistorical volatility profiles over a three-year period. From the resulting\nclusters, we constructed a multi-stage causal inference pipeline, incorporating\nthe Granger Causality Test (GCT), a customised Peter-Clark Momentary\nConditional Independence (PCMCI) test, and Effective Transfer Entropy (ETE) to\nidentify robust, predictive linkages. Subsequently, Dynamic Time Warping (DTW)\nand a K-Nearest Neighbours (KNN) classifier were utilised to determine the\noptimal time lag for trade execution. The resulting strategy was rigorously\nbacktested. Results: The proposed volatility-based trading strategy, tested\nfrom 8 June 2023 to 12 August 2023, demonstrated substantial efficacy. The\nportfolio yielded a total return of 15.38%, significantly outperforming the\n10.39% return of a comparative Buy-and-Hold strategy. Key performance metrics,\nincluding a Sharpe Ratio up to 2.17 and a win rate up to 100% for certain\npairs, confirmed the strategy's viability. Conclusion: This research\ncontributes a systematic and robust methodology for identifying profitable\ntrading opportunities derived from volatility-based causal relationships. The\nfindings have significant implications for both academic research in financial\nmodelling and the practical application of algorithmic trading, offering a\nstructured approach to developing resilient, data-driven strategies.",
      "pdf_url": "http://arxiv.org/pdf/2507.09347v1",
      "arxiv_url": "http://arxiv.org/abs/2507.09347v1",
      "published": "2025-07-12",
      "categories": [
        "q-fin.ST",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "title": "The Multiplicative Instrumental Variable Model",
      "authors": [
        "Jiewen Liu",
        "Chan Park",
        "Yonghoon Lee",
        "Yunshu Zhang",
        "Mengxin Yu",
        "James M. Robins",
        "Eric J. Tchetgen Tchetgen"
      ],
      "abstract": "The instrumental variable (IV) design is a common approach to address hidden\nconfounding bias. For validity, an IV must impact the outcome only through its\nassociation with the treatment. In addition, IV identification has required a\nhomogeneity condition such as monotonicity or no unmeasured common effect\nmodifier between the additive effect of the treatment on the outcome, and that\nof the IV on the treatment. In this work, we introduce a novel identifying\ncondition of no multiplicative interaction between the instrument and the\nunmeasured confounder in the treatment model, which we establish\nnonparametrically identifies the average treatment effect on the treated (ATT).\nFor inference, we propose an estimator that is multiply robust and\nsemiparametric efficient, while allowing for the use of machine learning to\nadaptively estimate required nuisance functions via cross-fitting. Finally, we\nillustrate the methods in extended simulations and an application on the causal\nimpact of a job training program on subsequent earnings.",
      "pdf_url": "http://arxiv.org/pdf/2507.09302v1",
      "arxiv_url": "http://arxiv.org/abs/2507.09302v1",
      "published": "2025-07-12",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Hybrid Autoregressive-Diffusion Model for Real-Time Streaming Sign Language Production",
      "authors": [
        "Maoxiao Ye",
        "Xinfeng Ye",
        "Mano Manoharan"
      ],
      "abstract": "Earlier Sign Language Production (SLP) models typically relied on\nautoregressive methods that generate output tokens one by one, which inherently\nprovide temporal alignment. Although techniques like Teacher Forcing can\nprevent model collapse during training, they still cannot solve the problem of\nerror accumulation during inference, since ground truth is unavailable at that\nstage. In contrast, more recent approaches based on diffusion models leverage\nstep-by-step denoising to enable high-quality generation. However, the\niterative nature of these models and the requirement to denoise entire\nsequences limit their applicability in real-time tasks like SLP. To address it,\nwe apply a hybrid approach combining autoregressive and diffusion models to SLP\nfor the first time, leveraging the strengths of both models in sequential\ndependency modeling and output refinement. To capture fine-grained body\nmovements, we design a Multi-Scale Pose Representation module that separately\nextracts detailed features from distinct articulators and integrates them via a\nMulti-Scale Fusion module. Furthermore, we introduce a Confidence-Aware Causal\nAttention mechanism that utilizes joint-level confidence scores to dynamically\nguide the pose generation process, improving accuracy and robustness. Extensive\nexperiments on the PHOENIX14T and How2Sign datasets demonstrate the\neffectiveness of our method in both generation quality and real-time streaming\nefficiency.",
      "pdf_url": "http://arxiv.org/pdf/2507.09105v1",
      "arxiv_url": "http://arxiv.org/abs/2507.09105v1",
      "published": "2025-07-12",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "MI CAM: Mutual Information Weighted Activation Mapping for Causal Visual Explanations of Convolutional Neural Networks",
      "authors": [
        "Ram S Iyer",
        "Narayan S Iyer",
        "Rugmini Ammal P"
      ],
      "abstract": "With the intervention of machine vision in our crucial day to day necessities\nincluding healthcare and automated power plants, attention has been drawn to\nthe internal mechanisms of convolutional neural networks, and the reason why\nthe network provides specific inferences. This paper proposes a novel post-hoc\nvisual explanation method called MI CAM based on activation mapping. Differing\nfrom previous class activation mapping based approaches, MI CAM produces\nsaliency visualizations by weighing each feature map through its mutual\ninformation with the input image and the final result is generated by a linear\ncombination of weights and activation maps. It also adheres to producing causal\ninterpretations as validated with the help of counterfactual analysis. We aim\nto exhibit the visual performance and unbiased justifications for the model\ninferencing procedure achieved by MI CAM. Our approach works at par with all\nstate-of-the-art methods but particularly outperforms some in terms of\nqualitative and quantitative measures. The implementation of proposed method\ncan be found on https://anonymous.4open.science/r/MI-CAM-4D27",
      "pdf_url": "http://arxiv.org/pdf/2507.09092v1",
      "arxiv_url": "http://arxiv.org/abs/2507.09092v1",
      "published": "2025-07-12",
      "categories": [
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "title": "Lumos-1: On Autoregressive Video Generation from a Unified Model Perspective",
      "authors": [
        "Hangjie Yuan",
        "Weihua Chen",
        "Jun Cen",
        "Hu Yu",
        "Jingyun Liang",
        "Shuning Chang",
        "Zhihui Lin",
        "Tao Feng",
        "Pengwei Liu",
        "Jiazheng Xing",
        "Hao Luo",
        "Jiasheng Tang",
        "Fan Wang",
        "Yi Yang"
      ],
      "abstract": "Autoregressive large language models (LLMs) have unified a vast range of\nlanguage tasks, inspiring preliminary efforts in autoregressive video\ngeneration. Existing autoregressive video generators either diverge from\nstandard LLM architectures, depend on bulky external text encoders, or incur\nprohibitive latency due to next-token decoding. In this paper, we introduce\nLumos-1, an autoregressive video generator that retains the LLM architecture\nwith minimal architectural modifications. To inject spatiotemporal correlations\nin LLMs, we identify the efficacy of incorporating 3D RoPE and diagnose its\nimbalanced frequency spectrum ranges. Therefore, we propose MM-RoPE, a RoPE\nscheme that preserves the original textual RoPE while providing comprehensive\nfrequency spectra and scaled 3D positions for modeling multimodal\nspatiotemporal data. Moreover, Lumos-1 resorts to a token dependency strategy\nthat obeys intra-frame bidirectionality and inter-frame temporal causality.\nBased on this dependency strategy, we identify the issue of frame-wise loss\nimbalance caused by spatial information redundancy and solve it by proposing\nAutoregressive Discrete Diffusion Forcing (AR-DF). AR-DF introduces temporal\ntube masking during training with a compatible inference-time masking policy to\navoid quality degradation. By using memory-efficient training techniques, we\npre-train Lumos-1 on only 48 GPUs, achieving performance comparable to EMU3 on\nGenEval, COSMOS-Video2World on VBench-I2V, and OpenSoraPlan on VBench-T2V. Code\nand models are available at https://github.com/alibaba-damo-academy/Lumos.",
      "pdf_url": "http://arxiv.org/pdf/2507.08801v1",
      "arxiv_url": "http://arxiv.org/abs/2507.08801v1",
      "published": "2025-07-11",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ]
    }
  ]
}