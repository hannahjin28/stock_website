{
  "last_updated": "2025-05-26T00:55:32.640585",
  "papers": [
    {
      "title": "Learning Adaptive and Temporally Causal Video Tokenization in a 1D Latent Space",
      "authors": [
        "Yan Li",
        "Changyao Tian",
        "Renqiu Xia",
        "Ning Liao",
        "Weiwei Guo",
        "Junchi Yan",
        "Hongsheng Li",
        "Jifeng Dai",
        "Hao Li",
        "Xue Yang"
      ],
      "abstract": "We propose AdapTok, an adaptive temporal causal video tokenizer that can\nflexibly allocate tokens for different frames based on video content. AdapTok\nis equipped with a block-wise masking strategy that randomly drops tail tokens\nof each block during training, and a block causal scorer to predict the\nreconstruction quality of video frames using different numbers of tokens.\nDuring inference, an adaptive token allocation strategy based on integer linear\nprogramming is further proposed to adjust token usage given predicted scores.\nSuch design allows for sample-wise, content-aware, and temporally dynamic token\nallocation under a controllable overall budget. Extensive experiments for video\nreconstruction and generation on UCF-101 and Kinetics-600 demonstrate the\neffectiveness of our approach. Without additional image data, AdapTok\nconsistently improves reconstruction quality and generation performance under\ndifferent token budgets, allowing for more scalable and token-efficient\ngenerative video modeling.",
      "pdf_url": "http://arxiv.org/pdf/2505.17011v1",
      "arxiv_url": "http://arxiv.org/abs/2505.17011v1",
      "published": "2025-05-22",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "Beyond Correlation: Towards Causal Large Language Model Agents in Biomedicine",
      "authors": [
        "Adib Bazgir",
        "Amir Habibdoust Lafmajani",
        "Yuwen Zhang"
      ],
      "abstract": "Large Language Models (LLMs) show promise in biomedicine but lack true causal\nunderstanding, relying instead on correlations. This paper envisions causal LLM\nagents that integrate multimodal data (text, images, genomics, etc.) and\nperform intervention-based reasoning to infer cause-and-effect. Addressing this\nrequires overcoming key challenges: designing safe, controllable agentic\nframeworks; developing rigorous benchmarks for causal evaluation; integrating\nheterogeneous data sources; and synergistically combining LLMs with structured\nknowledge (KGs) and formal causal inference tools. Such agents could unlock\ntransformative opportunities, including accelerating drug discovery through\nautomated hypothesis generation and simulation, enabling personalized medicine\nthrough patient-specific causal models. This research agenda aims to foster\ninterdisciplinary efforts, bridging causal concepts and foundation models to\ndevelop reliable AI partners for biomedical progress.",
      "pdf_url": "http://arxiv.org/pdf/2505.16982v1",
      "arxiv_url": "http://arxiv.org/abs/2505.16982v1",
      "published": "2025-05-22",
      "categories": [
        "cs.AI",
        "physics.med-ph"
      ]
    },
    {
      "title": "On the Out-of-Distribution Generalization of Self-Supervised Learning",
      "authors": [
        "Wenwen Qiang",
        "Jingyao Wang",
        "Zeen Song",
        "Jiangmeng Li",
        "Changwen Zheng"
      ],
      "abstract": "In this paper, we focus on the out-of-distribution (OOD) generalization of\nself-supervised learning (SSL). By analyzing the mini-batch construction during\nthe SSL training phase, we first give one plausible explanation for SSL having\nOOD generalization. Then, from the perspective of data generation and causal\ninference, we analyze and conclude that SSL learns spurious correlations during\nthe training process, which leads to a reduction in OOD generalization. To\naddress this issue, we propose a post-intervention distribution (PID) grounded\nin the Structural Causal Model. PID offers a scenario where the spurious\nvariable and label variable is mutually independent. Besides, we demonstrate\nthat if each mini-batch during SSL training satisfies PID, the resulting SSL\nmodel can achieve optimal worst-case OOD performance. This motivates us to\ndevelop a batch sampling strategy that enforces PID constraints through the\nlearning of a latent variable model. Through theoretical analysis, we\ndemonstrate the identifiability of the latent variable model and validate the\neffectiveness of the proposed sampling strategy. Experiments conducted on\nvarious downstream OOD tasks demonstrate the effectiveness of the proposed\nsampling strategy.",
      "pdf_url": "http://arxiv.org/pdf/2505.16675v1",
      "arxiv_url": "http://arxiv.org/abs/2505.16675v1",
      "published": "2025-05-22",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "Seeing Far and Clearly: Mitigating Hallucinations in MLLMs with Attention Causal Decoding",
      "authors": [
        "Feilong Tang",
        "Chengzhi Liu",
        "Zhongxing Xu",
        "Ming Hu",
        "Zelin Peng",
        "Zhiwei Yang",
        "Jionglong Su",
        "Minquan Lin",
        "Yifan Peng",
        "Xuelian Cheng",
        "Imran Razzak",
        "Zongyuan Ge"
      ],
      "abstract": "Recent advancements in multimodal large language models (MLLMs) have\nsignificantly improved performance in visual question answering. However, they\noften suffer from hallucinations. In this work, hallucinations are categorized\ninto two main types: initial hallucinations and snowball hallucinations. We\nargue that adequate contextual information can be extracted directly from the\ntoken interaction process. Inspired by causal inference in the decoding\nstrategy, we propose to leverage causal masks to establish information\npropagation between multimodal tokens. The hypothesis is that insufficient\ninteraction between those tokens may lead the model to rely on outlier tokens,\noverlooking dense and rich contextual cues. Therefore, we propose to intervene\nin the propagation process by tackling outlier tokens to enhance in-context\ninference. With this goal, we present FarSight, a versatile plug-and-play\ndecoding strategy to reduce attention interference from outlier tokens merely\nby optimizing the causal mask. The heart of our method is effective token\npropagation. We design an attention register structure within the upper\ntriangular matrix of the causal mask, dynamically allocating attention to\ncapture attention diverted to outlier tokens. Moreover, a positional awareness\nencoding method with a diminishing masking rate is proposed, allowing the model\nto attend to further preceding tokens, especially for video sequence tasks.\nWith extensive experiments, FarSight demonstrates significant\nhallucination-mitigating performance across different MLLMs on both image and\nvideo benchmarks, proving its effectiveness.",
      "pdf_url": "http://arxiv.org/pdf/2505.16652v1",
      "arxiv_url": "http://arxiv.org/abs/2505.16652v1",
      "published": "2025-05-22",
      "categories": [
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "title": "Causal-Invariant Cross-Domain Out-of-Distribution Recommendation",
      "authors": [
        "Jiajie Zhu",
        "Yan Wang",
        "Feng Zhu",
        "Pengfei Ding",
        "Hongyang Liu",
        "Zhu Sun"
      ],
      "abstract": "Cross-Domain Recommendation (CDR) aims to leverage knowledge from a\nrelatively data-richer source domain to address the data sparsity problem in a\nrelatively data-sparser target domain. While CDR methods need to address the\ndistribution shifts between different domains, i.e., cross-domain distribution\nshifts (CDDS), they typically assume independent and identical distribution\n(IID) between training and testing data within the target domain. However, this\nIID assumption rarely holds in real-world scenarios due to single-domain\ndistribution shift (SDDS). The above two co-existing distribution shifts lead\nto out-of-distribution (OOD) environments that hinder effective knowledge\ntransfer and generalization, ultimately degrading recommendation performance in\nCDR. To address these co-existing distribution shifts, we propose a novel\nCausal-Invariant Cross-Domain Out-of-distribution Recommendation framework,\ncalled CICDOR. In CICDOR, we first learn dual-level causal structures to infer\ndomain-specific and domain-shared causal-invariant user preferences for\ntackling both CDDS and SDDS under OOD environments in CDR. Then, we propose an\nLLM-guided confounder discovery module that seamlessly integrates LLMs with a\nconventional causal discovery method to extract observed confounders for\neffective deconfounding, thereby enabling accurate causal-invariant preference\ninference. Extensive experiments on two real-world datasets demonstrate the\nsuperior recommendation accuracy of CICDOR over state-of-the-art methods across\nvarious OOD scenarios.",
      "pdf_url": "http://arxiv.org/pdf/2505.16532v1",
      "arxiv_url": "http://arxiv.org/abs/2505.16532v1",
      "published": "2025-05-22",
      "categories": [
        "cs.IR"
      ]
    },
    {
      "title": "Benchmarking and Pushing the Multi-Bias Elimination Boundary of LLMs via Causal Effect Estimation-guided Debiasing",
      "authors": [
        "Zhouhao Sun",
        "Zhiyuan Kan",
        "Xiao Ding",
        "Li Du",
        "Yang Zhao",
        "Bing Qin",
        "Ting Liu"
      ],
      "abstract": "Despite significant progress, recent studies have indicated that current\nlarge language models (LLMs) may still utilize bias during inference, leading\nto the poor generalizability of LLMs. Some benchmarks are proposed to\ninvestigate the generalizability of LLMs, with each piece of data typically\ncontaining one type of controlled bias. However, a single piece of data may\ncontain multiple types of biases in practical applications. To bridge this gap,\nwe propose a multi-bias benchmark where each piece of data contains five types\nof biases. The evaluations conducted on this benchmark reveal that the\nperformance of existing LLMs and debiasing methods is unsatisfying,\nhighlighting the challenge of eliminating multiple types of biases\nsimultaneously. To overcome this challenge, we propose a causal effect\nestimation-guided multi-bias elimination method (CMBE). This method first\nestimates the causal effect of multiple types of biases simultaneously.\nSubsequently, we eliminate the causal effect of biases from the total causal\neffect exerted by both the semantic information and biases during inference.\nExperimental results show that CMBE can effectively eliminate multiple types of\nbias simultaneously to enhance the generalizability of LLMs.",
      "pdf_url": "http://arxiv.org/pdf/2505.16522v1",
      "arxiv_url": "http://arxiv.org/abs/2505.16522v1",
      "published": "2025-05-22",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "CAIFormer: A Causal Informed Transformer for Multivariate Time Series Forecasting",
      "authors": [
        "Xingyu Zhang",
        "Wenwen Qiang",
        "Siyu Zhao",
        "Huijie Guo",
        "Jiangmeng Li",
        "Chuxiong Sun",
        "Changwen Zheng"
      ],
      "abstract": "Most existing multivariate time series forecasting methods adopt an\nall-to-all paradigm that feeds all variable histories into a unified model to\npredict their future values without distinguishing their individual roles.\nHowever, this undifferentiated paradigm makes it difficult to identify\nvariable-specific causal influences and often entangles causally relevant\ninformation with spurious correlations. To address this limitation, we propose\nan all-to-one forecasting paradigm that predicts each target variable\nseparately. Specifically, we first construct a Structural Causal Model from\nobservational data and then, for each target variable, we partition the\nhistorical sequence into four sub-segments according to the inferred causal\nstructure: endogenous, direct causal, collider causal, and spurious\ncorrelation. The prediction relies solely on the first three causally relevant\nsub-segments, while the spurious correlation sub-segment is excluded.\nFurthermore, we propose Causal Informed Transformer (CAIFormer), a novel\nforecasting model comprising three components: Endogenous Sub-segment\nPrediction Block, Direct Causal Sub-segment Prediction Block, and Collider\nCausal Sub-segment Prediction Block, which process the endogenous, direct\ncausal, and collider causal sub-segments, respectively. Their outputs are then\ncombined to produce the final prediction. Extensive experiments on multiple\nbenchmark datasets demonstrate the effectiveness of the CAIFormer.",
      "pdf_url": "http://arxiv.org/pdf/2505.16308v1",
      "arxiv_url": "http://arxiv.org/abs/2505.16308v1",
      "published": "2025-05-22",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "MedCFVQA: A Causal Approach to Mitigate Modality Preference Bias in Medical Visual Question Answering",
      "authors": [
        "Shuchang Ye",
        "Usman Naseem",
        "Mingyuan Meng",
        "Dagan Feng",
        "Jinman Kim"
      ],
      "abstract": "Medical Visual Question Answering (MedVQA) is crucial for enhancing the\nefficiency of clinical diagnosis by providing accurate and timely responses to\nclinicians' inquiries regarding medical images. Existing MedVQA models suffered\nfrom modality preference bias, where predictions are heavily dominated by one\nmodality while overlooking the other (in MedVQA, usually questions dominate the\nanswer but images are overlooked), thereby failing to learn multimodal\nknowledge. To overcome the modality preference bias, we proposed a Medical\nCounterFactual VQA (MedCFVQA) model, which trains with bias and leverages\ncausal graphs to eliminate the modality preference bias during inference.\nExisting MedVQA datasets exhibit substantial prior dependencies between\nquestions and answers, which results in acceptable performance even if the\nmodel significantly suffers from the modality preference bias. To address this\nissue, we reconstructed new datasets by leveraging existing MedVQA datasets and\nChanged their P3rior dependencies (CP) between questions and their answers in\nthe training and test set. Extensive experiments demonstrate that MedCFVQA\nsignificantly outperforms its non-causal counterpart on both SLAKE, RadVQA and\nSLAKE-CP, RadVQA-CP datasets.",
      "pdf_url": "http://arxiv.org/pdf/2505.16209v2",
      "arxiv_url": "http://arxiv.org/abs/2505.16209v2",
      "published": "2025-05-22",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "PO-Flow: Flow-based Generative Models for Sampling Potential Outcomes and Counterfactuals",
      "authors": [
        "Dongze Wu",
        "David I. Inouye",
        "Yao Xie"
      ],
      "abstract": "We propose PO-Flow, a novel continuous normalizing flow (CNF) framework for\ncausal inference that jointly models potential outcomes and counterfactuals.\nTrained via flow matching, PO-Flow provides a unified framework for\nindividualized potential outcome prediction, counterfactual predictions, and\nuncertainty-aware density learning. Among generative models, it is the first to\nenable density learning of potential outcomes without requiring explicit\ndistributional assumptions (e.g., Gaussian mixtures), while also supporting\ncounterfactual prediction conditioned on factual outcomes in general\nobservational datasets. On benchmarks such as ACIC, IHDP, and IBM, it\nconsistently outperforms prior methods across a range of causal inference\ntasks. Beyond that, PO-Flow succeeds in high-dimensional settings, including\ncounterfactual image generation, demonstrating its broad applicability.",
      "pdf_url": "http://arxiv.org/pdf/2505.16051v1",
      "arxiv_url": "http://arxiv.org/abs/2505.16051v1",
      "published": "2025-05-21",
      "categories": [
        "stat.ML",
        "cs.LG"
      ]
    },
    {
      "title": "ThinkLess: A Training-Free Inference-Efficient Method for Reducing Reasoning Redundancy",
      "authors": [
        "Gengyang Li",
        "Yifeng Gao",
        "Yuming Li",
        "Yunfang Wu"
      ],
      "abstract": "While Chain-of-Thought (CoT) prompting improves reasoning in large language\nmodels (LLMs), the excessive length of reasoning tokens increases latency and\nKV cache memory usage, and may even truncate final answers under context\nlimits. We propose ThinkLess, an inference-efficient framework that terminates\nreasoning generation early and maintains output quality without modifying the\nmodel. Atttention analysis reveals that answer tokens focus minimally on\nearlier reasoning steps and primarily attend to the reasoning terminator token,\ndue to information migration under causal masking. Building on this insight,\nThinkLess inserts the terminator token at earlier positions to skip redundant\nreasoning while preserving the underlying knowledge transfer. To prevent format\ndiscruption casued by early termination, ThinkLess employs a lightweight\npost-regulation mechanism, relying on the model's natural instruction-following\nability to produce well-structured answers. Without fine-tuning or auxiliary\ndata, ThinkLess achieves comparable accuracy to full-length CoT decoding while\ngreatly reducing decoding time and memory consumption.",
      "pdf_url": "http://arxiv.org/pdf/2505.15684v2",
      "arxiv_url": "http://arxiv.org/abs/2505.15684v2",
      "published": "2025-05-21",
      "categories": [
        "cs.CL"
      ]
    }
  ]
}