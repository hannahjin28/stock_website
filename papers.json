{
  "last_updated": "2025-08-01T01:06:19.694992",
  "papers": [
    {
      "title": "A quantum experiment with joint exogeneity violation",
      "authors": [
        "Yuhao Wang",
        "Xingjian Zhang"
      ],
      "abstract": "In randomized experiments, the assumption of potential outcomes is usually\naccompanied by the \\emph{joint exogeneity} assumption. Although joint\nexogeneity has faced criticism as a counterfactual assumption since its\nproposal, no evidence has yet demonstrated its violation in randomized\nexperiments. In this paper, we reveal such a violation in a quantum experiment,\nthereby falsifying this assumption, at least in regimes where classical physics\ncannot provide a complete description. We further discuss its implications for\npotential outcome modelling, from both practial and philosophical perspectives.",
      "pdf_url": "http://arxiv.org/pdf/2507.22747v1",
      "arxiv_url": "http://arxiv.org/abs/2507.22747v1",
      "published": "2025-07-30",
      "categories": [
        "quant-ph",
        "math.ST",
        "physics.hist-ph",
        "stat.TH"
      ]
    },
    {
      "title": "Risk-inclusive Contextual Bandits for Early Phase Clinical Trials",
      "authors": [
        "Rohit Kanrar",
        "Chunlin Li",
        "Zara Ghodsi",
        "Margaret Gamalo"
      ],
      "abstract": "Early-phase clinical trials face the challenge of selecting optimal drug\ndoses that balance safety and efficacy due to uncertain dose-response\nrelationships and varied participant characteristics. Traditional randomized\ndose allocation often exposes participants to sub-optimal doses by not\nconsidering individual covariates, necessitating larger sample sizes and\nprolonging drug development. This paper introduces a risk-inclusive contextual\nbandit algorithm that utilizes multi-arm bandit (MAB) strategies to optimize\ndosing through participant-specific data integration. By combining two separate\nThompson samplers, one for efficacy and one for safety, the algorithm enhances\nthe balance between efficacy and safety in dose allocation. The effect sizes\nare estimated with a generalized version of asymptotic confidence sequences\n(AsympCS, Waudby-Smith et al., 2024), offering a uniform coverage guarantee for\nsequential causal inference over time. The validity of AsympCS is also\nestablished in the MAB setup with a possibly mis-specified model. The empirical\nresults demonstrate the strengths of this method in optimizing dose allocation\ncompared to randomized allocations and traditional contextual bandits focused\nsolely on efficacy. Moreover, an application on real data generated from a\nrecent Phase IIb study aligns with actual findings.",
      "pdf_url": "http://arxiv.org/pdf/2507.22344v1",
      "arxiv_url": "http://arxiv.org/abs/2507.22344v1",
      "published": "2025-07-30",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Dimension Reduction for Conditional Density Estimation with Applications to High-Dimensional Causal Inference",
      "authors": [
        "Jianhua Mei",
        "Fu Ouyang",
        "Thomas T. Yang"
      ],
      "abstract": "We propose a novel and computationally efficient approach for nonparametric\nconditional density estimation in high-dimensional settings that achieves\ndimension reduction without imposing restrictive distributional or functional\nform assumptions. To uncover the underlying sparsity structure of the data, we\ndevelop an innovative conditional dependence measure and a modified\ncross-validation procedure that enables data-driven variable selection, thereby\ncircumventing the need for subjective threshold selection. We demonstrate the\npractical utility of our dimension-reduced conditional density estimation by\napplying it to doubly robust estimators for average treatment effects. Notably,\nour proposed procedure is able to select relevant variables for nonparametric\npropensity score estimation and also inherently reduce the dimensionality of\noutcome regressions through a refined ignorability condition. We evaluate the\nfinite-sample properties of our approach through comprehensive simulation\nstudies and an empirical study on the effects of 401(k) eligibility on savings\nusing SIPP data.",
      "pdf_url": "http://arxiv.org/pdf/2507.22312v1",
      "arxiv_url": "http://arxiv.org/abs/2507.22312v1",
      "published": "2025-07-30",
      "categories": [
        "econ.EM"
      ]
    },
    {
      "title": "Hybrid Causal Identification and Causal Mechanism Clustering",
      "authors": [
        "Saixiong Liu",
        "Yuhua Qian",
        "Jue Li",
        "Honghong Cheng",
        "Feijiang Li"
      ],
      "abstract": "Bivariate causal direction identification is a fundamental and vital problem\nin the causal inference field. Among binary causal methods, most methods based\non additive noise only use one single causal mechanism to construct a causal\nmodel. In the real world, observations are always collected in different\nenvironments with heterogeneous causal relationships. Therefore, on observation\ndata, this paper proposes a Mixture Conditional Variational Causal Inference\nmodel (MCVCI) to infer heterogeneous causality. Specifically, according to the\nidentifiability of the Hybrid Additive Noise Model (HANM), MCVCI combines the\nsuperior fitting capabilities of the Gaussian mixture model and the neural\nnetwork and elegantly uses the likelihoods obtained from the probabilistic\nbounds of the mixture conditional variational auto-encoder as causal decision\ncriteria. Moreover, we model the casual heterogeneity into cluster numbers and\npropose the Mixture Conditional Variational Causal Clustering (MCVCC) method,\nwhich can reveal causal mechanism expression. Compared with state-of-the-art\nmethods, the comprehensive best performance demonstrates the effectiveness of\nthe methods proposed in this paper on several simulated and real data.",
      "pdf_url": "http://arxiv.org/pdf/2507.21792v1",
      "arxiv_url": "http://arxiv.org/abs/2507.21792v1",
      "published": "2025-07-29",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Towards Locally Deployable Fine-Tuned Causal Large Language Models for Mode Choice Behaviour",
      "authors": [
        "Tareq Alsaleh",
        "Bilal Farooq"
      ],
      "abstract": "This study investigates the adoption of open-access, locally deployable\ncausal large language models (LLMs) for travel mode choice prediction and\nintroduces LiTransMC, the first fine-tuned causal LLM developed for this task.\nWe systematically benchmark eleven LLMs (1-12B parameters) across three stated\nand revealed preference datasets, testing 396 configurations and generating\nover 79,000 synthetic commuter predictions. Beyond predictive accuracy, we\nevaluate models generated reasoning using BERTopic for topic modelling and a\nnovel Explanation Strength Index, providing the first structured analysis of\nhow LLMs articulate decision factors in alignment with behavioural theory.\nLiTransMC, fine-tuned using parameter efficient and loss masking strategy,\nachieved a weighted F1 score of 0.6845 and a Jensen-Shannon Divergence of\n0.000245, surpassing both untuned local models and larger proprietary systems,\nincluding GPT-4o with advanced persona inference and embedding-based loading,\nwhile also outperforming classical mode choice methods such as discrete choice\nmodels and machine learning classifiers for the same dataset. This dual\nimprovement, i.e., high instant-level accuracy and near-perfect distributional\ncalibration, demonstrates the feasibility of creating specialist, locally\ndeployable LLMs that integrate prediction and interpretability. Through\ncombining structured behavioural prediction with natural language reasoning,\nthis work unlocks the potential for conversational, multi-task transport models\ncapable of supporting agent-based simulations, policy testing, and behavioural\ninsight generation. These findings establish a pathway for transforming general\npurpose LLMs into specialized, explainable tools for transportation research\nand policy formulation, while maintaining privacy, reducing cost, and\nbroadening access through local deployment.",
      "pdf_url": "http://arxiv.org/pdf/2507.21432v1",
      "arxiv_url": "http://arxiv.org/abs/2507.21432v1",
      "published": "2025-07-29",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Personalized Treatment Effect Estimation from Unstructured Data",
      "authors": [
        "Henri Arno",
        "Thomas Demeester"
      ],
      "abstract": "Existing methods for estimating personalized treatment effects typically rely\non structured covariates, limiting their applicability to unstructured data.\nYet, leveraging unstructured data for causal inference has considerable\napplication potential, for instance in healthcare, where clinical notes or\nmedical images are abundant. To this end, we first introduce an approximate\n'plug-in' method trained directly on the neural representations of unstructured\ndata. However, when these fail to capture all confounding information, the\nmethod may be subject to confounding bias. We therefore introduce two\ntheoretically grounded estimators that leverage structured measurements of the\nconfounders during training, but allow estimating personalized treatment\neffects purely from unstructured inputs, while avoiding confounding bias. When\nthese structured measurements are only available for a non-representative\nsubset of the data, these estimators may suffer from sampling bias. To address\nthis, we further introduce a regression-based correction that accounts for the\nnon-uniform sampling, assuming the sampling mechanism is known or can be\nwell-estimated. Our experiments on two benchmark datasets show that the plug-in\nmethod, directly trainable on large unstructured datasets, achieves strong\nempirical performance across all settings, despite its simplicity.",
      "pdf_url": "http://arxiv.org/pdf/2507.20993v1",
      "arxiv_url": "http://arxiv.org/abs/2507.20993v1",
      "published": "2025-07-28",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "title": "Onboard Hyperspectral Super-Resolution with Deep Pushbroom Neural Network",
      "authors": [
        "Davide Piccinini",
        "Diego Valsesia",
        "Enrico Magli"
      ],
      "abstract": "Hyperspectral imagers on satellites obtain the fine spectral signatures\nessential for distinguishing one material from another at the expense of\nlimited spatial resolution. Enhancing the latter is thus a desirable\npreprocessing step in order to further improve the detection capabilities\noffered by hyperspectral images on downstream tasks. At the same time, there is\na growing interest towards deploying inference methods directly onboard of\nsatellites, which calls for lightweight image super-resolution methods that can\nbe run on the payload in real time. In this paper, we present a novel neural\nnetwork design, called Deep Pushbroom Super-Resolution (DPSR) that matches the\npushbroom acquisition of hyperspectral sensors by processing an image line by\nline in the along-track direction with a causal memory mechanism to exploit\npreviously acquired lines. This design greatly limits memory requirements and\ncomputational complexity, achieving onboard real-time performance, i.e., the\nability to super-resolve a line in the time it takes to acquire the next one,\non low-power hardware. Experiments show that the quality of the super-resolved\nimages is competitive or even outperforms state-of-the-art methods that are\nsignificantly more complex.",
      "pdf_url": "http://arxiv.org/pdf/2507.20765v1",
      "arxiv_url": "http://arxiv.org/abs/2507.20765v1",
      "published": "2025-07-28",
      "categories": [
        "eess.IV",
        "cs.CV"
      ]
    },
    {
      "title": "Causal Inference when Intervention Units and Outcome Units Differ",
      "authors": [
        "Georgia Papadogeorgou",
        "Zhaoyan Song",
        "Guido Imbens",
        "Fabrizia Mealli"
      ],
      "abstract": "We study causal inference in settings characterized by interference with a\nbipartite structure. There are two distinct sets of units: intervention units\nto which an intervention can be applied and outcome units on which the outcome\nof interest can be measured. Outcome units may be affected by interventions on\nsome, but not all, intervention units, as captured by a bipartite graph.\nExamples of this setting can be found in analyses of the impact of pollution\nabatement in plants on health outcomes for individuals, or the effect of\ntransportation network expansions on regional economic activity. We introduce\nand discuss a variety of old and new causal estimands for these bipartite\nsettings. We do not impose restrictions on the functional form of the exposure\nmapping and the potential outcomes, thus allowing for heterogeneity,\nnon-linearity, non-additivity, and potential interactions in treatment effects.\nWe propose unbiased weighting estimators for these estimands from a\ndesign-based perspective, based on the knowledge of the bipartite network under\ngeneral experimental designs. We derive their variance and prove consistency\nfor increasing number of outcome units. Using the Chinese high-speed rail\nconstruction study, analyzed in Borusyak and Hull [2023], we discuss\nnon-trivial positivity violations that depend on the estimands, the adopted\nexperimental design, and the structure of the bipartite graph.",
      "pdf_url": "http://arxiv.org/pdf/2507.20231v1",
      "arxiv_url": "http://arxiv.org/abs/2507.20231v1",
      "published": "2025-07-27",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Causal Inference for Circular Data",
      "authors": [
        "Kuan-Hsun Wu"
      ],
      "abstract": "In causal inference, a fundamental task is to estimate the effect resulting\nfrom a specific treatment, which is often handled with inverse probability\nweighting. Despite an abundance of attention to the advancement of this task,\nmost articles have focused on linear data rather than circular data, which are\nmeasured in angles. In this article, we extend the causal inference framework\nto accommodate circular data. Specifically, two new treatment effects, average\ndirection treatment effect (ADTE) and average length treatment effect (ALTE),\nare introduced to offer a proper causal explanation for these data. As the\naverage direction and average length describe the location and concentration of\na random sample of circular data, the ADTE and ALTE measure the change in\ndirection and length between two counterfactual outcomes. With inverse\nprobability weighting, we propose estimators that exhibit ideal theoretical\nproperties, which are validated by a simulation study. To illustrate the\npractical utility of our estimator, we analyze the effect of different job\ntypes on dispatchers' sleep patterns using data from Federal Railroad\nAdministration.",
      "pdf_url": "http://arxiv.org/pdf/2507.19889v2",
      "arxiv_url": "http://arxiv.org/abs/2507.19889v2",
      "published": "2025-07-26",
      "categories": [
        "stat.ME",
        "stat.AP"
      ]
    },
    {
      "title": "Adaptive Proximal Causal Inference with Some Invalid Proxies",
      "authors": [
        "Prabrisha Rakshit",
        "Xu Shi",
        "Eric Tchetgen Tchetgen"
      ],
      "abstract": "Proximal causal inference (PCI) is a recently proposed framework to identify\nand estimate the causal effect of an exposure on an outcome in the presence of\nhidden confounders, using observed proxies. Specifically, PCI relies on two\ntypes of proxies: a treatment-inducing confounding proxy, related to the\noutcome only through its association with unmeasured confounders (given\ntreatment and covariates), and an outcome-inducing confounding proxy, related\nto the treatment only through such association (given covariates). These\nproxies must satisfy stringent exclusion restrictions - namely, the treatment\nproxy must not affect the outcome, and the outcome proxy must not be affected\nby the treatment. To improve identification and potentially efficiency,\nmultiple proxies are often used, raising concerns about bias from exclusion\nviolations. To address this, we introduce necessary and sufficient conditions\nfor identifying causal effects in the presence of many proxies, some\npotentially invalid. Under a canonical proximal linear structural equations\nmodel, we propose a LASSO-based median estimator that jointly selects valid\nproxies and estimates the causal effect, with theoretical guarantees.\nRecognizing LASSO's limitations in consistently selecting valid treatment\nproxies, we develop an adaptive LASSO-based estimator with differential\npenalization. We show that it is root-n consistent and yields valid confidence\nintervals when a valid outcome proxy is available. We also extend the approach\nto settings with many potentially invalid outcome proxies. Theoretical results\nare supported by simulations and an application assessing the effect of right\nheart catheterization on 30-day survival in ICU patient.",
      "pdf_url": "http://arxiv.org/pdf/2507.19623v1",
      "arxiv_url": "http://arxiv.org/abs/2507.19623v1",
      "published": "2025-07-25",
      "categories": [
        "stat.ME"
      ]
    }
  ]
}