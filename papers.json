{
  "last_updated": "2025-11-23T01:01:14.585625",
  "papers": [
    {
      "title": "Possibilistic Instrumental Variable Regression",
      "authors": [
        "Gregor Steiner",
        "Jeremie Houssineau",
        "Mark F. J. Steel"
      ],
      "abstract": "Instrumental variable regression is a common approach for causal inference in the presence of unobserved confounding. However, identifying valid instruments is often difficult in practice. In this paper, we propose a novel method based on possibility theory that performs posterior inference on the treatment effect, conditional on a user-specified set of potential violations of the exogeneity assumption. Our method can provide informative results even when only a single, potentially invalid, instrument is available, offering a natural and principled framework for sensitivity analysis. Simulation experiments and a real-data application indicate strong performance of the proposed approach.",
      "pdf_url": "https://arxiv.org/pdf/2511.16029v1",
      "arxiv_url": "http://arxiv.org/abs/2511.16029v1",
      "published": "2025-11-20",
      "categories": [
        "stat.ME",
        "econ.EM",
        "math.ST"
      ]
    },
    {
      "title": "Bayesian Semiparametric Causal Inference: Targeted Doubly Robust Estimation of Treatment Effects",
      "authors": [
        "Gözde Sert",
        "Abhishek Chakrabortty",
        "Anirban Bhattacharya"
      ],
      "abstract": "We propose a semiparametric Bayesian methodology for estimating the average treatment effect (ATE) within the potential outcomes framework using observational data with high-dimensional nuisance parameters. Our method introduces a Bayesian debiasing procedure that corrects for bias arising from nuisance estimation and employs a targeted modeling strategy based on summary statistics rather than the full data. These summary statistics are identified in a debiased manner, enabling the estimation of nuisance bias via weighted observables and facilitating hierarchical learning of the ATE. By combining debiasing with sample splitting, our approach separates nuisance estimation from inference on the target parameter, reducing sensitivity to nuisance model specification. We establish that, under mild conditions, the marginal posterior for the ATE satisfies a Bernstein-von Mises theorem when both nuisance models are correctly specified and remains consistent and robust when only one is correct, achieving Bayesian double robustness. This ensures asymptotic efficiency and frequentist validity. Extensive simulations confirm the theoretical results, demonstrating accurate point estimation and credible intervals with nominal coverage, even in high-dimensional settings. The proposed framework can also be extended to other causal estimands, and its key principles offer a general foundation for advancing Bayesian semiparametric inference more broadly.",
      "pdf_url": "https://arxiv.org/pdf/2511.15904v1",
      "arxiv_url": "http://arxiv.org/abs/2511.15904v1",
      "published": "2025-11-19",
      "categories": [
        "stat.ME",
        "econ.EM",
        "math.ST",
        "stat.ML"
      ]
    },
    {
      "title": "Cross-Balancing for Data-Informed Design and Efficient Analysis of Observational Studies",
      "authors": [
        "Ying Jin",
        "José Zubizarreta"
      ],
      "abstract": "Causal inference starts with a simple idea: compare groups that differ by treatment, not much else. Traditionally, similar groups are constructed using only observed covariates; however, it remains a long-standing challenge to incorporate available outcome data into the study design while preserving valid inference. In this paper, we study the general problem of covariate adjustment, effect estimation, and statistical inference when balancing features are constructed or selected with the aid of outcome information from the data. We propose cross-balancing, a method that uses sample splitting to separate the error in feature construction from the error in weight estimation. Our framework addresses two cases: one where the features are learned functions and one where they are selected from a potentially high-dimensional dictionary. In both cases, we establish mild and general conditions under which cross-balancing produces consistent, asymptotically normal, and efficient estimators. In the learned-function case, cross-balancing achieves finite-sample bias reduction relative to plug-in-type estimators, and is multiply robust when the learned features converge at slow rates. In the variable-selection case, cross-balancing only requires a product condition on how well the selected variables approximate true functions. We illustrate cross-balancing in extensive simulations and an observational study, showing that careful use of outcome information can substantially improve both estimation and inference while maintaining interpretability.",
      "pdf_url": "https://arxiv.org/pdf/2511.15896v1",
      "arxiv_url": "http://arxiv.org/abs/2511.15896v1",
      "published": "2025-11-19",
      "categories": [
        "stat.ME",
        "math.ST",
        "stat.AP",
        "stat.ML"
      ]
    },
    {
      "title": "Causal Inference on Sequential Treatments via Tensor Completion",
      "authors": [
        "Chenyin Gao",
        "Han Chen",
        "Anru R. Zhang",
        "Shu Yang"
      ],
      "abstract": "Marginal Structural Models (MSMs) are popular for causal inference of sequential treatments in longitudinal observational studies, which however are sensitive to model misspecification. To achieve flexible modeling, we envision the potential outcomes to form a three-dimensional tensor indexed by subject, time, and treatment regime and propose a tensorized history-restricted MSM (HRMSM). The semi-parametric tensor factor model allows us to leverage the underlying low-rank structure of the potential outcomes tensor and exploit the pre-treatment covariate information to recover the counterfactual outcomes. We incorporate the inverse probability of treatment weighting in the loss function for tensor completion to adjust for time-varying confounding. Theoretically, a non-asymptotic upper bound on the Frobenius norm error for the proposed estimator is provided. Empirically, simulation studies show that the proposed tensor completion approach outperforms the parametric HRMSM and existing matrix/tensor completion methods. Finally, we illustrate the practical utility of the proposed approach to study the effect of ventilation on organ dysfunction from the Medical Information Mart for Intensive Care database.",
      "pdf_url": "https://arxiv.org/pdf/2511.15866v1",
      "arxiv_url": "http://arxiv.org/abs/2511.15866v1",
      "published": "2025-11-19",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Reflexive Evidence-Based Multimodal Learning for Clean Energy Transitions: Causal Insights on Cooking Fuel Access, Urbanization, and Carbon Emissions",
      "authors": [
        "Shan Shan"
      ],
      "abstract": "Achieving Sustainable Development Goal 7 (Affordable and Clean Energy) requires not only technological innovation but also a deeper understanding of the socioeconomic factors influencing energy access and carbon emissions. While these factors are gaining attention, critical questions remain, particularly regarding how to quantify their impacts on energy systems, model their cross-domain interactions, and capture feedback dynamics in the broader context of energy transitions. To address these gaps, this study introduces ClimateAgents, an AI-based framework that combines large language models with domain-specialized agents to support hypothesis generation and scenario exploration. Leveraging 20 years of socioeconomic and emissions data from 265 economies, countries and regions, and 98 indicators drawn from the World Bank database, the framework applies a machine learning based causal inference approach to identify key determinants of carbon emissions in an evidence-based, data driven manner. The analysis highlights three primary drivers: access to clean cooking fuels in rural areas, access to clean cooking fuels in urban areas, and the percentage of population living in urban areas. These findings underscore the critical role of clean cooking technologies and urbanization patterns in shaping emission outcomes. In line with growing calls for evidence-based AI policy, ClimateAgents offers a modular and reflexive learning system that supports the generation of credible and actionable insights for policy. By integrating heterogeneous data modalities, including structured indicators, policy documents, and semantic reasoning, the framework contributes to adaptive policymaking infrastructures that can evolve with complex socio-technical challenges. This approach aims to support a shift from siloed modeling to reflexive, modular systems designed for dynamic, context-aware climate action.",
      "pdf_url": "https://arxiv.org/pdf/2511.15342v1",
      "arxiv_url": "http://arxiv.org/abs/2511.15342v1",
      "published": "2025-11-19",
      "categories": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "title": "Causal Inference in Financial Event Studies",
      "authors": [
        "Paul Goldsmith-Pinkham",
        "Tianshu Lyu"
      ],
      "abstract": "Financial event studies, ubiquitous in finance research, typically use linear factor models with known factors to estimate abnormal returns and identify causal effects of information events. This paper demonstrates that when factor models are misspecified -- an almost certain reality -- traditional event study estimators produce inconsistent estimates of treatment effects. The bias is particularly severe during volatile periods, over long horizons, and when event timing correlates with market conditions. We derive precise conditions for identification and expressions for asymptotic bias. As an alternative, we propose synthetic control methods that construct replicating portfolios from control securities without imposing specific factor structures. Revisiting four empirical applications, we show that some established findings may reflect model misspecification rather than true treatment effects. While traditional methods remain reliable for short-horizon studies with random event timing, our results suggest caution when interpreting long-horizon or volatile-period event studies and highlight the importance of quasi-experimental designs when available.",
      "pdf_url": "https://arxiv.org/pdf/2511.15123v1",
      "arxiv_url": "http://arxiv.org/abs/2511.15123v1",
      "published": "2025-11-19",
      "categories": [
        "econ.EM",
        "econ.GN",
        "q-fin.GN"
      ]
    },
    {
      "title": "Individualized Prediction Bands in Causal Inference with Continuous Treatments",
      "authors": [
        "Max Sampson",
        "Kung-Sik Chan"
      ],
      "abstract": "Individualized treatments are crucial for optimal decision making and treatment allocation, specifically in personalized medicine based on the estimation of an individual's dose-response curve across a continuum of treatment levels, e.g., drug dosage. Current works focus on conditional mean and median estimates, which are useful but do not provide the full picture. We propose viewing causal inference with a continuous treatment as a covariate shift. This allows us to leverage existing weighted conformal prediction methods with both quantile and point estimates to compute individualized uncertainty quantification for dose-response curves. Our method, individualized prediction bands (IPB), is demonstrated via simulations and a real data analysis, which demonstrates the additional medical expenditure caused by continued smoking for selected individuals. The results demonstrate that IPB provides an effective solution to a gap in individual dose-response uncertainty quantification literature.",
      "pdf_url": "https://arxiv.org/pdf/2511.15075v1",
      "arxiv_url": "http://arxiv.org/abs/2511.15075v1",
      "published": "2025-11-19",
      "categories": [
        "stat.ME",
        "stat.AP"
      ]
    },
    {
      "title": "An Estimand-Focused Approach for AUC Estimation, Generalization, and Comparison: From Non-representative Samples to Target Population",
      "authors": [
        "Jiajun Liu",
        "Guangcai Mao",
        "Xiaofei Wang"
      ],
      "abstract": "The area under the ROC curve (AUC) is the standard measure of a biomarker's discriminatory accuracy; however, naive AUC estimates can be misleading when validation cohorts differ from the intended target population. Such covariate shifts commonly arise under biased or non-random sampling, distorting AUC estimations and thus impeding both generalization and cross-study comparison of AUC. We develop an estimand-focused framework for valid AUC estimation and benchmarking under covariate shift. Leveraging balancing ideas from causal inference, we extend calibration weighting to the U-statistic framework for AUC estimation and introduce a family of estimators that accommodate both summary-level and patient-level information; in certain specifications, some of these estimators attain double robustness. Furthermore, we establish asymptotic properties and study their performances across a spectrum of covariate shift severities and calibration choices in comprehensive simulations. Finally, we demonstrate practical utility in the POWER trials by evaluating how baseline stair-climb power (SCP) predicts 6-month survival among advanced non-small-cell lung cancer (NSCLC) patients. Together, the results provide a principled toolkit for anchoring biomarker AUCs to clinically relevant target populations and for comparing them fairly across studies despite distributional differences.",
      "pdf_url": "https://arxiv.org/pdf/2511.14992v1",
      "arxiv_url": "http://arxiv.org/abs/2511.14992v1",
      "published": "2025-11-19",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Integrating Causal Inference with Graph Neural Networks for Alzheimer's Disease Analysis",
      "authors": [
        "Pranay Kumar Peddi",
        "Dhrubajyoti Ghosh"
      ],
      "abstract": "Deep graph learning has advanced Alzheimer's (AD) disease classification from MRI, but most models remain correlational, confounding demographic and genetic factors with disease specific features. We present Causal-GCN, an interventional graph convolutional framework that integrates do-calculus-based back-door adjustment to identify brain regions exerting stable causal influence on AD progression. Each subject's MRI is represented as a structural connectome where nodes denote cortical and subcortical regions and edges encode anatomical connectivity. Confounders such as age, sec, and APOE4 genotype are summarized via principal components and included in the causal adjustment set. After training, interventions on individual regions are simulated by serving their incoming edges and altering node features to estimate average causal effects on disease probability. Applied to 484 subjects from the ADNI cohort, Causal-GCN achieves performance comparable to baseline GNNs while providing interpretable causal effect rankings that highlight posterior, cingulate, and insular hubs consistent with established AD neuropathology.",
      "pdf_url": "https://arxiv.org/pdf/2511.14922v1",
      "arxiv_url": "http://arxiv.org/abs/2511.14922v1",
      "published": "2025-11-18",
      "categories": [
        "cs.LG",
        "stat.ME"
      ]
    },
    {
      "title": "Uncovering Treatment Effect Heterogeneity in Pragmatic Gerontology Trials",
      "authors": [
        "Changjun Li",
        "Heather Allore",
        "Michael O. Harhay",
        "Fan Li",
        "Guangyu Tong"
      ],
      "abstract": "Detecting heterogeneity in treatment response enriches the interpretation of gerontologic trials. In aging research, estimating the effect of the intervention on clinically meaningful outcomes faces analytical challenges when it is truncated by death. For example, in the Whole Systems Demonstrator trial, a large cluster-randomized study evaluating telecare among older adults, the overall effect of the intervention on quality of life was found to be null. However, this marginal intervention estimate obscures potential heterogeneity of individuals responding to the intervention, particularly among those who survive to the end of follow-up. To explore this heterogeneity, we adopt a causal framework grounded in principal stratification, targeting the Survivor Average Causal Effect (SACE)-the treatment effect among \"always-survivors,\" or those who would survive regardless of treatment assignment. We extend this framework using Bayesian Additive Regression Trees (BART), a nonparametric machine learning method, to flexibly model both latent principal strata and stratum-specific potential outcomes. This enables the estimation of the Conditional SACE (CSACE), allowing us to uncover variation in treatment effects across subgroups defined by baseline characteristics. Our analysis reveals that despite the null average effect, some subgroups experience distinct quality of life benefits (or lack thereof) from telecare, highlighting opportunities for more personalized intervention strategies. This study demonstrates how embedding machine learning methods, such as BART, within a principled causal inference framework can offer deeper insights into trial data with complex features including truncation by death and clustering-key considerations in analyzing pragmatic gerontology trials.",
      "pdf_url": "https://arxiv.org/pdf/2511.14893v1",
      "arxiv_url": "http://arxiv.org/abs/2511.14893v1",
      "published": "2025-11-18",
      "categories": [
        "stat.AP",
        "stat.ME"
      ]
    }
  ]
}