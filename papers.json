{
  "last_updated": "2025-07-08T00:56:08.397665",
  "papers": [
    {
      "title": "FlowSpec: Continuous Pipelined Speculative Decoding for Efficient Distributed LLM Inference",
      "authors": [
        "Xing Liu",
        "Lizhuo Luo",
        "Ming Tang",
        "Chao Huang"
      ],
      "abstract": "Distributed inference serves as a promising approach to enabling the\ninference of large language models (LLMs) at the network edge. It distributes\nthe inference process to multiple devices to ensure that the LLMs can fit into\nthe device memory. Recent pipeline-based approaches have the potential to\nparallelize communication and computation, which helps reduce inference\nlatency. However, the benefit diminishes when the inference request at the\nnetwork edge is sparse, where pipeline is typically at low utilization. To\nenable efficient distributed LLM inference at the edge, we propose\n\\textbf{FlowSpec}, a pipeline-parallel tree-based speculative decoding\nframework. FlowSpec incorporates three key mechanisms to improve decoding\nefficiency: 1) score-based step-wise verification prioritizes more important\ndraft tokens to bring earlier accpeted tokens; 2) efficient draft management to\nprune invalid tokens while maintaining correct causal relationship during\nverification; 3) dynamic draft expansion strategies to supply high-quality\nspeculative inputs. These techniques work in concert to enhance both pipeline\nutilization and speculative efficiency. We evaluate FlowSpec on a real-world\ntestbed with other baselines. Experimental results demonstrate that our\nproposed framework significantly improves inference speed across diverse models\nand configurations, achieving speedup ratios 1.36$\\times$-1.77$\\times$ compared\nto baselines. Our code is publicly available at\n\\href{https://github.com/Leosang-lx/FlowSpec#}{https://github.com/Leosang-lx/FlowSpec\\#}",
      "pdf_url": "http://arxiv.org/pdf/2507.02620v1",
      "arxiv_url": "http://arxiv.org/abs/2507.02620v1",
      "published": "2025-07-03",
      "categories": [
        "cs.DC",
        "cs.AI"
      ]
    },
    {
      "title": "Nonlinear Network Reconstruction by Pairwise Time-delayed Transfer Entropy",
      "authors": [
        "Kai Chen",
        "Zhong-qi K. Tian",
        "Yifei Chen",
        "Songting Li",
        "Douglas Zhou"
      ],
      "abstract": "Analyzing network structural connectivity is crucial for understanding\ndynamics and functions of complex networks across disciplines. In many\nnetworks, structural connectivity is not observable, which requires to be\ninferred via causal inference methods. Among them, transfer entropy (TE) is one\nof the most broadly applied causality measure due to its model-free property.\nHowever, TE often faces the curse of dimensionality in high-dimensional\nprobability estimation, and the relation between the inferred causal\nconnectivity and the underlying structural connectivity remains poorly\nunderstood. Here we address these issues by proposing a pairwise time-delayed\ntransfer entropy (PTD-TE) method. We theoretically establish a quadratic\nrelationship between PTD-TE values and node coupling strengths, and demonstrate\nits immunity to dimensionality issues and broad applicability. Tests on\nbiological neuronal networks, nonlinear physical systems, and\nelectrophysiological data show PTD-TE achieves consistent, high-performance\nreconstructions. Compared to a bunch of existing approaches for network\nconnectivity reconstruction, PTD-TE outperforms these methods across various\nnetwork systems in accuracy and robustness against noise. Our framework\nprovides a scalable, model-agnostic tool for structural connectivity inference\nin nonlinear real-world networks.",
      "pdf_url": "http://arxiv.org/pdf/2507.02304v1",
      "arxiv_url": "http://arxiv.org/abs/2507.02304v1",
      "published": "2025-07-03",
      "categories": [
        "q-bio.NC"
      ]
    },
    {
      "title": "It's Hard to Be Normal: The Impact of Noise on Structure-agnostic Estimation",
      "authors": [
        "Jikai Jin",
        "Lester Mackey",
        "Vasilis Syrgkanis"
      ],
      "abstract": "Structure-agnostic causal inference studies how well one can estimate a\ntreatment effect given black-box machine learning estimates of nuisance\nfunctions (like the impact of confounders on treatment and outcomes). Here, we\nfind that the answer depends in a surprising way on the distribution of the\ntreatment noise. Focusing on the partially linear model of\n\\citet{robinson1988root}, we first show that the widely adopted double machine\nlearning (DML) estimator is minimax rate-optimal for Gaussian treatment noise,\nresolving an open problem of \\citet{mackey2018orthogonal}. Meanwhile, for\nindependent non-Gaussian treatment noise, we show that DML is always suboptimal\nby constructing new practical procedures with higher-order robustness to\nnuisance errors. These \\emph{ACE} procedures use structure-agnostic cumulant\nestimators to achieve $r$-th order insensitivity to nuisance errors whenever\nthe $(r+1)$-st treatment cumulant is non-zero. We complement these core results\nwith novel minimax guarantees for binary treatments in the partially linear\nmodel. Finally, using synthetic demand estimation experiments, we demonstrate\nthe practical benefits of our higher-order robust estimators.",
      "pdf_url": "http://arxiv.org/pdf/2507.02275v1",
      "arxiv_url": "http://arxiv.org/abs/2507.02275v1",
      "published": "2025-07-03",
      "categories": [
        "stat.ML",
        "cs.LG",
        "econ.EM",
        "math.ST",
        "stat.ME",
        "stat.TH"
      ]
    },
    {
      "title": "Reasoning to Edit: Hypothetical Instruction-Based Image Editing with Visual Reasoning",
      "authors": [
        "Qingdong He",
        "Xueqin Chen",
        "Chaoyi Wang",
        "Yanjie Pan",
        "Xiaobin Hu",
        "Zhenye Gan",
        "Yabiao Wang",
        "Chengjie Wang",
        "Xiangtai Li",
        "Jiangning Zhang"
      ],
      "abstract": "Instruction-based image editing (IIE) has advanced rapidly with the success\nof diffusion models. However, existing efforts primarily focus on simple and\nexplicit instructions to execute editing operations such as adding, deleting,\nmoving, or swapping objects. They struggle to handle more complex implicit\nhypothetical instructions that require deeper reasoning to infer plausible\nvisual changes and user intent. Additionally, current datasets provide limited\nsupport for training and evaluating reasoning-aware editing capabilities.\nArchitecturally, these methods also lack mechanisms for fine-grained detail\nextraction that support such reasoning. To address these limitations, we\npropose Reason50K, a large-scale dataset specifically curated for training and\nevaluating hypothetical instruction reasoning image editing, along with\nReasonBrain, a novel framework designed to reason over and execute implicit\nhypothetical instructions across diverse scenarios. Reason50K includes over 50K\nsamples spanning four key reasoning scenarios: Physical, Temporal, Causal, and\nStory reasoning. ReasonBrain leverages Multimodal Large Language Models (MLLMs)\nfor editing guidance generation and a diffusion model for image synthesis,\nincorporating a Fine-grained Reasoning Cue Extraction (FRCE) module to capture\ndetailed visual and textual semantics essential for supporting instruction\nreasoning. To mitigate the semantic loss, we further introduce a Cross-Modal\nEnhancer (CME) that enables rich interactions between the fine-grained cues and\nMLLM-derived features. Extensive experiments demonstrate that ReasonBrain\nconsistently outperforms state-of-the-art baselines on reasoning scenarios\nwhile exhibiting strong zero-shot generalization to conventional IIE tasks. Our\ndataset and code will be released publicly.",
      "pdf_url": "http://arxiv.org/pdf/2507.01908v1",
      "arxiv_url": "http://arxiv.org/abs/2507.01908v1",
      "published": "2025-07-02",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "HOI-Dyn: Learning Interaction Dynamics for Human-Object Motion Diffusion",
      "authors": [
        "Lin Wu",
        "Zhixiang Chen",
        "Jianglin Lan"
      ],
      "abstract": "Generating realistic 3D human-object interactions (HOIs) remains a\nchallenging task due to the difficulty of modeling detailed interaction\ndynamics. Existing methods treat human and object motions independently,\nresulting in physically implausible and causally inconsistent behaviors. In\nthis work, we present HOI-Dyn, a novel framework that formulates HOI generation\nas a driver-responder system, where human actions drive object responses. At\nthe core of our method is a lightweight transformer-based interaction dynamics\nmodel that explicitly predicts how objects should react to human motion. To\nfurther enforce consistency, we introduce a residual-based dynamics loss that\nmitigates the impact of dynamics prediction errors and prevents misleading\noptimization signals. The dynamics model is used only during training,\npreserving inference efficiency. Through extensive qualitative and quantitative\nexperiments, we demonstrate that our approach not only enhances the quality of\nHOI generation but also establishes a feasible metric for evaluating the\nquality of generated interactions.",
      "pdf_url": "http://arxiv.org/pdf/2507.01737v2",
      "arxiv_url": "http://arxiv.org/abs/2507.01737v2",
      "published": "2025-07-02",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "Relational Causal Discovery with Latent Confounders",
      "authors": [
        "Andrea Piras",
        "Matteo Negro",
        "Ragib Ahsan",
        "David Arbour",
        "Elena Zheleva"
      ],
      "abstract": "Estimating causal effects from real-world relational data can be challenging\nwhen the underlying causal model and potential confounders are unknown. While\nseveral causal discovery algorithms exist for learning causal models with\nlatent confounders from data, they assume that the data is independent and\nidentically distributed (i.i.d.) and are not well-suited for learning from\nrelational data. Similarly, existing relational causal discovery algorithms\nassume causal sufficiency, which is unrealistic for many real-world datasets.\nTo address this gap, we propose RelFCI, a sound and complete causal discovery\nalgorithm for relational data with latent confounders. Our work builds upon the\nFast Causal Inference (FCI) and Relational Causal Discovery (RCD) algorithms\nand it defines new graphical models, necessary to support causal discovery in\nrelational domains. We also establish soundness and completeness guarantees for\nrelational d-separation with latent confounders. We present experimental\nresults demonstrating the effectiveness of RelFCI in identifying the correct\ncausal structure in relational causal models with latent confounders.",
      "pdf_url": "http://arxiv.org/pdf/2507.01700v1",
      "arxiv_url": "http://arxiv.org/abs/2507.01700v1",
      "published": "2025-07-02",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "rdhte: Conditional Average Treatment Effects in RD Designs",
      "authors": [
        "Sebastian Calonico",
        "Matias D. Cattaneo",
        "Max H. Farrell",
        "Filippo Palomba",
        "Rocio Titiunik"
      ],
      "abstract": "Understanding causal heterogeneous treatment effects based on pretreatment\ncovariates is a crucial aspect of empirical work. Building on Calonico,\nCattaneo, Farrell, Palomba, and Titiunik (2025), this article discusses the\nsoftware package rdhte for estimation and inference of heterogeneous treatment\neffects in sharp regression discontinuity (RD) designs. The package includes\nthree main commands: rdhte conducts estimation and robust bias-corrected\ninference for heterogeneous RD treatment effects, for a given choice of the\nbandwidth parameter; rdbwhte implements automatic bandwidth selection methods;\nand rdhte lincom computes point estimates and robust bias-corrected confidence\nintervals for linear combinations, a post-estimation command specifically\ntailored to rdhte. We also provide an overview of heterogeneous effects for\nsharp RD designs, give basic details on the methodology, and illustrate using\nan empirical application. Finally, we discuss how the package rdhte\ncomplements, and in specific cases recovers, the canonical RD package rdrobust\n(Calonico, Cattaneo, Farrell, and Titiunik 2017).",
      "pdf_url": "http://arxiv.org/pdf/2507.01128v1",
      "arxiv_url": "http://arxiv.org/abs/2507.01128v1",
      "published": "2025-07-01",
      "categories": [
        "econ.EM"
      ]
    },
    {
      "title": "Bayesian analysis of the causal reference-based model for missing data in clinical trials",
      "authors": [
        "Brendah Nansereko",
        "Marcel Wolbers",
        "James Carpenter",
        "Jonathan Bartlett"
      ],
      "abstract": "The statistical analysis of clinical trials is often complicated by missing\ndata. Patients sometimes experience intercurrent events (ICEs), which usually\n(although not always) lead to missing subsequent outcome measurements for such\nindividuals. The reference-based imputation methods were proposed by Carpenter\net al. (2013) and have been commonly adopted for handling missing data due to\nICEs when estimating treatment policy strategy estimands. Conventionally, the\nvariance for reference-based estimators was obtained using Rubin's rules.\nHowever, Rubin's rules variance estimator is biased compared to the repeated\nsampling variance of the point estimator, due to uncongeniality. Repeated\nsampling variance estimators were proposed as an alternative to variance\nestimation for reference-based estimators. However, these have the property\nthat they decrease as the proportion of ICEs increases. White et al. (2019)\nintroduced a causal model incorporating the concept of a 'maintained treatment\neffect' following the occurrence of ICEs and showed that this causal model\nincluded common reference-based estimators as special cases. Building on this\nframework, we propose introducing a prior distribution for the maintained\neffect parameter to account for uncertainty in this assumption. Our approach\nprovides inference for reference-based estimators that explicitly reflects our\nuncertainty about how much treatment effects are maintained after the\noccurrence of ICEs. In trials where no or little post-ICE data are observed,\nour proposed Bayesian reference-based causal model approach can be used to\nestimate the treatment policy treatment effect, incorporating uncertainty about\nthe reference-based assumption. We compare the frequentist properties of this\napproach with existing reference-based methods through simulations and by\napplication to an antidepressant trial.",
      "pdf_url": "http://arxiv.org/pdf/2507.00680v2",
      "arxiv_url": "http://arxiv.org/abs/2507.00680v2",
      "published": "2025-07-01",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Quantum Bayesian inference with Suport vector states for intrusion detection",
      "authors": [
        "Nayema Mridha",
        "Garrv Sipani",
        "Eva R Gaarder",
        "Shah Haque",
        "Radhika Kuttala",
        "Binay P Akhouri",
        "Mohamad M Al Zein",
        "Eric Howard"
      ],
      "abstract": "We present a quantum Bayesian inference method for intrusion detection, using\nexplicitly constructed quantum circuits and statevector simulation. Prior and\nconditional probabilities are encoded via unitary gates, and posterior\ndistributions are extracted through symbolic post-selection. Applied to a\nscenario with network spikes, system vulnerabilities, and false alarms, the\nmethod yields joint, marginal, and conditional probabilities aligned with\ncausal structure. Our results demonstrate the feasibility and interpretability\nof quantum-native inference for information security applications",
      "pdf_url": "http://arxiv.org/pdf/2507.00403v1",
      "arxiv_url": "http://arxiv.org/abs/2507.00403v1",
      "published": "2025-07-01",
      "categories": [
        "quant-ph"
      ]
    },
    {
      "title": "Causal Prompting for Implicit Sentiment Analysis with Large Language Models",
      "authors": [
        "Jing Ren",
        "Wenhao Zhou",
        "Bowen Li",
        "Mujie Liu",
        "Nguyen Linh Dan Le",
        "Jiade Cen",
        "Liping Chen",
        "Ziqi Xu",
        "Xiwei Xu",
        "Xiaodong Li"
      ],
      "abstract": "Implicit Sentiment Analysis (ISA) aims to infer sentiment that is implied\nrather than explicitly stated, requiring models to perform deeper reasoning\nover subtle contextual cues. While recent prompting-based methods using Large\nLanguage Models (LLMs) have shown promise in ISA, they often rely on majority\nvoting over chain-of-thought (CoT) reasoning paths without evaluating their\ncausal validity, making them susceptible to internal biases and spurious\ncorrelations. To address this challenge, we propose CAPITAL, a causal prompting\nframework that incorporates front-door adjustment into CoT reasoning. CAPITAL\ndecomposes the overall causal effect into two components: the influence of the\ninput prompt on the reasoning chains, and the impact of those chains on the\nfinal output. These components are estimated using encoder-based clustering and\nthe NWGM approximation, with a contrastive learning objective used to better\nalign the encoder's representation with the LLM's reasoning space. Experiments\non benchmark ISA datasets with three LLMs demonstrate that CAPITAL consistently\noutperforms strong prompting baselines in both accuracy and robustness,\nparticularly under adversarial conditions. This work offers a principled\napproach to integrating causal inference into LLM prompting and highlights its\nbenefits for bias-aware sentiment reasoning. The source code and case study are\navailable at: https://github.com/whZ62/CAPITAL.",
      "pdf_url": "http://arxiv.org/pdf/2507.00389v1",
      "arxiv_url": "http://arxiv.org/abs/2507.00389v1",
      "published": "2025-07-01",
      "categories": [
        "cs.CL"
      ]
    }
  ]
}