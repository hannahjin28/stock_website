{
  "last_updated": "2025-06-30T00:59:04.132665",
  "papers": [
    {
      "title": "Causal inference via implied interventions",
      "authors": [
        "Carlos Garc√≠a Meixide",
        "Mark J. van der Laan"
      ],
      "abstract": "In the context of having an instrumental variable, the standard practice in\ncausal inference begins by targeting an effect of interest and proceeds by\nformulating assumptions enabling identification of this effect. We turn this\naround by simply not making assumptions anymore and just adhere to the\ninterventions we can identify, rather than starting with a desired causal\nestimand and imposing untestable hypotheses. The randomization of an instrument\nand its exclusion restriction define a class of auxiliary stochastic\ninterventions on the treatment that are implied by stochastic interventions on\nthe instrument. This mapping effectively characterizes the identifiable causal\neffects of the treatment on the outcome given the observable probability\ndistribution, leading to an explicit transparent G-computation formula under\nhidden confounding. Alternatively, searching for an intervention on the\ninstrument whose implied one best approximates a desired target -- whose causal\neffect the user aims to estimate -- naturally leads to a projection on a\nfunction space representing the closest identifiable treatment effect. The\ngenerality of this projection allows to select different norms and indexing\nsets for the function class that turn optimization into different estimation\nprocedures with the Highly Adaptive Lasso. This shift from identification under\nassumptions to identification under observation redefines how the problem of\ncausal inference is approached.",
      "pdf_url": "http://arxiv.org/pdf/2506.21501v1",
      "arxiv_url": "http://arxiv.org/abs/2506.21501v1",
      "published": "2025-06-26",
      "categories": [
        "math.ST",
        "stat.TH"
      ]
    },
    {
      "title": "Counterfactual Voting Adjustment for Quality Assessment and Fairer Voting in Online Platforms with Helpfulness Evaluation",
      "authors": [
        "Chang Liu",
        "Yixin Wang",
        "Moontae Lee"
      ],
      "abstract": "Efficient access to high-quality information is vital for online platforms.\nTo promote more useful information, users not only create new content but also\nevaluate existing content, often through helpfulness voting. Although\naggregated votes help service providers rank their user content, these votes\nare often biased by disparate accessibility per position and the cascaded\ninfluence of prior votes. For a fairer assessment of information quality, we\npropose the Counterfactual Voting Adjustment (CVA), a causal framework that\naccounts for the context in which individual votes are cast. Through\npreliminary and semi-synthetic experiments, we show that CVA effectively models\nthe position and herding biases, accurately recovering the predefined content\nquality. In a real experiment, we demonstrate that reranking content based on\nthe learned quality by CVA exhibits stronger alignment with both user sentiment\nand quality evaluation assessed by GPT-4o, outperforming system rankings based\non aggregated votes and model-based rerankings without causal inference. Beyond\nthe individual quality inference, our embeddings offer comparative insights\ninto the behavioral dynamics of expert user groups across 120 major\nStackExchange communities.",
      "pdf_url": "http://arxiv.org/pdf/2506.21362v1",
      "arxiv_url": "http://arxiv.org/abs/2506.21362v1",
      "published": "2025-06-26",
      "categories": [
        "cs.CE"
      ]
    },
    {
      "title": "Active Inference AI Systems for Scientific Discovery",
      "authors": [
        "Karthik Duraisamy"
      ],
      "abstract": "The rapid evolution of artificial intelligence has led to expectations of\ntransformative scientific discovery, yet current systems remain fundamentally\nlimited by their operational architectures, brittle reasoning mechanisms, and\ntheir separation from experimental reality. Building on earlier work, we\ncontend that progress in AI-driven science now depends on closing three\nfundamental gaps -- the abstraction gap, the reasoning gap, and the reality gap\n-- rather than on model size/data/test time compute. Scientific reasoning\ndemands internal representations that support simulation of actions and\nresponse, causal structures that distinguish correlation from mechanism, and\ncontinuous calibration. We define active inference AI systems for scientific\ndiscovery as those that (i) maintain long-lived research memories grounded in\ncausal self-supervised foundation models, (ii) symbolic or neuro-symbolic\nplanners equipped with Bayesian guardrails, (iii) grow persistent knowledge\ngraphs where thinking generates novel conceptual nodes, reasoning establishes\ncausal edges, and real-world interaction prunes false connections while\nstrengthening verified pathways, and (iv) refine their internal representations\nthrough closed-loop interaction with both high-fidelity simulators and\nautomated laboratories - an operational loop where mental simulation guides\naction and empirical surprise reshapes understanding. In essence, we outline an\narchitecture where discovery arises from the interplay between internal models\nthat enable counterfactual reasoning and external validation that grounds\nhypotheses in reality. It is also argued that the inherent ambiguity in\nfeedback from simulations and experiments, and underlying uncertainties makes\nhuman judgment indispensable, not as a temporary scaffold but as a permanent\narchitectural component.",
      "pdf_url": "http://arxiv.org/pdf/2506.21329v1",
      "arxiv_url": "http://arxiv.org/abs/2506.21329v1",
      "published": "2025-06-26",
      "categories": [
        "cs.AI",
        "physics.soc-ph",
        "68",
        "I.2"
      ]
    },
    {
      "title": "Influence and information in a collective of self-propelled particles",
      "authors": [
        "Jiahuan Pang",
        "Wendong Wang"
      ],
      "abstract": "While information-theoretic quantities, such as transfer entropy, have been\nwidely adopted to infer causal relationships in collective systems, a critical\ngap exists: the absence of quantitative evidence directly linking\ninformation-theoretic quantities to a physically defined influence. This letter\naddresses this gap by proposing a modified Vicsek model that enables the\ncalculation of a physically interpretable influence grounded in the angular\ninteractions between particles. Averaged pairwise influences can serve as new\norder parameters to indicate collective phase transitions. We reveal\nquantitative relations between information, represented by transfer entropy,\nand average influence in pairwise and collective interactions. We test three\ntypical methods of partial information decomposition and find that the method\nbased on intrinsic mutual information gives the most appropriate\ninterpretation. Overall, this work provides a model system for quantitative\nstudies of influence and information in complex systems.",
      "pdf_url": "http://arxiv.org/pdf/2506.20888v1",
      "arxiv_url": "http://arxiv.org/abs/2506.20888v1",
      "published": "2025-06-25",
      "categories": [
        "cond-mat.stat-mech",
        "nlin.AO"
      ]
    },
    {
      "title": "A Bayesian Nonparametric Approach for Semi-Competing Risks with Application to Cardiovascular Health",
      "authors": [
        "Karina Gelis-Cadena",
        "Michael Daniels",
        "Juned Siddique"
      ],
      "abstract": "We address causal estimation in semi-competing risks settings, where a\nnon-terminal event may be precluded by one or more terminal events. We define a\nprincipal-stratification causal estimand for treatment effects on the\nnon-terminal event, conditional on surviving past a specified landmark time. To\nestimate joint event-time distributions, we employ both vine-copula\nconstructions and Bayesian nonparametric Enriched Dirichlet-process mixtures\n(EDPM), enabling inference under minimal parametric assumptions. We index our\ncausal assumptions with sensitivity parameters. Posterior summaries via MCMC\nyield interpretable estimates with credible intervals. We illustrate the\nproposed method using data from a cardiovascular health study.",
      "pdf_url": "http://arxiv.org/pdf/2506.20860v1",
      "arxiv_url": "http://arxiv.org/abs/2506.20860v1",
      "published": "2025-06-25",
      "categories": [
        "stat.ME",
        "stat.AP"
      ]
    },
    {
      "title": "DiffuCoder: Understanding and Improving Masked Diffusion Models for Code Generation",
      "authors": [
        "Shansan Gong",
        "Ruixiang Zhang",
        "Huangjie Zheng",
        "Jiatao Gu",
        "Navdeep Jaitly",
        "Lingpeng Kong",
        "Yizhe Zhang"
      ],
      "abstract": "Diffusion large language models (dLLMs) are compelling alternatives to\nautoregressive (AR) models because their denoising models operate over the\nentire sequence. The global planning and iterative refinement features of dLLMs\nare particularly useful for code generation. However, current training and\ninference mechanisms for dLLMs in coding are still under-explored. To demystify\nthe decoding behavior of dLLMs and unlock their potential for coding, we\nsystematically investigate their denoising processes and reinforcement learning\n(RL) methods. We train a 7B dLLM, \\textbf{DiffuCoder}, on 130B tokens of code.\nUsing this model as a testbed, we analyze its decoding behavior, revealing how\nit differs from that of AR models: (1) dLLMs can decide how causal their\ngeneration should be without relying on semi-AR decoding, and (2) increasing\nthe sampling temperature diversifies not only token choices but also their\ngeneration order. This diversity creates a rich search space for RL rollouts.\nFor RL training, to reduce the variance of token log-likelihood estimates and\nmaintain training efficiency, we propose \\textbf{coupled-GRPO}, a novel\nsampling scheme that constructs complementary mask noise for completions used\nin training. In our experiments, coupled-GRPO significantly improves\nDiffuCoder's performance on code generation benchmarks (+4.4\\% on EvalPlus) and\nreduces reliance on AR bias during decoding. Our work provides deeper insight\ninto the machinery of dLLM generation and offers an effective, diffusion-native\nRL training framework. https://github.com/apple/ml-diffucoder.",
      "pdf_url": "http://arxiv.org/pdf/2506.20639v2",
      "arxiv_url": "http://arxiv.org/abs/2506.20639v2",
      "published": "2025-06-25",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "title": "Causal Inference for Latent Outcomes Learned with Factor Models",
      "authors": [
        "Jenna M. Landy",
        "Dafne Zorzetto",
        "Roberta De Vito",
        "Giovanni Parmigiani"
      ],
      "abstract": "In many fields$\\unicode{x2013}$including genomics, epidemiology, natural\nlanguage processing, social and behavioral sciences, and\neconomics$\\unicode{x2013}$it is increasingly important to address causal\nquestions in the context of factor models or representation learning. In this\nwork, we investigate causal effects on $\\textit{latent outcomes}$ derived from\nhigh-dimensional observed data using nonnegative matrix factorization. To the\nbest of our knowledge, this is the first study to formally address causal\ninference in this setting. A central challenge is that estimating a latent\nfactor model can cause an individual's learned latent outcome to depend on\nother individuals' treatments, thereby violating the standard causal inference\nassumption of no interference. We formalize this issue as\n$\\textit{learning-induced interference}$ and distinguish it from interference\npresent in a data-generating process. To address this, we propose a novel,\nintuitive, and theoretically grounded algorithm to estimate causal effects on\nlatent outcomes while mitigating learning-induced interference and improving\nestimation efficiency. We establish theoretical guarantees for the consistency\nof our estimator and demonstrate its practical utility through simulation\nstudies and an application to cancer mutational signature analysis. All\nbaseline and proposed methods are available in our open-source R package, ${\\tt\ncausalLFO}$.",
      "pdf_url": "http://arxiv.org/pdf/2506.20549v2",
      "arxiv_url": "http://arxiv.org/abs/2506.20549v2",
      "published": "2025-06-25",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Anytime-Valid Inference in Adaptive Experiments: Covariate Adjustment and Balanced Power",
      "authors": [
        "Daniel Molitor",
        "Samantha Gold"
      ],
      "abstract": "Adaptive experiments have become central to modern experimental design,\nenabling researchers to efficiently identify optimal treatments, improve\nstatistical power, and maximize respondent welfare. However, adaptive\nexperiments compromise valid inference and leave sub-optimal treatments\nunderpowered. We introduce two methodological advances for adaptive\nexperimentation. First, covariate-adjusted Mixture Adaptive Design (MADCovar)\nachieves substantial improvements in average treatment effect (ATE) precision\nby incorporating covariate adjustment within an anytime-valid inference\nframework. Second, power-modified MAD (MADMod) reallocates sample to\nunderpowered treatment arms, improving statistical power across all treatments\nwhile maintaining error control. Both methods provide anytime-valid guarantees,\nenabling continuous monitoring without inflating Type 1 error rates. Simulation\nstudies and empirical analyses demonstrate that MADCovar delivers significant\nprecision gains and that MADMod ensures robust inference even for suboptimal\ntreatments. Together, these methods address key limitations of adaptive\nexperiments and equip researchers with practical tools for precise and reliable\ncausal inference. Our proposed methods are implemented through an open-source\nsoftware package.",
      "pdf_url": "http://arxiv.org/pdf/2506.20523v1",
      "arxiv_url": "http://arxiv.org/abs/2506.20523v1",
      "published": "2025-06-25",
      "categories": [
        "stat.ME",
        "econ.EM",
        "stat.CO"
      ]
    },
    {
      "title": "The Role of Partisan Culture in Mental Health Language Online",
      "authors": [
        "Sachin R. Pendse",
        "Ben Rochford",
        "Neha Kumar",
        "Munmun De Choudhury"
      ],
      "abstract": "The impact of culture on how people express distress in online support\ncommunities is increasingly a topic of interest within Computer Supported\nCooperative Work (CSCW) and Human-Computer Interaction (HCI). In the United\nStates, distinct cultures have emerged from each of the two dominant political\nparties, forming a primary lens by which people navigate online and offline\nworlds. We examine whether partisan culture may play a role in how U.S.\nRepublican and Democrat users of online mental health support communities\nexpress distress. We present a large-scale observational study of 2,184,356\nposts from 8,916 statistically matched Republican, Democrat, and unaffiliated\nonline support community members. We utilize methods from causal inference to\nstatistically match partisan users along covariates that correspond with\ndemographic attributes and platform use, in order to create comparable cohorts\nfor analysis. We then leverage methods from natural language processing to\nunderstand how partisan expressions of distress compare between these sets of\nclosely matched opposing partisans, and between closely matched partisans and\ntypical support community members. Our data spans January 2013 to December\n2022, a period of both rising political polarization and mental health\nconcerns. We find that partisan culture does play into expressions of distress,\nunderscoring the importance of considering partisan cultural differences in the\ndesign of online support community platforms.",
      "pdf_url": "http://arxiv.org/pdf/2506.20377v1",
      "arxiv_url": "http://arxiv.org/abs/2506.20377v1",
      "published": "2025-06-25",
      "categories": [
        "cs.HC",
        "cs.CY",
        "cs.SI"
      ]
    },
    {
      "title": "Causal Operator Discovery in Partial Differential Equations via Counterfactual Physics-Informed Neural Networks",
      "authors": [
        "Ronald Katende"
      ],
      "abstract": "We develop a principled framework for discovering causal structure in partial\ndifferential equations (PDEs) using physics-informed neural networks and\ncounterfactual perturbations. Unlike classical residual minimization or sparse\nregression methods, our approach quantifies operator-level necessity through\nfunctional interventions on the governing dynamics. We introduce causal\nsensitivity indices and structural deviation metrics to assess the influence of\ncandidate differential operators within neural surrogates. Theoretically, we\nprove exact recovery of the causal operator support under restricted isometry\nor mutual coherence conditions, with residual bounds guaranteeing\nidentifiability. Empirically, we validate the framework on both synthetic and\nreal-world datasets across climate dynamics, tumor diffusion, and ocean flows.\nOur method consistently recovers governing operators even under noise,\nredundancy, and data scarcity, outperforming standard PINNs and DeepONets in\nstructural fidelity. This work positions causal PDE discovery as a tractable\nand interpretable inference task grounded in structural causal models and\nvariational residual analysis.",
      "pdf_url": "http://arxiv.org/pdf/2506.20181v1",
      "arxiv_url": "http://arxiv.org/abs/2506.20181v1",
      "published": "2025-06-25",
      "categories": [
        "cs.LG",
        "cs.NA",
        "math.NA"
      ]
    }
  ]
}