{
  "last_updated": "2025-10-28T00:51:04.782460",
  "papers": [
    {
      "title": "Resilient Radio Access Networks: AI and the Unknown Unknowns",
      "authors": [
        "Bho Matthiesen",
        "Armin Dekorsy",
        "Petar Popovski"
      ],
      "abstract": "5G networks offer exceptional reliability and availability, ensuring\nconsistent performance and user satisfaction. Yet they might still fail when\nconfronted with the unexpected. A resilient system is able to adapt to\nreal-world complexity, including operating conditions completely unanticipated\nduring system design. This makes resilience a vital attribute for communication\nsystems that must sustain service in scenarios where models are absent or too\nintricate to provide statistical guarantees. Such considerations indicate that\nartifical intelligence (AI) will play a major role in delivering resilience. In\nthis paper, we examine the challenges of designing AIs for resilient radio\naccess networks, especially with respect to unanticipated and rare disruptions.\nOur theoretical results indicate strong limitations of current statistical\nlearning methods for resilience and suggest connections to online learning and\ncausal inference.",
      "pdf_url": "http://arxiv.org/pdf/2510.21587v1",
      "arxiv_url": "http://arxiv.org/abs/2510.21587v1",
      "published": "2025-10-24",
      "categories": [
        "cs.IT",
        "math.IT"
      ]
    },
    {
      "title": "Handling Missing Responses under Cluster Dependence with Applications to Language Model Evaluation",
      "authors": [
        "Zhenghao Zeng",
        "David Arbour",
        "Avi Feller",
        "Ishita Dasgupta",
        "Atanu R Sinha",
        "Edward H. Kennedy"
      ],
      "abstract": "Human annotations play a crucial role in evaluating the performance of GenAI\nmodels. Two common challenges in practice, however, are missing annotations\n(the response variable of interest) and cluster dependence among human-AI\ninteractions (e.g., questions asked by the same user may be highly correlated).\nReliable inference must address both these issues to achieve unbiased\nestimation and appropriately quantify uncertainty when estimating average\nscores from human annotations. In this paper, we analyze the doubly robust\nestimator, a widely used method in missing data analysis and causal inference,\napplied to this setting and establish novel theoretical properties under\ncluster dependence. We further illustrate our findings through simulations and\na real-world conversation quality dataset. Our theoretical and empirical\nresults underscore the importance of incorporating cluster dependence in\nmissing response problems to perform valid statistical inference.",
      "pdf_url": "http://arxiv.org/pdf/2510.20928v1",
      "arxiv_url": "http://arxiv.org/abs/2510.20928v1",
      "published": "2025-10-23",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Generative Reasoning Recommendation via LLMs",
      "authors": [
        "Minjie Hong",
        "Zetong Zhou",
        "Zirun Guo",
        "Ziang Zhang",
        "Ruofan Hu",
        "Weinan Gan",
        "Jieming Zhu",
        "Zhou Zhao"
      ],
      "abstract": "Despite their remarkable reasoning capabilities across diverse domains, large\nlanguage models (LLMs) face fundamental challenges in natively functioning as\ngenerative reasoning recommendation models (GRRMs), where the intrinsic\nmodeling gap between textual semantics and collaborative filtering signals,\ncombined with the sparsity and stochasticity of user feedback, presents\nsignificant obstacles. This work explores how to build GRRMs by adapting\npre-trained LLMs, which achieves a unified understanding-reasoning-prediction\nmanner for recommendation tasks. We propose GREAM, an end-to-end framework that\nintegrates three components: (i) Collaborative-Semantic Alignment, which fuses\nheterogeneous textual evidence to construct semantically consistent, discrete\nitem indices and auxiliary alignment tasks that ground linguistic\nrepresentations in interaction semantics; (ii) Reasoning Curriculum Activation,\nwhich builds a synthetic dataset with explicit Chain-of-Thought supervision and\na curriculum that progresses through behavioral evidence extraction, latent\npreference modeling, intent inference, recommendation formulation, and denoised\nsequence rewriting; and (iii) Sparse-Regularized Group Policy Optimization\n(SRPO), which stabilizes post-training via Residual-Sensitive Verifiable Reward\nand Bonus-Calibrated Group Advantage Estimation, enabling end-to-end\noptimization under verifiable signals despite sparse successes. GREAM natively\nsupports two complementary inference modes: Direct Sequence Recommendation for\nhigh-throughput, low-latency deployment, and Sequential Reasoning\nRecommendation that first emits an interpretable reasoning chain for causal\ntransparency. Experiments on three datasets demonstrate consistent gains over\nstrong baselines, providing a practical path toward verifiable-RL-driven LLM\nrecommenders.",
      "pdf_url": "http://arxiv.org/pdf/2510.20815v1",
      "arxiv_url": "http://arxiv.org/abs/2510.20815v1",
      "published": "2025-10-23",
      "categories": [
        "cs.IR"
      ]
    },
    {
      "title": "Better Tokens for Better 3D: Advancing Vision-Language Modeling in 3D Medical Imaging",
      "authors": [
        "Ibrahim Ethem Hamamci",
        "Sezgin Er",
        "Suprosanna Shit",
        "Hadrien Reynaud",
        "Dong Yang",
        "Pengfei Guo",
        "Marc Edgar",
        "Daguang Xu",
        "Bernhard Kainz",
        "Bjoern Menze"
      ],
      "abstract": "Recent progress in vision-language modeling for 3D medical imaging has been\nfueled by large-scale computed tomography (CT) corpora with paired free-text\nreports, stronger architectures, and powerful pretrained models. This has\nenabled applications such as automated report generation and text-conditioned\n3D image synthesis. Yet, current approaches struggle with high-resolution,\nlong-sequence volumes: contrastive pretraining often yields vision encoders\nthat are misaligned with clinical language, and slice-wise tokenization blurs\nfine anatomy, reducing diagnostic performance on downstream tasks. We introduce\nBTB3D (Better Tokens for Better 3D), a causal convolutional encoder-decoder\nthat unifies 2D and 3D training and inference while producing compact,\nfrequency-aware volumetric tokens. A three-stage training curriculum enables\n(i) local reconstruction, (ii) overlapping-window tiling, and (iii)\nlong-context decoder refinement, during which the model learns from short slice\nexcerpts yet generalizes to scans exceeding 300 slices without additional\nmemory overhead. BTB3D sets a new state-of-the-art on two key tasks: it\nimproves BLEU scores and increases clinical F1 by 40% over CT2Rep, CT-CHAT, and\nMerlin for report generation; and it reduces FID by 75% and halves FVD compared\nto GenerateCT and MedSyn for text-to-CT synthesis, producing anatomically\nconsistent 512*512*241 volumes. These results confirm that precise\nthree-dimensional tokenization, rather than larger language backbones alone, is\nessential for scalable vision-language modeling in 3D medical imaging. The\ncodebase is available at: https://github.com/ibrahimethemhamamci/BTB3D",
      "pdf_url": "http://arxiv.org/pdf/2510.20639v1",
      "arxiv_url": "http://arxiv.org/abs/2510.20639v1",
      "published": "2025-10-23",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "On Multiple Robustness of Proximal Dynamic Treatment Regimes",
      "authors": [
        "Yuanshan Gao",
        "Yang Bai",
        "Yifan Cui"
      ],
      "abstract": "Dynamic treatment regimes are sequential decision rules that adapt treatment\naccording to individual time-varying characteristics and outcomes to achieve\noptimal effects, with applications in precision medicine, personalized\nrecommendations, and dynamic marketing. Estimating optimal dynamic treatment\nregimes via sequential randomized trials might face costly and ethical hurdles,\noften necessitating the use of historical observational data. In this work, we\nutilize proximal causal inference framework for learning optimal dynamic\ntreatment regimes when the unconfoundedness assumption fails. Our contributions\nare four-fold: (i) we propose three nonparametric identification methods for\noptimal dynamic treatment regimes; (ii) we establish the semiparametric\nefficiency bound for the value function of a given regime; (iii) we propose a\n(K+1)-robust method for learning optimal dynamic treatment regimes, where K is\nthe number of stages; (iv) as a by-product for marginal structural models, we\nestablish identification and estimation of counterfactual means under a static\nregime. Numerical experiments validate the efficiency and multiple robustness\nof our proposed methods.",
      "pdf_url": "http://arxiv.org/pdf/2510.20451v1",
      "arxiv_url": "http://arxiv.org/abs/2510.20451v1",
      "published": "2025-10-23",
      "categories": [
        "stat.ME",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ]
    },
    {
      "title": "Identification and Debiased Learning of Causal Effects with General Instrumental Variables",
      "authors": [
        "Shuyuan Chen",
        "Peng Zhang",
        "Yifan Cui"
      ],
      "abstract": "Instrumental variable methods are fundamental to causal inference when\ntreatment assignment is confounded by unobserved variables. In this article, we\ndevelop a general nonparametric framework for identification and learning with\nmulti-categorical or continuous instrumental variables. Specifically, we\npropose an additive instrumental variable framework to identify mean potential\noutcomes and the average treatment effect with a weighting function. Leveraging\nsemiparametric theory, we derive efficient influence functions and construct\nconsistent, asymptotically normal estimators via debiased machine learning.\nExtensions to longitudinal data, dynamic treatment regimes, and multiplicative\ninstrumental variables are further developed. We demonstrate the proposed\nmethod by employing simulation studies and analyzing real data from the Job\nTraining Partnership Act program.",
      "pdf_url": "http://arxiv.org/pdf/2510.20404v1",
      "arxiv_url": "http://arxiv.org/abs/2510.20404v1",
      "published": "2025-10-23",
      "categories": [
        "stat.ME",
        "econ.EM",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ]
    },
    {
      "title": "Incentivizing Consistent, Effective and Scalable Reasoning Capability in Audio LLMs via Reasoning Process Rewards",
      "authors": [
        "Jiajun Fan",
        "Roger Ren",
        "Jingyuan Li",
        "Rahul Pandey",
        "Prashanth Gurunath Shivakumar",
        "Ivan Bulyko",
        "Ankur Gandhe",
        "Ge Liu",
        "Yile Gu"
      ],
      "abstract": "The role of reasoning in Audio Large Language Models remains widely\nunderexplored, as introducing a reasoning process often degrades rather than\nimproves performance during inference, a phenomenon we term test-time inverse\nscaling, where longer reasoning chains yield progressively worse results. We\ndemonstrate that this stems not from fundamental limitations of reasoning\nitself, but from inadequate training: models without proper guidance for the\nreasoning process produce hallucinatory, inconsistent reasoning that\naccumulates errors over longer chains. To address these challenges, we\nintroduce CESAR (Consistent, Effective, and Scalable Audio Reasoners), shifting\nfrom outcome verification to rewarding the reasoning process. Our online\nreinforcement learning framework employs Group Relative Policy Optimization\nwith a multi-faceted reward suite that incentivizes not only correctness and\nformat but also consistency, structured analytical patterns, causal reasoning,\ndomain-knowledge integration, and calibrated reasoning depth. CESAR resolves\ntest-time inverse scaling, transforming reasoning from detriments into gains\nwhile revealing model-specific ``reasoning sweet spots\", where performance\npeaks during test-time scaling. We achieve state-of-the-art results on MMAU\nTest-mini, substantially outperforming Gemini 2.5 Pro and GPT-4o Audio, and\nnear-human-level performance on MMSU reasoning tasks. Through AI-as-judge\nevaluations and qualitative comparisons, we provide both quantitative and\nqualitative validation of our improved reasoning quality. Importantly, enhanced\nreasoning creates synergistic effects, simultaneously improving multimodal\nreasoning and perception capabilities. Overall, CESAR establishes a principled\nmethod for developing robust and scalable reasoning in Audio LLMs.",
      "pdf_url": "http://arxiv.org/pdf/2510.20867v1",
      "arxiv_url": "http://arxiv.org/abs/2510.20867v1",
      "published": "2025-10-23",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Bias-Variance Tradeoff of Matching Prior to Difference-in-Differences When Parallel Trends is Violated",
      "authors": [
        "Mingxuan Ge",
        "Dae Woong Ham"
      ],
      "abstract": "Quasi-experimental causal inference methods have become central in empirical\noperations management (OM) for guiding managerial decisions. Among these,\nempiricists utilize the Difference-in-Differences (DiD) estimator, which relies\non the parallel trends assumption. To improve its plausibility, researchers\noften match treated and control units before applying DiD, with the intuition\nthat matched groups are more likely to evolve similarly absent treatment.\nExisting work that analyze this practice, however, has focused solely on bias.\nWe complement and fill an important gap by analyzing the full bias-variance\ntradeoff. Under a linear structural model with unobserved time-varying\nconfounders, we show that variance results contrast with established bias\ninsights: matching on observed covariates prior to DiD is not always\nrecommended over the classic (unmatched) DiD due to a sample size tradeoff;\nfurthermore, matching additionally on pre-treatment outcomes is always\nbeneficial as such tradeoff no longer exists once matching is performed. We\ntherefore advocate mean squared error (MSE) as a final metric and give\npractitioner-friendly guidelines with theoretical guarantees on when (and on\nwhat variables) they should match on. We apply these insights to a recent study\non how the introduction of monetary incentives by a knowledge-sharing platform\naffects its general engagement and show that the authors' matching choice prior\nto DiD was both warranted and critical. In particular, we provide new\nmanagerial insights that after a full bias correction, their estimated effect\nwith matching still remains statistically significant, demonstrating that the\nchosen matching-DiD approach is sufficiently robust to address managerial\nconcerns over violations of parallel trends.",
      "pdf_url": "http://arxiv.org/pdf/2510.20191v1",
      "arxiv_url": "http://arxiv.org/abs/2510.20191v1",
      "published": "2025-10-23",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Treatment Effect Learning Under Sequential Randomization",
      "authors": [
        "Rina Friedberg",
        "Richard Mudd",
        "Patrick Johnstone",
        "Melissa Pothen",
        "Vishal Vaingankar",
        "Vishwanath Sangale",
        "Abbas Zaidi"
      ],
      "abstract": "Sequential treatment assignments in online experiments lead to complex\ndependency structures, often rendering identification, estimation and inference\nover treatments a challenge. Treatments in one session (e.g., a user logging\non) can have an effect that persists into subsequent sessions, leading to\ncumulative effects on outcomes measured at a later stage. This can render\nstandard methods for identification and inference trivially misspecified. We\npropose T-Learners layered into the G-Formula for this setting, building on\nliterature from causal machine learning and identification in sequential\nsettings. In a simple simulation, this approach prevents decaying accuracy in\nthe presence of carry-over effects, highlighting the importance of\nidentification and inference strategies tailored to the nature of systems often\nseen in the tech domain.",
      "pdf_url": "http://arxiv.org/pdf/2510.20078v1",
      "arxiv_url": "http://arxiv.org/abs/2510.20078v1",
      "published": "2025-10-22",
      "categories": [
        "stat.AP",
        "stat.ME"
      ]
    },
    {
      "title": "LLM-Augmented Symbolic NLU System for More Reliable Continuous Causal Statement Interpretation",
      "authors": [
        "Xin Lian",
        "Kenneth D. Forbus"
      ],
      "abstract": "Despite the broad applicability of large language models (LLMs), their\nreliance on probabilistic inference makes them vulnerable to errors such as\nhallucination in generated facts and inconsistent output structure in natural\nlanguage understanding (NLU) tasks. By contrast, symbolic NLU systems provide\ninterpretable understanding grounded in curated lexicons, semantic resources,\nand syntactic & semantic interpretation rules. They produce relational\nrepresentations that can be used for accurate reasoning and planning, as well\nas incremental debuggable learning. However, symbolic NLU systems tend to be\nmore limited in coverage than LLMs and require scarce knowledge representation\nand linguistics skills to extend and maintain. This paper explores a hybrid\napproach that integrates the broad-coverage language processing of LLMs with\nthe symbolic NLU capabilities of producing structured relational\nrepresentations to hopefully get the best of both approaches. We use LLMs for\nrephrasing and text simplification, to provide broad coverage, and as a source\nof information to fill in knowledge gaps more automatically. We use symbolic\nNLU to produce representations that can be used for reasoning and for\nincremental learning. We evaluate this approach on the task of extracting and\ninterpreting quantities and causal laws from commonsense science texts, along\nwith symbolic- and LLM-only pipelines. Our results suggest that our hybrid\nmethod works significantly better than the symbolic-only pipeline.",
      "pdf_url": "http://arxiv.org/pdf/2510.19988v1",
      "arxiv_url": "http://arxiv.org/abs/2510.19988v1",
      "published": "2025-10-22",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    }
  ]
}