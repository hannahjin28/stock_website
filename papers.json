{
  "last_updated": "2026-02-04T01:07:36.184787",
  "papers": [
    {
      "title": "C-kNN-LSH: A Nearest-Neighbor Algorithm for Sequential Counterfactual Inference",
      "authors": [
        "Jing Wang",
        "Jie Shen",
        "Qiaomin Xie",
        "Jeremy C Weiss"
      ],
      "abstract": "Estimating causal effects from longitudinal trajectories is central to understanding the progression of complex conditions and optimizing clinical decision-making, such as comorbidities and long COVID recovery. We introduce \\emph{C-kNN--LSH}, a nearest-neighbor framework for sequential causal inference designed to handle such high-dimensional, confounded situations. By utilizing locality-sensitive hashing, we efficiently identify ``clinical twins'' with similar covariate histories, enabling local estimation of conditional treatment effects across evolving disease states. To mitigate bias from irregular sampling and shifting patient recovery profiles, we integrate neighborhood estimator with a doubly-robust correction.\n  Theoretical analysis guarantees our estimator is consistent and second-order robust to nuisance error.\n  Evaluated on a real-world Long COVID cohort with 13,511 participants, \\emph{C-kNN-LSH} demonstrates superior performance in capturing recovery heterogeneity and estimating policy values compared to existing baselines.",
      "pdf_url": "https://arxiv.org/pdf/2602.02371v1",
      "arxiv_url": "http://arxiv.org/abs/2602.02371v1",
      "published": "2026-02-02",
      "categories": [
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "title": "Causal Inference for Preprocessed Outcomes with an Application to Functional Connectivity",
      "authors": [
        "Zihang Wang",
        "Razieh Nabi",
        "Benjamin B. Risk"
      ],
      "abstract": "In biomedical research, repeated measurements within each subject are often processed to remove artifacts and unwanted sources of variation. The resulting data are used to construct derived outcomes that act as proxies for scientific outcomes that are not directly observable. Although intra-subject processing is widely used, its impact on inter-subject statistical inference has not been systematically studied, and a principled framework for causal analysis in this setting is lacking. In this article, we propose a semiparametric framework for causal inference with derived outcomes obtained after intra-subject processing. This framework applies to settings with a modular structure, where intra-subject analyses are conducted independently across subjects and are followed by inter-subject analyses based on parameters from the intra-subject stage. We develop multiply robust estimators of causal parameters under rate conditions on both intra-subject and inter-subject models, which allows the use of flexible machine learning. We specialize the framework to a mediation setting and focus on the natural direct effect. For high dimensional inference, we employ a step-down procedure that controls the exceedance rate of the false discovery proportion. Simulation studies demonstrate the superior performance of the proposed approach. We apply our method to estimate the impact of stimulant medication on brain connectivity in children with autism spectrum disorder.",
      "pdf_url": "https://arxiv.org/pdf/2602.02240v1",
      "arxiv_url": "http://arxiv.org/abs/2602.02240v1",
      "published": "2026-02-02",
      "categories": [
        "stat.ME",
        "stat.ML"
      ]
    },
    {
      "title": "Posterior Uncertainty for Targeted Parameters in Bayesian Bootstrap Procedures",
      "authors": [
        "Magid Sabbagh",
        "David A. Stephens"
      ],
      "abstract": "We propose a general method to carry out a valid Bayesian analysis of a finite-dimensional `targeted' parameter in the presence of a finite-dimensional nuisance parameter. We apply our methods to causal inference based on estimating equations. While much of the literature in Bayesian causal inference has relied on the conventional 'likelihood times prior' framework, a recently proposed method, the 'Linked Bayesian Bootstrap', deviated from this classical setting to obtain valid Bayesian inference using the Dirichlet process and the Bayesian bootstrap. These methods rely on an adjustment based on the propensity score and explain how to handle the uncertainty concerning it when studying the posterior distribution of a treatment effect. We examine theoretically the asymptotic properties of the posterior distribution obtained and show that our proposed method, a generalized version of the 'Linked Bayesian Bootstrap', enjoys desirable frequentist properties. In addition, we show that the credible intervals have asymptotically the correct coverage properties. We discuss the applications of our method to mis-specified and singly-robust models in causal inference.",
      "pdf_url": "https://arxiv.org/pdf/2602.02216v1",
      "arxiv_url": "http://arxiv.org/abs/2602.02216v1",
      "published": "2026-02-02",
      "categories": [
        "stat.ME",
        "math.ST",
        "stat.CO"
      ]
    },
    {
      "title": "Fact or Fake? Assessing the Role of Deepfake Detectors in Multimodal Misinformation Detection",
      "authors": [
        "A S M Sharifuzzaman Sagar",
        "Mohammed Bennamoun",
        "Farid Boussaid",
        "Naeha Sharif",
        "Lian Xu",
        "Shaaban Sahmoud",
        "Ali Kishk"
      ],
      "abstract": "In multimodal misinformation, deception usually arises not just from pixel-level manipulations in an image, but from the semantic and contextual claim jointly expressed by the image-text pair. Yet most deepfake detectors, engineered to detect pixel-level forgeries, do not account for claim-level meaning, despite their growing integration in automated fact-checking (AFC) pipelines. This raises a central scientific and practical question: Do pixel-level detectors contribute useful signal for verifying image-text claims, or do they instead introduce misleading authenticity priors that undermine evidence-based reasoning? We provide the first systematic analysis of deepfake detectors in the context of multimodal misinformation detection. Using two complementary benchmarks, MMFakeBench and DGM4, we evaluate: (1) state-of-the-art image-only deepfake detectors, (2) an evidence-driven fact-checking system that performs tool-guided retrieval via Monte Carlo Tree Search (MCTS) and engages in deliberative inference through Multi-Agent Debate (MAD), and (3) a hybrid fact-checking system that injects detector outputs as auxiliary evidence. Results across both benchmark datasets show that deepfake detectors offer limited standalone value, achieving F1 scores in the range of 0.26-0.53 on MMFakeBench and 0.33-0.49 on DGM4, and that incorporating their predictions into fact-checking pipelines consistently reduces performance by 0.04-0.08 F1 due to non-causal authenticity assumptions. In contrast, the evidence-centric fact-checking system achieves the highest performance, reaching F1 scores of approximately 0.81 on MMFakeBench and 0.55 on DGM4. Overall, our findings demonstrate that multimodal claim verification is driven primarily by semantic understanding and external evidence, and that pixel-level artifact signals do not reliably enhance reasoning over real-world image-text misinformation.",
      "pdf_url": "https://arxiv.org/pdf/2602.01854v1",
      "arxiv_url": "http://arxiv.org/abs/2602.01854v1",
      "published": "2026-02-02",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "No Generation without Representation: Efficient Causal Protein Language Models Enable Zero-Shot Fitness Estimation",
      "authors": [
        "Furkan Eris"
      ],
      "abstract": "Protein language models (PLMs) face a fundamental divide: masked language models (MLMs) excel at fitness prediction while causal models enable generation, forcing practitioners to maintain separate architectures. We introduce \\textbf{Proust}, a 309M-parameter causal PLM that bridges this gap through architectural innovations adapted from recent LLM research, including grouped-query attention with shared K/V projections, cross-layer value residuals, and depthwise causal convolutions. Trained on 33B tokens in 40 B200 GPU-hours, Proust achieves Spearman $œÅ= 0.390$ on ProteinGym substitutions, competitive with MLMs requiring 50--200$\\times$ the compute. On indels, Proust sets a new state-of-the-art, outperforming models up to 20$\\times$ larger. On EVEREST viral fitness benchmarks, it approaches structure-aware methods using sequence alone. These powerful representations position Proust in a sweet spot as it also retains native generative capabilities that MLMs lack by design. Interpretability analysis reveals that per-position entropy variance predicts, to an extent, when retrieval augmentation helps and hurts. Such insights can grow in both quantity and quality at scale and inform capabilities such as test-time scaling. Code and weights are available at https://github.com/Furkan9015/proust-inference",
      "pdf_url": "https://arxiv.org/pdf/2602.01845v1",
      "arxiv_url": "http://arxiv.org/abs/2602.01845v1",
      "published": "2026-02-02",
      "categories": [
        "cs.LG",
        "q-bio.QM"
      ]
    },
    {
      "title": "Optimizing Prompts for Large Language Models: A Causal Approach",
      "authors": [
        "Wei Chen",
        "Yanbin Fang",
        "Shuran Fu",
        "Fasheng Xu",
        "Xuan Wei"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly embedded in enterprise workflows, yet their performance remains highly sensitive to prompt design. Automatic Prompt Optimization (APO) seeks to mitigate this instability, but existing approaches face two persistent challenges. First, commonly used prompt strategies rely on static instructions that perform well on average but fail to adapt to heterogeneous queries. Second, more dynamic approaches depend on offline reward models that are fundamentally correlational, confounding prompt effectiveness with query characteristics. We propose Causal Prompt Optimization (CPO), a framework that reframes prompt design as a problem of causal estimation. CPO operates in two stages. First, it learns an offline causal reward model by applying Double Machine Learning (DML) to semantic embeddings of prompts and queries, isolating the causal effect of prompt variations from confounding query attributes. Second, it utilizes this unbiased reward signal to guide a resource-efficient search for query-specific prompts without relying on costly online evaluation. We evaluate CPO across benchmarks in mathematical reasoning, visualization, and data analytics. CPO consistently outperforms human-engineered prompts and state-of-the-art automated optimizers. The gains are driven primarily by improved robustness on hard queries, where existing methods tend to deteriorate. Beyond performance, CPO fundamentally reshapes the economics of prompt optimization: by shifting evaluation from real-time model execution to an offline causal model, it enables high-precision, per-query customization at a fraction of the inference cost required by online methods. Together, these results establish causal inference as a scalable foundation for reliable and cost-efficient prompt optimization in enterprise LLM deployments.",
      "pdf_url": "https://arxiv.org/pdf/2602.01711v1",
      "arxiv_url": "http://arxiv.org/abs/2602.01711v1",
      "published": "2026-02-02",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Difference-in-Differences under Local Dependence on Networks",
      "authors": [
        "Akihiro Sato",
        "Shonosuke Sugasawa"
      ],
      "abstract": "Estimating causal effects under interference, where the stable unit treatment value assumption is violated, is critical in fields such as regional and public economics. Much of the existing research on causal inference under interference relies on a pre-specified \"exposure mapping\". This paper focuses on difference-in-difference and proposes a nonparametric identification strategy for direct and indirect average treatment effects under local interference on an observed network. In particular, we proposed a new concept of an indirect effect measuring the total outward influence of the intervension. Based on parallel trends assumption conditional on the neighborhood treatment vector, we develop inverse probability weighted and doubly robust estimators. We establish their asymptotic properties, including consistency under misspecification of nuisance models under some regularity conditions. Simulation studies and an empirical application demonstrate the effectiveness of the proposed method.",
      "pdf_url": "https://arxiv.org/pdf/2602.01631v1",
      "arxiv_url": "http://arxiv.org/abs/2602.01631v1",
      "published": "2026-02-02",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Causal Preference Elicitation",
      "authors": [
        "Edwin V. Bonilla",
        "He Zhao",
        "Daniel M. Steinberg"
      ],
      "abstract": "We propose causal preference elicitation, a Bayesian framework for expert-in-the-loop causal discovery that actively queries local edge relations to concentrate a posterior over directed acyclic graphs (DAGs). From any black-box observational posterior, we model noisy expert judgments with a three-way likelihood over edge existence and direction. Posterior inference uses a flexible particle approximation, and queries are selected by an efficient expected information gain criterion on the expert's categorical response. Experiments on synthetic graphs, protein signaling data, and a human gene perturbation benchmark show faster posterior concentration and improved recovery of directed effects under tight query budgets.",
      "pdf_url": "https://arxiv.org/pdf/2602.01483v1",
      "arxiv_url": "http://arxiv.org/abs/2602.01483v1",
      "published": "2026-02-01",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME"
      ]
    },
    {
      "title": "DCD: Decomposition-based Causal Discovery from Autocorrelated and Non-Stationary Temporal Data",
      "authors": [
        "Muhammad Hasan Ferdous",
        "Md Osman Gani"
      ],
      "abstract": "Multivariate time series in domains such as finance, climate science, and healthcare often exhibit long-term trends, seasonal patterns, and short-term fluctuations, complicating causal inference under non-stationarity and autocorrelation. Existing causal discovery methods typically operate on raw observations, making them vulnerable to spurious edges and misattributed temporal dependencies. We introduce a decomposition-based causal discovery framework that separates each time series into trend, seasonal, and residual components and performs component-specific causal analysis. Trend components are assessed using stationarity tests, seasonal components using kernel-based dependence measures, and residual components using constraint-based causal discovery. The resulting component-level graphs are integrated into a unified multi-scale causal structure. This approach isolates long- and short-range causal effects, reduces spurious associations, and improves interpretability. Across extensive synthetic benchmarks and real-world climate data, our framework more accurately recovers ground-truth causal structure than state-of-the-art baselines, particularly under strong non-stationarity and temporal autocorrelation.",
      "pdf_url": "https://arxiv.org/pdf/2602.01433v1",
      "arxiv_url": "http://arxiv.org/abs/2602.01433v1",
      "published": "2026-02-01",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "title": "An Odd Estimator for Shapley Values",
      "authors": [
        "Fabian Fumagalli",
        "Landon Butler",
        "Justin Singh Kang",
        "Kannan Ramchandran",
        "R. Teal Witter"
      ],
      "abstract": "The Shapley value is a ubiquitous framework for attribution in machine learning, encompassing feature importance, data valuation, and causal inference. However, its exact computation is generally intractable, necessitating efficient approximation methods. While the most effective and popular estimators leverage the paired sampling heuristic to reduce estimation error, the theoretical mechanism driving this improvement has remained opaque. In this work, we provide an elegant and fundamental justification for paired sampling: we prove that the Shapley value depends exclusively on the odd component of the set function, and that paired sampling orthogonalizes the regression objective to filter out the irrelevant even component. Leveraging this insight, we propose OddSHAP, a novel consistent estimator that performs polynomial regression solely on the odd subspace. By utilizing the Fourier basis to isolate this subspace and employing a proxy model to identify high-impact interactions, OddSHAP overcomes the combinatorial explosion of higher-order approximations. Through an extensive benchmark evaluation, we find that OddSHAP achieves state-of-the-art estimation accuracy.",
      "pdf_url": "https://arxiv.org/pdf/2602.01399v1",
      "arxiv_url": "http://arxiv.org/abs/2602.01399v1",
      "published": "2026-02-01",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    }
  ]
}