{
  "last_updated": "2025-07-01T01:02:05.748264",
  "papers": [
    {
      "title": "Rethinking Visual Token Reduction in LVLMs under Cross-modal Misalignment",
      "authors": [
        "Rui Xu",
        "Yunke Wang",
        "Yong Luo",
        "Bo Du"
      ],
      "abstract": "Large Vision-Language Models (LVLMs) encode visual inputs as dense sequences\nof patch-level tokens to capture fine-grained semantics. These visual tokens\noften outnumber their textual counterparts by a large margin, leading to\nsubstantial computational overhead and limiting the scalability of LVLMs in\npractice. Previous efforts have explored visual token reduction either prior to\nor within the large language models (LLM). However, most in-LLM reduction\napproaches rely on text-conditioned interactions, implicitly assuming that\ntextual tokens can reliably capture the importance of visual tokens. In this\nwork, we revisit this assumption and reveal causal, semantic, and spatial forms\nof cross-modal misalignment. These misalignments undermine the effectiveness of\ntext-guided visual token reduction. To address this, we introduce VisionDrop, a\ntraining-free, visual-only pruning framework that selects informative visual\ntokens based on intra-modal (visual-to-visual) attention, without relying on\ntextual signals. To further suppress redundancy throughout the model hierarchy,\nwe treat the visual encoder and the LLM as a unified system and design a\nprogressive pruning pipeline. Our method performs dominant token selection and\nlightweight contextual merging at multiple stages, enabling fine-grained visual\ninformation to be retained even under aggressive token budgets. Extensive\nexperiments across diverse benchmarks show that VisionDrop achieves consistent\nimprovements over existing methods, despite requiring no additional training or\ncomplex modifications. Its simple yet effective design enables efficient\ninference while preserving strong performance across tasks.",
      "pdf_url": "http://arxiv.org/pdf/2506.22283v1",
      "arxiv_url": "http://arxiv.org/abs/2506.22283v1",
      "published": "2025-06-27",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "Efficient Estimation of Causal Effects Under Two-Phase Sampling with Error-Prone Outcome and Treatment Measurements",
      "authors": [
        "Keith Barnatchez",
        "Kevin P. Josey",
        "Nima S. Hejazi",
        "Bryan E. Shepherd",
        "Giovanni Parmigiani",
        "Rachel Nethery"
      ],
      "abstract": "Measurement error is a common challenge for causal inference studies using\nelectronic health record (EHR) data, where clinical outcomes and treatments are\nfrequently mismeasured. Researchers often address measurement error by\nconducting manual chart reviews to validate measurements in a subset of the\nfull EHR data -- a form of two-phase sampling. To improve efficiency, phase-two\nsamples are often collected in a biased manner dependent on the patients'\ninitial, error-prone measurements. In this work, motivated by our aim of\nperforming causal inference with error-prone outcome and treatment measurements\nunder two-phase sampling, we develop solutions applicable to both this specific\nproblem and the broader problem of causal inference with two-phase samples. For\nour specific measurement error problem, we construct two asymptotically\nequivalent doubly-robust estimators of the average treatment effect and\ndemonstrate how these estimators arise from two previously disconnected\napproaches to constructing efficient estimators in general two-phase sampling\nsettings. We document various sources of instability affecting estimators from\neach approach and propose modifications that can considerably improve finite\nsample performance in any two-phase sampling context. We demonstrate the\nutility of our proposed methods through simulation studies and an illustrative\nexample assessing effects of antiretroviral therapy on occurrence of\nAIDS-defining events in patients with HIV from the Vanderbilt Comprehensive\nCare Clinic.",
      "pdf_url": "http://arxiv.org/pdf/2506.21777v1",
      "arxiv_url": "http://arxiv.org/abs/2506.21777v1",
      "published": "2025-06-26",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "THE-Tree: Can Tracing Historical Evolution Enhance Scientific Verification and Reasoning?",
      "authors": [
        "Xin Wang",
        "Jiyao Liu",
        "Yulong Xiao",
        "Junzhi Ning",
        "Lihao Liu",
        "Junjun He",
        "Botian Shi",
        "Kaicheng Yu"
      ],
      "abstract": "Large Language Models (LLMs) are accelerating scientific idea generation, but\nrigorously evaluating these numerous, often superficial, AI-generated\npropositions for novelty and factual accuracy is a critical bottleneck; manual\nverification is too slow.Existing validation methods are inadequate: LLMs as\nstandalone verifiers may hallucinate and lack domain knowledge (our findings\nshow ~60\\% unawareness of relevant papers in specific domains), while\ntraditional citation networks lack explicit causality and narrative surveys are\nunstructured.This underscores a core challenge: the absence of structured,\nverifiable, and causally-linked historical data of scientific evolution.To\naddress this,we introduce \\textbf{THE-Tree} (\\textbf{T}echnology\n\\textbf{H}istory \\textbf{E}volution Tree), a computational framework that\nconstructs such domain-specific evolution trees from scientific\nliterature.THE-Tree employs a search algorithm to explore evolutionary paths.\nDuring its node expansion, it utilizes a novel \"Think-Verbalize-Cite-Verify\"\nprocess: an LLM proposes potential advancements and cites supporting\nliterature. Critically, each proposed evolutionary link is then validated for\nlogical coherence and evidential support by a recovered natural language\ninference mechanism that interrogates the cited literature, ensuring that each\nstep is grounded.We construct and validate 88 THE-Trees across diverse domains\nand release a benchmark dataset including up to 71k fact verifications covering\n27k papers to foster further research.Experiments demonstrate that i) in graph\ncompletion, our THE-Tree improves hit@1 by 8\\% to 14\\% across multiple models\ncompared to traditional citation networks; ii) for predicting future scientific\ndevelopments, it improves hit@1 metric by nearly 10\\%; and iii) when combined\nwith other methods, it boosts the performance of evaluating important\nscientific papers by almost 100\\%.",
      "pdf_url": "http://arxiv.org/pdf/2506.21763v1",
      "arxiv_url": "http://arxiv.org/abs/2506.21763v1",
      "published": "2025-06-26",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "ImplicitQA: Going beyond frames towards Implicit Video Reasoning",
      "authors": [
        "Sirnam Swetha",
        "Rohit Gupta",
        "Parth Parag Kulkarni",
        "David G Shatwell",
        "Jeffrey A Chan Santiago",
        "Nyle Siddiqui",
        "Joseph Fioresi",
        "Mubarak Shah"
      ],
      "abstract": "Video QA has made significant strides by leveraging multimodal learning to\nalign visual and textual modalities. However, current benchmarks overwhelmingly\nfocus on questions answerable through explicit visual content - actions,\nobjects & events directly observable within individual frames or short clips.\nIn contrast, creative and cinematic videos - such as movies, TV shows, and\nnarrative-driven content - employ storytelling techniques that deliberately\nomit certain depictions, requiring viewers to infer motives, causality, and\nrelationships across discontinuous frames. Humans naturally excel at such\nimplicit reasoning, seamlessly integrating information across time and context\nto construct coherent narratives. Current VideoQA systems and benchmarks fail\nto capture this essential dimension of human-like understanding. To bridge this\ngap, we present ImplicitQA, a novel benchmark specifically designed to test\nmodels on implicit reasoning. It comprises 1K meticulously annotated QA pairs\nderived from 320+ high-quality creative video clips, systematically categorized\ninto key reasoning dimensions: lateral and vertical spatial reasoning, depth\nand proximity, viewpoint and visibility, motion and trajectory, causal and\nmotivational reasoning, social interactions, physical context, and inferred\ncounting. These annotations are deliberately challenging, crafted by authors\nensuring high-quality. Our extensive evaluations on leading VideoQA models\nreveals performance degradation, underscoring their reliance on surface-level\nvisual cues and highlighting the difficulty of implicit reasoning. Performance\nvariations across models further illustrate the complexity and diversity of the\nchallenges presented by ImplicitQA. By releasing both the dataset and our data\ncollection framework, we aim to stimulate further research and development in\nthe community. https://huggingface.co/datasets/ucf-crcv/ImplicitQA.",
      "pdf_url": "http://arxiv.org/pdf/2506.21742v1",
      "arxiv_url": "http://arxiv.org/abs/2506.21742v1",
      "published": "2025-06-26",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "Causal inference via implied interventions",
      "authors": [
        "Carlos Garc√≠a Meixide",
        "Mark J. van der Laan"
      ],
      "abstract": "In the context of having an instrumental variable, the standard practice in\ncausal inference begins by targeting an effect of interest and proceeds by\nformulating assumptions enabling identification of this effect. We turn this\naround by simply not making assumptions anymore and just adhere to the\ninterventions we can identify, rather than starting with a desired causal\nestimand and imposing untestable hypotheses. The randomization of an instrument\nand its exclusion restriction define a class of auxiliary stochastic\ninterventions on the treatment that are implied by stochastic interventions on\nthe instrument. This mapping effectively characterizes the identifiable causal\neffects of the treatment on the outcome given the observable probability\ndistribution, leading to an explicit transparent G-computation formula under\nhidden confounding. Alternatively, searching for an intervention on the\ninstrument whose implied one best approximates a desired target -- whose causal\neffect the user aims to estimate -- naturally leads to a projection on a\nfunction space representing the closest identifiable treatment effect. The\ngenerality of this projection allows to select different norms and indexing\nsets for the function class that turn optimization into different estimation\nprocedures with the Highly Adaptive Lasso. This shift from identification under\nassumptions to identification under observation redefines how the problem of\ncausal inference is approached.",
      "pdf_url": "http://arxiv.org/pdf/2506.21501v1",
      "arxiv_url": "http://arxiv.org/abs/2506.21501v1",
      "published": "2025-06-26",
      "categories": [
        "math.ST",
        "stat.TH"
      ]
    },
    {
      "title": "Counterfactual Voting Adjustment for Quality Assessment and Fairer Voting in Online Platforms with Helpfulness Evaluation",
      "authors": [
        "Chang Liu",
        "Yixin Wang",
        "Moontae Lee"
      ],
      "abstract": "Efficient access to high-quality information is vital for online platforms.\nTo promote more useful information, users not only create new content but also\nevaluate existing content, often through helpfulness voting. Although\naggregated votes help service providers rank their user content, these votes\nare often biased by disparate accessibility per position and the cascaded\ninfluence of prior votes. For a fairer assessment of information quality, we\npropose the Counterfactual Voting Adjustment (CVA), a causal framework that\naccounts for the context in which individual votes are cast. Through\npreliminary and semi-synthetic experiments, we show that CVA effectively models\nthe position and herding biases, accurately recovering the predefined content\nquality. In a real experiment, we demonstrate that reranking content based on\nthe learned quality by CVA exhibits stronger alignment with both user sentiment\nand quality evaluation assessed by GPT-4o, outperforming system rankings based\non aggregated votes and model-based rerankings without causal inference. Beyond\nthe individual quality inference, our embeddings offer comparative insights\ninto the behavioral dynamics of expert user groups across 120 major\nStackExchange communities.",
      "pdf_url": "http://arxiv.org/pdf/2506.21362v1",
      "arxiv_url": "http://arxiv.org/abs/2506.21362v1",
      "published": "2025-06-26",
      "categories": [
        "cs.CE"
      ]
    },
    {
      "title": "Active Inference AI Systems for Scientific Discovery",
      "authors": [
        "Karthik Duraisamy"
      ],
      "abstract": "The rapid evolution of artificial intelligence has led to expectations of\ntransformative scientific discovery, yet current systems remain fundamentally\nlimited by their operational architectures, brittle reasoning mechanisms, and\ntheir separation from experimental reality. Building on earlier work, we\ncontend that progress in AI-driven science now depends on closing three\nfundamental gaps -- the abstraction gap, the reasoning gap, and the reality gap\n-- rather than on model size/data/test time compute. Scientific reasoning\ndemands internal representations that support simulation of actions and\nresponse, causal structures that distinguish correlation from mechanism, and\ncontinuous calibration. We define active inference AI systems for scientific\ndiscovery as those that (i) maintain long-lived research memories grounded in\ncausal self-supervised foundation models, (ii) symbolic or neuro-symbolic\nplanners equipped with Bayesian guardrails, (iii) grow persistent knowledge\ngraphs where thinking generates novel conceptual nodes, reasoning establishes\ncausal edges, and real-world interaction prunes false connections while\nstrengthening verified pathways, and (iv) refine their internal representations\nthrough closed-loop interaction with both high-fidelity simulators and\nautomated laboratories - an operational loop where mental simulation guides\naction and empirical surprise reshapes understanding. In essence, we outline an\narchitecture where discovery arises from the interplay between internal models\nthat enable counterfactual reasoning and external validation that grounds\nhypotheses in reality. It is also argued that the inherent ambiguity in\nfeedback from simulations and experiments, and underlying uncertainties makes\nhuman judgment indispensable, not as a temporary scaffold but as a permanent\narchitectural component.",
      "pdf_url": "http://arxiv.org/pdf/2506.21329v1",
      "arxiv_url": "http://arxiv.org/abs/2506.21329v1",
      "published": "2025-06-26",
      "categories": [
        "cs.AI",
        "physics.soc-ph",
        "68",
        "I.2"
      ]
    },
    {
      "title": "Influence and information in a collective of self-propelled particles",
      "authors": [
        "Jiahuan Pang",
        "Wendong Wang"
      ],
      "abstract": "While information-theoretic quantities, such as transfer entropy, have been\nwidely adopted to infer causal relationships in collective systems, a critical\ngap exists: the absence of quantitative evidence directly linking\ninformation-theoretic quantities to a physically defined influence. This letter\naddresses this gap by proposing a modified Vicsek model that enables the\ncalculation of a physically interpretable influence grounded in the angular\ninteractions between particles. Averaged pairwise influences can serve as new\norder parameters to indicate collective phase transitions. We reveal\nquantitative relations between information, represented by transfer entropy,\nand average influence in pairwise and collective interactions. We test three\ntypical methods of partial information decomposition and find that the method\nbased on intrinsic mutual information gives the most appropriate\ninterpretation. Overall, this work provides a model system for quantitative\nstudies of influence and information in complex systems.",
      "pdf_url": "http://arxiv.org/pdf/2506.20888v1",
      "arxiv_url": "http://arxiv.org/abs/2506.20888v1",
      "published": "2025-06-25",
      "categories": [
        "cond-mat.stat-mech",
        "nlin.AO"
      ]
    },
    {
      "title": "A Bayesian Nonparametric Approach for Semi-Competing Risks with Application to Cardiovascular Health",
      "authors": [
        "Karina Gelis-Cadena",
        "Michael Daniels",
        "Juned Siddique"
      ],
      "abstract": "We address causal estimation in semi-competing risks settings, where a\nnon-terminal event may be precluded by one or more terminal events. We define a\nprincipal-stratification causal estimand for treatment effects on the\nnon-terminal event, conditional on surviving past a specified landmark time. To\nestimate joint event-time distributions, we employ both vine-copula\nconstructions and Bayesian nonparametric Enriched Dirichlet-process mixtures\n(EDPM), enabling inference under minimal parametric assumptions. We index our\ncausal assumptions with sensitivity parameters. Posterior summaries via MCMC\nyield interpretable estimates with credible intervals. We illustrate the\nproposed method using data from a cardiovascular health study.",
      "pdf_url": "http://arxiv.org/pdf/2506.20860v1",
      "arxiv_url": "http://arxiv.org/abs/2506.20860v1",
      "published": "2025-06-25",
      "categories": [
        "stat.ME",
        "stat.AP"
      ]
    },
    {
      "title": "DiffuCoder: Understanding and Improving Masked Diffusion Models for Code Generation",
      "authors": [
        "Shansan Gong",
        "Ruixiang Zhang",
        "Huangjie Zheng",
        "Jiatao Gu",
        "Navdeep Jaitly",
        "Lingpeng Kong",
        "Yizhe Zhang"
      ],
      "abstract": "Diffusion large language models (dLLMs) are compelling alternatives to\nautoregressive (AR) models because their denoising models operate over the\nentire sequence. The global planning and iterative refinement features of dLLMs\nare particularly useful for code generation. However, current training and\ninference mechanisms for dLLMs in coding are still under-explored. To demystify\nthe decoding behavior of dLLMs and unlock their potential for coding, we\nsystematically investigate their denoising processes and reinforcement learning\n(RL) methods. We train a 7B dLLM, \\textbf{DiffuCoder}, on 130B tokens of code.\nUsing this model as a testbed, we analyze its decoding behavior, revealing how\nit differs from that of AR models: (1) dLLMs can decide how causal their\ngeneration should be without relying on semi-AR decoding, and (2) increasing\nthe sampling temperature diversifies not only token choices but also their\ngeneration order. This diversity creates a rich search space for RL rollouts.\nFor RL training, to reduce the variance of token log-likelihood estimates and\nmaintain training efficiency, we propose \\textbf{coupled-GRPO}, a novel\nsampling scheme that constructs complementary mask noise for completions used\nin training. In our experiments, coupled-GRPO significantly improves\nDiffuCoder's performance on code generation benchmarks (+4.4\\% on EvalPlus) and\nreduces reliance on AR bias during decoding. Our work provides deeper insight\ninto the machinery of dLLM generation and offers an effective, diffusion-native\nRL training framework. https://github.com/apple/ml-diffucoder.",
      "pdf_url": "http://arxiv.org/pdf/2506.20639v2",
      "arxiv_url": "http://arxiv.org/abs/2506.20639v2",
      "published": "2025-06-25",
      "categories": [
        "cs.CL"
      ]
    }
  ]
}