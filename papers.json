{
  "last_updated": "2025-05-10T00:50:39.146576",
  "papers": [
    {
      "title": "Federated Deconfounding and Debiasing Learning for Out-of-Distribution Generalization",
      "authors": [
        "Zhuang Qi",
        "Sijin Zhou",
        "Lei Meng",
        "Han Hu",
        "Han Yu",
        "Xiangxu Meng"
      ],
      "abstract": "Attribute bias in federated learning (FL) typically leads local models to\noptimize inconsistently due to the learning of non-causal associations,\nresulting degraded performance. Existing methods either use data augmentation\nfor increasing sample diversity or knowledge distillation for learning\ninvariant representations to address this problem. However, they lack a\ncomprehensive analysis of the inference paths, and the interference from\nconfounding factors limits their performance. To address these limitations, we\npropose the \\underline{Fed}erated \\underline{D}econfounding and\n\\underline{D}ebiasing \\underline{L}earning (FedDDL) method. It constructs a\nstructured causal graph to analyze the model inference process, and performs\nbackdoor adjustment to eliminate confounding paths. Specifically, we design an\nintra-client deconfounding learning module for computer vision tasks to\ndecouple background and objects, generating counterfactual samples that\nestablish a connection between the background and any label, which stops the\nmodel from using the background to infer the label. Moreover, we design an\ninter-client debiasing learning module to construct causal prototypes to reduce\nthe proportion of the background in prototype components. Notably, it bridges\nthe gap between heterogeneous representations via causal prototypical\nregularization. Extensive experiments on 2 benchmarking datasets demonstrate\nthat \\methodname{} significantly enhances the model capability to focus on main\nobjects in unseen data, leading to 4.5\\% higher Top-1 Accuracy on average over\n9 state-of-the-art existing methods.",
      "pdf_url": "http://arxiv.org/pdf/2505.04979v1",
      "arxiv_url": "http://arxiv.org/abs/2505.04979v1",
      "published": "2025-05-08",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "Moments of Causal Effects",
      "authors": [
        "Yuta Kawakami",
        "Jin Tian"
      ],
      "abstract": "The moments of random variables are fundamental statistical measures for\ncharacterizing the shape of a probability distribution, encompassing metrics\nsuch as mean, variance, skewness, and kurtosis. Additionally, the product\nmoments, including covariance and correlation, reveal the relationships between\nmultiple random variables. On the other hand, the primary focus of causal\ninference is the evaluation of causal effects, which are defined as the\ndifference between two potential outcomes. While traditional causal effect\nassessment focuses on the average causal effect, this work provides\ndefinitions, identification theorems, and bounds for moments and product\nmoments of causal effects to analyze their distribution and relationships. We\nconduct experiments to illustrate the estimation of the moments of causal\neffects from finite samples and demonstrate their practical application using a\nreal-world medical dataset.",
      "pdf_url": "http://arxiv.org/pdf/2505.04971v1",
      "arxiv_url": "http://arxiv.org/abs/2505.04971v1",
      "published": "2025-05-08",
      "categories": [
        "stat.ME",
        "cs.AI"
      ]
    },
    {
      "title": "R^3-VQA: \"Read the Room\" by Video Social Reasoning",
      "authors": [
        "Lixing Niu",
        "Jiapeng Li",
        "Xingping Yu",
        "Shu Wang",
        "Ruining Feng",
        "Bo Wu",
        "Ping Wei",
        "Yisen Wang",
        "Lifeng Fan"
      ],
      "abstract": "\"Read the room\" is a significant social reasoning capability in human daily\nlife. Humans can infer others' mental states from subtle social cues. Previous\nsocial reasoning tasks and datasets lack complexity (e.g., simple scenes, basic\ninteractions, incomplete mental state variables, single-step reasoning, etc.)\nand fall far short of the challenges present in real-life social interactions.\nIn this paper, we contribute a valuable, high-quality, and comprehensive video\ndataset named R^3-VQA with precise and fine-grained annotations of social\nevents and mental states (i.e., belief, intent, desire, and emotion) as well as\ncorresponding social causal chains in complex social scenarios. Moreover, we\ninclude human-annotated and model-generated QAs. Our task R^3-VQA includes\nthree aspects: Social Event Understanding, Mental State Estimation, and Social\nCausal Reasoning. As a benchmark, we comprehensively evaluate the social\nreasoning capabilities and consistencies of current state-of-the-art large\nvision-language models (LVLMs). Comprehensive experiments show that (i) LVLMs\nare still far from human-level consistent social reasoning in complex social\nscenarios; (ii) Theory of Mind (ToM) prompting can help LVLMs perform better on\nsocial reasoning tasks. We provide some of our dataset and codes in\nsupplementary material and will release our full dataset and codes upon\nacceptance.",
      "pdf_url": "http://arxiv.org/pdf/2505.04147v1",
      "arxiv_url": "http://arxiv.org/abs/2505.04147v1",
      "published": "2025-05-07",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Regularized Fingerprinting with Linearly Optimal Weight Matrix in Detection and Attribution of Climate Change",
      "authors": [
        "Haoran Li",
        "Yan Li"
      ],
      "abstract": "Climate change detection and attribution plays a central role in establishing\nthe causal influence of human activities on global warming. The most widely\nused framework, optimal fingerprinting, is a linear regression model with\nerrors-in-variables (EIV), in which each covariate is subject to measurement\nerror whose covariance matrix is the same as that of the regression error up to\na known scale. The reliability of such detection and attribution analyses\ncritically depends on accurate inference of the regression coefficients. The\noptimal weight matrix in estimating the regression coefficient is the precision\nmatrix of the regression error, which is typically unknown and has to be\nestimated from climate model simulations with appropriate regularization.\nHowever, the estimators from the prevailing method, regularized optimal\nfingerprinting, are not optimal as believed, owing to the unreliable estimation\nof the optimal weight matrix, and their uncertainties are underestimated,\nleading to too narrow confidence intervals to match the nominal confidence\nlevels. In this paper, we propose consistent estimates of the variances of\nregression coefficients for weight matrices within the class of linear\nshrinkage estimators. Building on this result, we derive a linearly optimal\nweight matrix that directly minimizes the asymptotic variances of the estimated\nscaling factors within the fingerprinting framework. Numerical studies confirm\nthat the proposed method yields confidence intervals with empirical coverage\nrates close to the nominal level, while also achieving shorter average interval\nlengths. In applications to the detection and attribution analyses of annual\nmean near-surface air temperature at the global, continental, and\nsubcontinental scales during 1951--2020, the proposed method produced shorter\nconfidence intervals than the existing approaches in most of the analyses.",
      "pdf_url": "http://arxiv.org/pdf/2505.04070v1",
      "arxiv_url": "http://arxiv.org/abs/2505.04070v1",
      "published": "2025-05-07",
      "categories": [
        "stat.ME",
        "physics.ao-ph",
        "physics.data-an"
      ]
    },
    {
      "title": "Causal Inference in Counterbalanced Within-Subjects Designs",
      "authors": [
        "Justin Ho",
        "Jonathan Min"
      ],
      "abstract": "Experimental designs are fundamental for estimating causal effects. In some\nfields, within-subjects designs, which expose participants to both control and\ntreatment at different time periods, are used to address practical and\nlogistical concerns. Counterbalancing, a common technique in within-subjects\ndesigns, aims to remove carryover effects by randomizing treatment sequences.\nDespite its appeal, counterbalancing relies on the assumption that carryover\neffects are symmetric and cancel out, which is often unverifiable a priori. In\nthis paper, we formalize the challenges of counterbalanced within-subjects\ndesigns using the potential outcomes framework. We introduce sequential\nexchangeability as an additional identification assumption necessary for valid\ncausal inference in these designs. To address identification concerns, we\npropose diagnostic checks, the use of washout periods, and covariate\nadjustments, and alternative experimental designs to counterbalanced\nwithin-subjects design. Our findings demonstrate the limitations of\ncounterbalancing and provide guidance on when and how within-subjects designs\ncan be appropriately used for causal inference.",
      "pdf_url": "http://arxiv.org/pdf/2505.03937v1",
      "arxiv_url": "http://arxiv.org/abs/2505.03937v1",
      "published": "2025-05-06",
      "categories": [
        "stat.ME",
        "econ.EM"
      ]
    },
    {
      "title": "Scientific Hypothesis Generation and Validation: Methods, Datasets, and Future Directions",
      "authors": [
        "Adithya Kulkarni",
        "Fatimah Alotaibi",
        "Xinyue Zeng",
        "Longfeng Wu",
        "Tong Zeng",
        "Barry Menglong Yao",
        "Minqian Liu",
        "Shuaicheng Zhang",
        "Lifu Huang",
        "Dawei Zhou"
      ],
      "abstract": "Large Language Models (LLMs) are transforming scientific hypothesis\ngeneration and validation by enabling information synthesis, latent\nrelationship discovery, and reasoning augmentation. This survey provides a\nstructured overview of LLM-driven approaches, including symbolic frameworks,\ngenerative models, hybrid systems, and multi-agent architectures. We examine\ntechniques such as retrieval-augmented generation, knowledge-graph completion,\nsimulation, causal inference, and tool-assisted reasoning, highlighting\ntrade-offs in interpretability, novelty, and domain alignment. We contrast\nearly symbolic discovery systems (e.g., BACON, KEKADA) with modern LLM\npipelines that leverage in-context learning and domain adaptation via\nfine-tuning, retrieval, and symbolic grounding. For validation, we review\nsimulation, human-AI collaboration, causal modeling, and uncertainty\nquantification, emphasizing iterative assessment in open-world contexts. The\nsurvey maps datasets across biomedicine, materials science, environmental\nscience, and social science, introducing new resources like AHTech and\nCSKG-600. Finally, we outline a roadmap emphasizing novelty-aware generation,\nmultimodal-symbolic integration, human-in-the-loop systems, and ethical\nsafeguards, positioning LLMs as agents for principled, scalable scientific\ndiscovery.",
      "pdf_url": "http://arxiv.org/pdf/2505.04651v1",
      "arxiv_url": "http://arxiv.org/abs/2505.04651v1",
      "published": "2025-05-06",
      "categories": [
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "Counterfactual Inference for Eliminating Sentiment Bias in Recommender Systems",
      "authors": [
        "Le Pan",
        "Yuanjiang Cao",
        "Chengkai Huang",
        "Wenjie Zhang",
        "Lina Yao"
      ],
      "abstract": "Recommender Systems (RSs) aim to provide personalized recommendations for\nusers. A newly discovered bias, known as sentiment bias, uncovers a common\nphenomenon within Review-based RSs (RRSs): the recommendation accuracy of users\nor items with negative reviews deteriorates compared with users or items with\npositive reviews. Critical users and niche items are disadvantaged by such\nunfair recommendations. We study this problem from the perspective of\ncounterfactual inference with two stages. At the model training stage, we build\na causal graph and model how sentiment influences the final rating score.\nDuring the inference stage, we decouple the direct and indirect effects to\nmitigate the impact of sentiment bias and remove the indirect effect using\ncounterfactual inference. We have conducted extensive experiments, and the\nresults validate that our model can achieve comparable performance on rating\nprediction for better recommendations and effective mitigation of sentiment\nbias. To the best of our knowledge, this is the first work to employ\ncounterfactual inference on sentiment bias mitigation in RSs.",
      "pdf_url": "http://arxiv.org/pdf/2505.03655v1",
      "arxiv_url": "http://arxiv.org/abs/2505.03655v1",
      "published": "2025-05-06",
      "categories": [
        "cs.IR",
        "cs.AI"
      ]
    },
    {
      "title": "Integrated Sensing, Computing, Communication, and Control for Time-Sequence-Based Semantic Communications",
      "authors": [
        "Qingliang Li",
        "Bo Chang",
        "Weidong Mei",
        "Zhi Chen"
      ],
      "abstract": "In the upcoming industrial internet of things (IIoT) era, a surge of\ntask-oriented applications will rely on real-time wireless control systems\n(WCSs). For these systems, ultra-reliable and low-latency wireless\ncommunication will be crucial to ensure the timely transmission of control\ninformation. To achieve this purpose, we propose a novel time-sequence-based\nsemantic communication paradigm, where an integrated sensing, computing,\ncommunication, and control (ISC3) architecture is developed to make sensible\nsemantic inference (SI) for the control information over time sequences,\nenabling adaptive control of the robot. However, due to the causal correlations\nin the time sequence, the control information does not present the Markov\nproperty. To address this challenge, we compute the mutual information of the\ncontrol information sensed at the transmitter (Tx) over different time and\nidentify their temporal semantic correlation via a semantic feature extractor\n(SFE) module. By this means, highly correlated information transmission can be\navoided, thus greatly reducing the communication overhead. Meanwhile, a\nsemantic feature reconstructor (SFR) module is employed at the receiver (Rx) to\nreconstruct the control information based on the previously received one if the\ninformation transmission is not activated at the Tx. Furthermore, a control\ngain policy is also employed at the Rx to adaptively adjust the control gain\nfor the controlled target based on several practical aspects such as the\nquality of the information transmission from the Tx to the Rx. We design the\nneural network structures of the above modules/policies and train their\nparameters by a novel hybrid reward multi-agent deep reinforcement learning\nframework. On-site experiments are conducted to evaluate the performance of our\nproposed method in practice, which shows significant gains over other baseline\nschemes.",
      "pdf_url": "http://arxiv.org/pdf/2505.03127v1",
      "arxiv_url": "http://arxiv.org/abs/2505.03127v1",
      "published": "2025-05-06",
      "categories": [
        "eess.SY",
        "cs.IT",
        "cs.SY",
        "math.IT"
      ]
    },
    {
      "title": "Multi-View Learning with Context-Guided Receptance for Image Denoising",
      "authors": [
        "Binghong Chen",
        "Tingting Chai",
        "Wei Jiang",
        "Yuanrong Xu",
        "Guanglu Zhou",
        "Xiangqian Wu"
      ],
      "abstract": "Image denoising is essential in low-level vision applications such as\nphotography and automated driving. Existing methods struggle with\ndistinguishing complex noise patterns in real-world scenes and consume\nsignificant computational resources due to reliance on Transformer-based\nmodels. In this work, the Context-guided Receptance Weighted Key-Value (\\M)\nmodel is proposed, combining enhanced multi-view feature integration with\nefficient sequence modeling. Our approach introduces the Context-guided Token\nShift (CTS) paradigm, which effectively captures local spatial dependencies and\nenhance the model's ability to model real-world noise distributions.\nAdditionally, the Frequency Mix (FMix) module extracting frequency-domain\nfeatures is designed to isolate noise in high-frequency spectra, and is\nintegrated with spatial representations through a multi-view learning process.\nTo improve computational efficiency, the Bidirectional WKV (BiWKV) mechanism is\nadopted, enabling full pixel-sequence interaction with linear complexity while\novercoming the causal selection constraints. The model is validated on multiple\nreal-world image denoising datasets, outperforming the existing\nstate-of-the-art methods quantitatively and reducing inference time up to 40\\%.\nQualitative results further demonstrate the ability of our model to restore\nfine details in various scenes.",
      "pdf_url": "http://arxiv.org/pdf/2505.02705v1",
      "arxiv_url": "http://arxiv.org/abs/2505.02705v1",
      "published": "2025-05-05",
      "categories": [
        "eess.IV",
        "cs.CV"
      ]
    },
    {
      "title": "Structure Causal Models and LLMs Integration in Medical Visual Question Answering",
      "authors": [
        "Zibo Xu",
        "Qiang Li",
        "Weizhi Nie",
        "Weijie Wang",
        "Anan Liu"
      ],
      "abstract": "Medical Visual Question Answering (MedVQA) aims to answer medical questions\naccording to medical images. However, the complexity of medical data leads to\nconfounders that are difficult to observe, so bias between images and questions\nis inevitable. Such cross-modal bias makes it challenging to infer medically\nmeaningful answers. In this work, we propose a causal inference framework for\nthe MedVQA task, which effectively eliminates the relative confounding effect\nbetween the image and the question to ensure the precision of the\nquestion-answering (QA) session. We are the first to introduce a novel causal\ngraph structure that represents the interaction between visual and textual\nelements, explicitly capturing how different questions influence visual\nfeatures. During optimization, we apply the mutual information to discover\nspurious correlations and propose a multi-variable resampling front-door\nadjustment method to eliminate the relative confounding effect, which aims to\nalign features based on their true causal relevance to the question-answering\ntask. In addition, we also introduce a prompt strategy that combines multiple\nprompt forms to improve the model's ability to understand complex medical data\nand answer accurately. Extensive experiments on three MedVQA datasets\ndemonstrate that 1) our method significantly improves the accuracy of MedVQA,\nand 2) our method achieves true causal correlations in the face of complex\nmedical data.",
      "pdf_url": "http://arxiv.org/pdf/2505.02703v1",
      "arxiv_url": "http://arxiv.org/abs/2505.02703v1",
      "published": "2025-05-05",
      "categories": [
        "cs.CV"
      ]
    }
  ]
}