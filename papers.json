{
  "last_updated": "2025-06-22T01:00:27.383867",
  "papers": [
    {
      "title": "Causal inference amid missingness-specific independencies and mechanism shifts",
      "authors": [
        "Johan de Aguas",
        "Leonard Henckel",
        "Johan Pensar",
        "Guido Biele"
      ],
      "abstract": "The recovery of causal effects in structural models with missing data often\nrelies on $m$-graphs, which assume that missingness mechanisms do not directly\ninfluence substantive variables. Yet, in many real-world settings, missing data\ncan alter decision-making processes, as the absence of key information may\naffect downstream actions and states. To overcome this limitation, we introduce\n$lm$-SCMs and $lm$-graphs, which extend $m$-graphs by integrating a label set\nthat represents relevant context-specific independencies (CSI), accounting for\nmechanism shifts induced by missingness. We define two causal effects within\nthese systems: the Full Average Treatment Effect (FATE), which reflects the\neffect in a hypothetical scenario had no data been missing, and the Natural\nAverage Treatment Effect (NATE), which captures the effect under the unaltered\nCSIs in the system. We propose recovery criteria for these queries and present\ndoubly-robust estimators for a graphical model inspired by a real-world\napplication. Simulations highlight key differences between these estimands and\nestimation methods. Findings from the application case suggest a small effect\nof ADHD treatment upon test achievement among Norwegian children, with a slight\neffect shift due to missing pre-tests scores.",
      "pdf_url": "http://arxiv.org/pdf/2506.15441v1",
      "arxiv_url": "http://arxiv.org/abs/2506.15441v1",
      "published": "2025-06-18",
      "categories": [
        "stat.ME",
        "math.ST",
        "stat.TH",
        "62D20, 62H22"
      ]
    },
    {
      "title": "Double Machine Learning for Conditional Moment Restrictions: IV regression, Proximal Causal Learning and Beyond",
      "authors": [
        "Daqian Shao",
        "Ashkan Soleymani",
        "Francesco Quinzan",
        "Marta Kwiatkowska"
      ],
      "abstract": "Solving conditional moment restrictions (CMRs) is a key problem considered in\nstatistics, causal inference, and econometrics, where the aim is to solve for a\nfunction of interest that satisfies some conditional moment equalities.\nSpecifically, many techniques for causal inference, such as instrumental\nvariable (IV) regression and proximal causal learning (PCL), are CMR problems.\nMost CMR estimators use a two-stage approach, where the first-stage estimation\nis directly plugged into the second stage to estimate the function of interest.\nHowever, naively plugging in the first-stage estimator can cause heavy bias in\nthe second stage. This is particularly the case for recently proposed CMR\nestimators that use deep neural network (DNN) estimators for both stages, where\nregularisation and overfitting bias is present. We propose DML-CMR, a two-stage\nCMR estimator that provides an unbiased estimate with fast convergence rate\nguarantees. We derive a novel learning objective to reduce bias and develop the\nDML-CMR algorithm following the double/debiased machine learning (DML)\nframework. We show that our DML-CMR estimator can achieve the minimax optimal\nconvergence rate of $O(N^{-1/2})$ under parameterisation and mild regularity\nconditions, where $N$ is the sample size. We apply DML-CMR to a range of\nproblems using DNN estimators, including IV regression and proximal causal\nlearning on real-world datasets, demonstrating state-of-the-art performance\nagainst existing CMR estimators and algorithms tailored to those problems.",
      "pdf_url": "http://arxiv.org/pdf/2506.14950v1",
      "arxiv_url": "http://arxiv.org/abs/2506.14950v1",
      "published": "2025-06-17",
      "categories": [
        "stat.ML",
        "cs.LG",
        "stat.ME"
      ]
    },
    {
      "title": "CDP: Towards Robust Autoregressive Visuomotor Policy Learning via Causal Diffusion",
      "authors": [
        "Jiahua Ma",
        "Yiran Qin",
        "Yixiong Li",
        "Xuanqi Liao",
        "Yulan Guo",
        "Ruimao Zhang"
      ],
      "abstract": "Diffusion Policy (DP) enables robots to learn complex behaviors by imitating\nexpert demonstrations through action diffusion. However, in practical\napplications, hardware limitations often degrade data quality, while real-time\nconstraints restrict model inference to instantaneous state and scene\nobservations. These limitations seriously reduce the efficacy of learning from\nexpert demonstrations, resulting in failures in object localization, grasp\nplanning, and long-horizon task execution. To address these challenges, we\npropose Causal Diffusion Policy (CDP), a novel transformer-based diffusion\nmodel that enhances action prediction by conditioning on historical action\nsequences, thereby enabling more coherent and context-aware visuomotor policy\nlearning. To further mitigate the computational cost associated with\nautoregressive inference, a caching mechanism is also introduced to store\nattention key-value pairs from previous timesteps, substantially reducing\nredundant computations during execution. Extensive experiments in both\nsimulated and real-world environments, spanning diverse 2D and 3D manipulation\ntasks, demonstrate that CDP uniquely leverages historical action sequences to\nachieve significantly higher accuracy than existing methods. Moreover, even\nwhen faced with degraded input observation quality, CDP maintains remarkable\nprecision by reasoning through temporal continuity, which highlights its\npractical robustness for robotic control under realistic, imperfect conditions.",
      "pdf_url": "http://arxiv.org/pdf/2506.14769v1",
      "arxiv_url": "http://arxiv.org/abs/2506.14769v1",
      "published": "2025-06-17",
      "categories": [
        "cs.CV",
        "cs.RO"
      ]
    },
    {
      "title": "VideoMAR: Autoregressive Video Generatio with Continuous Tokens",
      "authors": [
        "Hu Yu",
        "Biao Gong",
        "Hangjie Yuan",
        "DanDan Zheng",
        "Weilong Chai",
        "Jingdong Chen",
        "Kecheng Zheng",
        "Feng Zhao"
      ],
      "abstract": "Masked-based autoregressive models have demonstrated promising image\ngeneration capability in continuous space. However, their potential for video\ngeneration remains under-explored. In this paper, we propose \\textbf{VideoMAR},\na concise and efficient decoder-only autoregressive image-to-video model with\ncontinuous tokens, composing temporal frame-by-frame and spatial masked\ngeneration. We first identify temporal causality and spatial bi-directionality\nas the first principle of video AR models, and propose the next-frame diffusion\nloss for the integration of mask and video generation. Besides, the huge cost\nand difficulty of long sequence autoregressive modeling is a basic but crucial\nissue. To this end, we propose the temporal short-to-long curriculum learning\nand spatial progressive resolution training, and employ progressive temperature\nstrategy at inference time to mitigate the accumulation error. Furthermore,\nVideoMAR replicates several unique capacities of language models to video\ngeneration. It inherently bears high efficiency due to simultaneous\ntemporal-wise KV cache and spatial-wise parallel generation, and presents the\ncapacity of spatial and temporal extrapolation via 3D rotary embeddings. On the\nVBench-I2V benchmark, VideoMAR surpasses the previous state-of-the-art (Cosmos\nI2V) while requiring significantly fewer parameters ($9.3\\%$), training data\n($0.5\\%$), and GPU resources ($0.2\\%$).",
      "pdf_url": "http://arxiv.org/pdf/2506.14168v2",
      "arxiv_url": "http://arxiv.org/abs/2506.14168v2",
      "published": "2025-06-17",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Estimation of Treatment Effects in Extreme and Unobserved Data",
      "authors": [
        "Jiyuan Tan",
        "Jose Blanchet",
        "Vasilis Syrgkanis"
      ],
      "abstract": "Causal effect estimation seeks to determine the impact of an intervention\nfrom observational data. However, the existing causal inference literature\nprimarily addresses treatment effects on frequently occurring events. But what\nif we are interested in estimating the effects of a policy intervention whose\nbenefits, while potentially important, can only be observed and measured in\nrare yet impactful events, such as extreme climate events? The standard causal\ninference methodology is not designed for this type of inference since the\nevents of interest may be scarce in the observed data and some degree of\nextrapolation is necessary. Extreme Value Theory (EVT) provides methodologies\nfor analyzing statistical phenomena in such extreme regimes. We introduce a\nnovel framework for assessing treatment effects in extreme data to capture the\ncausal effect at the occurrence of rare events of interest. In particular, we\nemploy the theory of multivariate regular variation to model extremities. We\ndevelop a consistent estimator for extreme treatment effects and present a\nrigorous non-asymptotic analysis of its performance. We illustrate the\nperformance of our estimator using both synthetic and semi-synthetic data.",
      "pdf_url": "http://arxiv.org/pdf/2506.14051v1",
      "arxiv_url": "http://arxiv.org/abs/2506.14051v1",
      "published": "2025-06-16",
      "categories": [
        "stat.ML",
        "cs.LG",
        "math.ST",
        "stat.ME",
        "stat.TH"
      ]
    },
    {
      "title": "Mixture of Weight-shared Heterogeneous Group Attention Experts for Dynamic Token-wise KV Optimization",
      "authors": [
        "Guanghui Song",
        "Dongping Liao",
        "Yiren Zhao",
        "Kejiang Ye",
        "Cheng-zhong Xu",
        "Xitong Gao"
      ],
      "abstract": "Transformer models face scalability challenges in causal language modeling\n(CLM) due to inefficient memory allocation for growing key-value (KV) caches,\nwhich strains compute and storage resources. Existing methods like Grouped\nQuery Attention (GQA) and token-level KV optimization improve efficiency but\nrely on rigid resource allocation, often discarding \"low-priority\" tokens or\nstatically grouping them, failing to address the dynamic spectrum of token\nimportance. We propose mixSGA, a novel mixture-of-expert (MoE) approach that\ndynamically optimizes token-wise computation and memory allocation. Unlike\nprior approaches, mixSGA retains all tokens while adaptively routing them to\nspecialized experts with varying KV group sizes, balancing granularity and\nefficiency. Our key novelties include: (1) a token-wise expert-choice routing\nmechanism guided by learned importance scores, enabling proportional resource\nallocation without token discard; (2) weight-sharing across grouped attention\nprojections to minimize parameter overhead; and (3) an auxiliary loss to ensure\none-hot routing decisions for training-inference consistency in CLMs. Extensive\nevaluations across Llama3, TinyLlama, OPT, and Gemma2 model families show\nmixSGA's superiority over static baselines. On instruction-following and\ncontinued pretraining tasks, mixSGA achieves higher ROUGE-L and lower\nperplexity under the same KV budgets.",
      "pdf_url": "http://arxiv.org/pdf/2506.13541v1",
      "arxiv_url": "http://arxiv.org/abs/2506.13541v1",
      "published": "2025-06-16",
      "categories": [
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "title": "Chaos, coherence and turbulence",
      "authors": [
        "Javier Jimenez"
      ],
      "abstract": "This paper is a personal overview of the efforts over the last half century\nto understand fluid turbulence in terms of simpler coherent units. The\nconsequences of chaos and the concept of coherence are first reviewed, using\nexamples from free-shear and wall-bounded shear flows, and including how the\nsimplifications due to coherent structures have been useful in the\nconceptualization and control of turbulence. It is remarked that, even if this\napproach has revolutionized our understanding of the flow, most of turbulence\ncannot yet be described by structures. This includes cascades, both direct and\ninverse, and possibly junk turbulence, whose role, if any, is currently\nunknown. This part of the paper is mostly a catalog of questions, some of them\nanswered and others still open. A second part of the paper examines which new\ntechniques can be expected to help in attacking the open questions, and which,\nin the opinion of the author, are the strengths and limitations of current\napproaches, such as data-driven science and causal inference.",
      "pdf_url": "http://arxiv.org/pdf/2506.13417v1",
      "arxiv_url": "http://arxiv.org/abs/2506.13417v1",
      "published": "2025-06-16",
      "categories": [
        "physics.flu-dyn"
      ]
    },
    {
      "title": "Fortified Proximal Causal Inference with Many Invalid Proxies",
      "authors": [
        "Myeonghun Yu",
        "Xu Shi",
        "Eric J. Tchetgen Tchetgen"
      ],
      "abstract": "Causal inference from observational data often relies on the assumption of no\nunmeasured confounding, an assumption frequently violated in practice due to\nunobserved or poorly measured covariates. Proximal causal inference (PCI)\noffers a promising framework for addressing unmeasured confounding using a pair\nof outcome and treatment confounding proxies. However, existing PCI methods\ntypically assume all specified proxies are valid, which may be unrealistic and\nis untestable without extra assumptions. In this paper, we develop a\nsemiparametric approach for a many-proxy PCI setting that accommodates\npotentially invalid treatment confounding proxies. We introduce a new class of\nfortified confounding bridge functions and establish nonparametric\nidentification of the population average treatment effect (ATE) under the\nassumption that at least $\\gamma$ out of $K$ candidate treatment confounding\nproxies are valid, for any $\\gamma \\leq K$ set by the analyst without requiring\nknowledge of which proxies are valid. We establish a local semiparametric\nefficiency bound and develop a class of multiply robust, locally efficient\nestimators for the ATE. These estimators are thus simultaneously robust to\ninvalid treatment confounding proxies and model misspecification of nuisance\nparameters. The proposed methods are evaluated through simulation and applied\nto assess the effect of right heart catheterization in critically ill patients.",
      "pdf_url": "http://arxiv.org/pdf/2506.13152v1",
      "arxiv_url": "http://arxiv.org/abs/2506.13152v1",
      "published": "2025-06-16",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Honesty in Causal Forests: When It Helps and When It Hurts",
      "authors": [
        "Yanfang Hou",
        "Carlos Fernández-Loría"
      ],
      "abstract": "Causal forests are increasingly used to personalize decisions based on\nestimated treatment effects. A distinctive modeling choice in this method is\nhonest estimation: using separate data for splitting and for estimating effects\nwithin leaves. This practice is the default in most implementations and is\nwidely seen as desirable for causal inference. But we show that honesty can\nhurt the accuracy of individual-level effect estimates. The reason is a classic\nbias-variance trade-off: honesty reduces variance by preventing overfitting,\nbut increases bias by limiting the model's ability to discover and exploit\nmeaningful heterogeneity in treatment effects. This trade-off depends on the\nsignal-to-noise ratio (SNR): honesty helps when effect heterogeneity is hard to\ndetect (low SNR), but hurts when the signal is strong (high SNR). In essence,\nhonesty acts as a form of regularization, and like any regularization choice,\nit should be guided by out-of-sample performance, not adopted by default.",
      "pdf_url": "http://arxiv.org/pdf/2506.13107v1",
      "arxiv_url": "http://arxiv.org/abs/2506.13107v1",
      "published": "2025-06-16",
      "categories": [
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "title": "Discussion of \"Causal and counterfactual views of missing data models\" by Razieh Nabi, Rohit Bhattacharya, Ilya Shpitser, & James M. Robins",
      "authors": [
        "Alex W. Levis",
        "Edward H. Kennedy"
      ],
      "abstract": "We congratulate Nabi et al. (2022) on their impressive and insightful paper,\nwhich illustrates the benefits of using causal/counterfactual perspectives and\ntools in missing data problems. This paper represents an important approach to\nmissing-not-at-random (MNAR) problems, exploiting nonparametric independence\nrestrictions for identification, as opposed to parametric/semiparametric\nmodels, or resorting to sensitivity analysis. Crucially, the authors represent\nthese restrictions with missing data directed acyclic graphs (m-DAGs), which\ncan be useful to determine identification in complex and interesting MNAR\nmodels. In this discussion we consider: (i) how/whether other tools from causal\ninference could be useful in missing data problems, (ii) problems that combine\nboth missing data and causal inference together, and (iii) some work on\nestimation in one of the authors' example MNAR models.",
      "pdf_url": "http://arxiv.org/pdf/2506.13025v1",
      "arxiv_url": "http://arxiv.org/abs/2506.13025v1",
      "published": "2025-06-16",
      "categories": [
        "stat.ME"
      ]
    }
  ]
}