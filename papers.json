{
  "last_updated": "2025-10-15T00:52:01.299456",
  "papers": [
    {
      "title": "The Role of Congeniality in Multiple Imputation for Doubly Robust Causal Estimation",
      "authors": [
        "Lucy D'Agostino McGowan"
      ],
      "abstract": "This paper provides clear and practical guidance on the specification of\nimputation models when multiple imputation is used in conjunction with doubly\nrobust estimation methods for causal inference. Through theoretical arguments\nand targeted simulations, we show that when a confounder has missing data the\ncorresponding imputation model must include all variables used in either the\npropensity score model or the outcome model, and that these variables must\nappear in the same functional form as in the final analysis. Violating these\nconditions can lead to biased treatment effect estimates, even when both\ncomponents of the doubly robust estimator are correctly specified. We present a\nmathematical framework for doubly robust estimation combined with multiple\nimputation, establish the theoretical requirements for proper imputation in\nthis setting, and demonstrate the consequences of misspecification through\nsimulation. Based on these findings, we offer concrete recommendations to\nensure valid inference when using multiple imputation with doubly robust\nmethods in applied causal analyses.",
      "pdf_url": "http://arxiv.org/pdf/2510.11633v1",
      "arxiv_url": "http://arxiv.org/abs/2510.11633v1",
      "published": "2025-10-13",
      "categories": [
        "stat.ME",
        "stat.AP"
      ]
    },
    {
      "title": "Causal Disentanglement Learning for Accurate Anomaly Detection in Multivariate Time Series",
      "authors": [
        "Wonah Kim",
        "Jeonghyeon Park",
        "Dongsan Jun",
        "Jungkyu Han",
        "Sejin Chun"
      ],
      "abstract": "Disentangling complex causal relationships is important for accurate\ndetection of anomalies. In multivariate time series analysis, dynamic\ninteractions among data variables over time complicate the interpretation of\ncausal relationships. Traditional approaches assume statistical independence\nbetween variables in unsupervised settings, whereas recent methods capture\nfeature correlations through graph representation learning. However, their\nrepresentations fail to explicitly infer the causal relationships over\ndifferent time periods. To solve the problem, we propose Causally Disentangled\nRepresentation Learning for Anomaly Detection (CDRL4AD) to detect anomalies and\nidentify their causal relationships in multivariate time series. First, we\ndesign the causal process as model input, the temporal heterogeneous graph, and\ncausal relationships. Second, our representation identifies causal\nrelationships over different time periods and disentangles latent variables to\ninfer the corresponding causal factors. Third, our experiments on real-world\ndatasets demonstrate that CDRL4AD outperforms state-of-the-art methods in terms\nof accuracy and root cause analysis. Fourth, our model analysis validates\nhyperparameter sensitivity and the time complexity of CDRL4AD. Last, we conduct\na case study to show how our approach assists human experts in diagnosing the\nroot causes of anomalies.",
      "pdf_url": "http://arxiv.org/pdf/2510.11084v1",
      "arxiv_url": "http://arxiv.org/abs/2510.11084v1",
      "published": "2025-10-13",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "FBS Model-based Maintenance Record Accumulation for Failure-Cause Inference in Manufacturing Systems",
      "authors": [
        "Takuma Fujiu",
        "Sho Okazaki",
        "Kohei Kaminishi",
        "Yuji Nakata",
        "Shota Hamamoto",
        "Kenshin Yokose",
        "Tatsunori Hara",
        "Yasushi Umeda",
        "Jun Ota"
      ],
      "abstract": "In manufacturing systems, identifying the causes of failures is crucial for\nmaintaining and improving production efficiency. In knowledge-based\nfailure-cause inference, it is important that the knowledge base (1) explicitly\nstructures knowledge about the target system and about failures, and (2)\ncontains sufficiently long causal chains of failures. In this study, we\nconstructed Diagnostic Knowledge Ontology and proposed a\nFunction-Behavior-Structure (FBS) model-based maintenance-record accumulation\nmethod based on it. Failure-cause inference using the maintenance records\naccumulated by the proposed method showed better agreement with the set of\ncandidate causes enumerated by experts, especially in difficult cases where the\nnumber of related cases is small and the vocabulary used differs. In the\nfuture, it will be necessary to develop inference methods tailored to these\nmaintenance records, build a user interface, and carry out validation on larger\nand more diverse systems. Additionally, this approach leverages the\nunderstanding and knowledge of the target in the design phase to support\nknowledge accumulation and problem solving during the maintenance phase, and it\nis expected to become a foundation for knowledge sharing across the entire\nengineering chain in the future.",
      "pdf_url": "http://arxiv.org/pdf/2510.11003v1",
      "arxiv_url": "http://arxiv.org/abs/2510.11003v1",
      "published": "2025-10-13",
      "categories": [
        "cs.AI",
        "cs.IR"
      ]
    },
    {
      "title": "Identifying treatment effects on categorical outcomes in IV models",
      "authors": [
        "Onil Boussim"
      ],
      "abstract": "This paper provides a nonparametric framework for causal inference with\ncategorical outcomes under binary treatment and binary instrument settings. We\ndecompose the observed joint probability of outcomes and treatment into\nmarginal probabilities of potential outcomes and treatment, and association\nparameters that capture selection bias due to unobserved heterogeneity. Under a\nnovel identifying assumption, association similarity, which requires the\ndependence between unobserved factors and potential outcomes to be invariant\nacross treatment states, we achieve point identification of the full\ndistribution of potential outcomes. Recognizing that this assumption may be\nstrong in some contexts, we propose two weaker alternatives: monotonic\nassociation, which restricts the direction of selection heterogeneity, and\nbounded association, which constrains its magnitude. These relaxed assumptions\ndeliver sharp partial identification bounds that nest point identification as a\nspecial case and facilitate transparent sensitivity analysis. We illustrate the\nframework in an empirical application, estimating the causal effect of private\nhealth insurance on health outcomes.",
      "pdf_url": "http://arxiv.org/pdf/2510.10946v1",
      "arxiv_url": "http://arxiv.org/abs/2510.10946v1",
      "published": "2025-10-13",
      "categories": [
        "econ.EM"
      ]
    },
    {
      "title": "Large Language Models for Full-Text Methods Assessment: A Case Study on Mediation Analysis",
      "authors": [
        "Wenqing Zhang",
        "Trang Nguyen",
        "Elizabeth A. Stuart",
        "Yiqun T. Chen"
      ],
      "abstract": "Systematic reviews are crucial for synthesizing scientific evidence but\nremain labor-intensive, especially when extracting detailed methodological\ninformation. Large language models (LLMs) offer potential for automating\nmethodological assessments, promising to transform evidence synthesis. Here,\nusing causal mediation analysis as a representative methodological domain, we\nbenchmarked state-of-the-art LLMs against expert human reviewers across 180\nfull-text scientific articles. Model performance closely correlated with human\njudgments (accuracy correlation 0.71; F1 correlation 0.97), achieving\nnear-human accuracy on straightforward, explicitly stated methodological\ncriteria. However, accuracy sharply declined on complex, inference-intensive\nassessments, lagging expert reviewers by up to 15%. Errors commonly resulted\nfrom superficial linguistic cues -- for instance, models frequently\nmisinterpreted keywords like \"longitudinal\" or \"sensitivity\" as automatic\nevidence of rigorous methodological approache, leading to systematic\nmisclassifications. Longer documents yielded lower model accuracy, whereas\npublication year showed no significant effect. Our findings highlight an\nimportant pattern for practitioners using LLMs for methods review and synthesis\nfrom full texts: current LLMs excel at identifying explicit methodological\nfeatures but require human oversight for nuanced interpretations. Integrating\nautomated information extraction with targeted expert review thus provides a\npromising approach to enhance efficiency and methodological rigor in evidence\nsynthesis across diverse scientific fields.",
      "pdf_url": "http://arxiv.org/pdf/2510.10762v1",
      "arxiv_url": "http://arxiv.org/abs/2510.10762v1",
      "published": "2025-10-12",
      "categories": [
        "cs.CL",
        "stat.AP"
      ]
    },
    {
      "title": "OmniVideoBench: Towards Audio-Visual Understanding Evaluation for Omni MLLMs",
      "authors": [
        "Caorui Li",
        "Yu Chen",
        "Yiyan Ji",
        "Jin Xu",
        "Zhenyu Cui",
        "Shihao Li",
        "Yuanxing Zhang",
        "Jiafu Tang",
        "Zhenghao Song",
        "Dingling Zhang",
        "Ying He",
        "Haoxiang Liu",
        "Yuxuan Wang",
        "Qiufeng Wang",
        "Zhenhe Wu",
        "Jiehui Luo",
        "Zhiyu Pan",
        "Weihao Xie",
        "Chenchen Zhang",
        "Zhaohui Wang",
        "Jiayi Tian",
        "Yanghai Wang",
        "Zhe Cao",
        "Minxin Dai",
        "Ke Wang",
        "Runzhe Wen",
        "Yinghao Ma",
        "Yaning Pan",
        "Sungkyun Chang",
        "Termeh Taheri",
        "Haiwen Xia",
        "Christos Plachouras",
        "Emmanouil Benetos",
        "Yizhi Li",
        "Ge Zhang",
        "Jian Yang",
        "Tianhao Peng",
        "Zili Wang",
        "Minghao Liu",
        "Junran Peng",
        "Zhaoxiang Zhang",
        "Jiaheng Liu"
      ],
      "abstract": "Recent advances in multimodal large language models (MLLMs) have demonstrated\nsubstantial potential in video understanding. However, existing benchmarks fail\nto comprehensively evaluate synergistic reasoning capabilities across audio and\nvisual modalities, often neglecting either one of the modalities or integrating\nthem in a logically inconsistent manner. To bridge this gap, we introduce\nOmniVideoBench, a large-scale and rigorously designed benchmark dedicated to\nassessing synergistic audio-visual understanding, with a strong emphasis on\nmodality complementarity and logical consistency. Specifically, OmniVideoBench\ncomprises 1000 high-quality question-answer(QA) pairs, each annotated with\nstep-by-step reasoning traces, derived from 628 diverse videos ranging from\nseveral seconds to 30 minutes, and manually verified to guarantee complete\ncorrectness and uniqueness. Moreover, OmniVideoBench encompasses 13 carefully\ndesigned question types, covering temporal reasoning, spatial localization,\ncounting, causal inference, summarization, and beyond, thereby capturing the\nessential challenges of video understanding. Evaluation of multiple MLLMs on\nOmniVideoBench reveals a pronounced gap between model performance and human\nreasoning, with open-source models lagging significantly behind their\nclosed-source counterparts, underscoring the inherent difficulty of genuine\naudio-visual reasoning. We will release OmniVideoBench to foster the\ndevelopment of MLLMs with stronger and more generalizable reasoning\ncapabilities.",
      "pdf_url": "http://arxiv.org/pdf/2510.10689v1",
      "arxiv_url": "http://arxiv.org/abs/2510.10689v1",
      "published": "2025-10-12",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "DiffHeads: Differential Analysis and Inference-Time Masking of Bias Heads in Large Language Models",
      "authors": [
        "Tingxu Han",
        "Wei Song",
        "Ziqi Ding",
        "Ziming Li",
        "Chunrong Fang",
        "Yuekang Li",
        "Dongfang Liu",
        "Zhenyu Chen",
        "Zhenting Wang"
      ],
      "abstract": "Large language models (LLMs) increasingly mediate decisions in domains where\nunfair treatment of demographic groups is unacceptable. Existing work probes\nwhen biased outputs appear, but gives little insight into the mechanisms that\ngenerate them, leaving existing mitigations largely fragile. In this paper, we\nconduct a systematic investigation LLM unfairness and propose DiffHeads, a\nlightweight debiasing framework for LLMs. We first compare Direct-Answer (DA)\nprompting to Chain-of-Thought (CoT) prompting across eight representative open-\nand closed-source LLMs. DA will trigger the nature bias part of LLM and improve\nmeasured unfairness by 534.5%-391.9% in both one-turn and two-turn dialogues.\nNext, we define a token-to-head contribution score that traces each token's\ninfluence back to individual attention heads. This reveals a small cluster of\nbias heads that activate under DA but stay largely dormant with CoT, providing\nthe first causal link between prompting strategy and bias emergence. Finally,\nbuilding on this insight, we propose DiffHeads that identifies bias heads\nthrough differential activation analysis between DA and CoT, and selectively\nmasks only those heads. DiffHeads reduces unfairness by 49.4%, and 40.3% under\nDA and CoT, respectively, without harming model utility.",
      "pdf_url": "http://arxiv.org/pdf/2510.10142v1",
      "arxiv_url": "http://arxiv.org/abs/2510.10142v1",
      "published": "2025-10-11",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Bayesian Multivariable Bidirectional Mendelian Randomization",
      "authors": [
        "Bitan Sarkar",
        "Yuchao Jiang",
        "Yang Ni"
      ],
      "abstract": "Mendelian randomization (MR) is a pivotal tool in genetic epidemiology,\nleveraging genetic variants as instrumental variables to infer causal\nrelationships between modifiable exposures and health outcomes. Traditional MR\nmethods, while powerful, often rest on stringent assumptions such as the\nabsence of feedback loops, which are frequently violated in complex biological\nsystems. In addition, many popular MR approaches focus on only two variables\n(i.e., one exposure and one outcome) whereas our motivating applications have\nmany variables. In this article, we introduce a novel Bayesian framework for\n\\emph{multivariable} MR that concurrently addresses \\emph{unmeasured\nconfounding} and \\emph{feedback loops}. Central to our approach is a sparse\nconditional cyclic graphical model with a sparse error variance-covariance\nmatrix. Two structural priors are employed to enable the modeling and inference\nof causal relationships as well as latent confounding structures. Our method is\ndesigned to operate effectively with summary-level data, facilitating its\napplication in contexts where individual-level data are inaccessible, e.g., due\nto privacy concerns. It can also account for horizontal pleiotropy. Through\nextensive simulations and applications to the GTEx and OneK1K data, we\ndemonstrate the superior performance of our approach in recovering biologically\nplausible causal relationships in the presence of possible feedback loops and\nunmeasured confounding. The R package that implements the proposed method is\navailable at \\texttt{MR.RGM}.",
      "pdf_url": "http://arxiv.org/pdf/2510.09991v1",
      "arxiv_url": "http://arxiv.org/abs/2510.09991v1",
      "published": "2025-10-11",
      "categories": [
        "stat.ME",
        "stat.AP"
      ]
    },
    {
      "title": "Efficient Autoregressive Inference for Transformer Probabilistic Models",
      "authors": [
        "Conor Hassan",
        "Nasrulloh Loka",
        "Cen-You Li",
        "Daolang Huang",
        "Paul E. Chang",
        "Yang Yang",
        "Francesco Silvestrin",
        "Samuel Kaski",
        "Luigi Acerbi"
      ],
      "abstract": "Transformer-based models for amortized probabilistic inference, such as\nneural processes, prior-fitted networks, and tabular foundation models, excel\nat single-pass marginal prediction. However, many real-world applications, from\nsignal interpolation to multi-column tabular predictions, require coherent\njoint distributions that capture dependencies between predictions. While purely\nautoregressive architectures efficiently generate such distributions, they\nsacrifice the flexible set-conditioning that makes these models powerful for\nmeta-learning. Conversely, the standard approach to obtain joint distributions\nfrom set-based models requires expensive re-encoding of the entire augmented\nconditioning set at each autoregressive step. We introduce a causal\nautoregressive buffer that preserves the advantages of both paradigms. Our\napproach decouples context encoding from updating the conditioning set. The\nmodel processes the context once and caches it. A dynamic buffer then captures\ntarget dependencies: as targets are incorporated, they enter the buffer and\nattend to both the cached context and previously buffered targets. This enables\nefficient batched autoregressive generation and one-pass joint log-likelihood\nevaluation. A unified training strategy allows seamless integration of\nset-based and autoregressive modes at minimal additional cost. Across synthetic\nfunctions, EEG signals, cognitive models, and tabular data, our method matches\npredictive accuracy of strong baselines while delivering up to 20 times faster\njoint sampling. Our approach combines the efficiency of autoregressive\ngenerative models with the representational power of set-based conditioning,\nmaking joint prediction practical for transformer-based probabilistic models.",
      "pdf_url": "http://arxiv.org/pdf/2510.09477v1",
      "arxiv_url": "http://arxiv.org/abs/2510.09477v1",
      "published": "2025-10-10",
      "categories": [
        "stat.ML",
        "cs.LG"
      ]
    },
    {
      "title": "Sensitivity Analysis for Causal ML: A Use Case at Booking.com",
      "authors": [
        "Philipp Bach",
        "Victor Chernozhukov",
        "Carlos Cinelli",
        "Lin Jia",
        "Sven Klaassen",
        "Nils Skotara",
        "Martin Spindler"
      ],
      "abstract": "Causal Machine Learning has emerged as a powerful tool for flexibly\nestimating causal effects from observational data in both industry and\nacademia. However, causal inference from observational data relies on\nuntestable assumptions about the data-generating process, such as the absence\nof unobserved confounders. When these assumptions are violated, causal effect\nestimates may become biased, undermining the validity of research findings. In\nthese contexts, sensitivity analysis plays a crucial role, by enabling data\nscientists to assess the robustness of their findings to plausible violations\nof unconfoundedness. This paper introduces sensitivity analysis and\ndemonstrates its practical relevance through a (simulated) data example based\non a use case at Booking.com. We focus our presentation on a recently proposed\nmethod by Chernozhukov et al. (2023), which derives general non-parametric\nbounds on biases due to omitted variables, and is fully compatible with (though\nnot limited to) modern inferential tools of Causal Machine Learning. By\npresenting this use case, we aim to raise awareness of sensitivity analysis and\nhighlight its importance in real-world scenarios.",
      "pdf_url": "http://arxiv.org/pdf/2510.09109v1",
      "arxiv_url": "http://arxiv.org/abs/2510.09109v1",
      "published": "2025-10-10",
      "categories": [
        "econ.EM"
      ]
    }
  ]
}