{
  "last_updated": "2025-07-13T01:02:41.239438",
  "papers": [
    {
      "title": "Efficient Causal Discovery for Autoregressive Time Series",
      "authors": [
        "Mohammad Fesanghary",
        "Achintya Gopal"
      ],
      "abstract": "In this study, we present a novel constraint-based algorithm for causal\nstructure learning specifically designed for nonlinear autoregressive time\nseries. Our algorithm significantly reduces computational complexity compared\nto existing methods, making it more efficient and scalable to larger problems.\nWe rigorously evaluate its performance on synthetic datasets, demonstrating\nthat our algorithm not only outperforms current techniques, but also excels in\nscenarios with limited data availability. These results highlight its potential\nfor practical applications in fields requiring efficient and accurate causal\ninference from nonlinear time series data.",
      "pdf_url": "http://arxiv.org/pdf/2507.07898v1",
      "arxiv_url": "http://arxiv.org/abs/2507.07898v1",
      "published": "2025-07-10",
      "categories": [
        "cs.LG",
        "stat.AP"
      ]
    },
    {
      "title": "Efficient and Scalable Estimation of Distributional Treatment Effects with Multi-Task Neural Networks",
      "authors": [
        "Tomu Hirata",
        "Undral Byambadalai",
        "Tatsushi Oka",
        "Shota Yasui",
        "Shingo Uto"
      ],
      "abstract": "We propose a novel multi-task neural network approach for estimating\ndistributional treatment effects (DTE) in randomized experiments. While DTE\nprovides more granular insights into the experiment outcomes over conventional\nmethods focusing on the Average Treatment Effect (ATE), estimating it with\nregression adjustment methods presents significant challenges. Specifically,\nprecision in the distribution tails suffers due to data imbalance, and\ncomputational inefficiencies arise from the need to solve numerous regression\nproblems, particularly in large-scale datasets commonly encountered in\nindustry. To address these limitations, our method leverages multi-task neural\nnetworks to estimate conditional outcome distributions while incorporating\nmonotonic shape constraints and multi-threshold label learning to enhance\naccuracy. To demonstrate the practical effectiveness of our proposed method, we\napply our method to both simulated and real-world datasets, including a\nrandomized field experiment aimed at reducing water consumption in the US and a\nlarge-scale A/B test from a leading streaming platform in Japan. The\nexperimental results consistently demonstrate superior performance across\nvarious datasets, establishing our method as a robust and practical solution\nfor modern causal inference applications requiring a detailed understanding of\ntreatment effect heterogeneity.",
      "pdf_url": "http://arxiv.org/pdf/2507.07738v1",
      "arxiv_url": "http://arxiv.org/abs/2507.07738v1",
      "published": "2025-07-10",
      "categories": [
        "cs.LG",
        "econ.EM"
      ]
    },
    {
      "title": "Sparse Causal Discovery with Generative Intervention for Unsupervised Graph Domain Adaptation",
      "authors": [
        "Junyu Luo",
        "Yuhao Tang",
        "Yiwei Fu",
        "Xiao Luo",
        "Zhizhuo Kou",
        "Zhiping Xiao",
        "Wei Ju",
        "Wentao Zhang",
        "Ming Zhang"
      ],
      "abstract": "Unsupervised Graph Domain Adaptation (UGDA) leverages labeled source domain\ngraphs to achieve effective performance in unlabeled target domains despite\ndistribution shifts. However, existing methods often yield suboptimal results\ndue to the entanglement of causal-spurious features and the failure of global\nalignment strategies. We propose SLOGAN (Sparse Causal Discovery with\nGenerative Intervention), a novel approach that achieves stable graph\nrepresentation transfer through sparse causal modeling and dynamic intervention\nmechanisms. Specifically, SLOGAN first constructs a sparse causal graph\nstructure, leveraging mutual information bottleneck constraints to disentangle\nsparse, stable causal features while compressing domain-dependent spurious\ncorrelations through variational inference. To address residual spurious\ncorrelations, we innovatively design a generative intervention mechanism that\nbreaks local spurious couplings through cross-domain feature recombination\nwhile maintaining causal feature semantic consistency via covariance\nconstraints. Furthermore, to mitigate error accumulation in target domain\npseudo-labels, we introduce a category-adaptive dynamic calibration strategy,\nensuring stable discriminative learning. Extensive experiments on multiple\nreal-world datasets demonstrate that SLOGAN significantly outperforms existing\nbaselines.",
      "pdf_url": "http://arxiv.org/pdf/2507.07621v1",
      "arxiv_url": "http://arxiv.org/abs/2507.07621v1",
      "published": "2025-07-10",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "Goal-Oriented Sequential Bayesian Experimental Design for Causal Learning",
      "authors": [
        "Zheyu Zhang",
        "Jiayuan Dong",
        "Jie Liu",
        "Xun Huan"
      ],
      "abstract": "We present GO-CBED, a goal-oriented Bayesian framework for sequential causal\nexperimental design. Unlike conventional approaches that select interventions\naimed at inferring the full causal model, GO-CBED directly maximizes the\nexpected information gain (EIG) on user-specified causal quantities of\ninterest, enabling more targeted and efficient experimentation. The framework\nis both non-myopic, optimizing over entire intervention sequences, and\ngoal-oriented, targeting only model aspects relevant to the causal query. To\naddress the intractability of exact EIG computation, we introduce a variational\nlower bound estimator, optimized jointly through a transformer-based policy\nnetwork and normalizing flow-based variational posteriors. The resulting policy\nenables real-time decision-making via an amortized network. We demonstrate that\nGO-CBED consistently outperforms existing baselines across various causal\nreasoning and discovery tasks-including synthetic structural causal models and\nsemi-synthetic gene regulatory networks-particularly in settings with limited\nexperimental budgets and complex causal mechanisms. Our results highlight the\nbenefits of aligning experimental design objectives with specific research\ngoals and of forward-looking sequential planning.",
      "pdf_url": "http://arxiv.org/pdf/2507.07359v1",
      "arxiv_url": "http://arxiv.org/abs/2507.07359v1",
      "published": "2025-07-10",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME",
        "stat.ML"
      ]
    },
    {
      "title": "Beyond the ATE: Interpretable Modelling of Treatment Effects over Dose and Time",
      "authors": [
        "Julianna Piskorz",
        "Krzysztof Kacprzyk",
        "Mihaela van der Schaar"
      ],
      "abstract": "The Average Treatment Effect (ATE) is a foundational metric in causal\ninference, widely used to assess intervention efficacy in randomized controlled\ntrials (RCTs). However, in many applications -- particularly in healthcare --\nthis static summary fails to capture the nuanced dynamics of treatment effects\nthat vary with both dose and time. We propose a framework for modelling\ntreatment effect trajectories as smooth surfaces over dose and time, enabling\nthe extraction of clinically actionable insights such as onset time, peak\neffect, and duration of benefit. To ensure interpretability, robustness, and\nverifiability -- key requirements in high-stakes domains -- we adapt\nSemanticODE, a recent framework for interpretable trajectory modelling, to the\ncausal setting where treatment effects are never directly observed. Our\napproach decouples the estimation of trajectory shape from the specification of\nclinically relevant properties (e.g., maxima, inflection points), supporting\ndomain-informed priors, post-hoc editing, and transparent analysis. We show\nthat our method yields accurate, interpretable, and editable models of\ntreatment dynamics, facilitating both rigorous causal analysis and practical\ndecision-making.",
      "pdf_url": "http://arxiv.org/pdf/2507.07271v1",
      "arxiv_url": "http://arxiv.org/abs/2507.07271v1",
      "published": "2025-07-09",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "Debiased Semiparametric Efficient Changes-in-Changes Estimation",
      "authors": [
        "Jinghao Sun",
        "Eric J. Tchetgen Tchetgen"
      ],
      "abstract": "We introduce a novel extension of the influential changes-in-changes (CiC)\nframework [Athey and Imbens, 2006] to estimate the average treatment effect on\nthe treated (ATT) and distributional causal estimands in panel data settings\nwith unmeasured confounding. While CiC relaxes the parallel trends assumption\ninherent in difference-in-differences (DiD), existing approaches typically\naccommodate only a single scalar unobserved confounder and rely on monotonicity\nassumptions between the confounder and the outcome. Moreover, current\nformulations lack inference procedures and theoretical guarantees that\naccommodate continuous covariates. Motivated by the intricate nature of\nconfounding in empirical applications and the need to incorporate continuous\ncovariates in a principled manner, we make two key contributions in this\ntechnical report. First, we establish nonparametric identification under a\nnovel set of assumptions that permit high-dimensional unmeasured confounders\nand non-monotonic relationships between confounders and outcomes. Second, we\nconstruct efficient estimators that are Neyman orthogonal to\ninfinite-dimensional nuisance parameters, facilitating valid inference even in\nthe presence of high-dimensional continuous or discrete covariates and flexible\nmachine learning-based nuisance estimation.",
      "pdf_url": "http://arxiv.org/pdf/2507.07228v1",
      "arxiv_url": "http://arxiv.org/abs/2507.07228v1",
      "published": "2025-07-09",
      "categories": [
        "stat.ME",
        "econ.EM"
      ]
    },
    {
      "title": "Deep Disentangled Representation Network for Treatment Effect Estimation",
      "authors": [
        "Hui Meng",
        "Keping Yang",
        "Xuyu Peng",
        "Bo Zheng"
      ],
      "abstract": "Estimating individual-level treatment effect from observational data is a\nfundamental problem in causal inference and has attracted increasing attention\nin the fields of education, healthcare, and public policy.In this work, we\nconcentrate on the study of disentangled representation methods that have shown\npromising outcomes by decomposing observed covariates into instrumental,\nconfounding, and adjustment factors. However, most of the previous work has\nprimarily revolved around generative models or hard decomposition methods for\ncovariates, which often struggle to guarantee the attainment of precisely\ndisentangled factors. In order to effectively model different causal\nrelationships, we propose a novel treatment effect estimation algorithm that\nincorporates a mixture of experts with multi-head attention and a linear\northogonal regularizer to softly decompose the pre-treatment variables, and\nsimultaneously eliminates selection bias via importance sampling re-weighting\ntechniques. We conduct extensive experiments on both public semi-synthetic and\nreal-world production datasets. The experimental results clearly demonstrate\nthat our algorithm outperforms the state-of-the-art methods focused on\nindividual treatment effects.",
      "pdf_url": "http://arxiv.org/pdf/2507.06650v1",
      "arxiv_url": "http://arxiv.org/abs/2507.06650v1",
      "published": "2025-07-09",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "PromiseTune: Unveiling Causally Promising and Explainable Configuration Tuning",
      "authors": [
        "Pengzhou Chen",
        "Tao Chen"
      ],
      "abstract": "The high configurability of modern software systems has made configuration\ntuning a crucial step for assuring system performance, e.g., latency or\nthroughput. However, given the expensive measurements, large configuration\nspace, and rugged configuration landscape, existing tuners suffer\nineffectiveness due to the difficult balance of budget utilization between\nexploring uncertain regions (for escaping from local optima) and exploiting\nguidance of known good configurations (for fast convergence). The root cause is\nthat we lack knowledge of where the promising regions lay, which also causes\nchallenges in the explainability of the results.\n  In this paper, we propose PromiseTune that tunes configuration guided by\ncausally purified rules. PromiseTune is unique in the sense that we learn\nrules, which reflect certain regions in the configuration landscape, and purify\nthem with causal inference. The remaining rules serve as approximated\nreflections of the promising regions, bounding the tuning to emphasize these\nplaces in the landscape. This, as we demonstrate, can effectively mitigate the\nimpact of the exploration and exploitation trade-off. Those purified regions\ncan then be paired with the measured configurations to provide spatial\nexplainability at the landscape level. Comparing with 11 state-of-the-art\ntuners on 12 systems and varying budgets, we show that PromiseTune performs\nsignificantly better than the others with 42% superior rank to the overall\nsecond best while providing richer information to explain the hidden system\ncharacteristics.",
      "pdf_url": "http://arxiv.org/pdf/2507.05995v2",
      "arxiv_url": "http://arxiv.org/abs/2507.05995v2",
      "published": "2025-07-08",
      "categories": [
        "cs.SE"
      ]
    },
    {
      "title": "Estimating Interventional Distributions with Uncertain Causal Graphs through Meta-Learning",
      "authors": [
        "Anish Dhir",
        "Cristiana Diaconu",
        "Valentinian Mihai Lungu",
        "James Requeima",
        "Richard E. Turner",
        "Mark van der Wilk"
      ],
      "abstract": "In scientific domains -- from biology to the social sciences -- many\nquestions boil down to \\textit{What effect will we observe if we intervene on a\nparticular variable?} If the causal relationships (e.g.~a causal graph) are\nknown, it is possible to estimate the intervention distributions. In the\nabsence of this domain knowledge, the causal structure must be discovered from\nthe available observational data. However, observational data are often\ncompatible with multiple causal graphs, making methods that commit to a single\nstructure prone to overconfidence. A principled way to manage this structural\nuncertainty is via Bayesian inference, which averages over a posterior\ndistribution on possible causal structures and functional mechanisms.\nUnfortunately, the number of causal structures grows super-exponentially with\nthe number of nodes in the graph, making computations intractable. We propose\nto circumvent these challenges by using meta-learning to create an end-to-end\nmodel: the Model-Averaged Causal Estimation Transformer Neural Process\n(MACE-TNP). The model is trained to predict the Bayesian model-averaged\ninterventional posterior distribution, and its end-to-end nature bypasses the\nneed for expensive calculations. Empirically, we demonstrate that MACE-TNP\noutperforms strong Bayesian baselines. Our work establishes meta-learning as a\nflexible and scalable paradigm for approximating complex Bayesian causal\ninference, that can be scaled to increasingly challenging settings in the\nfuture.",
      "pdf_url": "http://arxiv.org/pdf/2507.05526v1",
      "arxiv_url": "http://arxiv.org/abs/2507.05526v1",
      "published": "2025-07-07",
      "categories": [
        "cs.LG",
        "stat.ME",
        "stat.ML"
      ]
    },
    {
      "title": "Identification of Causal Effects with a Bunching Design",
      "authors": [
        "Carolina Caetano",
        "Gregorio Caetano",
        "Leonard Goff",
        "Eric Nielsen"
      ],
      "abstract": "We show that causal effects can be identified when there is bunching in the\ndistribution of a continuous treatment variable, without imposing any\nparametric assumptions. This yields a new nonparametric method for overcoming\nselection bias in the absence of instrumental variables, panel data, or other\npopular research designs for causal inference. The method leverages the change\nof variables theorem from integration theory, relating the selection bias to\nthe ratio of the density of the treatment and the density of the part of the\noutcome that varies with confounders. At the bunching point, the treatment\nlevel is constant, so the variation in the outcomes is due entirely to\nunobservables, allowing us to identify the denominator. Our main result\nidentifies the average causal response to the treatment among individuals who\nmarginally select into the bunching point. We further show that under\nadditional smoothness assumptions on the selection bias, treatment effects away\nfrom the bunching point may also be identified. We propose estimators based on\nstandard software packages and apply the method to estimate the effect of\nmaternal smoking during pregnancy on birth weight.",
      "pdf_url": "http://arxiv.org/pdf/2507.05210v1",
      "arxiv_url": "http://arxiv.org/abs/2507.05210v1",
      "published": "2025-07-07",
      "categories": [
        "econ.EM"
      ]
    }
  ]
}