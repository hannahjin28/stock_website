{
  "last_updated": "2025-10-27T00:57:13.602440",
  "papers": [
    {
      "title": "Generative Reasoning Recommendation via LLMs",
      "authors": [
        "Minjie Hong",
        "Zetong Zhou",
        "Zirun Guo",
        "Ziang Zhang",
        "Ruofan Hu",
        "Weinan Gan",
        "Jieming Zhu",
        "Zhou Zhao"
      ],
      "abstract": "Despite their remarkable reasoning capabilities across diverse domains, large\nlanguage models (LLMs) face fundamental challenges in natively functioning as\ngenerative reasoning recommendation models (GRRMs), where the intrinsic\nmodeling gap between textual semantics and collaborative filtering signals,\ncombined with the sparsity and stochasticity of user feedback, presents\nsignificant obstacles. This work explores how to build GRRMs by adapting\npre-trained LLMs, which achieves a unified understanding-reasoning-prediction\nmanner for recommendation tasks. We propose GREAM, an end-to-end framework that\nintegrates three components: (i) Collaborative-Semantic Alignment, which fuses\nheterogeneous textual evidence to construct semantically consistent, discrete\nitem indices and auxiliary alignment tasks that ground linguistic\nrepresentations in interaction semantics; (ii) Reasoning Curriculum Activation,\nwhich builds a synthetic dataset with explicit Chain-of-Thought supervision and\na curriculum that progresses through behavioral evidence extraction, latent\npreference modeling, intent inference, recommendation formulation, and denoised\nsequence rewriting; and (iii) Sparse-Regularized Group Policy Optimization\n(SRPO), which stabilizes post-training via Residual-Sensitive Verifiable Reward\nand Bonus-Calibrated Group Advantage Estimation, enabling end-to-end\noptimization under verifiable signals despite sparse successes. GREAM natively\nsupports two complementary inference modes: Direct Sequence Recommendation for\nhigh-throughput, low-latency deployment, and Sequential Reasoning\nRecommendation that first emits an interpretable reasoning chain for causal\ntransparency. Experiments on three datasets demonstrate consistent gains over\nstrong baselines, providing a practical path toward verifiable-RL-driven LLM\nrecommenders.",
      "pdf_url": "http://arxiv.org/pdf/2510.20815v1",
      "arxiv_url": "http://arxiv.org/abs/2510.20815v1",
      "published": "2025-10-23",
      "categories": [
        "cs.IR"
      ]
    },
    {
      "title": "Better Tokens for Better 3D: Advancing Vision-Language Modeling in 3D Medical Imaging",
      "authors": [
        "Ibrahim Ethem Hamamci",
        "Sezgin Er",
        "Suprosanna Shit",
        "Hadrien Reynaud",
        "Dong Yang",
        "Pengfei Guo",
        "Marc Edgar",
        "Daguang Xu",
        "Bernhard Kainz",
        "Bjoern Menze"
      ],
      "abstract": "Recent progress in vision-language modeling for 3D medical imaging has been\nfueled by large-scale computed tomography (CT) corpora with paired free-text\nreports, stronger architectures, and powerful pretrained models. This has\nenabled applications such as automated report generation and text-conditioned\n3D image synthesis. Yet, current approaches struggle with high-resolution,\nlong-sequence volumes: contrastive pretraining often yields vision encoders\nthat are misaligned with clinical language, and slice-wise tokenization blurs\nfine anatomy, reducing diagnostic performance on downstream tasks. We introduce\nBTB3D (Better Tokens for Better 3D), a causal convolutional encoder-decoder\nthat unifies 2D and 3D training and inference while producing compact,\nfrequency-aware volumetric tokens. A three-stage training curriculum enables\n(i) local reconstruction, (ii) overlapping-window tiling, and (iii)\nlong-context decoder refinement, during which the model learns from short slice\nexcerpts yet generalizes to scans exceeding 300 slices without additional\nmemory overhead. BTB3D sets a new state-of-the-art on two key tasks: it\nimproves BLEU scores and increases clinical F1 by 40% over CT2Rep, CT-CHAT, and\nMerlin for report generation; and it reduces FID by 75% and halves FVD compared\nto GenerateCT and MedSyn for text-to-CT synthesis, producing anatomically\nconsistent 512*512*241 volumes. These results confirm that precise\nthree-dimensional tokenization, rather than larger language backbones alone, is\nessential for scalable vision-language modeling in 3D medical imaging. The\ncodebase is available at: https://github.com/ibrahimethemhamamci/BTB3D",
      "pdf_url": "http://arxiv.org/pdf/2510.20639v1",
      "arxiv_url": "http://arxiv.org/abs/2510.20639v1",
      "published": "2025-10-23",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "On Multiple Robustness of Proximal Dynamic Treatment Regimes",
      "authors": [
        "Yuanshan Gao",
        "Yang Bai",
        "Yifan Cui"
      ],
      "abstract": "Dynamic treatment regimes are sequential decision rules that adapt treatment\naccording to individual time-varying characteristics and outcomes to achieve\noptimal effects, with applications in precision medicine, personalized\nrecommendations, and dynamic marketing. Estimating optimal dynamic treatment\nregimes via sequential randomized trials might face costly and ethical hurdles,\noften necessitating the use of historical observational data. In this work, we\nutilize proximal causal inference framework for learning optimal dynamic\ntreatment regimes when the unconfoundedness assumption fails. Our contributions\nare four-fold: (i) we propose three nonparametric identification methods for\noptimal dynamic treatment regimes; (ii) we establish the semiparametric\nefficiency bound for the value function of a given regime; (iii) we propose a\n(K+1)-robust method for learning optimal dynamic treatment regimes, where K is\nthe number of stages; (iv) as a by-product for marginal structural models, we\nestablish identification and estimation of counterfactual means under a static\nregime. Numerical experiments validate the efficiency and multiple robustness\nof our proposed methods.",
      "pdf_url": "http://arxiv.org/pdf/2510.20451v1",
      "arxiv_url": "http://arxiv.org/abs/2510.20451v1",
      "published": "2025-10-23",
      "categories": [
        "stat.ME",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ]
    },
    {
      "title": "Identification and Debiased Learning of Causal Effects with General Instrumental Variables",
      "authors": [
        "Shuyuan Chen",
        "Peng Zhang",
        "Yifan Cui"
      ],
      "abstract": "Instrumental variable methods are fundamental to causal inference when\ntreatment assignment is confounded by unobserved variables. In this article, we\ndevelop a general nonparametric framework for identification and learning with\nmulti-categorical or continuous instrumental variables. Specifically, we\npropose an additive instrumental variable framework to identify mean potential\noutcomes and the average treatment effect with a weighting function. Leveraging\nsemiparametric theory, we derive efficient influence functions and construct\nconsistent, asymptotically normal estimators via debiased machine learning.\nExtensions to longitudinal data, dynamic treatment regimes, and multiplicative\ninstrumental variables are further developed. We demonstrate the proposed\nmethod by employing simulation studies and analyzing real data from the Job\nTraining Partnership Act program.",
      "pdf_url": "http://arxiv.org/pdf/2510.20404v1",
      "arxiv_url": "http://arxiv.org/abs/2510.20404v1",
      "published": "2025-10-23",
      "categories": [
        "stat.ME",
        "econ.EM",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ]
    },
    {
      "title": "Bias-Variance Tradeoff of Matching Prior to Difference-in-Differences When Parallel Trends is Violated",
      "authors": [
        "Mingxuan Ge",
        "Dae Woong Ham"
      ],
      "abstract": "Quasi-experimental causal inference methods have become central in empirical\noperations management (OM) for guiding managerial decisions. Among these,\nempiricists utilize the Difference-in-Differences (DiD) estimator, which relies\non the parallel trends assumption. To improve its plausibility, researchers\noften match treated and control units before applying DiD, with the intuition\nthat matched groups are more likely to evolve similarly absent treatment.\nExisting work that analyze this practice, however, has focused solely on bias.\nWe complement and fill an important gap by analyzing the full bias-variance\ntradeoff. Under a linear structural model with unobserved time-varying\nconfounders, we show that variance results contrast with established bias\ninsights: matching on observed covariates prior to DiD is not always\nrecommended over the classic (unmatched) DiD due to a sample size tradeoff;\nfurthermore, matching additionally on pre-treatment outcomes is always\nbeneficial as such tradeoff no longer exists once matching is performed. We\ntherefore advocate mean squared error (MSE) as a final metric and give\npractitioner-friendly guidelines with theoretical guarantees on when (and on\nwhat variables) they should match on. We apply these insights to a recent study\non how the introduction of monetary incentives by a knowledge-sharing platform\naffects its general engagement and show that the authors' matching choice prior\nto DiD was both warranted and critical. In particular, we provide new\nmanagerial insights that after a full bias correction, their estimated effect\nwith matching still remains statistically significant, demonstrating that the\nchosen matching-DiD approach is sufficiently robust to address managerial\nconcerns over violations of parallel trends.",
      "pdf_url": "http://arxiv.org/pdf/2510.20191v1",
      "arxiv_url": "http://arxiv.org/abs/2510.20191v1",
      "published": "2025-10-23",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Treatment Effect Learning Under Sequential Randomization",
      "authors": [
        "Rina Friedberg",
        "Richard Mudd",
        "Patrick Johnstone",
        "Melissa Pothen",
        "Vishal Vaingankar",
        "Vishwanath Sangale",
        "Abbas Zaidi"
      ],
      "abstract": "Sequential treatment assignments in online experiments lead to complex\ndependency structures, often rendering identification, estimation and inference\nover treatments a challenge. Treatments in one session (e.g., a user logging\non) can have an effect that persists into subsequent sessions, leading to\ncumulative effects on outcomes measured at a later stage. This can render\nstandard methods for identification and inference trivially misspecified. We\npropose T-Learners layered into the G-Formula for this setting, building on\nliterature from causal machine learning and identification in sequential\nsettings. In a simple simulation, this approach prevents decaying accuracy in\nthe presence of carry-over effects, highlighting the importance of\nidentification and inference strategies tailored to the nature of systems often\nseen in the tech domain.",
      "pdf_url": "http://arxiv.org/pdf/2510.20078v1",
      "arxiv_url": "http://arxiv.org/abs/2510.20078v1",
      "published": "2025-10-22",
      "categories": [
        "stat.AP",
        "stat.ME"
      ]
    },
    {
      "title": "LLM-Augmented Symbolic NLU System for More Reliable Continuous Causal Statement Interpretation",
      "authors": [
        "Xin Lian",
        "Kenneth D. Forbus"
      ],
      "abstract": "Despite the broad applicability of large language models (LLMs), their\nreliance on probabilistic inference makes them vulnerable to errors such as\nhallucination in generated facts and inconsistent output structure in natural\nlanguage understanding (NLU) tasks. By contrast, symbolic NLU systems provide\ninterpretable understanding grounded in curated lexicons, semantic resources,\nand syntactic & semantic interpretation rules. They produce relational\nrepresentations that can be used for accurate reasoning and planning, as well\nas incremental debuggable learning. However, symbolic NLU systems tend to be\nmore limited in coverage than LLMs and require scarce knowledge representation\nand linguistics skills to extend and maintain. This paper explores a hybrid\napproach that integrates the broad-coverage language processing of LLMs with\nthe symbolic NLU capabilities of producing structured relational\nrepresentations to hopefully get the best of both approaches. We use LLMs for\nrephrasing and text simplification, to provide broad coverage, and as a source\nof information to fill in knowledge gaps more automatically. We use symbolic\nNLU to produce representations that can be used for reasoning and for\nincremental learning. We evaluate this approach on the task of extracting and\ninterpreting quantities and causal laws from commonsense science texts, along\nwith symbolic- and LLM-only pipelines. Our results suggest that our hybrid\nmethod works significantly better than the symbolic-only pipeline.",
      "pdf_url": "http://arxiv.org/pdf/2510.19988v1",
      "arxiv_url": "http://arxiv.org/abs/2510.19988v1",
      "published": "2025-10-22",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "Benchmarking World-Model Learning",
      "authors": [
        "Archana Warrier",
        "Dat Nguyen",
        "Michelangelo Naim",
        "Moksh Jain",
        "Yichao Liang",
        "Karen Schroeder",
        "Cambridge Yang",
        "Joshua B. Tenenbaum",
        "Sebastian Vollmer",
        "Kevin Ellis",
        "Zenna Tavares"
      ],
      "abstract": "Model-learning agents should gather information to learn world models that\nsupport many downstream tasks and inferences, such as predicting unobserved\nstates, estimating near- and far-term consequences of actions, planning action\nsequences, and detecting changes in dynamics. Current methods for learning and\nevaluating world models diverge from this goal: training and evaluation are\nanchored to next-frame prediction, and success is scored by reward maximization\nin the same environment. We propose WorldTest, a protocol to evaluate\nmodel-learning agents that separates reward-free interaction from a scored test\nphase in a different but related environment. WorldTest is\nopen-ended$\\unicode{x2014}$models should support many different tasks unknown\nahead of time$\\unicode{x2014}$and agnostic to model representation, allowing\ncomparison across approaches. We instantiated WorldTest with AutumnBench, a\nsuite of 43 interactive grid-world environments and 129 tasks across three\nfamilies: masked-frame prediction, planning, and predicting changes to the\ncausal dynamics. We compared 517 human participants and three frontier models\non AutumnBench. We found that humans outperform the models, and scaling compute\nimproves performance only in some environments but not others. WorldTest\nprovides a novel template$\\unicode{x2014}$reward-free exploration, derived\ntests, and behavior-based scoring$\\unicode{x2014}$to evaluate what agents learn\nabout environment dynamics, and AutumnBench exposes significant headroom in\nworld-model learning.",
      "pdf_url": "http://arxiv.org/pdf/2510.19788v2",
      "arxiv_url": "http://arxiv.org/abs/2510.19788v2",
      "published": "2025-10-22",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Lookahead Routing for Large Language Models",
      "authors": [
        "Canbin Huang",
        "Tianyuan Shi",
        "Yuhua Zhu",
        "Ruijun Chen",
        "Xiaojun Quan"
      ],
      "abstract": "Large language model (LLM) routers improve the efficiency of multi-model\nsystems by directing each query to the most appropriate model while leveraging\nthe diverse strengths of heterogeneous LLMs. Most existing approaches frame\nrouting as a classification problem based solely on the input query. While this\nreduces overhead by avoiding inference across all models, it overlooks valuable\ninformation that could be gleaned from potential outputs and fails to capture\nimplicit intent or contextual nuances that often emerge only during response\ngeneration. These limitations can result in suboptimal routing decisions,\nparticularly for complex or ambiguous queries that require deeper semantic\nunderstanding. To address this challenge, we propose Lookahead, a routing\nframework that \"foresees\" potential model outputs by predicting their latent\nrepresentations and uses these predictions to guide model selection, thus\nenabling more informed routing without full inference. Within this framework,\nwe implement two approaches based on causal and masked language models.\nEmpirical evaluations across seven public benchmarks - spanning instruction\nfollowing, mathematical reasoning, and code generation - show that Lookahead\nconsistently outperforms existing routing baselines, achieving an average\nperformance gain of 7.7% over the state-of-the-art. Our code is available at\nhttps://github.com/huangcb01/lookahead-routing.",
      "pdf_url": "http://arxiv.org/pdf/2510.19506v1",
      "arxiv_url": "http://arxiv.org/abs/2510.19506v1",
      "published": "2025-10-22",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "title": "A New Targeted-Federated Learning Framework for Estimating Heterogeneity of Treatment Effects: A Robust Framework with Applications in Aging Cohorts",
      "authors": [
        "Rong Zhao",
        "Jason Falvey",
        "Xu Shi",
        "Vernon M. Chinchilli",
        "Chixiang Chen"
      ],
      "abstract": "Analyzing data from multiple sources offers valuable opportunities to improve\nthe estimation efficiency of causal estimands. However, this analysis also\nposes many challenges due to population heterogeneity and data privacy\nconstraints. While several advanced methods for causal inference in federated\nsettings have been developed in recent years, many focus on difference-based\naveraged causal effects and are not designed to study effect modification. In\nthis study, we introduce a novel targeted-federated learning framework to study\nthe heterogeneity of treatment effects (HTEs) for a targeted population by\nproposing a projection-based estimand. This HTE framework integrates\ninformation from multiple data sources without sharing raw data, while\naccounting for covariate distribution shifts among sources. Our proposed\napproach is shown to be doubly robust, conveniently supporting both\ndifference-based estimands for continuous outcomes and odds ratio-based\nestimands for binary outcomes. Furthermore, we develop a\ncommunication-efficient bootstrap-based selection procedure to detect\nnon-transportable data sources, thereby enhancing robust information\naggregation without introducing bias. The superior performance of the proposed\nestimator over existing methods is demonstrated through extensive simulation\nstudies, and the utility of our approach has been shown in a real-world data\napplication using nationwide Medicare-linked data.",
      "pdf_url": "http://arxiv.org/pdf/2510.19243v1",
      "arxiv_url": "http://arxiv.org/abs/2510.19243v1",
      "published": "2025-10-22",
      "categories": [
        "stat.ME"
      ]
    }
  ]
}