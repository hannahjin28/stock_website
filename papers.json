{
  "last_updated": "2025-04-18T00:50:29.448235",
  "papers": [
    {
      "title": "Cobra: Efficient Line Art COlorization with BRoAder References",
      "authors": [
        "Junhao Zhuang",
        "Lingen Li",
        "Xuan Ju",
        "Zhaoyang Zhang",
        "Chun Yuan",
        "Ying Shan"
      ],
      "abstract": "The comic production industry requires reference-based line art colorization\nwith high accuracy, efficiency, contextual consistency, and flexible control. A\ncomic page often involves diverse characters, objects, and backgrounds, which\ncomplicates the coloring process. Despite advancements in diffusion models for\nimage generation, their application in line art colorization remains limited,\nfacing challenges related to handling extensive reference images,\ntime-consuming inference, and flexible control. We investigate the necessity of\nextensive contextual image guidance on the quality of line art colorization. To\naddress these challenges, we introduce Cobra, an efficient and versatile method\nthat supports color hints and utilizes over 200 reference images while\nmaintaining low latency. Central to Cobra is a Causal Sparse DiT architecture,\nwhich leverages specially designed positional encodings, causal sparse\nattention, and Key-Value Cache to effectively manage long-context references\nand ensure color identity consistency. Results demonstrate that Cobra achieves\naccurate line art colorization through extensive contextual reference,\nsignificantly enhancing inference speed and interactivity, thereby meeting\ncritical industrial demands. We release our codes and models on our project\npage: https://zhuang2002.github.io/Cobra/.",
      "pdf_url": "http://arxiv.org/pdf/2504.12240v1",
      "arxiv_url": "http://arxiv.org/abs/2504.12240v1",
      "published": "2025-04-16",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "Semiparametric Causal Discovery and Inference with Invalid Instruments",
      "authors": [
        "Jing Zou",
        "Wei Li",
        "Wei Lin"
      ],
      "abstract": "Learning causal relationships among a set of variables, as encoded by a\ndirected acyclic graph, from observational data is complicated by the presence\nof unobserved confounders. Instrumental variables (IVs) are a popular remedy\nfor this issue, but most existing methods either assume the validity of all IVs\nor postulate a specific form of relationship, such as a linear model, between\nthe primary variables and the IVs. To overcome these limitations, we introduce\na partially linear structural equation model for causal discovery and inference\nthat accommodates potentially invalid IVs and allows for general dependence of\nthe primary variables on the IVs. We establish identification under this\nsemiparametric model by constructing surrogate valid IVs, and develop a\nfinite-sample procedure for estimating the causal structures and effects.\nTheoretically, we show that our procedure consistently learns the causal\nstructures, yields asymptotically normal estimates, and effectively controls\nthe false discovery rate in edge recovery. Simulation studies demonstrate the\nsuperiority of our method over existing competitors, and an application to\ninferring gene regulatory networks in Alzheimer's disease illustrates its\nusefulness.",
      "pdf_url": "http://arxiv.org/pdf/2504.12085v1",
      "arxiv_url": "http://arxiv.org/abs/2504.12085v1",
      "published": "2025-04-16",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Causality-enhanced Decision-Making for Autonomous Mobile Robots in Dynamic Environments",
      "authors": [
        "Luca Castri",
        "Gloria Beraldo",
        "Nicola Bellotto"
      ],
      "abstract": "The growing integration of robots in shared environments -- such as\nwarehouses, shopping centres, and hospitals -- demands a deep understanding of\nthe underlying dynamics and human behaviours, including how, when, and where\nindividuals engage in various activities and interactions. This knowledge goes\nbeyond simple correlation studies and requires a more comprehensive causal\nanalysis. By leveraging causal inference to model cause-and-effect\nrelationships, we can better anticipate critical environmental factors and\nenable autonomous robots to plan and execute tasks more effectively. To this\nend, we propose a novel causality-based decision-making framework that reasons\nover a learned causal model to predict battery usage and human obstructions,\nunderstanding how these factors could influence robot task execution. Such\nreasoning framework assists the robot in deciding when and how to complete a\ngiven task. To achieve this, we developed also PeopleFlow, a new Gazebo-based\nsimulator designed to model context-sensitive human-robot spatial interactions\nin shared workspaces. PeopleFlow features realistic human and robot\ntrajectories influenced by contextual factors such as time, environment layout,\nand robot state, and can simulate a large number of agents. While the simulator\nis general-purpose, in this paper we focus on a warehouse-like environment as a\ncase study, where we conduct an extensive evaluation benchmarking our causal\napproach against a non-causal baseline. Our findings demonstrate the efficacy\nof the proposed solutions, highlighting how causal reasoning enables autonomous\nrobots to operate more efficiently and safely in dynamic environments shared\nwith humans.",
      "pdf_url": "http://arxiv.org/pdf/2504.11901v2",
      "arxiv_url": "http://arxiv.org/abs/2504.11901v2",
      "published": "2025-04-16",
      "categories": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "title": "A cautionary note for plasmode simulation studies in the setting of causal inference",
      "authors": [
        "Pamela A Shaw",
        "Susan Gruber",
        "Brian D. Williamson",
        "Rishi Desai",
        "Susan M. Shortreed",
        "Chloe Krakauer",
        "Jennifer C. Nelson",
        "Mark J. van der Laan"
      ],
      "abstract": "Plasmode simulation has become an important tool for evaluating the operating\ncharacteristics of different statistical methods in complex settings, such as\npharmacoepidemiological studies of treatment effectiveness using electronic\nhealth records (EHR) data. These studies provide insight into how estimator\nperformance is impacted by challenges including rare events, small sample size,\netc., that can indicate which among a set of methods performs best in a\nreal-world dataset. Plasmode simulation combines data resampled from a\nreal-world dataset with synthetic data to generate a known truth for an\nestimand in realistic data. There are different potential plasmode strategies\ncurrently in use. We compare two popular plasmode simulation frameworks. We\nprovide numerical evidence and a theoretical result, which shows that one of\nthese frameworks can cause certain estimators to incorrectly appear overly\nbiased with lower than nominal confidence interval coverage. Detailed\nsimulation studies using both synthetic and real-world EHR data demonstrate\nthat these pitfalls remain at large sample sizes and when analyzing data from a\nrandomized controlled trial. We conclude with guidance for the choice of a\nplasmode simulation approach that maintains good theoretical properties to\nallow a fair evaluation of statistical methods while also maintaining the\ndesired similarity to real data.",
      "pdf_url": "http://arxiv.org/pdf/2504.11740v1",
      "arxiv_url": "http://arxiv.org/abs/2504.11740v1",
      "published": "2025-04-16",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Looking beyond the next token",
      "authors": [
        "Abitha Thankaraj",
        "Yiding Jiang",
        "J. Zico Kolter",
        "Yonatan Bisk"
      ],
      "abstract": "The structure of causal language model training assumes that each token can\nbe accurately predicted from the previous context. This contrasts with humans'\nnatural writing and reasoning process, where goals are typically known before\nthe exact argument or phrasings. While this mismatch has been well studied in\nthe literature, the working assumption has been that architectural changes are\nneeded to address this mismatch. We argue that rearranging and processing the\ntraining data sequences can allow models to more accurately imitate the true\ndata-generating process, and does not require any other changes to the\narchitecture or training infrastructure. We demonstrate that this technique,\nTrelawney, and the inference algorithms derived from it allow us to improve\nperformance on several key benchmarks that span planning, algorithmic\nreasoning, and story generation tasks. Finally, our method naturally enables\nthe generation of long-term goals at no additional cost. We investigate how\nusing the model's goal-generation capability can further improve planning and\nreasoning. Additionally, we believe Trelawney could potentially open doors to\nnew capabilities beyond the current language modeling paradigm.",
      "pdf_url": "http://arxiv.org/pdf/2504.11336v1",
      "arxiv_url": "http://arxiv.org/abs/2504.11336v1",
      "published": "2025-04-15",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Clinically Interpretable Survival Risk Stratification in Head and Neck Cancer Using Bayesian Networks and Markov Blankets",
      "authors": [
        "Keyur D. Shah",
        "Ibrahim Chamseddine",
        "Xiaohan Yuan",
        "Sibo Tian",
        "Richard Qiu",
        "Jun Zhou",
        "Anees Dhabaan",
        "Hania Al-Hallaq",
        "David S. Yu",
        "Harald Paganetti",
        "Xiaofeng Yang"
      ],
      "abstract": "Purpose: To identify a clinically interpretable subset of survival-relevant\nfeatures in HN cancer using Bayesian Network (BN) and evaluate its prognostic\nand causal utility. Methods and Materials: We used the RADCURE dataset,\nconsisting of 3,346 patients with H&N cancer treated with definitive\n(chemo)radiotherapy. A probabilistic BN was constructed to model dependencies\namong clinical, anatomical, and treatment variables. The Markov Blanket (MB) of\ntwo-year survival (SVy2) was extracted and used to train a logistic regression\nmodel. After excluding incomplete cases, a temporal split yielded a train/test\n(2,174/820) dataset using 2007 as the cutoff year. Model performance was\nassessed using area under the ROC curve (AUC), C-index, and Kaplan-Meier (KM)\nsurvival stratification. Model fit was further evaluated using a log-likelihood\nratio (LLR) test. Causal inference was performed using do-calculus\ninterventions on MB variables. Results: The MB of SVy2 included 6 clinically\nrelevant features: ECOG performance status, T-stage, HPV status, disease site,\nthe primary gross tumor volume (GTVp), and treatment modality. The model\nachieved an AUC of 0.65 and C-index of 0.78 on the test dataset, significantly\nstratifying patients into high- and low-risk groups (log-rank p < 0.01). Model\nfit was further supported by a log-likelihood ratio of 70.32 (p < 0.01).\nSubgroup analyses revealed strong performance in HPV-negative (AUC = 0.69,\nC-index = 0.76), T4 (AUC = 0.69, C-index = 0.80), and large-GTV (AUC = 0.67,\nC-index = 0.75) cohorts, each showing significant KM separation. Causal\nanalysis further supported the positive survival impact of ECOG 0, HPV-positive\nstatus, and chemoradiation. Conclusions: A compact, MB-derived BN model can\nrobustly stratify survival risk in HN cancer. The model enables explainable\nprognostication and supports individualized decision-making across key clinical\nsubgroups.",
      "pdf_url": "http://arxiv.org/pdf/2504.11188v1",
      "arxiv_url": "http://arxiv.org/abs/2504.11188v1",
      "published": "2025-04-15",
      "categories": [
        "physics.med-ph"
      ]
    },
    {
      "title": "On relative universality, regression operator, and conditional independence",
      "authors": [
        "Bing Li",
        "Ben Jones",
        "Andreas Artemiou"
      ],
      "abstract": "The notion of relative universality with respect to a {\\sigma}-field was\nintroduced to establish the unbiasedness and Fisher consistency of an estimator\nin nonlinear sufficient dimension reduction. However, there is a gap in the\nproof of this result in the existing literature. The existing definition of\nrelative universality seems to be too strong for the proof to be valid. In this\nnote we modify the definition of relative universality using the concept of\n\\k{o}-measurability, and rigorously establish the mentioned unbiasedness and\nFisher consistency. The significance of this result is beyond its original\ncontext of sufficient dimension reduction, because relative universality allows\nus to use the regression operator to fully characterize conditional\nindependence, a crucially important statistical relation that sits at the core\nof many areas and methodologies in statistics and machine learning, such as\ndimension reduction, graphical models, probability embedding, causal inference,\nand Bayesian estimation.",
      "pdf_url": "http://arxiv.org/pdf/2504.11044v1",
      "arxiv_url": "http://arxiv.org/abs/2504.11044v1",
      "published": "2025-04-15",
      "categories": [
        "math.ST",
        "stat.ME",
        "stat.ML",
        "stat.TH",
        "62",
        "G.3"
      ]
    },
    {
      "title": "A conceptual synthesis of causal assumptions for causal discovery and inference",
      "authors": [
        "Hannah E. Correia"
      ],
      "abstract": "This work presents a conceptual synthesis of causal discovery and inference\nframeworks, with a focus on how foundational assumptions -- causal sufficiency,\ncausal faithfulness, and the causal Markov condition -- are formalized and\noperationalized across methodological traditions. Through structured tables and\ncomparative summaries, I map core assumptions, tasks, and analytical choices\nfrom multiple causal frameworks, highlighting their connections and\ndifferences. The synthesis provides practical guidance for researchers\ndesigning causal studies, especially in settings where observational or\nexperimental constraints challenge standard approaches. This guide spans all\nphases of causal analysis, including question formulation, formalization of\nbackground knowledge, selection of appropriate frameworks, choice of study\ndesign or algorithm, and interpretation. It is intended as a tool to support\nrigorous causal reasoning across diverse empirical domains.",
      "pdf_url": "http://arxiv.org/pdf/2504.11035v1",
      "arxiv_url": "http://arxiv.org/abs/2504.11035v1",
      "published": "2025-04-15",
      "categories": [
        "stat.ME",
        "q-bio.QM",
        "stat.AP",
        "stat.OT",
        "62A01"
      ]
    },
    {
      "title": "Can LLMs Leverage Observational Data? Towards Data-Driven Causal Discovery with LLMs",
      "authors": [
        "Yuni Susanti",
        "Michael Färber"
      ],
      "abstract": "Causal discovery traditionally relies on statistical methods applied to\nobservational data, often requiring large datasets and assumptions about\nunderlying causal structures. Recent advancements in Large Language Models\n(LLMs) have introduced new possibilities for causal discovery by providing\ndomain expert knowledge. However, it remains unclear whether LLMs can\neffectively process observational data for causal discovery. In this work, we\nexplore the potential of LLMs for data-driven causal discovery by integrating\nobservational data for LLM-based reasoning. Specifically, we examine whether\nLLMs can effectively utilize observational data through two prompting\nstrategies: pairwise prompting and breadth first search (BFS)-based prompting.\nIn both approaches, we incorporate the observational data directly into the\nprompt to assess LLMs' ability to infer causal relationships from such data.\nExperiments on benchmark datasets show that incorporating observational data\nenhances causal discovery, boosting F1 scores by up to 0.11 point using both\npairwise and BFS LLM-based prompting, while outperforming traditional\nstatistical causal discovery baseline by up to 0.52 points. Our findings\nhighlight the potential and limitations of LLMs for data-driven causal\ndiscovery, demonstrating their ability to move beyond textual metadata and\neffectively interpret and utilize observational data for more informed causal\nreasoning. Our studies lays the groundwork for future advancements toward fully\nLLM-driven causal discovery.",
      "pdf_url": "http://arxiv.org/pdf/2504.10936v1",
      "arxiv_url": "http://arxiv.org/abs/2504.10936v1",
      "published": "2025-04-15",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "Bayesian analysis of regression discontinuity designs with heterogeneous treatment effects",
      "authors": [
        "Kevin Tao",
        "Y. Samuel Wang",
        "David Ruppert"
      ],
      "abstract": "Regression Discontinuity Design (RDD) is a popular framework for estimating a\ncausal effect in settings where treatment is assigned if an observed covariate\nexceeds a fixed threshold. We consider estimation and inference in the common\nsetting where the sample consists of multiple known sub-populations with\npotentially heterogeneous treatment effects. In the applied literature, it is\ncommon to account for heterogeneity by either fitting a parametric model or\nconsidering each sub-population separately. In contrast, we develop a Bayesian\nhierarchical model using Gaussian process regression which allows for\nnon-parametric regression while borrowing information across sub-populations.\nWe derive the posterior distribution, prove posterior consistency, and develop\na Metropolis-Hastings within Gibbs sampling algorithm. In extensive\nsimulations, we show that the proposed procedure outperforms existing methods\nin both estimation and inferential tasks. Finally, we apply our procedure to\nU.S. Senate election data and discover an incumbent party advantage which is\nheterogeneous over different time periods.",
      "pdf_url": "http://arxiv.org/pdf/2504.10652v1",
      "arxiv_url": "http://arxiv.org/abs/2504.10652v1",
      "published": "2025-04-14",
      "categories": [
        "math.ST",
        "stat.ME",
        "stat.TH",
        "62C10"
      ]
    }
  ]
}