{
  "last_updated": "2025-11-20T00:52:54.608422",
  "papers": [
    {
      "title": "Skewness-Robust Causal Discovery in Location-Scale Noise Models",
      "authors": [
        "Daniel Klippert",
        "Alexander Marx"
      ],
      "abstract": "To distinguish Markov equivalent graphs in causal discovery, it is necessary to restrict the structural causal model. Crucially, we need to be able to distinguish cause $X$ from effect $Y$ in bivariate models, that is, distinguish the two graphs $X \\to Y$ and $Y \\to X$. Location-scale noise models (LSNMs), in which the effect $Y$ is modeled based on the cause $X$ as $Y = f(X) + g(X)N$, form a flexible class of models that is general and identifiable in most cases. Estimating these models for arbitrary noise terms $N$, however, is challenging. Therefore, practical estimators are typically restricted to symmetric distributions, such as the normal distribution. As we showcase in this paper, when $N$ is a skewed random variable, which is likely in real-world domains, the reliability of these approaches decreases. To approach this limitation, we propose SkewD, a likelihood-based algorithm for bivariate causal discovery under LSNMs with skewed noise distributions. SkewD extends the usual normal-distribution framework to the skew-normal setting, enabling reliable inference under symmetric and skewed noise. For parameter estimation, we employ a combination of a heuristic search and an expectation conditional maximization algorithm. We evaluate SkewD on novel synthetically generated datasets with skewed noise as well as established benchmark datasets. Throughout our experiments, SkewD exhibits a strong performance and, in comparison to prior work, remains robust under high skewness.",
      "pdf_url": "https://arxiv.org/pdf/2511.14441v1",
      "arxiv_url": "http://arxiv.org/abs/2511.14441v1",
      "published": "2025-11-18",
      "categories": [
        "stat.ML",
        "cs.LG"
      ]
    },
    {
      "title": "InstantViR: Real-Time Video Inverse Problem Solver with Distilled Diffusion Prior",
      "authors": [
        "Weimin Bai",
        "Suzhe Xu",
        "Yiwei Ren",
        "Jinhua Hao",
        "Ming Sun",
        "Wenzheng Chen",
        "He Sun"
      ],
      "abstract": "Video inverse problems are fundamental to streaming, telepresence, and AR/VR, where high perceptual quality must coexist with tight latency constraints. Diffusion-based priors currently deliver state-of-the-art reconstructions, but existing approaches either adapt image diffusion models with ad hoc temporal regularizers - leading to temporal artifacts - or rely on native video diffusion models whose iterative posterior sampling is far too slow for real-time use. We introduce InstantViR, an amortized inference framework for ultra-fast video reconstruction powered by a pre-trained video diffusion prior. We distill a powerful bidirectional video diffusion model (teacher) into a causal autoregressive student that maps a degraded video directly to its restored version in a single forward pass, inheriting the teacher's strong temporal modeling while completely removing iterative test-time optimization. The distillation is prior-driven: it only requires the teacher diffusion model and known degradation operators, and does not rely on externally paired clean/noisy video data. To further boost throughput, we replace the video-diffusion backbone VAE with a high-efficiency LeanVAE via an innovative teacher-space regularized distillation scheme, enabling low-latency latent-space processing. Across streaming random inpainting, Gaussian deblurring and super-resolution, InstantViR matches or surpasses the reconstruction quality of diffusion-based baselines while running at over 35 FPS on NVIDIA A100 GPUs, achieving up to 100 times speedups over iterative video diffusion solvers. These results show that diffusion-based video reconstruction is compatible with real-time, interactive, editable, streaming scenarios, turning high-quality video restoration into a practical component of modern vision systems.",
      "pdf_url": "https://arxiv.org/pdf/2511.14208v1",
      "arxiv_url": "http://arxiv.org/abs/2511.14208v1",
      "published": "2025-11-18",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "Synthetic Survival Control: Extending Synthetic Controls for \"When-If\" Decision",
      "authors": [
        "Jessy Xinyi Han",
        "Devavrat Shah"
      ],
      "abstract": "Estimating causal effects on time-to-event outcomes from observational data is particularly challenging due to censoring, limited sample sizes, and non-random treatment assignment. The need for answering such \"when-if\" questions--how the timing of an event would change under a specified intervention--commonly arises in real-world settings with heterogeneous treatment adoption and confounding. To address these challenges, we propose Synthetic Survival Control (SSC) to estimate counterfactual hazard trajectories in a panel data setting where multiple units experience potentially different treatments over multiple periods. In such a setting, SSC estimates the counterfactual hazard trajectory for a unit of interest as a weighted combination of the observed trajectories from other units. To provide formal justification, we introduce a panel framework with a low-rank structure for causal survival analysis. Indeed, such a structure naturally arises under classical parametric survival models. Within this framework, for the causal estimand of interest, we establish identification and finite sample guarantees for SSC. We validate our approach using a multi-country clinical dataset of cancer treatment outcomes, where the staggered introduction of new therapies creates a quasi-experimental setting. Empirically, we find that access to novel treatments is associated with improved survival, as reflected by lower post-intervention hazard trajectories relative to their synthetic counterparts. Given the broad relevance of survival analysis across medicine, economics, and public policy, our framework offers a general and interpretable tool for counterfactual survival inference using observational data.",
      "pdf_url": "https://arxiv.org/pdf/2511.14133v1",
      "arxiv_url": "http://arxiv.org/abs/2511.14133v1",
      "published": "2025-11-18",
      "categories": [
        "cs.LG",
        "econ.EM",
        "stat.ML"
      ]
    },
    {
      "title": "How to Marginalize in Causal Structure Learning?",
      "authors": [
        "William Zhao",
        "Guy Van den Broeck",
        "Benjie Wang"
      ],
      "abstract": "Bayesian networks (BNs) are a widely used class of probabilistic graphical models employed in numerous application domains. However, inferring the network's graphical structure from data remains challenging. Bayesian structure learners approach this problem by inferring a posterior distribution over the possible directed acyclic graphs underlying the BN. The inference process often requires marginalizing over probability distributions, which is typically done using dynamic programming methods that restrict the set of possible parents for each node. Instead, we present a novel method that utilizes tractable probabilistic circuits to circumvent this restriction. This method utilizes a new learning routine that trains these circuits on both the original distribution and marginal queries. The architecture of probabilistic circuits then inherently allows for fast and exact marginalization on the learned distribution. We then show empirically that utilizing our method to answer marginals allows Bayesian structure learners to improve their performance compared to current methods.",
      "pdf_url": "https://arxiv.org/pdf/2511.14001v1",
      "arxiv_url": "http://arxiv.org/abs/2511.14001v1",
      "published": "2025-11-18",
      "categories": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "title": "On robust Bayesian causal inference",
      "authors": [
        "Angelos Alexopoulos",
        "Nikolaos Demiris"
      ],
      "abstract": "This paper develops a Bayesian framework for robust causal inference from longitudinal observational data. Many contemporary methods rely on structural assumptions, such as factor models, to adjust for unobserved confounding, but they can lead to biased causal estimands when mis-specified. We focus on directly estimating time--unit--specific causal effects and use generalised Bayesian inference to quantify model mis-specification and adjust for it, while retaining interpretable posterior inference. We select the learning rate~$ω$ based on a proper scoring rule that jointly evaluates point and interval accuracy of the causal estimand, thus providing a coherent, decision-theoretic foundation for tuning~$ω$. Simulation studies and applications to real data demonstrate improved calibration, sharpness, and robustness in estimating causal effects.",
      "pdf_url": "https://arxiv.org/pdf/2511.13895v1",
      "arxiv_url": "http://arxiv.org/abs/2511.13895v1",
      "published": "2025-11-17",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Causal computations in Semi Markovian Structural Causal Models using divide and conquer",
      "authors": [
        "Anna Rodum Bjøru",
        "Rafael Cabañas",
        "Helge Langseth",
        "Antonio Salmerón"
      ],
      "abstract": "Recently, Bjøru et al. proposed a novel divide-and-conquer algorithm for bounding counterfactual probabilities in structural causal models (SCMs). They assumed that the SCMs were learned from purely observational data, leading to an imprecise characterization of the marginal distributions of exogenous variables. Their method leveraged the canonical representation of structural equations to decompose a general SCM with high-cardinality exogenous variables into a set of sub-models with low-cardinality exogenous variables. These sub-models had precise marginals over the exogenous variables and therefore admitted efficient exact inference. The aggregated results were used to bound counterfactual probabilities in the original model. The approach was developed for Markovian models, where each exogenous variable affects only a single endogenous variable. In this paper, we investigate extending the methodology to \\textit{semi-Markovian} SCMs, where exogenous variables may influence multiple endogenous variables. Such models are capable of representing confounding relationships that Markovian models cannot. We illustrate the challenges of this extension using a minimal example, which motivates a set of alternative solution strategies. These strategies are evaluated both theoretically and through a computational study.",
      "pdf_url": "https://arxiv.org/pdf/2511.13852v1",
      "arxiv_url": "http://arxiv.org/abs/2511.13852v1",
      "published": "2025-11-17",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Uncovering Causal Drivers of Energy Efficiency for Industrial Process in Foundry via Time-Series Causal Inference",
      "authors": [
        "Zhipeng Ma",
        "Bo Nørregaard Jørgensen",
        "Zheng Grace Ma"
      ],
      "abstract": "Improving energy efficiency in industrial foundry processes is a critical challenge, as these operations are highly energy-intensive and marked by complex interdependencies among process variables. Correlation-based analyses often fail to distinguish true causal drivers from spurious associations, limiting their usefulness for decision-making. This paper applies a time-series causal inference framework to identify the operational factors that directly affect energy efficiency in induction furnace melting. Using production data from a Danish foundry, the study integrates time-series clustering to segment melting cycles into distinct operational modes with the PCMCI+ algorithm, a state-of-the-art causal discovery method, to uncover cause-effect relationships within each mode. Across clusters, robust causal relations among energy consumption, furnace temperature, and material weight define the core drivers of efficiency, while voltage consistently influences cooling water temperature with a delayed response. Cluster-specific differences further distinguish operational regimes: efficient clusters are characterized by stable causal structures, whereas inefficient ones exhibit reinforcing feedback loops and atypical dependencies. The contributions of this study are twofold. First, it introduces an integrated clustering-causal inference pipeline as a methodological innovation for analyzing energy-intensive processes. Second, it provides actionable insights that enable foundry operators to optimize performance, reduce energy consumption, and lower emissions.",
      "pdf_url": "https://arxiv.org/pdf/2511.13389v1",
      "arxiv_url": "http://arxiv.org/abs/2511.13389v1",
      "published": "2025-11-17",
      "categories": [
        "cs.IR",
        "cs.LG"
      ]
    },
    {
      "title": "Cognitive Maps in Language Models: A Mechanistic Analysis of Spatial Planning",
      "authors": [
        "Caroline Baumgartner",
        "Eleanor Spens",
        "Neil Burgess",
        "Petru Manescu"
      ],
      "abstract": "How do large language models solve spatial navigation tasks? We investigate this by training GPT-2 models on three spatial learning paradigms in grid environments: passive exploration (Foraging Model- predicting steps in random walks), goal-directed planning (generating optimal shortest paths) on structured Hamiltonian paths (SP-Hamiltonian), and a hybrid model fine-tuned with exploratory data (SP-Random Walk). Using behavioural, representational and mechanistic analyses, we uncover two fundamentally different learned algorithms. The Foraging model develops a robust, map-like representation of space, akin to a 'cognitive map'. Causal interventions reveal that it learns to consolidate spatial information into a self-sufficient coordinate system, evidenced by a sharp phase transition where its reliance on historical direction tokens vanishes by the middle layers of the network. The model also adopts an adaptive, hierarchical reasoning system, switching between a low-level heuristic for short contexts and map-based inference for longer ones. In contrast, the goal-directed models learn a path-dependent algorithm, remaining reliant on explicit directional inputs throughout all layers. The hybrid model, despite demonstrating improved generalisation over its parent, retains the same path-dependent strategy. These findings suggest that the nature of spatial intelligence in transformers may lie on a spectrum, ranging from generalisable world models shaped by exploratory data to heuristics optimised for goal-directed tasks. We provide a mechanistic account of this generalisation-optimisation trade-off and highlight how the choice of training regime influences the strategies that emerge.",
      "pdf_url": "https://arxiv.org/pdf/2511.13371v1",
      "arxiv_url": "http://arxiv.org/abs/2511.13371v1",
      "published": "2025-11-17",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Causal Inference, Biomarker Discovery, Graph Neural Network, Feature Selection",
      "authors": [
        "Chaowang Lan",
        "Jingxin Wu",
        "Yulong Yuan",
        "Chuxun Liu",
        "Huangyi Kang",
        "Caihua Liu"
      ],
      "abstract": "Biomarker discovery from high-throughput transcriptomic data is crucial for advancing precision medicine. However, existing methods often neglect gene-gene regulatory relationships and lack stability across datasets, leading to conflation of spurious correlations with genuine causal effects. To address these issues, we develop a causal graph neural network (Causal-GNN) method that integrates causal inference with multi-layer graph neural networks (GNNs). The key innovation is the incorporation of causal effect estimation for identifying stable biomarkers, coupled with a GNN-based propensity scoring mechanism that leverages cross-gene regulatory networks. Experimental results demonstrate that our method achieves consistently high predictive accuracy across four distinct datasets and four independent classifiers. Moreover, it enables the identification of more stable biomarkers compared to traditional methods. Our work provides a robust, efficient, and biologically interpretable tool for biomarker discovery, demonstrating strong potential for broad application across medical disciplines.",
      "pdf_url": "https://arxiv.org/pdf/2511.13295v1",
      "arxiv_url": "http://arxiv.org/abs/2511.13295v1",
      "published": "2025-11-17",
      "categories": [
        "q-bio.QM",
        "cs.LG"
      ]
    },
    {
      "title": "The Final-Stage Bottleneck: A Systematic Dissection of the R-Learner for Network Causal Inference",
      "authors": [
        "Sairam S",
        "Sara Girdhar",
        "Shivam Soni"
      ],
      "abstract": "The R-Learner is a powerful, theoretically-grounded framework for estimating heterogeneous treatment effects, prized for its robustness to nuisance model errors. However, its application to network data, where causal heterogeneity is often graph-dependent, presents a critical challenge to its core assumption of a well-specified final-stage model. In this paper, we conduct a large-scale empirical study to systematically dissect the R-Learner framework on graphs. We provide the first rigorous evidence that the primary driver of performance is the inductive bias of the final-stage CATE estimator, an effect that dominates the choice of nuisance models. Our central finding is the quantification of a catastrophic \"representation bottleneck\": we prove with overwhelming statistical significance (p < 0.001) that R-Learners with a graph-blind final stage fail completely (MSE > 4.0), even when paired with powerful GNN nuisance models. Conversely, our proposed end-to-end Graph R-Learner succeeds and significantly outperforms a strong, non-DML GNN T-Learner baseline. Furthermore, we identify and provide a mechanistic explanation for a subtle, topology-dependent \"nuisance bottleneck,\" linking it to GNN over-squashing via a targeted \"Hub-Periphery Trade-off\" analysis. Our findings are validated across diverse synthetic and semi-synthetic benchmarks. We release our code as a reproducible benchmark to facilitate future research on this critical \"final-stage bottleneck.\"",
      "pdf_url": "https://arxiv.org/pdf/2511.13018v1",
      "arxiv_url": "http://arxiv.org/abs/2511.13018v1",
      "published": "2025-11-17",
      "categories": [
        "cs.LG"
      ]
    }
  ]
}