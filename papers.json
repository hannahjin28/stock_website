{
  "last_updated": "2025-12-25T00:57:09.189502",
  "papers": [
    {
      "title": "Information-theoretic signatures of causality in Bayesian networks and hypergraphs",
      "authors": [
        "Sung En Chiang",
        "Zhaolu Liu",
        "Robert L. Peach",
        "Mauricio Barahona"
      ],
      "abstract": "Analyzing causality in multivariate systems involves establishing how information is generated, distributed and combined, and thus requires tools that capture interactions beyond pairwise relations. Higher-order information theory provides such tools. In particular, Partial Information Decomposition (PID) allows the decomposition of the information that a set of sources provides about a target into redundant, unique, and synergistic components. Yet the mathematical connection between such higher-order information-theoretic measures and causal structure remains undeveloped. Here we establish the first theoretical correspondence between PID components and causal structure in both Bayesian networks and hypergraphs. We first show that in Bayesian networks unique information precisely characterizes direct causal neighbors, while synergy identifies collider relationships. This establishes a localist causal discovery paradigm in which the structure surrounding each variable can be recovered from its immediate informational footprint, eliminating the need for global search over graph space. Extending these results to higher-order systems, we prove that PID signatures in Bayesian hypergraphs differentiate parents, children, co-heads, and co-tails, revealing a higher-order collider effect unique to multi-tail hyperedges. We also present procedures by which our results can be used to characterize systematically the causal structure of Bayesian networks and hypergraphs. Our results position PID as a rigorous, model-agnostic foundation for inferring both pairwise and higher-order causal structure, and introduce a fundamentally local information-theoretic viewpoint on causal discovery.",
      "pdf_url": "https://arxiv.org/pdf/2512.20552v1",
      "arxiv_url": "http://arxiv.org/abs/2512.20552v1",
      "published": "2025-12-23",
      "categories": [
        "cs.IT",
        "stat.ML"
      ]
    },
    {
      "title": "ScoreMatchingRiesz: Auto-DML with Infinitesimal Classification",
      "authors": [
        "Masahiro Kato"
      ],
      "abstract": "This study proposes Riesz representer estimation methods based on score matching. The Riesz representer is a key component in debiased machine learning for constructing $\\sqrt{n}$-consistent and efficient estimators in causal inference and structural parameter estimation. To estimate the Riesz representer, direct approaches have garnered attention, such as Riesz regression and the covariate balancing propensity score. These approaches can also be interpreted as variants of direct density ratio estimation (DRE) in several applications such as average treatment effect estimation. In DRE, it is well known that flexible models can easily overfit the observed data due to the estimand and the form of the loss function. To address this issue, recent work has proposed modeling the density ratio as a product of multiple intermediate density ratios and estimating it using score-matching techniques, which are often used in the diffusion model literature. We extend score-matching-based DRE methods to Riesz representer estimation. Our proposed method not only mitigates overfitting but also provides insights for causal inference by bridging marginal effects and average policy effects through time score functions.",
      "pdf_url": "https://arxiv.org/pdf/2512.20523v1",
      "arxiv_url": "http://arxiv.org/abs/2512.20523v1",
      "published": "2025-12-23",
      "categories": [
        "econ.EM",
        "cs.LG",
        "math.ST",
        "stat.ME",
        "stat.ML"
      ]
    },
    {
      "title": "Exploring the nature of gravity with quantum information methods",
      "authors": [
        "Bruna Sahdo",
        "Natália Salomé Móller"
      ],
      "abstract": "The aim of this article is to provide an introduction to the use of quantum information methods for investigating the interface between quantum theory and gravity. To this end, we discuss the basic principles of two current research streams that use this approach. The first one explores a phenomenon known as gravitationally induced entanglement, which aims to infer whether the gravitational field responsible for the interaction between two massive bodies must be quantized or not. The second stream investigates causal structures, thereby providing indirect evidence that spacetime may exhibit non-classical behavior. Before presenting these topics, we briefly review some fundamental concepts and experiments from quantum information theory, such as the Mach-Zehnder interferometer, the Stern-Gerlach experiment, Bell inequalities and entanglement, and the language of quantum circuits.",
      "pdf_url": "https://arxiv.org/pdf/2512.20429v1",
      "arxiv_url": "http://arxiv.org/abs/2512.20429v1",
      "published": "2025-12-23",
      "categories": [
        "quant-ph",
        "gr-qc"
      ]
    },
    {
      "title": "Estimation and Inference for Causal Explainability",
      "authors": [
        "Weihan Zhang",
        "Zijun Gao"
      ],
      "abstract": "Understanding how much each variable contributes to an outcome is a central question across disciplines. A causal view of explainability is favorable for its ability in uncovering underlying mechanisms and generalizing to new contexts. Based on a family of causal explainability quantities, we develop methods for their estimation and inference. In particular, we construct a one-step correction estimator using semi-parametric efficiency theory, which explicitly leverages the independence structure of variables to reduce the asymptotic variance. For a null hypothesis on the boundary, i.e., zero explainability, we show its equivalence to Fisher's sharp null, which motivates a randomization-based inference procedure. Finally, we illustrate the empirical efficacy of our approach through simulations as well as an immigration experiment dataset, where we investigate how features and their interactions shape public opinion toward admitting immigrants.",
      "pdf_url": "https://arxiv.org/pdf/2512.20219v1",
      "arxiv_url": "http://arxiv.org/abs/2512.20219v1",
      "published": "2025-12-23",
      "categories": [
        "stat.ME",
        "stat.AP"
      ]
    },
    {
      "title": "Causal Inference with the \"Napkin Graph\"",
      "authors": [
        "Anna Guo",
        "David Benkeser",
        "Razieh Nabi"
      ],
      "abstract": "Unmeasured confounding can render identification strategies based on adjustment functionals invalid. We study the \"Napkin graph\", a causal structure that encapsulates patterns of M-bias, instrumental variables, and the classical back-door and front-door models within a single graphical framework, yet requires a nonstandard identification strategy: the average treatment effect is expressed as a ratio of two g-formulas. We develop novel estimators for this functional, including doubly robust one-step and targeted minimum loss-based estimators that remain asymptotically linear when nuisance functions are estimated at slower-than-parametric rates using machine learning. We also show how a generalized independence restriction encoded by the Napkin graph, known as a Verma constraint, can be exploited to improve efficiency, illustrating more generally how such constraints in hidden variable DAGs can inform semiparametric inference. The proposed methods are validated through simulations and applied to the Finnish Life Course study to estimate the effect of educational attainment on income. An accompanying R package, napkincausal, implements all proposed procedures.",
      "pdf_url": "https://arxiv.org/pdf/2512.19861v1",
      "arxiv_url": "http://arxiv.org/abs/2512.19861v1",
      "published": "2025-12-22",
      "categories": [
        "stat.ME",
        "stat.ML"
      ]
    },
    {
      "title": "Toward Scalable and Valid Conditional Independence Testing with Spectral Representations",
      "authors": [
        "Alek Frohlich",
        "Vladimir Kostic",
        "Karim Lounici",
        "Daniel Perazzo",
        "Massimiliano Pontil"
      ],
      "abstract": "Conditional independence (CI) is central to causal inference, feature selection, and graphical modeling, yet it is untestable in many settings without additional assumptions. Existing CI tests often rely on restrictive structural conditions, limiting their validity on real-world data. Kernel methods using the partial covariance operator offer a more principled approach but suffer from limited adaptivity, slow convergence, and poor scalability. In this work, we explore whether representation learning can help address these limitations. Specifically, we focus on representations derived from the singular value decomposition of the partial covariance operator and use them to construct a simple test statistic, reminiscent of the Hilbert-Schmidt Independence Criterion (HSIC). We also introduce a practical bi-level contrastive algorithm to learn these representations. Our theory links representation learning error to test performance and establishes asymptotic validity and power guarantees. Preliminary experiments suggest that this approach offers a practical and statistically grounded path toward scalable CI testing, bridging kernel-based theory with modern representation learning.",
      "pdf_url": "https://arxiv.org/pdf/2512.19510v1",
      "arxiv_url": "http://arxiv.org/abs/2512.19510v1",
      "published": "2025-12-22",
      "categories": [
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "title": "Real-Time Streamable Generative Speech Restoration with Flow Matching",
      "authors": [
        "Simon Welker",
        "Bunlong Lay",
        "Maris Hillemann",
        "Tal Peer",
        "Timo Gerkmann"
      ],
      "abstract": "Diffusion-based generative models have greatly impacted the speech processing field in recent years, exhibiting high speech naturalness and spawning a new research direction. Their application in real-time communication is, however, still lagging behind due to their computation-heavy nature involving multiple calls of large DNNs.\n  Here, we present Stream.FM, a frame-causal flow-based generative model with an algorithmic latency of 32 milliseconds (ms) and a total latency of 48 ms, paving the way for generative speech processing in real-time communication. We propose a buffered streaming inference scheme and an optimized DNN architecture, show how learned few-step numerical solvers can boost output quality at a fixed compute budget, explore model weight compression to find favorable points along a compute/quality tradeoff, and contribute a model variant with 24 ms total latency for the speech enhancement task.\n  Our work looks beyond theoretical latencies, showing that high-quality streaming generative speech processing can be realized on consumer GPUs available today. Stream.FM can solve a variety of speech processing tasks in a streaming fashion: speech enhancement, dereverberation, codec post-filtering, bandwidth extension, STFT phase retrieval, and Mel vocoding. As we verify through comprehensive evaluations and a MUSHRA listening test, Stream.FM establishes a state-of-the-art for generative streaming speech restoration, exhibits only a reasonable reduction in quality compared to a non-streaming variant, and outperforms our recent work (Diffusion Buffer) on generative streaming speech enhancement while operating at a lower latency.",
      "pdf_url": "https://arxiv.org/pdf/2512.19442v1",
      "arxiv_url": "http://arxiv.org/abs/2512.19442v1",
      "published": "2025-12-22",
      "categories": [
        "eess.SP",
        "cs.LG",
        "cs.SD"
      ]
    },
    {
      "title": "Attention Is Not What You Need",
      "authors": [
        "Zhang Chong"
      ],
      "abstract": "We revisit a basic question in sequence modeling: is explicit self-attention actually necessary for strong performance and reasoning? We argue that standard multi-head attention is best seen as a form of tensor lifting: hidden vectors are mapped into a high-dimensional space of pairwise interactions, and learning proceeds by constraining this lifted tensor through gradient descent. This mechanism is extremely expressive but mathematically opaque, because after many layers it becomes very hard to describe the model with a small family of explicit invariants.\n  To explore an alternative, we propose an attention-free architecture based on Grassmann flows. Instead of forming an L by L attention matrix, our Causal Grassmann layer (i) linearly reduces token states, (ii) encodes local token pairs as two-dimensional subspaces on a Grassmann manifold via Plucker coordinates, and (iii) fuses these geometric features back into the hidden states through gated mixing. Information therefore propagates by controlled deformations of low-rank subspaces over multi-scale local windows, so the core computation lives on a finite-dimensional manifold rather than in an unstructured tensor space.\n  On the Wikitext-2 language modeling benchmark, purely Grassmann-based models with 13 to 18 million parameters achieve validation perplexities within about 10 to 15 percent of size-matched Transformers. On the SNLI natural language inference task, a Grassmann-Plucker head on top of DistilBERT slightly outperforms a Transformer head, with best validation and test accuracies of 0.8550 and 0.8538 compared to 0.8545 and 0.8511. We analyze the complexity of Grassmann mixing, show linear scaling in sequence length for fixed rank, and argue that such manifold-based designs offer a more structured route toward geometric and invariant-based interpretations of neural reasoning.",
      "pdf_url": "https://arxiv.org/pdf/2512.19428v1",
      "arxiv_url": "http://arxiv.org/abs/2512.19428v1",
      "published": "2025-12-22",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.AG"
      ]
    },
    {
      "title": "VIGOR+: Iterative Confounder Generation and Validation via LLM-CEVAE Feedback Loop",
      "authors": [
        "JiaWei Zhu",
        "ZiHeng Liu"
      ],
      "abstract": "Hidden confounding remains a fundamental challenge in causal inference from observational data. Recent advances leverage Large Language Models (LLMs) to generate plausible hidden confounders based on domain knowledge, yet a critical gap exists: LLM-generated confounders often exhibit semantic plausibility without statistical utility. We propose VIGOR+ (Variational Information Gain for iterative cOnfounder Refinement), a novel framework that closes the loop between LLM-based confounder generation and CEVAE-based statistical validation. Unlike prior approaches that treat generation and validation as separate stages, VIGOR+ establishes an iterative feedback mechanism: validation signals from CEVAE (including information gain, latent consistency metrics, and diagnostic messages) are transformed into natural language feedback that guides subsequent LLM generation rounds. This iterative refinement continues until convergence criteria are met. We formalize the feedback mechanism, prove convergence properties under mild assumptions, and provide a complete algorithmic framework.",
      "pdf_url": "https://arxiv.org/pdf/2512.19349v1",
      "arxiv_url": "http://arxiv.org/abs/2512.19349v1",
      "published": "2025-12-22",
      "categories": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Causal Heterogeneous Graph Learning Method for Chronic Obstructive Pulmonary Disease Prediction",
      "authors": [
        "Leming Zhou",
        "Zuo Wang",
        "Zhigang Liu"
      ],
      "abstract": "Due to the insufficient diagnosis and treatment capabilities at the grassroots level, there are still deficiencies in the early identification and early warning of acute exacerbation of Chronic obstructive pulmonary disease (COPD), often resulting in a high prevalence rate and high burden, but the screening rate is relatively low. In order to gradually improve this situation. In this paper, this study develop a Causal Heterogeneous Graph Representation Learning (CHGRL) method for COPD comorbidity risk prediction method that: a) constructing a heterogeneous Our dataset includes the interaction between patients and diseases; b) A cause-aware heterogeneous graph learning architecture has been constructed, combining causal inference mechanisms with heterogeneous graph learning, which can support heterogeneous graph causal learning for different types of relationships; and c) Incorporate the causal loss function in the model design, and add counterfactual reasoning learning loss and causal regularization loss on the basis of the cross-entropy classification loss. We evaluate our method and compare its performance with strong GNN baselines. Following experimental evaluation, the proposed model demonstrates high detection accuracy.",
      "pdf_url": "https://arxiv.org/pdf/2512.19194v1",
      "arxiv_url": "http://arxiv.org/abs/2512.19194v1",
      "published": "2025-12-22",
      "categories": [
        "cs.LG"
      ]
    }
  ]
}