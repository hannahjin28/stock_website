{
  "last_updated": "2025-08-03T01:05:24.454439",
  "papers": [
    {
      "title": "Relative Bias Under Imperfect Identification in Observational Causal Inference",
      "authors": [
        "Melody Huang",
        "Cory McCartan"
      ],
      "abstract": "To conduct causal inference in observational settings, researchers must rely\non certain identifying assumptions. In practice, these assumptions are unlikely\nto hold exactly. This paper considers the bias of selection-on-observables,\ninstrumental variables, and proximal inference estimates under violations of\ntheir identifying assumptions. We develop bias expressions for IV and proximal\ninference that show how violations of their respective assumptions are\namplified by any unmeasured confounding in the outcome variable. We propose a\nset of sensitivity tools that quantify the sensitivity of different\nidentification strategies, and an augmented bias contour plot visualizes the\nrelationship between these strategies. We argue that the act of choosing an\nidentification strategy implicitly expresses a belief about the degree of\nviolations that must be present in alternative identification strategies. Even\nwhen researchers intend to conduct an IV or proximal analysis, a sensitivity\nanalysis comparing different identification strategies can help to better\nunderstand the implications of each set of assumptions. Throughout, we compare\nthe different approaches on a re-analysis of the impact of state surveillance\non the incidence of protest in Communist Poland.",
      "pdf_url": "http://arxiv.org/pdf/2507.23743v1",
      "arxiv_url": "http://arxiv.org/abs/2507.23743v1",
      "published": "2025-07-31",
      "categories": [
        "stat.ME",
        "econ.EM"
      ]
    },
    {
      "title": "Incorporating structural uncertainty in causal decision making",
      "authors": [
        "Maurits Kaptein"
      ],
      "abstract": "Practitioners making decisions based on causal effects typically ignore\nstructural uncertainty. We analyze when this uncertainty is consequential\nenough to warrant methodological solutions (Bayesian model averaging over\ncompeting causal structures). Focusing on bivariate relationships ($X\n\\rightarrow Y$ vs. $X \\leftarrow Y$), we establish that model averaging is\nbeneficial when: (1) structural uncertainty is moderate to high, (2) causal\neffects differ substantially between structures, and (3) loss functions are\nsufficiently sensitive to the size of the causal effect. We prove optimality\nresults of our suggested methodological solution under regularity conditions\nand demonstrate through simulations that modern causal discovery methods can\nprovide, within limits, the necessary quantification. Our framework complements\nexisting robust causal inference approaches by addressing a distinct source of\nuncertainty typically overlooked in practice.",
      "pdf_url": "http://arxiv.org/pdf/2507.23495v1",
      "arxiv_url": "http://arxiv.org/abs/2507.23495v1",
      "published": "2025-07-31",
      "categories": [
        "cs.LG",
        "math.ST",
        "stat.TH"
      ]
    },
    {
      "title": "Causal Reasoning in Pieces: Modular In-Context Learning for Causal Discovery",
      "authors": [
        "Kacper Kadziolka",
        "Saber Salehkaleybar"
      ],
      "abstract": "Causal inference remains a fundamental challenge for large language models.\nRecent advances in internal reasoning with large language models have sparked\ninterest in whether state-of-the-art reasoning models can robustly perform\ncausal discovery-a task where conventional models often suffer from severe\noverfitting and near-random performance under data perturbations. We study\ncausal discovery on the Corr2Cause benchmark using the emergent OpenAI's\no-series and DeepSeek-R model families and find that these reasoning-first\narchitectures achieve significantly greater native gains than prior approaches.\nTo capitalize on these strengths, we introduce a modular in-context pipeline\ninspired by the Tree-of-Thoughts and Chain-of-Thoughts methodologies, yielding\nnearly three-fold improvements over conventional baselines. We further probe\nthe pipeline's impact by analyzing reasoning chain length, complexity, and\nconducting qualitative and quantitative comparisons between conventional and\nreasoning models. Our findings suggest that while advanced reasoning models\nrepresent a substantial leap forward, carefully structured in-context\nframeworks are essential to maximize their capabilities and offer a\ngeneralizable blueprint for causal discovery across diverse domains.",
      "pdf_url": "http://arxiv.org/pdf/2507.23488v1",
      "arxiv_url": "http://arxiv.org/abs/2507.23488v1",
      "published": "2025-07-31",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Causal2Vec: Improving Decoder-only LLMs as Versatile Embedding Models",
      "authors": [
        "Ailiang Lin",
        "Zhuoyun Li",
        "Kotaro Funakoshi"
      ],
      "abstract": "Decoder-only large language models (LLMs) are increasingly used to build\nembedding models that effectively encode the semantic information of natural\nlanguage texts into dense vector representations for various embedding tasks.\nHowever, many existing methods primarily focus on removing the causal attention\nmask in LLMs to enable bidirectional attention, potentially undermining the\nmodel's ability to extract semantic information acquired during pretraining.\nAdditionally, leading unidirectional approaches often rely on extra input text\nto overcome the inherent limitations of causal attention, inevitably increasing\ncomputational costs. In this work, we propose Causal2Vec, a general-purpose\nembedding model tailored to enhance the performance of decoder-only LLMs\nwithout altering their original architectures or introducing significant\ncomputational overhead. Specifically, we first employ a lightweight BERT-style\nmodel to pre-encode the input text into a single Contextual token, which is\nthen prepended to the LLM's input sequence, allowing each token to capture\ncontextualized information even without attending to future tokens.\nFurthermore, to mitigate the recency bias introduced by last-token pooling and\nhelp LLMs better leverage the semantic information encoded in the Contextual\ntoken, we concatenate the last hidden states of Contextual and EOS tokens as\nthe final text embedding. In practice, Causal2Vec achieves state-of-the-art\nperformance on the Massive Text Embeddings Benchmark (MTEB) among models\ntrained solely on publicly available retrieval datasets, while reducing the\nrequired sequence length by up to 85% and inference time by up to 82% compared\nto best-performing methods.",
      "pdf_url": "http://arxiv.org/pdf/2507.23386v1",
      "arxiv_url": "http://arxiv.org/abs/2507.23386v1",
      "published": "2025-07-31",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "title": "ISO-Bench: Benchmarking Multimodal Causal Reasoning in Visual-Language Models through Procedural Plans",
      "authors": [
        "Ananya Sadana",
        "Yash Kumar Lal",
        "Jiawei Zhou"
      ],
      "abstract": "Understanding causal relationships across modalities is a core challenge for\nmultimodal models operating in real-world environments. We introduce ISO-Bench,\na benchmark for evaluating whether models can infer causal dependencies between\nvisual observations and procedural text. Each example presents an image of a\ntask step and a text snippet from a plan, with the goal of deciding whether the\nvisual step occurs before or after the referenced text step. Evaluation results\non ten frontier vision-language models show underwhelming performance: the best\nzero-shot F1 is only 0.57, and chain-of-thought reasoning yields only modest\ngains (up to 0.62 F1), largely behind humans (0.98 F1). Our analysis further\nhighlights concrete directions for improving causal understanding in multimodal\nmodels.",
      "pdf_url": "http://arxiv.org/pdf/2507.23135v1",
      "arxiv_url": "http://arxiv.org/abs/2507.23135v1",
      "published": "2025-07-30",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "title": "A quantum experiment with joint exogeneity violation",
      "authors": [
        "Yuhao Wang",
        "Xingjian Zhang"
      ],
      "abstract": "In randomized experiments, the assumption of potential outcomes is usually\naccompanied by the \\emph{joint exogeneity} assumption. Although joint\nexogeneity has faced criticism as a counterfactual assumption since its\nproposal, no evidence has yet demonstrated its violation in randomized\nexperiments. In this paper, we reveal such a violation in a quantum experiment,\nthereby falsifying this assumption, at least in regimes where classical physics\ncannot provide a complete description. We further discuss its implications for\npotential outcome modelling, from both practial and philosophical perspectives.",
      "pdf_url": "http://arxiv.org/pdf/2507.22747v1",
      "arxiv_url": "http://arxiv.org/abs/2507.22747v1",
      "published": "2025-07-30",
      "categories": [
        "quant-ph",
        "math.ST",
        "physics.hist-ph",
        "stat.TH"
      ]
    },
    {
      "title": "Risk-inclusive Contextual Bandits for Early Phase Clinical Trials",
      "authors": [
        "Rohit Kanrar",
        "Chunlin Li",
        "Zara Ghodsi",
        "Margaret Gamalo"
      ],
      "abstract": "Early-phase clinical trials face the challenge of selecting optimal drug\ndoses that balance safety and efficacy due to uncertain dose-response\nrelationships and varied participant characteristics. Traditional randomized\ndose allocation often exposes participants to sub-optimal doses by not\nconsidering individual covariates, necessitating larger sample sizes and\nprolonging drug development. This paper introduces a risk-inclusive contextual\nbandit algorithm that utilizes multi-arm bandit (MAB) strategies to optimize\ndosing through participant-specific data integration. By combining two separate\nThompson samplers, one for efficacy and one for safety, the algorithm enhances\nthe balance between efficacy and safety in dose allocation. The effect sizes\nare estimated with a generalized version of asymptotic confidence sequences\n(AsympCS, Waudby-Smith et al., 2024), offering a uniform coverage guarantee for\nsequential causal inference over time. The validity of AsympCS is also\nestablished in the MAB setup with a possibly mis-specified model. The empirical\nresults demonstrate the strengths of this method in optimizing dose allocation\ncompared to randomized allocations and traditional contextual bandits focused\nsolely on efficacy. Moreover, an application on real data generated from a\nrecent Phase IIb study aligns with actual findings.",
      "pdf_url": "http://arxiv.org/pdf/2507.22344v1",
      "arxiv_url": "http://arxiv.org/abs/2507.22344v1",
      "published": "2025-07-30",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Dimension Reduction for Conditional Density Estimation with Applications to High-Dimensional Causal Inference",
      "authors": [
        "Jianhua Mei",
        "Fu Ouyang",
        "Thomas T. Yang"
      ],
      "abstract": "We propose a novel and computationally efficient approach for nonparametric\nconditional density estimation in high-dimensional settings that achieves\ndimension reduction without imposing restrictive distributional or functional\nform assumptions. To uncover the underlying sparsity structure of the data, we\ndevelop an innovative conditional dependence measure and a modified\ncross-validation procedure that enables data-driven variable selection, thereby\ncircumventing the need for subjective threshold selection. We demonstrate the\npractical utility of our dimension-reduced conditional density estimation by\napplying it to doubly robust estimators for average treatment effects. Notably,\nour proposed procedure is able to select relevant variables for nonparametric\npropensity score estimation and also inherently reduce the dimensionality of\noutcome regressions through a refined ignorability condition. We evaluate the\nfinite-sample properties of our approach through comprehensive simulation\nstudies and an empirical study on the effects of 401(k) eligibility on savings\nusing SIPP data.",
      "pdf_url": "http://arxiv.org/pdf/2507.22312v1",
      "arxiv_url": "http://arxiv.org/abs/2507.22312v1",
      "published": "2025-07-30",
      "categories": [
        "econ.EM"
      ]
    },
    {
      "title": "Hybrid Causal Identification and Causal Mechanism Clustering",
      "authors": [
        "Saixiong Liu",
        "Yuhua Qian",
        "Jue Li",
        "Honghong Cheng",
        "Feijiang Li"
      ],
      "abstract": "Bivariate causal direction identification is a fundamental and vital problem\nin the causal inference field. Among binary causal methods, most methods based\non additive noise only use one single causal mechanism to construct a causal\nmodel. In the real world, observations are always collected in different\nenvironments with heterogeneous causal relationships. Therefore, on observation\ndata, this paper proposes a Mixture Conditional Variational Causal Inference\nmodel (MCVCI) to infer heterogeneous causality. Specifically, according to the\nidentifiability of the Hybrid Additive Noise Model (HANM), MCVCI combines the\nsuperior fitting capabilities of the Gaussian mixture model and the neural\nnetwork and elegantly uses the likelihoods obtained from the probabilistic\nbounds of the mixture conditional variational auto-encoder as causal decision\ncriteria. Moreover, we model the casual heterogeneity into cluster numbers and\npropose the Mixture Conditional Variational Causal Clustering (MCVCC) method,\nwhich can reveal causal mechanism expression. Compared with state-of-the-art\nmethods, the comprehensive best performance demonstrates the effectiveness of\nthe methods proposed in this paper on several simulated and real data.",
      "pdf_url": "http://arxiv.org/pdf/2507.21792v1",
      "arxiv_url": "http://arxiv.org/abs/2507.21792v1",
      "published": "2025-07-29",
      "categories": [
        "cs.AI"
      ]
    },
    {
      "title": "Towards Locally Deployable Fine-Tuned Causal Large Language Models for Mode Choice Behaviour",
      "authors": [
        "Tareq Alsaleh",
        "Bilal Farooq"
      ],
      "abstract": "This study investigates the adoption of open-access, locally deployable\ncausal large language models (LLMs) for travel mode choice prediction and\nintroduces LiTransMC, the first fine-tuned causal LLM developed for this task.\nWe systematically benchmark eleven LLMs (1-12B parameters) across three stated\nand revealed preference datasets, testing 396 configurations and generating\nover 79,000 synthetic commuter predictions. Beyond predictive accuracy, we\nevaluate models generated reasoning using BERTopic for topic modelling and a\nnovel Explanation Strength Index, providing the first structured analysis of\nhow LLMs articulate decision factors in alignment with behavioural theory.\nLiTransMC, fine-tuned using parameter efficient and loss masking strategy,\nachieved a weighted F1 score of 0.6845 and a Jensen-Shannon Divergence of\n0.000245, surpassing both untuned local models and larger proprietary systems,\nincluding GPT-4o with advanced persona inference and embedding-based loading,\nwhile also outperforming classical mode choice methods such as discrete choice\nmodels and machine learning classifiers for the same dataset. This dual\nimprovement, i.e., high instant-level accuracy and near-perfect distributional\ncalibration, demonstrates the feasibility of creating specialist, locally\ndeployable LLMs that integrate prediction and interpretability. Through\ncombining structured behavioural prediction with natural language reasoning,\nthis work unlocks the potential for conversational, multi-task transport models\ncapable of supporting agent-based simulations, policy testing, and behavioural\ninsight generation. These findings establish a pathway for transforming general\npurpose LLMs into specialized, explainable tools for transportation research\nand policy formulation, while maintaining privacy, reducing cost, and\nbroadening access through local deployment.",
      "pdf_url": "http://arxiv.org/pdf/2507.21432v1",
      "arxiv_url": "http://arxiv.org/abs/2507.21432v1",
      "published": "2025-07-29",
      "categories": [
        "cs.CL",
        "cs.AI"
      ]
    }
  ]
}