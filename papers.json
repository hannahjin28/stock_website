{
  "last_updated": "2025-03-26T00:49:33.840440",
  "papers": [
    {
      "title": "Causal Links Between Anthropogenic Emissions and Air Pollution Dynamics in Delhi",
      "authors": [
        "Sourish Das",
        "Sudeep Shukla",
        "Alka Yadav",
        "Anirban Chakraborti"
      ],
      "abstract": "Air pollution poses significant health and environmental challenges,\nparticularly in rapidly urbanizing regions. Delhi-National Capital Region\nexperiences air pollution episodes due to complex interactions between\nanthropogenic emissions and meteorological conditions. Understanding the causal\ndrivers of key pollutants such as $PM_{2.5}$ and ground $O_3$ is crucial for\ndeveloping effective mitigation strategies. This study investigates the causal\nlinks of anthropogenic emissions on $PM_{2.5}$ and $O_3$ concentrations using\npredictive modeling and causal inference techniques. Integrating\nhigh-resolution air quality data from Jan 2018 to Aug 2023 across 32 monitoring\nstations, we develop predictive regression models that incorporate\nmeteorological variables (temperature and relative humidity), pollutant\nconcentrations ($NO_2, SO_2, CO$), and seasonal harmonic components to capture\nboth diurnal and annual cycles. Here, we show that reductions in anthropogenic\nemissions lead to significant decreases in $PM_{2.5}$ levels, whereas their\neffect on $O_3$ remains marginal and statistically insignificant. To address\nspatial heterogeneity, we employ Gaussian Process modeling. Further, we use\nGranger causality analysis and counterfactual simulation to establish direct\ncausal links. Validation using real-world data from the COVID-19 lockdown\nconfirms that reduced emissions led to a substantial drop in $PM_{2.5}$ but\nonly a slight, insignificant change in $O_3$. The findings highlight the\nnecessity of targeted emission reduction policies while emphasizing the need\nfor integrated strategies addressing both particulate and ozone pollution.\nThese insights are crucial for policymakers designing air pollution\ninterventions in other megacities, and offer a scalable methodology for\ntackling complex urban air pollution through data-driven decision-making.",
      "pdf_url": "http://arxiv.org/pdf/2503.18912v1",
      "arxiv_url": "http://arxiv.org/abs/2503.18912v1",
      "published": "2025-03-24",
      "categories": [
        "stat.AP",
        "physics.ao-ph",
        "physics.soc-ph",
        "stat.ML"
      ]
    },
    {
      "title": "A Causal Adjustment Module for Debiasing Scene Graph Generation",
      "authors": [
        "Li Liu",
        "Shuzhou Sun",
        "Shuaifeng Zhi",
        "Fan Shi",
        "Zhen Liu",
        "Janne Heikkil√§",
        "Yongxiang Liu"
      ],
      "abstract": "While recent debiasing methods for Scene Graph Generation (SGG) have shown\nimpressive performance, these efforts often attribute model bias solely to the\nlong-tail distribution of relationships, overlooking the more profound causes\nstemming from skewed object and object pair distributions. In this paper, we\nemploy causal inference techniques to model the causality among these observed\nskewed distributions. Our insight lies in the ability of causal inference to\ncapture the unobservable causal effects between complex distributions, which is\ncrucial for tracing the roots of model bias. Specifically, we introduce the\nMediator-based Causal Chain Model (MCCM), which, in addition to modeling\ncausality among objects, object pairs, and relationships, incorporates mediator\nvariables, i.e., cooccurrence distribution, for complementing the causality.\nFollowing this, we propose the Causal Adjustment Module (CAModule) to estimate\nthe modeled causal structure, using variables from MCCM as inputs to produce a\nset of adjustment factors aimed at correcting biased model predictions.\nMoreover, our method enables the composition of zero-shot relationships,\nthereby enhancing the model's ability to recognize such relationships.\nExperiments conducted across various SGG backbones and popular benchmarks\ndemonstrate that CAModule achieves state-of-the-art mean recall rates, with\nsignificant improvements also observed on the challenging zero-shot recall rate\nmetric.",
      "pdf_url": "http://arxiv.org/pdf/2503.17862v1",
      "arxiv_url": "http://arxiv.org/abs/2503.17862v1",
      "published": "2025-03-22",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "A Roadmap Towards Improving Multi-Agent Reinforcement Learning With Causal Discovery And Inference",
      "authors": [
        "Giovanni Briglia",
        "Stefano Mariani",
        "Franco Zambonelli"
      ],
      "abstract": "Causal reasoning is increasingly used in Reinforcement Learning (RL) to\nimprove the learning process in several dimensions: efficacy of learned\npolicies, efficiency of convergence, generalisation capabilities, safety and\ninterpretability of behaviour. However, applications of causal reasoning to\nMulti-Agent RL (MARL) are still mostly unexplored. In this paper, we take the\nfirst step in investigating the opportunities and challenges of applying causal\nreasoning in MARL. We measure the impact of a simple form of causal\naugmentation in state-of-the-art MARL scenarios increasingly requiring\ncooperation, and with state-of-the-art MARL algorithms exploiting various\ndegrees of collaboration between agents. Then, we discuss the positive as well\nas negative results achieved, giving us the chance to outline the areas where\nfurther research may help to successfully transfer causal RL to the multi-agent\nsetting.",
      "pdf_url": "http://arxiv.org/pdf/2503.17803v1",
      "arxiv_url": "http://arxiv.org/abs/2503.17803v1",
      "published": "2025-03-22",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA",
        "stat.ME"
      ]
    },
    {
      "title": "Causal Inference based Transfer Learning with LLMs: An Efficient Framework for Industrial RUL Prediction",
      "authors": [
        "Yan Chen",
        "Cheng Liu"
      ],
      "abstract": "Accurate prediction of Remaining Useful Life (RUL) for complex industrial\nmachinery is critical for the reliability and maintenance of mechatronic\nsystems, but it is challenged by high-dimensional, noisy sensor data. We\npropose the Causal-Informed Data Pruning Framework (CIDPF), which pioneers the\nuse of causal inference to identify sensor signals with robust causal\nrelationships to RUL through PCMCI-based stability analysis, while a Gaussian\nMixture Model (GMM) screens for anomalies. By training on only 10% of the\npruned data, CIDPF fine-tunes pre-trained Large Language Models (LLMs) using\nparameter-efficient strategies, reducing training time by 90% compared to\ntraditional approaches. Experiments on the N-CMAPSS dataset demonstrate that\nCIDPF achieves a 26% lower RMSE than existing methods and a 25% improvement\nover full-data baselines, showcasing superior accuracy and computational\nefficiency in industrial mechatronic systems. The framework's adaptability to\nmulti-condition scenarios further underscores its practicality for industrial\ndeployment.",
      "pdf_url": "http://arxiv.org/pdf/2503.17686v1",
      "arxiv_url": "http://arxiv.org/abs/2503.17686v1",
      "published": "2025-03-22",
      "categories": [
        "eess.SP"
      ]
    },
    {
      "title": "Fairness-Driven LLM-based Causal Discovery with Active Learning and Dynamic Scoring",
      "authors": [
        "Khadija Zanna",
        "Akane Sano"
      ],
      "abstract": "Causal discovery (CD) plays a pivotal role in numerous scientific fields by\nclarifying the causal relationships that underlie phenomena observed in diverse\ndisciplines. Despite significant advancements in CD algorithms that enhance\nbias and fairness analyses in machine learning, their application faces\nchallenges due to the high computational demands and complexities of\nlarge-scale data. This paper introduces a framework that leverages Large\nLanguage Models (LLMs) for CD, utilizing a metadata-based approach akin to the\nreasoning processes of human experts. By shifting from pairwise queries to a\nmore scalable breadth-first search (BFS) strategy, the number of required\nqueries is reduced from quadratic to linear in terms of variable count, thereby\naddressing scalability concerns inherent in previous approaches. This method\nutilizes an Active Learning (AL) and a Dynamic Scoring Mechanism that\nprioritizes queries based on their potential information gain, combining mutual\ninformation, partial correlation, and LLM confidence scores to refine the\ncausal graph more efficiently and accurately. This BFS query strategy reduces\nthe required number of queries significantly, thereby addressing scalability\nconcerns inherent in previous approaches. This study provides a more scalable\nand efficient solution for leveraging LLMs in fairness-driven CD, highlighting\nthe effects of the different parameters on performance. We perform fairness\nanalyses on the inferred causal graphs, identifying direct and indirect effects\nof sensitive attributes on outcomes. A comparison of these analyses against\nthose from graphs produced by baseline methods highlights the importance of\naccurate causal graph construction in understanding bias and ensuring fairness\nin machine learning systems.",
      "pdf_url": "http://arxiv.org/pdf/2503.17569v1",
      "arxiv_url": "http://arxiv.org/abs/2503.17569v1",
      "published": "2025-03-21",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "title": "Calibration Strategies for Robust Causal Estimation: Theoretical and Empirical Insights on Propensity Score Based Estimators",
      "authors": [
        "Jan Rabenseifner",
        "Sven Klaassen",
        "Jannis Kueck",
        "Philipp Bach"
      ],
      "abstract": "The partitioning of data for estimation and calibration critically impacts\nthe performance of propensity score based estimators like inverse probability\nweighting (IPW) and double/debiased machine learning (DML) frameworks. We\nextend recent advances in calibration techniques for propensity score\nestimation, improving the robustness of propensity scores in challenging\nsettings such as limited overlap, small sample sizes, or unbalanced data. Our\ncontributions are twofold: First, we provide a theoretical analysis of the\nproperties of calibrated estimators in the context of DML. To this end, we\nrefine existing calibration frameworks for propensity score models, with a\nparticular emphasis on the role of sample-splitting schemes in ensuring valid\ncausal inference. Second, through extensive simulations, we show that\ncalibration reduces variance of inverse-based propensity score estimators while\nalso mitigating bias in IPW, even in small-sample regimes. Notably, calibration\nimproves stability for flexible learners (e.g., gradient boosting) while\npreserving the doubly robust properties of DML. A key insight is that, even\nwhen methods perform well without calibration, incorporating a calibration step\ndoes not degrade performance, provided that an appropriate sample-splitting\napproach is chosen.",
      "pdf_url": "http://arxiv.org/pdf/2503.17290v1",
      "arxiv_url": "http://arxiv.org/abs/2503.17290v1",
      "published": "2025-03-21",
      "categories": [
        "stat.ML",
        "cs.LG",
        "econ.EM",
        "stat.ME"
      ]
    },
    {
      "title": "Casual Inference via Style Bias Deconfounding for Domain Generalization",
      "authors": [
        "Jiaxi Li",
        "Di Lin",
        "Hao Chen",
        "Hongying Liu",
        "Liang Wan",
        "Wei Feng"
      ],
      "abstract": "Deep neural networks (DNNs) often struggle with out-of-distribution data,\nlimiting their reliability in diverse realworld applications. To address this\nissue, domain generalization methods have been developed to learn\ndomain-invariant features from single or multiple training domains, enabling\ngeneralization to unseen testing domains. However, existing approaches usually\noverlook the impact of style frequency within the training set. This oversight\npredisposes models to capture spurious visual correlations caused by style\nconfounding factors, rather than learning truly causal representations, thereby\nundermining inference reliability. In this work, we introduce Style\nDeconfounding Causal Learning (SDCL), a novel causal inference-based framework\ndesigned to explicitly address style as a confounding factor. Our approaches\nbegins with constructing a structural causal model (SCM) tailored to the domain\ngeneralization problem and applies a backdoor adjustment strategy to account\nfor style influence. Building on this foundation, we design a style-guided\nexpert module (SGEM) to adaptively clusters style distributions during\ntraining, capturing the global confounding style. Additionally, a back-door\ncausal learning module (BDCL) performs causal interventions during feature\nextraction, ensuring fair integration of global confounding styles into sample\npredictions, effectively reducing style bias. The SDCL framework is highly\nversatile and can be seamlessly integrated with state-of-the-art data\naugmentation techniques. Extensive experiments across diverse natural and\nmedical image recognition tasks validate its efficacy, demonstrating superior\nperformance in both multi-domain and the more challenging single-domain\ngeneralization scenarios.",
      "pdf_url": "http://arxiv.org/pdf/2503.16852v1",
      "arxiv_url": "http://arxiv.org/abs/2503.16852v1",
      "published": "2025-03-21",
      "categories": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "title": "Feedback-augmented Non-homogeneous Hidden Markov Models for Longitudinal Causal Inference",
      "authors": [
        "Jouni Helske"
      ],
      "abstract": "Hidden Markov models are widely used for modeling sequential data but\ntypically have limited applicability in observational causal inference due to\ntheir strong conditional independence assumptions. I introduce\nfeedback-augmented non-homogeneous hidden Markov model (FAN-HMM), which\nincorporate time-varying covariates and feedback mechanisms from past\nobservations to latent states and future responses. Integrating these models\nwith the structural causal model framework allows flexible causal inference in\nlongitudinal data with time-varying unobserved heterogeneity and multiple\ncausal pathways. I show how, in a common case of categorical response\nvariables, long-term causal effects can be estimated efficiently without the\nneed for simulating counterfactual trajectories. Using simulation experiments,\nI study the performance of FAN-HMM under the common misspecification of the\nnumber of latent states, and finally apply the proposed approach to estimate\nthe effect of the 2013 parental leave reform on fathers' paternal leave uptake\nin Finnish workplaces.",
      "pdf_url": "http://arxiv.org/pdf/2503.16014v1",
      "arxiv_url": "http://arxiv.org/abs/2503.16014v1",
      "published": "2025-03-20",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "Critical review of patient outcome study in head and neck cancer radiotherapy",
      "authors": [
        "Jingyuan Chen",
        "Yunze Yang",
        "Chenbin Liu",
        "Hongying Feng",
        "Jason M. Holmes",
        "Lian Zhang",
        "Steven J. Frank",
        "Charles B. Simone II",
        "Daniel J. Ma",
        "Samir H. Patel",
        "Wei Liu"
      ],
      "abstract": "Rapid technological advances in radiation therapy have significantly improved\ndose delivery and tumor control for head and neck cancers. However,\ntreatment-related toxicities caused by high-dose exposure to critical\nstructures remain a significant clinical challenge, underscoring the need for\naccurate prediction of clinical outcomes-encompassing both tumor control and\nadverse events (AEs). This review critically evaluates the evolution of\ndata-driven approaches in predicting patient outcomes in head and neck cancer\npatients treated with radiation therapy, from traditional dose-volume\nconstraints to cutting-edge artificial intelligence (AI) and causal inference\nframework. The integration of linear energy transfer in patient outcomes study,\nwhich has uncovered critical mechanisms behind unexpected toxicity, was also\nintroduced for proton therapy. Three transformative methodological advances are\nreviewed: radiomics, AI-based algorithms, and causal inference frameworks.\nWhile radiomics has enabled quantitative characterization of medical images, AI\nmodels have demonstrated superior capability than traditional models. However,\nthe field faces significant challenges in translating statistical correlations\nfrom real-world data into interventional clinical insights. We highlight that\nhow causal inference methods can bridge this gap by providing a rigorous\nframework for identifying treatment effects. Looking ahead, we envision that\ncombining these complementary approaches, especially the interventional\nprediction models, will enable more personalized treatment strategies,\nultimately improving both tumor control and quality of life for head and neck\ncancer patients treated with radiation therapy.",
      "pdf_url": "http://arxiv.org/pdf/2503.15691v1",
      "arxiv_url": "http://arxiv.org/abs/2503.15691v1",
      "published": "2025-03-19",
      "categories": [
        "physics.med-ph"
      ]
    },
    {
      "title": "R$^2$: A LLM Based Novel-to-Screenplay Generation Framework with Causal Plot Graphs",
      "authors": [
        "Zefeng Lin",
        "Yi Xiao",
        "Zhiqiang Mo",
        "Qifan Zhang",
        "Jie Wang",
        "Jiayang Chen",
        "Jiajing Zhang",
        "Hui Zhang",
        "Zhengyi Liu",
        "Xianyong Fang",
        "Xiaohua Xu"
      ],
      "abstract": "Automatically adapting novels into screenplays is important for the TV, film,\nor opera industries to promote products with low costs. The strong performances\nof large language models (LLMs) in long-text generation call us to propose a\nLLM based framework Reader-Rewriter (R$^2$) for this task. However, there are\ntwo fundamental challenges here. First, the LLM hallucinations may cause\ninconsistent plot extraction and screenplay generation. Second, the\ncausality-embedded plot lines should be effectively extracted for coherent\nrewriting. Therefore, two corresponding tactics are proposed: 1) A\nhallucination-aware refinement method (HAR) to iteratively discover and\neliminate the affections of hallucinations; and 2) a causal plot-graph\nconstruction method (CPC) based on a greedy cycle-breaking algorithm to\nefficiently construct plot lines with event causalities. Recruiting those\nefficient techniques, R$^2$ utilizes two modules to mimic the human screenplay\nrewriting process: The Reader module adopts a sliding window and CPC to build\nthe causal plot graphs, while the Rewriter module generates first the scene\noutlines based on the graphs and then the screenplays. HAR is integrated into\nboth modules for accurate inferences of LLMs. Experimental results demonstrate\nthe superiority of R$^2$, which substantially outperforms three existing\napproaches (51.3%, 22.6%, and 57.1% absolute increases) in pairwise comparison\nat the overall win rate for GPT-4o.",
      "pdf_url": "http://arxiv.org/pdf/2503.15655v1",
      "arxiv_url": "http://arxiv.org/abs/2503.15655v1",
      "published": "2025-03-19",
      "categories": [
        "cs.AI"
      ]
    }
  ]
}