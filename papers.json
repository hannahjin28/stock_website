{
  "last_updated": "2025-10-02T00:48:45.097028",
  "papers": [
    {
      "title": "Computationally and statistically efficient estimation of time-smoothed counterfactual curves",
      "authors": [
        "Herbert P. Susmann",
        "Nicholas T. Williams",
        "Richard Liu",
        "Jessica G. Young",
        "Iván Díaz"
      ],
      "abstract": "Longitudinal causal inference is concerned with defining, identifying, and\nestimating the effect of a time-varying intervention on a time-varying outcome\nthat is indexed by a follow-up time. In an observational study, Robins's\ngeneralized g-formula can identify causal effects induced by a broad class of\ntime-varying interventions. Various methods for estimating the generalized\ng-formula have been posed for different outcome types, such as a failure event\nindicator by a specified time (e.g. mortality by 5 year follow-up), as well as\ncontinuous or dichotomous/multi-valued outcomes measures at a specified time\n(e.g. blood pressure in mm/hg or an indicator of high blood pressure at 5-year\nfollow-up). Multiply-robust, data-adaptive estimators leverage flexible\nnonparametric estimation algorithms while allowing for statistical inference.\nHowever, extant methods do not accommodate time-smoothing when multiple\noutcomes are measured over time, which can lead to substantial loss of\nprecision. We propose a novel multiply-robust estimator of the generalized\ng-formula that accommodates time-smoothing over numerous available outcome\nmeasures. Our approach accommodates any intervention that can be described as a\nLongitudinal Modified Treatment Policy, a flexible class suitable for binary,\nmulti-valued, and continuous longitudinal treatments. Our method produces an\nestimate of the effect curve: the causal effect of the intervention on the\noutcome at each measurement time, taking into account censoring and\nnon-monotonic outcome missingness patterns. In simulations we find that the\nproposed algorithm outperforms extant multiply-robust approaches for effect\ncurve estimation in scenarios with high degrees of outcome missingness and when\nthere is strong confounding. We apply the method to study longitudinal effects\nof union membership on wages.",
      "pdf_url": "http://arxiv.org/pdf/2509.26554v1",
      "arxiv_url": "http://arxiv.org/abs/2509.26554v1",
      "published": "2025-09-30",
      "categories": [
        "stat.ME"
      ]
    },
    {
      "title": "An Orthogonal Learner for Individualized Outcomes in Markov Decision Processes",
      "authors": [
        "Emil Javurek",
        "Valentyn Melnychuk",
        "Jonas Schweisthal",
        "Konstantin Hess",
        "Dennis Frauen",
        "Stefan Feuerriegel"
      ],
      "abstract": "Predicting individualized potential outcomes in sequential decision-making is\ncentral for optimizing therapeutic decisions in personalized medicine (e.g.,\nwhich dosing sequence to give to a cancer patient). However, predicting\npotential outcomes over long horizons is notoriously difficult. Existing\nmethods that break the curse of the horizon typically lack strong theoretical\nguarantees such as orthogonality and quasi-oracle efficiency. In this paper, we\nrevisit the problem of predicting individualized potential outcomes in\nsequential decision-making (i.e., estimating Q-functions in Markov decision\nprocesses with observational data) through a causal inference lens. In\nparticular, we develop a comprehensive theoretical foundation for meta-learners\nin this setting with a focus on beneficial theoretical properties. As a result,\nwe yield a novel meta-learner called DRQ-learner and establish that it is: (1)\ndoubly robust (i.e., valid inference under the misspecification of one of the\nnuisances), (2) Neyman-orthogonal (i.e., insensitive to first-order estimation\nerrors in the nuisance functions), and (3) achieves quasi-oracle efficiency\n(i.e., behaves asymptotically as if the ground-truth nuisance functions were\nknown). Our DRQ-learner is applicable to settings with both discrete and\ncontinuous state spaces. Further, our DRQ-learner is flexible and can be used\ntogether with arbitrary machine learning models (e.g., neural networks). We\nvalidate our theoretical results through numerical experiments, thereby showing\nthat our meta-learner outperforms state-of-the-art baselines.",
      "pdf_url": "http://arxiv.org/pdf/2509.26429v1",
      "arxiv_url": "http://arxiv.org/abs/2509.26429v1",
      "published": "2025-09-30",
      "categories": [
        "stat.ML",
        "cs.LG"
      ]
    },
    {
      "title": "MotionRAG: Motion Retrieval-Augmented Image-to-Video Generation",
      "authors": [
        "Chenhui Zhu",
        "Yilu Wu",
        "Shuai Wang",
        "Gangshan Wu",
        "Limin Wang"
      ],
      "abstract": "Image-to-video generation has made remarkable progress with the advancements\nin diffusion models, yet generating videos with realistic motion remains highly\nchallenging. This difficulty arises from the complexity of accurately modeling\nmotion, which involves capturing physical constraints, object interactions, and\ndomain-specific dynamics that are not easily generalized across diverse\nscenarios. To address this, we propose MotionRAG, a retrieval-augmented\nframework that enhances motion realism by adapting motion priors from relevant\nreference videos through Context-Aware Motion Adaptation (CAMA). The key\ntechnical innovations include: (i) a retrieval-based pipeline extracting\nhigh-level motion features using video encoder and specialized resamplers to\ndistill semantic motion representations; (ii) an in-context learning approach\nfor motion adaptation implemented through a causal transformer architecture;\n(iii) an attention-based motion injection adapter that seamlessly integrates\ntransferred motion features into pretrained video diffusion models. Extensive\nexperiments demonstrate that our method achieves significant improvements\nacross multiple domains and various base models, all with negligible\ncomputational overhead during inference. Furthermore, our modular design\nenables zero-shot generalization to new domains by simply updating the\nretrieval database without retraining any components. This research enhances\nthe core capability of video generation systems by enabling the effective\nretrieval and transfer of motion priors, facilitating the synthesis of\nrealistic motion dynamics.",
      "pdf_url": "http://arxiv.org/pdf/2509.26391v1",
      "arxiv_url": "http://arxiv.org/abs/2509.26391v1",
      "published": "2025-09-30",
      "categories": [
        "cs.CV"
      ]
    },
    {
      "title": "MR$^2$-Bench: Going Beyond Matching to Reasoning in Multimodal Retrieval",
      "authors": [
        "Junjie Zhou",
        "Ze Liu",
        "Lei Xiong",
        "Jin-Ge Yao",
        "Yueze Wang",
        "Shitao Xiao",
        "Fenfen Lin",
        "Miguel Hu Chen",
        "Zhicheng Dou",
        "Siqi Bao",
        "Defu Lian",
        "Yongping Xiong",
        "Zheng Liu"
      ],
      "abstract": "Multimodal retrieval is becoming a crucial component of modern AI\napplications, yet its evaluation lags behind the demands of more realistic and\nchallenging scenarios. Existing benchmarks primarily probe surface-level\nsemantic correspondence (e.g., object-text matching) while failing to assess\nthe deeper reasoning required to capture complex relationships between visual\nand textual information. To address this gap, we introduce MR$^2$-Bench, a\nreasoning-intensive benchmark for multimodal retrieval. MR$^2$-Bench presents\nthe following critical values: 1) all tasks are reasoning-driven, going beyond\nshallow matching to effectively assess models' capacity for logical, spatial,\nand causal inference; 2) it features diverse multimodal data, such as natural\nimages, diagrams, and visual puzzles, enabling comprehensive evaluation across\ncontent types; 3) it supports complex queries and documents containing multiple\nimages and covers diverse retrieval scenarios, more accurately reflecting\nreal-world applications. Our benchmark contains 1,309 curated queries, derived\neither from manual collection and annotation or from selective consolidation of\npublic datasets. Despite achieving strong results on existing benchmarks,\ncurrent state-of-the-art models still struggle on MR$^2$-Bench: for example,\nthe leading Seed1.6-Embedding model attains a Recall@1 of 77.78 on MMEB, but\nonly 9.91 on MR$^2$-Bench. This substantial performance gap highlights both the\nincreased challenge posed by our benchmark and the pressing need for further\nadvances in reasoning-intensive multimodal retrieval. The dataset and\nevaluation code will be made publicly available at\nhttps://github.com/VectorSpaceLab/MR2-Bench.",
      "pdf_url": "http://arxiv.org/pdf/2509.26378v1",
      "arxiv_url": "http://arxiv.org/abs/2509.26378v1",
      "published": "2025-09-30",
      "categories": [
        "cs.IR",
        "cs.CV"
      ]
    },
    {
      "title": "Staged Event Trees for Transparent Treatment Effect Estimation",
      "authors": [
        "Gherardo Varando",
        "Manuele Leonelli",
        "Jordi Cerdà-Bautista",
        "Vasileios Sitokonstantinou",
        "Gustau Camps-Valls"
      ],
      "abstract": "Average and conditional treatment effects are fundamental causal quantities\nused to evaluate the effectiveness of treatments in various critical\napplications, including clinical settings and policy-making. Beyond the\ngold-standard estimators from randomized trials, numerous methods have been\nproposed to estimate treatment effects using observational data. In this paper,\nwe provide a novel characterization of widely used causal inference techniques\nwithin the framework of staged event trees, demonstrating their capacity to\nenhance treatment effect estimation. These models offer a distinct advantage\ndue to their interpretability, making them particularly valuable for practical\napplications. We implement classical estimators within the framework of staged\nevent trees and illustrate their capabilities through both simulation studies\nand real-world applications. Furthermore, we showcase how staged event trees\nexplicitly and visually describe when standard causal assumptions, such as\npositivity, hold, further enhancing their practical utility.",
      "pdf_url": "http://arxiv.org/pdf/2509.26265v1",
      "arxiv_url": "http://arxiv.org/abs/2509.26265v1",
      "published": "2025-09-30",
      "categories": [
        "stat.ME",
        "stat.ML"
      ]
    },
    {
      "title": "ExoPredicator: Learning Abstract Models of Dynamic Worlds for Robot Planning",
      "authors": [
        "Yichao Liang",
        "Dat Nguyen",
        "Cambridge Yang",
        "Tianyang Li",
        "Joshua B. Tenenbaum",
        "Carl Edward Rasmussen",
        "Adrian Weller",
        "Zenna Tavares",
        "Tom Silver",
        "Kevin Ellis"
      ],
      "abstract": "Long-horizon embodied planning is challenging because the world does not only\nchange through an agent's actions: exogenous processes (e.g., water heating,\ndominoes cascading) unfold concurrently with the agent's actions. We propose a\nframework for abstract world models that jointly learns (i) symbolic state\nrepresentations and (ii) causal processes for both endogenous actions and\nexogenous mechanisms. Each causal process models the time course of a\nstochastic cause-effect relation. We learn these world models from limited data\nvia variational Bayesian inference combined with LLM proposals. Across five\nsimulated tabletop robotics environments, the learned models enable fast\nplanning that generalizes to held-out tasks with more objects and more complex\ngoals, outperforming a range of baselines.",
      "pdf_url": "http://arxiv.org/pdf/2509.26255v2",
      "arxiv_url": "http://arxiv.org/abs/2509.26255v2",
      "published": "2025-09-30",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "title": "Act to See, See to Act: Diffusion-Driven Perception-Action Interplay for Adaptive Policies",
      "authors": [
        "Jing Wang",
        "Weiting Peng",
        "Jing Tang",
        "Zeyu Gong",
        "Xihua Wang",
        "Bo Tao",
        "Li Cheng"
      ],
      "abstract": "Existing imitation learning methods decouple perception and action, which\noverlooks the causal reciprocity between sensory representations and action\nexecution that humans naturally leverage for adaptive behaviors. To bridge this\ngap, we introduce Action--Guided Diffusion Policy (DP--AG), a unified\nrepresentation learning that explicitly models a dynamic interplay between\nperception and action through probabilistic latent dynamics. DP--AG encodes\nlatent observations into a Gaussian posterior via variational inference and\nevolves them using an action-guided SDE, where the Vector-Jacobian Product\n(VJP) of the diffusion policy's noise predictions serves as a structured\nstochastic force driving latent updates. To promote bidirectional learning\nbetween perception and action, we introduce a cycle--consistent contrastive\nloss that organizes the gradient flow of the noise predictor into a coherent\nperception--action loop, enforcing mutually consistent transitions in both\nlatent updates and action refinements. Theoretically, we derive a variational\nlower bound for the action-guided SDE, and prove that the contrastive objective\nenhances continuity in both latent and action trajectories. Empirically, DP--AG\nsignificantly outperforms state--of--the--art methods across simulation\nbenchmarks and real-world UR5 manipulation tasks. As a result, our DP--AG\noffers a promising step toward bridging biological adaptability and artificial\npolicy learning.",
      "pdf_url": "http://arxiv.org/pdf/2509.25822v1",
      "arxiv_url": "http://arxiv.org/abs/2509.25822v1",
      "published": "2025-09-30",
      "categories": [
        "cs.RO"
      ]
    },
    {
      "title": "Dynamic Causal Attack Graph based Cyber-security Risk Assessment Framework for CTCS System",
      "authors": [
        "Zikai Zhang"
      ],
      "abstract": "Protecting the security of the train control system is a critical issue to\nensure the safe and reliable operation of high-speed trains. Scientific\nmodeling and analysis for the security risk is a promising way to guarantee\nsystem security. However, the representation and assessment of the\nmulti-staged, causally related, and temporal-dynamic changed attack\ndependencies are difficult in the train control system. To solve the above\nchallenges, a security assessment framework based on the Dynamical Causality\nAttack Graph (DCAG) model is introduced in this paper. Firstly, the DCAG model\nis generated based on the attack graph with consideration of temporal attack\npropagation and multi-stage attack event causality propagation. Then, the DCAG\nmodel is analyzed based on Bayesian inference and logic gateway-based\ninference. Through the case analysis of the CTCS-3 system, the security\nassessment framework is validated. With the DCAG-based security assessment\nframework, we can not only perform appropriate security risk quantification\ncalculations, but also explore the importance of different attacks on system\nsecurity risks, which is helpful in adjusting the cyber security defense\npolicy.",
      "pdf_url": "http://arxiv.org/pdf/2509.25786v1",
      "arxiv_url": "http://arxiv.org/abs/2509.25786v1",
      "published": "2025-09-30",
      "categories": [
        "eess.SY",
        "cs.SY"
      ]
    },
    {
      "title": "Coupling Generative Modeling and an Autoencoder with the Causal Bridge",
      "authors": [
        "Ruolin Meng",
        "Ming-Yu Chung",
        "Dhanajit Brahma",
        "Ricardo Henao",
        "Lawrence Carin"
      ],
      "abstract": "We consider inferring the causal effect of a treatment (intervention) on an\noutcome of interest in situations where there is potentially an unobserved\nconfounder influencing both the treatment and the outcome. This is achievable\nby assuming access to two separate sets of control (proxy) measurements\nassociated with treatment and outcomes, which are used to estimate treatment\neffects through a function termed the em causal bridge (CB). We present a new\ntheoretical perspective, associated assumptions for when estimating treatment\neffects with the CB is feasible, and a bound on the average error of the\ntreatment effect when the CB assumptions are violated. From this new\nperspective, we then demonstrate how coupling the CB with an autoencoder\narchitecture allows for the sharing of statistical strength between observed\nquantities (proxies, treatment, and outcomes), thus improving the quality of\nthe CB estimates. Experiments on synthetic and real-world data demonstrate the\neffectiveness of the proposed approach in relation to the state-of-the-art\nmethodology for proxy measurements.",
      "pdf_url": "http://arxiv.org/pdf/2509.25599v1",
      "arxiv_url": "http://arxiv.org/abs/2509.25599v1",
      "published": "2025-09-29",
      "categories": [
        "stat.ML",
        "cs.LG",
        "stat.ME"
      ]
    },
    {
      "title": "Optimal Nuisance Function Tuning for Estimating a Doubly Robust Functional under Proportional Asymptotics",
      "authors": [
        "Sean McGrath",
        "Debarghya Mukherjee",
        "Rajarshi Mukherjee",
        "Zixiao Jolene Wang"
      ],
      "abstract": "In this paper, we explore the asymptotically optimal tuning parameter choice\nin ridge regression for estimating nuisance functions of a statistical\nfunctional that has recently gained prominence in conditional independence\ntesting and causal inference. Given a sample of size $n$, we study estimators\nof the Expected Conditional Covariance (ECC) between variables $Y$ and $A$\ngiven a high-dimensional covariate $X \\in \\mathbb{R}^p$. Under linear\nregression models for $Y$ and $A$ on $X$ and the proportional asymptotic regime\n$p/n \\to c \\in (0, \\infty)$, we evaluate three existing ECC estimators and two\nsample splitting strategies for estimating the required nuisance functions.\nSince no consistent estimator of the nuisance functions exists in the\nproportional asymptotic regime without imposing further structure on the\nproblem, we first derive debiased versions of the ECC estimators that utilize\nthe ridge regression nuisance function estimators. We show that our bias\ncorrection strategy yields $\\sqrt{n}$-consistent estimators of the ECC across\ndifferent sample splitting strategies and estimator choices. We then derive the\nasymptotic variances of these debiased estimators to illustrate the nuanced\ninterplay between the sample splitting strategy, estimator choice, and tuning\nparameters of the nuisance function estimators for optimally estimating the\nECC. Our analysis reveals that prediction-optimal tuning parameters (i.e.,\nthose that optimally estimate the nuisance functions) may not lead to the\nlowest asymptotic variance of the ECC estimator -- thereby demonstrating the\nneed to be careful in selecting tuning parameters based on the final goal of\ninference. Finally, we verify our theoretical results through extensive\nnumerical experiments.",
      "pdf_url": "http://arxiv.org/pdf/2509.25536v1",
      "arxiv_url": "http://arxiv.org/abs/2509.25536v1",
      "published": "2025-09-29",
      "categories": [
        "math.ST",
        "stat.ME",
        "stat.ML",
        "stat.TH"
      ]
    }
  ]
}