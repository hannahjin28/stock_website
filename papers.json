{
  "last_updated": "2025-03-04T00:47:54.957722",
  "papers": [
    {
      "title": "Persuasion Should be Double-Blind: A Multi-Domain Dialogue Dataset With Faithfulness Based on Causal Theory of Mind",
      "authors": [
        "Dingyi Zhang",
        "Deyu Zhou"
      ],
      "abstract": "Persuasive dialogue plays a pivotal role in human communication, influencing\nvarious domains. Recent persuasive dialogue datasets often fail to align with\nreal-world interpersonal interactions, leading to unfaithful representations.\nFor instance, unrealistic scenarios may arise, such as when the persuadee\nexplicitly instructs the persuader on which persuasion strategies to employ,\nwith each of the persuadee's questions corresponding to a specific strategy for\nthe persuader to follow. This issue can be attributed to a violation of the\n\"Double Blind\" condition, where critical information is fully shared between\nparticipants. In actual human interactions, however, key information such as\nthe mental state of the persuadee and the persuasion strategies of the\npersuader is not directly accessible. The persuader must infer the persuadee's\nmental state using Theory of Mind capabilities and construct arguments that\nalign with the persuadee's motivations. To address this gap, we introduce\nToMMA, a novel multi-agent framework for dialogue generation that is guided by\ncausal Theory of Mind. This framework ensures that information remains\nundisclosed between agents, preserving \"double-blind\" conditions, while causal\nToM directs the persuader's reasoning, enhancing alignment with human-like\npersuasion dynamics. Consequently, we present CToMPersu, a multi-domain,\nmulti-turn persuasive dialogue dataset that tackles both double-blind and\nlogical coherence issues, demonstrating superior performance across multiple\nmetrics and achieving better alignment with real human dialogues. Our dataset\nand prompts are available at https://github.com/DingyiZhang/ToMMA-CToMPersu .",
      "pdf_url": "http://arxiv.org/pdf/2502.21297v1",
      "arxiv_url": "http://arxiv.org/abs/2502.21297v1",
      "published": "2025-02-28",
      "categories": [
        "cs.CL"
      ]
    },
    {
      "title": "Amortized Conditional Independence Testing",
      "authors": [
        "Bao Duong",
        "Nu Hoang",
        "Thin Nguyen"
      ],
      "abstract": "Testing for the conditional independence structure in data is a fundamental\nand critical task in statistics and machine learning, which finds natural\napplications in causal discovery - a highly relevant problem to many scientific\ndisciplines. Existing methods seek to design explicit test statistics that\nquantify the degree of conditional dependence, which is highly challenging yet\ncannot capture nor utilize prior knowledge in a data-driven manner. In this\nstudy, an entirely new approach is introduced, where we instead propose to\namortize conditional independence testing and devise ACID - a novel\ntransformer-based neural network architecture that learns to test for\nconditional independence. ACID can be trained on synthetic data in a supervised\nlearning fashion, and the learned model can then be applied to any dataset of\nsimilar natures or adapted to new domains by fine-tuning with a negligible\ncomputational cost. Our extensive empirical evaluations on both synthetic and\nreal data reveal that ACID consistently achieves state-of-the-art performance\nagainst existing baselines under multiple metrics, and is able to generalize\nrobustly to unseen sample sizes, dimensionalities, as well as non-linearities\nwith a remarkably low inference time.",
      "pdf_url": "http://arxiv.org/pdf/2502.20925v1",
      "arxiv_url": "http://arxiv.org/abs/2502.20925v1",
      "published": "2025-02-28",
      "categories": [
        "stat.ML",
        "cs.LG"
      ]
    },
    {
      "title": "Everything, Everywhere, All at Once: Is Mechanistic Interpretability Identifiable?",
      "authors": [
        "Maxime Méloux",
        "Silviu Maniu",
        "François Portet",
        "Maxime Peyrard"
      ],
      "abstract": "As AI systems are used in high-stakes applications, ensuring interpretability\nis crucial. Mechanistic Interpretability (MI) aims to reverse-engineer neural\nnetworks by extracting human-understandable algorithms to explain their\nbehavior. This work examines a key question: for a given behavior, and under\nMI's criteria, does a unique explanation exist? Drawing on identifiability in\nstatistics, where parameters are uniquely inferred under specific assumptions,\nwe explore the identifiability of MI explanations.\n  We identify two main MI strategies: (1) \"where-then-what,\" which isolates a\ncircuit replicating model behavior before interpreting it, and (2)\n\"what-then-where,\" which starts with candidate algorithms and searches for\nneural activation subspaces implementing them, using causal alignment.\n  We test both strategies on Boolean functions and small multi-layer\nperceptrons, fully enumerating candidate explanations. Our experiments reveal\nsystematic non-identifiability: multiple circuits can replicate behavior, a\ncircuit can have multiple interpretations, several algorithms can align with\nthe network, and one algorithm can align with different subspaces.\n  Is uniqueness necessary? A pragmatic approach may require only predictive and\nmanipulability standards. If uniqueness is essential for understanding,\nstricter criteria may be needed. We also reference the inner interpretability\nframework, which validates explanations through multiple criteria. This work\ncontributes to defining explanation standards in AI.",
      "pdf_url": "http://arxiv.org/pdf/2502.20914v1",
      "arxiv_url": "http://arxiv.org/abs/2502.20914v1",
      "published": "2025-02-28",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Transfer Learning in Latent Contextual Bandits with Covariate Shift Through Causal Transportability",
      "authors": [
        "Mingwei Deng",
        "Ville Kyrki",
        "Dominik Baumann"
      ],
      "abstract": "Transferring knowledge from one environment to another is an essential\nability of intelligent systems. Nevertheless, when two environments are\ndifferent, naively transferring all knowledge may deteriorate the performance,\na phenomenon known as negative transfer. In this paper, we address this issue\nwithin the framework of multi-armed bandits from the perspective of causal\ninference. Specifically, we consider transfer learning in latent contextual\nbandits, where the actual context is hidden, but a potentially high-dimensional\nproxy is observable. We further consider a covariate shift in the context\nacross environments. We show that naively transferring all knowledge for\nclassical bandit algorithms in this setting led to negative transfer. We then\nleverage transportability theory from causal inference to develop algorithms\nthat explicitly transfer effective knowledge for estimating the causal effects\nof interest in the target environment. Besides, we utilize variational\nautoencoders to approximate causal effects under the presence of a\nhigh-dimensional proxy. We test our algorithms on synthetic and semi-synthetic\ndatasets, empirically demonstrating consistently improved learning efficiency\nacross different proxies compared to baseline algorithms, showing the\neffectiveness of our causal framework in transferring knowledge.",
      "pdf_url": "http://arxiv.org/pdf/2502.20153v1",
      "arxiv_url": "http://arxiv.org/abs/2502.20153v1",
      "published": "2025-02-27",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "Economic Causal Inference Based on DML Framework: Python Implementation of Binary and Continuous Treatment Variables",
      "authors": [
        "Shunxin Yao"
      ],
      "abstract": "This study utilizes a simulated dataset to establish Python code for Double\nMachine Learning (DML) using Anaconda's Jupyter Notebook and the DML software\npackage from GitHub. The research focuses on causal inference experiments for\nboth binary and continuous treatment variables. The findings reveal that the\nDML model demonstrates relatively stable performance in calculating the Average\nTreatment Effect (ATE) and its robustness metrics. However, the study also\nhighlights that the computation of Conditional Average Treatment Effect (CATE)\nremains a significant challenge for future DML modeling, particularly in the\ncontext of continuous treatment variables. This underscores the need for\nfurther research and development in this area to enhance the model's\napplicability and accuracy.",
      "pdf_url": "http://arxiv.org/pdf/2502.19898v1",
      "arxiv_url": "http://arxiv.org/abs/2502.19898v1",
      "published": "2025-02-27",
      "categories": [
        "econ.EM",
        "62P20, 91B84",
        "C.1.3; G.3; I.2.6; J.4"
      ]
    },
    {
      "title": "Semiparametric Triple Difference Estimators",
      "authors": [
        "Sina Akbari",
        "Negar Kiyavash",
        "AmirEmad Ghassami"
      ],
      "abstract": "The triple difference causal inference framework is an extension of the\nwell-known difference-in-differences framework. It relaxes the parallel trends\nassumption of the difference-in-differences framework through leveraging data\nfrom an auxiliary domain. Despite being commonly applied in empirical research,\nthe triple difference framework has received relatively limited attention in\nthe statistics literature. Specifically, investigating the intricacies of\nidentification and the design of robust and efficient estimators for this\nframework has remained largely unexplored. This work aims to address these gaps\nin the literature. From the identification standpoint, we present outcome\nregression and weighting methods to identify the average treatment effect on\nthe treated in both panel data and repeated cross-section settings. For the\nlatter, we relax the commonly made assumption of time-invariant covariates.\nFrom the estimation perspective, we consider semiparametric estimators for the\ntriple difference framework in both panel data and repeated cross-sections\nsettings. We demonstrate that our proposed estimators are doubly robust.",
      "pdf_url": "http://arxiv.org/pdf/2502.19788v1",
      "arxiv_url": "http://arxiv.org/abs/2502.19788v1",
      "published": "2025-02-27",
      "categories": [
        "econ.EM",
        "stat.ME"
      ]
    },
    {
      "title": "Causal Effect Estimation under Networked Interference without Networked Unconfoundedness Assumption",
      "authors": [
        "Weilin Chen",
        "Ruichu Cai",
        "Jie Qiao",
        "Yuguang Yan",
        "José Miguel Hernández-Lobato"
      ],
      "abstract": "Estimating causal effects under networked interference is a crucial yet\nchallenging problem. Existing methods based on observational data mainly rely\non the networked unconfoundedness assumption, which guarantees the\nidentification of networked effects. However, the networked unconfoundedness\nassumption is usually violated due to the latent confounders in observational\ndata, hindering the identification of networked effects. Interestingly, in such\nnetworked settings, interactions between units provide valuable information for\nrecovering latent confounders. In this paper, we identify three types of latent\nconfounders in networked inference that hinder identification: those affecting\nonly the individual, those affecting only neighbors, and those influencing\nboth. Specifically, we devise a networked effect estimator based on\nidentifiable representation learning techniques. Theoretically, we establish\nthe identifiability of all latent confounders, and leveraging the identified\nlatent confounders, we provide the networked effect identification result.\nExtensive experiments validate our theoretical results and demonstrate the\neffectiveness of the proposed method.",
      "pdf_url": "http://arxiv.org/pdf/2502.19741v1",
      "arxiv_url": "http://arxiv.org/abs/2502.19741v1",
      "published": "2025-02-27",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "Training Robust Graph Neural Networks by Modeling Noise Dependencies",
      "authors": [
        "Yeonjun In",
        "Kanghoon Yoon",
        "Sukwon Yun",
        "Kibum Kim",
        "Sungchul Kim",
        "Chanyoung Park"
      ],
      "abstract": "In real-world applications, node features in graphs often contain noise from\nvarious sources, leading to significant performance degradation in GNNs.\nAlthough several methods have been developed to enhance robustness, they rely\non the unrealistic assumption that noise in node features is independent of the\ngraph structure and node labels, thereby limiting their applicability. To this\nend, we introduce a more realistic noise scenario, dependency-aware noise on\ngraphs (DANG), where noise in node features create a chain of noise\ndependencies that propagates to the graph structure and node labels. We propose\na novel robust GNN, DA-GNN, which captures the causal relationships among\nvariables in the data generating process (DGP) of DANG using variational\ninference. In addition, we present new benchmark datasets that simulate DANG in\nreal-world applications, enabling more practical research on robust GNNs.\nExtensive experiments demonstrate that DA-GNN consistently outperforms existing\nbaselines across various noise scenarios, including both DANG and conventional\nnoise models commonly considered in this field.",
      "pdf_url": "http://arxiv.org/pdf/2502.19670v1",
      "arxiv_url": "http://arxiv.org/abs/2502.19670v1",
      "published": "2025-02-27",
      "categories": [
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "title": "Treatment Non-Adherence Bias in Clinical Machine Learning: A Real-World Study on Hypertension Medication",
      "authors": [
        "Zhongyuan Liang",
        "Arvind Suresh",
        "Irene Y. Chen"
      ],
      "abstract": "Machine learning systems trained on electronic health records (EHRs)\nincreasingly guide treatment decisions, but their reliability depends on the\ncritical assumption that patients follow the prescribed treatments recorded in\nEHRs. Using EHR data from 3,623 hypertension patients, we investigate how\ntreatment non-adherence introduces implicit bias that can fundamentally distort\nboth causal inference and predictive modeling. By extracting patient adherence\ninformation from clinical notes using a large language model, we identify 786\npatients (21.7%) with medication non-adherence. We further uncover key\ndemographic and clinical factors associated with non-adherence, as well as\npatient-reported reasons including side effects and difficulties obtaining\nrefills. Our findings demonstrate that this implicit bias can not only reverse\nestimated treatment effects, but also degrade model performance by up to 5%\nwhile disproportionately affecting vulnerable populations by exacerbating\ndisparities in decision outcomes and model error rates. This highlights the\nimportance of accounting for treatment non-adherence in developing responsible\nand equitable clinical machine learning systems.",
      "pdf_url": "http://arxiv.org/pdf/2502.19625v1",
      "arxiv_url": "http://arxiv.org/abs/2502.19625v1",
      "published": "2025-02-26",
      "categories": [
        "cs.LG"
      ]
    },
    {
      "title": "Towards a robust approach to infer causality in molecular systems satisfying detailed balance",
      "authors": [
        "Vittorio Del Tatto",
        "Debarshi Banerjee",
        "Ali Hassanali",
        "Alessandro Laio"
      ],
      "abstract": "The ability to distinguish between correlation and causation of variables in\nmolecular systems remains an interesting and open area of investigation. In\nthis work, we probe causality in a molecular system using two independent\ncomputational methods that infer the causal direction through the language of\ninformation transfer. Specifically, we demonstrate that a molecular dynamics\nsimulation involving a single Tryptophan in liquid water displays asymmetric\ninformation transfer between specific collective variables, such as solute and\nsolvent coordinates. Analyzing a discrete Markov-state and Langevin dynamics on\na 2D free energy surface, we show that the same kind of asymmetries can emerge\neven in extremely simple systems, undergoing equilibrium and time-reversible\ndynamics. We use these model systems to rationalize the unidirectional\ninformation transfer in the molecular system in terms of asymmetries in the\nunderlying free energy landscape and/or relaxation dynamics of the relevant\ncoordinates. Finally, we propose a computational experiment that allows one to\ndecide if an asymmetric information transfer between two variables corresponds\nto a genuine causal link.",
      "pdf_url": "http://arxiv.org/pdf/2502.19384v1",
      "arxiv_url": "http://arxiv.org/abs/2502.19384v1",
      "published": "2025-02-26",
      "categories": [
        "physics.chem-ph",
        "cond-mat.stat-mech",
        "physics.bio-ph"
      ]
    }
  ]
}